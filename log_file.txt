
==========================================================================================
Sun Nov 12 03:27:28 2017
Leg5_max_20epoch_20aug_10ela_3inten_reflect
optim.SGD(net.parameters(), lr=1e-2, momentum=0.99, weight_decay=1e-4)
Number of epoch max: 10
Epoch 1: Train loss: 0.182850, Val loss: 0.205819
Epoch 2: Train loss: 0.123207, Val loss: 0.239206
Epoch 3: Train loss: 0.099463, Val loss: 0.235972
Epoch 4: Train loss: 0.089766, Val loss: 0.253289
Epoch 5: Train loss: 0.083057, Val loss: 0.246170
Epoch 6: Train loss: 0.081598, Val loss: 0.241467
Epoch 7: Train loss: 0.077782, Val loss: 0.297287
Epoch 8: Train loss: 0.076883, Val loss: 0.274143
Epoch 9: Train loss: 0.074491, Val loss: 0.255067
Epoch 10: Train loss: 0.074480, Val loss: 0.276261
Best model at epoch: 1
Total training time: 4.95727509419
Unet2_model_Leg5_max_20epoch_20aug_10ela_3inten_reflect_min_loss
Precision: 0.96764 
Recall: 0.95391 
F1_measure: 0.96073 
iou: 0.90470
Unet2_model_2epoch_Leg5_max_20epoch_20aug_10ela_3inten_reflect
Precision: 0.97011 
Recall: 0.94431 
F1_measure: 0.95703 
iou: 0.90222
Unet2_model_4epoch_Leg5_max_20epoch_20aug_10ela_3inten_reflect
Precision: 0.96838 
Recall: 0.94760 
F1_measure: 0.95787 
iou: 0.90156
Unet2_model_6epoch_Leg5_max_20epoch_20aug_10ela_3inten_reflect
Precision: 0.96742 
Recall: 0.94931 
F1_measure: 0.95828 
iou: 0.90113
Unet2_model_8epoch_Leg5_max_20epoch_20aug_10ela_3inten_reflect
Precision: 0.96586 
Recall: 0.94805 
F1_measure: 0.95687 
iou: 0.89723
Unet2_model_10epoch_Leg5_max_20epoch_20aug_10ela_3inten_reflect
Precision: 0.96835 
Recall: 0.94050 
F1_measure: 0.95422 
iou: 0.89635
Sun Nov 12 09:19:51 2017
==========================================================================================

==========================================================================================
Thu Nov 16 10:12:27 2017
Leg6_max_6epoch_20aug_10ela_3inten_reflect —> best model so far
optim.SGD(net.parameters(), lr=1e-2, momentum=0.99)
Number of epoch max: 6
Epoch 1: Train loss: 0.234447, Val loss: 0.222773
Epoch 2: Train loss: 0.160805, Val loss: 0.235453
Unet2_model_2epoch_Leg6_max_6epoch_20aug_10ela_3inten_reflect
Precision: 0.96780 
Recall: 0.94387 
F1_measure: 0.95569 
iou: 0.89794
Epoch 3: Train loss: 0.135008, Val loss: 0.278031
Epoch 4: Train loss: 0.112155, Val loss: 0.339875
Unet2_model_4epoch_Leg6_max_6epoch_20aug_10ela_3inten_reflect
Precision: 0.96893 
Recall: 0.93810 
F1_measure: 0.95327 
iou: 0.89587
Epoch 5: Train loss: 0.096257, Val loss: 0.367362
Epoch 6: Train loss: 0.085662, Val loss: 0.382800
Unet2_model_6epoch_Leg6_max_6epoch_20aug_10ela_3inten_reflect
Precision: 0.97062 
Recall: 0.92641 
F1_measure: 0.94800 
iou: 0.89016
Best model at epoch: 2
Total training time: 2.58076416559

==========================================================================================
Thu Nov 16 13:20:12 2017
Leg7_add_dropout_20aug_10ela_3inten_reflect
optim.SGD(net.parameters(), lr=1e-2, momentum=0.99)
Number of epoch max: 6
Epoch 1: Train loss: 0.254697, Val loss: 0.227665
Epoch 2: Train loss: 0.168720, Val loss: 0.244532
Unet2_model_2epoch_Leg7_add_dropout_20aug_10ela_3inten_reflect
Precision: 0.97117 
Recall: 0.92649 
F1_measure: 0.94830 
iou: 0.89103
Epoch 3: Train loss: 0.146217, Val loss: 0.277395
Epoch 4: Train loss: 0.125674, Val loss: 0.302659
Unet2_model_4epoch_Leg7_add_dropout_20aug_10ela_3inten_reflect
Precision: 0.97189 
Recall: 0.91057 
F1_measure: 0.94023 
iou: 0.88011
Epoch 5: Train loss: 0.108071, Val loss: 0.339253
Epoch 6: Train loss: 0.095928, Val loss: 0.388086
Unet2_model_6epoch_Leg7_add_dropout_20aug_10ela_3inten_reflect
Precision: 0.97081 
Recall: 0.92720 
F1_measure: 0.94851 
iou: 0.89114
Best model at epoch: 2
Total training time: 2.53306306309
Unet2_model_Leg7_add_dropout_20aug_10ela_3inten_reflect_min_val_loss
Precision: 0.97117 
Recall: 0.92649 
F1_measure: 0.94830 
iou: 0.89103
Thu Nov 16 15:58:37 2017

==========================================================================================
Thu Nov 16 22:09:32 2017
Leg8_hist_equal_20aug_10ela_3inten_reflect
optim.SGD(net.parameters(), lr=1e-2, momentum=0.99)
Number of epoch max: 6
Epoch 1: Train loss: 0.204963, Val loss: 0.197687
Epoch 2: Train loss: 0.155134, Val loss: 0.217207
Unet2_model_2epoch_Leg8_hist_equal_20aug_10ela_3inten_reflect
Precision: 0.96673 
Recall: 0.95506 
F1_measure: 0.96086 
iou: 0.90373
Epoch 3: Train loss: 0.129746, Val loss: 0.235593
Epoch 4: Train loss: 0.106507, Val loss: 0.257720
Unet2_model_4epoch_Leg8_hist_equal_20aug_10ela_3inten_reflect
Precision: 0.96803 
Recall: 0.95173 
F1_measure: 0.95981 
iou: 0.90390
Epoch 5: Train loss: 0.091015, Val loss: 0.325022
Epoch 6: Train loss: 0.080875, Val loss: 0.309368
Unet2_model_6epoch_Leg8_hist_equal_20aug_10ela_3inten_reflect
Precision: 0.96725 
Recall: 0.95205 
F1_measure: 0.95959 
iou: 0.90266
Best model at epoch: 2
Total training time: 2.49690055807
Unet2_model_Leg8_hist_equal_20aug_10ela_3inten_reflect_min_val_loss
Precision: 0.96673 
Recall: 0.95506 
F1_measure: 0.96086 
iou: 0.90373
Fri Nov 17 00:45:49 2017
==========================================================================================

==========================================================================================
Fri Nov 17 03:56:21 2017
Leg9_hist_removeSigmoid_20aug_10ela_3inten_reflect
optim.SGD(net.parameters(), lr=1e-2, momentum=0.99)
Number of epoch max: 6
Epoch 1: Train loss: 0.202652, Val loss: 0.214923
Epoch 2: Train loss: 0.153123, Val loss: 0.243432
Unet2_model_2epoch_Leg9_hist_removeSigmoid_20aug_10ela_3inten_reflect
Precision: 0.96676 
Recall: 0.95723 
F1_measure: 0.96197 
iou: 0.90551
Epoch 3: Train loss: 0.126660, Val loss: 0.241306
Epoch 4: Train loss: 0.104540, Val loss: 0.257358
Unet2_model_4epoch_Leg9_hist_removeSigmoid_20aug_10ela_3inten_reflect
Precision: 0.96840 
Recall: 0.94924 
F1_measure: 0.95872 
iou: 0.90282
Epoch 5: Train loss: 0.090110, Val loss: 0.278125
Epoch 6: Train loss: 0.080475, Val loss: 0.314867
Unet2_model_6epoch_Leg9_hist_removeSigmoid_20aug_10ela_3inten_reflect
Precision: 0.96795 
Recall: 0.95053 
F1_measure: 0.95916 
iou: 0.90300
Best model at epoch: 3
Total training time: 2.51218006611
Unet2_model_Leg9_hist_removeSigmoid_20aug_10ela_3inten_reflect_min_val_loss
Precision: 0.96875 
Recall: 0.94779 
F1_measure: 0.95816 
iou: 0.90242
Fri Nov 17 06:33:43 2017
==========================================================================================
Fri Nov 17 08:31:21 2017
Leg11_hist_2dropout_rmSigmoid_20aug_10ela_3inten_reflect
optim.SGD(net.parameters(), lr=1e-2, momentum=0.99)
Number of epoch max: 6
Epoch 1: Train loss: 0.204687, Val loss: 0.197225
Epoch 2: Train loss: 0.155621, Val loss: 0.227819
Unet2_model_2epoch_Leg11_hist_2dropout_rmSigmoid_20aug_10ela_3inten_reflect
Precision: 0.96861 
Recall: 0.94960 
F1_measure: 0.95901 
iou: 0.90321
Epoch 3: Train loss: 0.131744, Val loss: 0.255790
Epoch 4: Train loss: 0.110189, Val loss: 0.243029
Unet2_model_4epoch_Leg11_hist_2dropout_rmSigmoid_20aug_10ela_3inten_reflect
Precision: 0.96815 
Recall: 0.94760 
F1_measure: 0.95776 
iou: 0.90119
Epoch 5: Train loss: 0.095146, Val loss: 0.295047
Epoch 6: Train loss: 0.085739, Val loss: 0.307342
Unet2_model_6epoch_Leg11_hist_2dropout_rmSigmoid_20aug_10ela_3inten_reflect
Precision: 0.96728 
Recall: 0.95004 
F1_measure: 0.95858 
iou: 0.90124
Best model at epoch: 2
Total training time: 2.51744142605
Unet2_model_Leg11_hist_2dropout_rmSigmoid_20aug_10ela_3inten_reflect_min_val_loss
Precision: 0.96861 
Recall: 0.94960 
F1_measure: 0.95901 
iou: 0.90321
Fri Nov 17 11:07:37 2017
==========================================================================================
Fri Nov 17 11:08:20 2017

—> wrong setup

Leg12_hist_2dropout_0_2_rmSigmoid_20aug_10ela_3inten_reflect
optim.SGD(net.parameters(), lr=1e-2, momentum=0.99)
Number of epoch max: 6
Epoch 1: Train loss: 0.201987, Val loss: 0.208616
Epoch 2: Train loss: 0.156695, Val loss: 0.215440
Unet2_model_2epoch_Leg12_hist_2dropout_0_2_rmSigmoid_20aug_10ela_3inten_reflect
Precision: 0.96985 
Recall: 0.94768 
F1_measure: 0.95863 
iou: 0.90419
Epoch 3: Train loss: 0.133633, Val loss: 0.251022
Epoch 4: Train loss: 0.111785, Val loss: 0.251288
Unet2_model_4epoch_Leg12_hist_2dropout_0_2_rmSigmoid_20aug_10ela_3inten_reflect
Precision: 0.96842 
Recall: 0.94747 
F1_measure: 0.95783 
iou: 0.90160
Epoch 5: Train loss: 0.096616, Val loss: 0.267744
Epoch 6: Train loss: 0.086624, Val loss: 0.309991
Unet2_model_6epoch_Leg12_hist_2dropout_0_2_rmSigmoid_20aug_10ela_3inten_reflect
Precision: 0.96836 
Recall: 0.94725 
F1_measure: 0.95769 
iou: 0.90130
Best model at epoch: 2
Total training time: 2.51349877417
Unet2_model_Leg12_hist_2dropout_0_2_rmSigmoid_20aug_10ela_3inten_reflect_min_val_loss
Precision: 0.96985 
Recall: 0.94768 
F1_measure: 0.95863 
iou: 0.90419
Fri Nov 17 13:45:01 2017
==========================================================================================
Fri Nov 17 13:49:57 2017
Leg13_hist_rmSigmoid_20aug_10ela_3inten_reflect
optim.SGD(net.parameters(), lr=1e-2, momentum=0.99)
Number of epoch max: 20
Epoch 1: Train loss: 0.201817, Val loss: 0.198530
Epoch 2: Train loss: 0.153067, Val loss: 0.246596
Unet2_model_2epoch_Leg13_hist_rmSigmoid_20aug_10ela_3inten_reflect
Precision: 0.96979 
Recall: 0.94617 
F1_measure: 0.95783 
iou: 0.90301
Epoch 3: Train loss: 0.126363, Val loss: 0.245076
Epoch 4: Train loss: 0.103510, Val loss: 0.274070
Unet2_model_4epoch_Leg13_hist_rmSigmoid_20aug_10ela_3inten_reflect
Precision: 0.96721 
Recall: 0.95367 
F1_measure: 0.96039 
iou: 0.90387
Epoch 5: Train loss: 0.089181, Val loss: 0.272553
Epoch 6: Train loss: 0.079476, Val loss: 0.313082
Unet2_model_6epoch_Leg13_hist_rmSigmoid_20aug_10ela_3inten_reflect
Precision: 0.96894 
Recall: 0.94872 
F1_measure: 0.95873 
iou: 0.90341
Epoch 7: Train loss: 0.072543, Val loss: 0.318549
Epoch 8: Train loss: 0.067163, Val loss: 0.354286
Unet2_model_8epoch_Leg13_hist_rmSigmoid_20aug_10ela_3inten_reflect
Precision: 0.96636 
Recall: 0.95467 
F1_measure: 0.96048 
iou: 0.90305
Epoch 9: Train loss: 0.062579, Val loss: 0.358414
Epoch 10: Train loss: 0.059130, Val loss: 0.352299
Unet2_model_10epoch_Leg13_hist_rmSigmoid_20aug_10ela_3inten_reflect
Precision: 0.96913 
Recall: 0.94526 
F1_measure: 0.95705 
iou: 0.90133
Epoch 11: Train loss: 0.056051, Val loss: 0.378128
Epoch 12: Train loss: 0.053524, Val loss: 0.408848
Unet2_model_12epoch_Leg13_hist_rmSigmoid_20aug_10ela_3inten_reflect
Precision: 0.96768 
Recall: 0.95011 
F1_measure: 0.95882 
iou: 0.90219
Epoch 13: Train loss: 0.051304, Val loss: 0.400888
Epoch 14: Train loss: 0.049292, Val loss: 0.438926
Unet2_model_14epoch_Leg13_hist_rmSigmoid_20aug_10ela_3inten_reflect
Precision: 0.96689 
Recall: 0.95196 
F1_measure: 0.95937 
iou: 0.90209
Epoch 15: Train loss: 0.047762, Val loss: 0.425603
Epoch 16: Train loss: 0.046099, Val loss: 0.433100
Unet2_model_16epoch_Leg13_hist_rmSigmoid_20aug_10ela_3inten_reflect
Precision: 0.96711 
Recall: 0.95082 
F1_measure: 0.95890 
iou: 0.90170
Epoch 17: Train loss: 0.044654, Val loss: 0.466312
Epoch 18: Train loss: 0.043419, Val loss: 0.464526
Unet2_model_18epoch_Leg13_hist_rmSigmoid_20aug_10ela_3inten_reflect
Precision: 0.96734 
Recall: 0.94969 
F1_measure: 0.95844 
iou: 0.90134
Epoch 19: Train loss: 0.042505, Val loss: 0.469079
Epoch 20: Train loss: 0.041337, Val loss: 0.485115
Unet2_model_20epoch_Leg13_hist_rmSigmoid_20aug_10ela_3inten_reflect
Precision: 0.96742 
Recall: 0.94917 
F1_measure: 0.95821 
iou: 0.90111
Best model at epoch: 3
Total training time: 8.3220644131
Unet2_model_Leg13_hist_rmSigmoid_20aug_10ela_3inten_reflect_min_val_loss
Precision: 0.96776 
Recall: 0.95292 
F1_measure: 0.96029 
iou: 0.90428
Fri Nov 17 22:15:01 2017

==========================================================================================



==========================================================================================
Sat Nov 18 04:03:46 2017
Leg12_droput_0_2_rmSigmoid_20aug_10ela_3inten_reflect
Sat Nov 18 04:03:44 2017

dropbox version: 3:03pm, 11/17/17

import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.autograd import Variable
import math


class ConvBnRelu(nn.Module):
    def __init__(self, in_channels, out_channels, kernel_size, padding, stride):
        super(ConvBnRelu, self).__init__()
        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=kernel_size, padding=padding, stride=stride)
        self.bn = nn.BatchNorm2d(out_channels)
        self.relu = nn.ReLU()

    def forward(self, x):
        x = self.conv(x)
        # x = self.bn(x)
        x = self.relu(x)
        return x


class StackEncoder(nn.Module):
    def __init__(self, in_channels, out_channels):
        super(StackEncoder, self).__init__()
        self.convr1 = ConvBnRelu(in_channels, out_channels, kernel_size=(3, 3), stride=1, padding=0)
        self.convr2 = ConvBnRelu(out_channels, out_channels, kernel_size=(3, 3), stride=1, padding=0)
        self.maxPool = nn.MaxPool2d(kernel_size=(2, 2), stride=2)

    def forward(self, x):
        x = self.convr1(x)
        x = self.convr2(x)
        x_trace = x             # save x to use in concat in the Decoder path
        out = self.maxPool(x)
        return out, x_trace


class StackDecoder(nn.Module):
    def __init__(self, in_channels, out_channels, upsample_size, padding, drop_out=False):
        super(StackDecoder, self).__init__()

        self.drop_out = drop_out
        self.dropout_layer = nn.Dropout2d(p=0.5)

        ''' this is old version
        self.upSample = nn.Upsample(size=upsample_size, scale_factor=(2, 2), mode="bilinear")
        self.convr1 = ConvBnRelu(in_channels, out_channels, kernel_size=(3, 3), stride=1, padding=padding)
        # Crop + concat step between these 2
        self.convr2 = ConvBnRelu(in_channels, out_channels, kernel_size=(3, 3), stride=1, padding=padding)
        '''
        self.upSample = nn.ConvTranspose2d(in_channels, out_channels, 2, stride=2)
        self.convr1 = ConvBnRelu(in_channels, out_channels, kernel_size=(3, 3), stride=1, padding=padding)
        self.convr2 = ConvBnRelu(out_channels, out_channels, kernel_size=(3, 3), stride=1, padding=padding)

    def _crop_concat(self, upsampled, bypass):
        """
         Crop y to the (h, w) of x and concat them.
         Used for the expansive path.
        Returns:
            The concatenated tensor
        """
        c = (bypass.size()[2] - upsampled.size()[2]) // 2
        bypass = F.pad(bypass, (-c, -c, -c, -c))

        return torch.cat((bypass, upsampled), 1)

    def forward(self, x, down_tensor):
        '''old version
        x = self.upSample(x)
        x = self.convr1(x)
        x = self._crop_concat(x, down_tensor)
        x = self.convr2(x)
        '''

        x = self.upSample(x)
        x = self._crop_concat(x, down_tensor)
        x = self.convr1(x)
        if self.drop_out: x = self.dropout_layer(x)
        x = self.convr2(x)
        if self.drop_out: x = self.dropout_layer(x)
        return x


class UNet_BN(nn.Module):
    def __init__(self):
        super(UNet_BN, self).__init__()
        # channels, height, width = in_shape

        # self.dropout = dropout

        self.model_code = ""        # variable to save model and main function when loaded

        self.down1 = StackEncoder(1, 64)
        self.down2 = StackEncoder(64, 128)
        self.down3 = StackEncoder(128, 256)
        self.down4 = StackEncoder(256, 512)

        self.center = nn.Sequential(
            # nn.Dropout2d(p=0.2),
            ConvBnRelu(512, 1024, kernel_size=(3, 3), stride=1, padding=0),
            nn.Dropout2d(p=0.2),
            ConvBnRelu(1024, 1024, kernel_size=(3, 3), stride=1, padding=0),
            nn.Dropout2d(p=0.2)
        )

        self.up1 = StackDecoder(in_channels=1024, out_channels=512, upsample_size=(64,64), padding = 1)
        self.up2 = StackDecoder(in_channels=512, out_channels=256, upsample_size=(128,128), padding = 1)
        self.up3 = StackDecoder(in_channels=256, out_channels=128, upsample_size=(256,256), padding = 1)
        self.up4 = StackDecoder(in_channels=128, out_channels=64, upsample_size=(512,512), padding = 1)

        # 1x1 convolution at the last layer
        # Different from the paper is the output size here
        self.output_seg_map = nn.Conv2d(64, 1, kernel_size=(1, 1), padding=0, stride=1)

        self._initialize_weights()

    def forward(self, x):
        x, x_trace1 = self.down1(x)
        x, x_trace2 = self.down2(x)
        x, x_trace3 = self.down3(x)
        x, x_trace4 = self.down4(x)
        x = self.center(x)
        x = self.up1(x, x_trace4)
        x = self.up2(x, x_trace3)
        x = self.up3(x, x_trace2)
        x = self.up4(x, x_trace1)

        x = self.output_seg_map(x)
        # x = F.sigmoid(x)
        # out = torch.squeeze(out, dim=1)
        return x


    def _initialize_weights(self):
        for m in self.modules():
            if isinstance(m, nn.Conv2d):
                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels
                m.weight.data.normal_(0, math.sqrt(2. / n))
                if m.bias is not None:
                    m.bias.data.zero_()
            elif isinstance(m, nn.BatchNorm2d):
                m.weight.data.fill_(1)
                m.bias.data.zero_()

# x = Variable(torch.randn(1,1,636,636))       # simulate input image
# net = UNet_BN()
# out = net(x)
# print("input: ", x)
# print("output: ", out)

===============from __future__ import print_function, division
import torch
from torch import optim
from torch.autograd import Variable
from torch.utils.data import DataLoader
import numpy as np
import torch.nn as nn
import torch.nn.functional as F
import Unet
import Unet_BatchNorm
import tifffile as tiff
import Utils
import time
from sklearn.metrics import average_precision_score, recall_score, f1_score
import Analysis

def to_var(x):
    if torch.cuda.is_available():
        return Variable(x.cuda())
    else:
        return Variable(x)

### BinaryCrossEntropyLoss2d().forward(logits, labels)
class BinaryCrossEntropyLoss2d(nn.Module):
    def __init__(self, weight=None, size_average=True):
        """
        Binary cross entropy loss 2D
        Args:
            weight:
            size_average:
        """
        super(BinaryCrossEntropyLoss2d, self).__init__()
        self.bce_loss = nn.BCELoss(weight, size_average)

    def forward(self, probs, targets):
        probs = F.sigmoid(probs)
        probs_flat = probs.view(-1)  # Flatten
        targets_flat = targets.view(-1)  # Flatten
        return self.bce_loss(probs_flat, targets_flat)      # (output, labels)

class SoftDiceLoss(nn.Module):
    def __init__(self, weight=None, size_average=True):
        super(SoftDiceLoss, self).__init__()

    def forward(self, probs, targets):
        smooth = 1
        num = targets.size(0)
        probs = F.sigmoid(probs)
        m1 = probs.view(num, -1)
        m2 = targets.view(num, -1)
        intersection = (m1 * m2)
        score = 2. * (intersection.sum(1) + smooth) / (m1.sum(1) + m2.sum(1) + smooth)
        score = 1 - score.sum() / num
        return score

def _criterion(logits, labels):
    return BinaryCrossEntropyLoss2d().forward(logits, labels) + \
        SoftDiceLoss().forward(logits, labels)

def NetEval(net,valdata_loader,crit):
    loss = 0.
    count = 0
    net.eval()
    for i,data in enumerate(valdata_loader,0):
        inputs, labels = data
        inputs, labels = to_var(inputs), to_var(labels)
        out = net(inputs)
        l = crit(out, labels)
        loss += l.data[0]
        count += 1
    return loss/count

# calculate Precision, Recall, F1-measure, IoU over the validation set
def Net_performace_val(net,valdata_loader):
    precision_list = []
    recall_list = []
    iou_list = []
    net.eval()
    print("len of valdata: ", len(valdata_loader))
    for i,data in enumerate(valdata_loader,0):

        inputs, labels = data
        out = NetPredict(net, inputs)   # out is numpy array 512x512
        labels = labels.numpy()
        labels = labels[0,0,:,:]        # labels is numpy array 512x512
        # remove the case where the mask is plain black
        if np.sum(labels) < 0.01*np.shape(labels)[0]*np.shape(labels)[1]: continue

        precision = average_precision_score(labels, out)
        recall = recall_score(labels, out, average='weighted')
        iou = IoU(out, labels)
        precision_list.append(precision)
        recall_list.append(recall)
        iou_list.append(iou)

    precision, recall, iou = np.mean(precision_list), np.mean(recall_list), np.mean(iou_list)
    F1_measure = 2.0*precision*recall/(precision + recall)

    return precision, recall, F1_measure, iou

# calculate IoU
def IoU(pred, target):
    # Ignore IoU for background class
    cls = 0.5
    pred_inds = pred > cls
    target_inds = target > cls

    intersection = (pred_inds[target_inds]).sum()  # Cast to long to prevent overflows
    union = pred_inds.sum() + target_inds.sum() - intersection
    if union == 0:
        ious = float('nan')  # If there is no ground truth, do not include in evaluation
    else:
        ious = 1.0*intersection / max(union, 1)
    return ious

#process the test data and save to separate .tif image
def NetTest(net,testdata_loader,path = "data/results/"):
    net.eval()
    for i, data in enumerate(testdata_loader, 0):
        if i >= 30: return 1        # for debug
        data = to_var(data)
        out = net(data)

        out = F.sigmoid(out)

        imgname = path + str(i) + ".tif"
        img = out.cpu()
        img = img[0,0,:,:]
        img = img.data.numpy()
        img_shape = img.shape
        img = img.reshape(-1)
        img[img < 0.5] = 0; img[img >= 0.5] = 1
        img = img.reshape(img_shape)
        img = np.uint8(img * 255)
        tiff.imsave(imgname, img)

# return input image size like 512x512, numpy array
def NetPredict(net, data):
    net.eval()
    data = to_var(data)
    out = net(data)

    out = F.sigmoid(out)

    img = out.cpu()
    img = img[0, 0, :, :]
    img = img.data.numpy()
    img_shape = img.shape
    img = img.reshape(-1)
    img[img < 0.5] = 0;
    img[img >= 0.5] = 1
    img = img.reshape(img_shape)
    return img
def write_2_log(content):
    path = "log_file.txt"
    output = open(path, "a")
    output.write("\n")
    output.write(content)
    output.close()

if __name__ == '__main__':
    '''subjects to change for each exp:
    + path to the dataset
    + opt function
    + leg description
    + N_epoch
    + saved_model
    '''
    start_begining = time.time()

    # path = "data/dataset"
    path = "/home/anhxtuan/HanLe/dataset/20aug_10ela_3inten_reflect"

    import os
    print("Does the folder exist?: ", os.path.isdir(path))
    print("Does the path exist?: ", os.path.exists(path))

    imgs_train, imgs_mask_train = Utils.load_train_data(npy_path=path)
    imgs_val, imgs_mask_val = Utils.load_val_data(npy_path=path)
    batch_size = 1
    trainset = zip(imgs_train, imgs_mask_train)
    trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,
                                              shuffle=True, num_workers=2)
    valset = zip(imgs_val, imgs_mask_val)
    valloader = torch.utils.data.DataLoader(valset, batch_size=batch_size,
                                              shuffle=False, num_workers=2)
    # net = Unet.UNet()                     # Unet 1
    net = Unet_BatchNorm.UNet_BN()          # Unet 2 with batchNorm


    # if torch.cuda.is_available():
    #     torch.set_default_tensor_type('torch.cuda.FloatTensor')
    #     net.load_state_dict(torch.load(model_file))
    #     # net.eval()
    #     net.cuda()

    f1 = open("Unet_BatchNorm.py", 'r')     # embede code into the model to be saved later
    f2 = open("UnetTrain.py", 'r')
    f3 = open("Utils.py", 'r')
    model_notes = time.strftime("%c") + "\n" + f1.read() + "\n" + "==="*5 + f2.read() + "\n" + "==="*5 + f3.read()
    f1.close()
    f2.close()

    criterion = BinaryCrossEntropyLoss2d()
    # criterion = SoftDiceLoss()
    # criterion = nn.BCELoss()

    if torch.cuda.is_available():
        net.cuda()
        # criterion.cuda()

    opt = optim.SGD(net.parameters(), lr=1e-2, momentum=0.99)       # subject to change
    # opt = optim.RMSprop(net.parameters(), lr=2e-4)
    # RMSprop[22](learning rate 0.001) with weight decay set to 0.001.
    # opt = optim.Adam(net.parameters(), lr=1e-3, weight_decay=1e-4)

    train_loss = []
    val_loss = []

    print("[epoch, #image] Loss")
    leg = "Leg12_droput_0_2_rmSigmoid_20aug_10ela_3inten_reflect"
    print("Processing: ", leg)
    model_name = ""

    N_epoch = 6
    model_saved = np.arange(2,N_epoch+1,2)
    val_loss_min = 100

    write_2_log("==="*30)
    write_2_log(time.strftime("%c"))       # time, date of exp
    write_2_log(leg)
    write_2_log(model_notes)
    write_2_log(time.strftime("%c"))  # time, date of exp
    write_2_log(leg)
    write_2_log("optim.SGD(net.parameters(), lr=1e-2, momentum=0.99)")
    write_2_log("Number of epoch max: " + str(N_epoch))


    min_model_epoch = 0
    for epoch in range(N_epoch):
        running_loss = 0.0; count = 0
        net.train()
        for i, data in enumerate(trainloader, 0):
            inputs, labels = data
            temp = labels.numpy()
            temp = temp[0, 0, :, :]  # labels is numpy array 512x512
            # remove the case where the mask is plain black
            if np.sum(temp) < 0.01 * np.shape(temp)[0] * np.shape(temp)[1]: continue
            inputs, labels = to_var(inputs), to_var(labels)
            opt.zero_grad()
            out = net(inputs)
            loss = criterion(out, labels)
            loss.backward()
            opt.step()
            running_loss += loss.data[0]
            count += 1

        net.eval()
        val_loss_temp = NetEval(net, valloader, criterion)
        if epoch > 0 and val_loss_temp < val_loss_min:        # save the model which has the lowest val_loss, ignore first epoch
            val_loss_min = val_loss_temp
            torch.save(net.state_dict(), "Unet2_model_" + leg + "_min_val_loss")  # save model
            min_model_epoch = epoch + 1

        disp = 'Epoch %d: Train loss: %.6f, Val loss: %.6f' % (epoch + 1, running_loss/count, val_loss_temp)
        write_2_log(disp)
        print(disp)
        val_loss.append(val_loss_temp)
        train_loss.append(running_loss/count); running_loss = 0.0

        if (epoch + 1) in model_saved:        # save checkpoint
            model_name = "Unet2_model_" + str(epoch+1) + "epoch_" + leg
            torch.save(net.state_dict(), model_name)  # save model
            Analysis.analysis(model_file = model_name, valloader = valloader)

    write_2_log("Best model at epoch: " + str(min_model_epoch))
    write_2_log("Total training time: " + str((time.time() - start_begining) / 3600.0))

    val_loss_file = "data/results" + "/val_loss_" + str(N_epoch) + "epoch_" + leg + ".npy"
    train_loss_file = "data/results" + "/training_loss_" + str(N_epoch) + "epoch_" + leg + ".npy"

    np.save(val_loss_file, val_loss)
    np.save(train_loss_file, train_loss)
    print("total processing time in seconds: ", time.time() - start_begining)
    print("total processing time in mins: ", (time.time() - start_begining) / 60.0)
    print("total processing time in hours: ", (time.time() - start_begining) / 3600.0)

    Analysis.analysis(model_file="Unet2_model_" + leg + "_min_val_loss", valloader=valloader)

    Analysis.PlotLoss(model_file = model_name, loss_train_path = train_loss_file, loss_val_path = val_loss_file, epoch_No = N_epoch)

    write_2_log(time.strftime("%c"))  # time, date of exp
===============import numpy as np
import torch.nn as nn
import torch
import cv2
from lcn import LecunLCN

LCN_enable = False

def input_filled_mirroring(x):      # fill missing data by mirroring the input image
    '''input size 636 --> output size 512'''
    w, h = x.shape
    e = 62  # extra width on 1 edge
    y = np.zeros((h + e * 2, w + e * 2))
    y[e:h + e, e:w + e] = x
    y[e:e + h, 0:e] = np.flip(y[e:e + h, e:2 * e], 1)  # flip vertically
    y[e:e + h, e + w:2 * e + w] = np.flip(y[e:e + h, w:e + w], 1)  # flip vertically
    y[0:e, 0:2 * e + w] = np.flip(y[e:2 * e, 0:2 * e + w], 0)  # flip horizontally
    y[e + h:2 * e + h, 0:2 * e + w] = np.flip(y[h:e + h, 0:2 * e + w], 0)  # flip horizontally
    return y

def nearest_cells_distance(pos, img):
    # searching in 8 directions to find 2 nearest distances to neighbor cells
    curr_value = img[pos]
    w = img.shape[0];h = img.shape[1]
    count_detect = 0  # detect 2 nearest neighbors. break the search if count_detect = 2
    x, y = pos

    # print("w,h: ", (w, h))
    d1 = 9999999;d2 = 9999999;d3 = 9999999;d4 = 9999999
    d5 = 9999999;d6 = 9999999;d7 = 9999999;d8 = 9999999
    for i in range(1, max(w, h)):
        # (x+1, y), (x+1, y+1), (x+1, y-1),
        # (x, y+1), (x, y-1)
        # (x-1, y), (x-1,y+1), (x-1,y-1),
        if x + i < w:
            if img[(x + i, y)] != curr_value and d1 == 9999999:
                d1 = i; count_detect += 1
            if y + i < h:
                if img[(x + i, y + i)] != curr_value and d2 == 9999999:
                    d2 = i; count_detect += 1
            elif y - i >= 0:
                if img[(x + i, y - i)] != curr_value and d3 == 9999999:
                    d3 = i; count_detect += 1
        if y + i < h:
            if img[(x, y + i)] != curr_value and d4 == 9999999:
                d4 = i; count_detect += 1
        if y - i >= 0:
            if img[(x, y - i)] != curr_value and d5 == 9999999:
                d5 = i; count_detect += 1
        if x - i >= 0:
            if img[(x - i, y)] != curr_value and d6 == 9999999:
                d6 = i; count_detect += 1
            if y + i < h:
                if img[(x - i, y + i)] != curr_value and d7 == 9999999:
                    d7 = i; count_detect += 1
            elif y - i >= 0:
                if img[(x - i, y - i)] != curr_value and d8 == 9999999:
                    d8 = i; count_detect += 1
        if count_detect >= 2: break

    d = [d1, d2, d3, d4, d5, d6, d7, d8]
    min_index = np.argmin(d)
    dist1 = d[min_index]
    d.remove(dist1)
    min_index = np.argmin(d)
    dist2 = d[min_index]
    return dist1, dist2

def create_weight_map(imgs_mask):
        print('-' * 30)
        print('Creating weights for masks ...')
        print('-' * 30)
        weight_map = np.ndarray(
            (len(imgs_mask), 1, np.shape(imgs_mask)[2], np.shape(imgs_mask)[3]), dtype=np.float32)
        w_0 = 10; sigma = 4
        imgs_w, imgs_h = np.shape(imgs_mask)[2], np.shape(imgs_mask)[3]
        total_pixels = imgs_w*imgs_h
        import time
        start = time.time()
        for i in range(len(imgs_mask)):
            if i%10 == 0: print("Done processing: %d images, time passed: %.2f mins" % (i, (time.time() - start)/60.0))
            temp = imgs_mask[i,0,:,:]
            w_border = 1 - np.sum(temp)/total_pixels        # w_c of pixel on the border (black)
            for m in range(imgs_w):
                for n in range(imgs_h):
                    # loop through all pixel of the mask
                    d1,d2 = nearest_cells_distance((m,n), temp)
                    w_c = w_border
                    if temp[m,n] == 0: w_c = 1 - w_border
                    weight_map[i,0,m,n] = w_c*5 + w_0*np.exp(-(d1 + d2)**2/(2*sigma**2))
                    # print("w_0*np.exp(): ", w_0*np.exp(-(d1 + d2)**2/(2*sigma**2)))
                    # print("w_border: ", w_border)

        np.save('data/dataset/weight_map_train.npy', weight_map)

        return weight_map

def load_train_data(npy_path = "data/dataset", hist_equal = False):

    print('-' * 30)
    print('load train images...')

    imgs_train = np.load(npy_path + "/imgs_train.npy")
    imgs_mask_train = np.load(npy_path + "/imgs_mask_train.npy")

    if hist_equal: imgs_train = hist_equalization(imgs_train)

    # weight_map_train = np.load(npy_path + "/weight_map_train.npy")
    # weight_map_train = weight_map_train.astype('float32')

    imgs_train = imgs_train.astype('float32')
    imgs_mask_train = imgs_mask_train.astype('float32')

    if LCN_enable:
        imgs_train = imgs_train.astype('float64')
        imgs_train = LecunLCN(imgs_train, image_shape=imgs_train.shape).output.eval()
        imgs_train = imgs_train.astype('float32')

    if not LCN_enable: imgs_train /= 255

    imgs_train -= imgs_train.mean(axis=0)
    imgs_mask_train /= 255
    imgs_mask_train[imgs_mask_train > 0.5] = 1
    imgs_mask_train[imgs_mask_train <= 0.5] = 0

    # weight_map_train = create_weight_map(imgs_mask_train)

    print("Done loading traing data")
    print('-' * 30)
    return imgs_train, imgs_mask_train

def load_val_data(npy_path = "data/dataset", hist_equal = True):

    print('-' * 30)
    print('load validation images...')

    imgs_train = np.load(npy_path + "/imgs_val.npy")
    imgs_mask_train = np.load(npy_path + "/imgs_mask_val.npy")

    if hist_equal: imgs_train = hist_equalization(imgs_train)

    imgs_train = imgs_train.astype('float32')
    imgs_mask_train = imgs_mask_train.astype('float32')

    if LCN_enable:
        imgs_train = imgs_train.astype('float64')
        imgs_train = LecunLCN(imgs_train, image_shape=imgs_train.shape).output.eval()
        imgs_train = imgs_train.astype('float32')

    if not LCN_enable: imgs_train /= 255
    imgs_train -= imgs_train.mean(axis=0)
    imgs_mask_train /= 255
    imgs_mask_train[imgs_mask_train > 0.5] = 1
    imgs_mask_train[imgs_mask_train <= 0.5] = 0
    print("Done loading validation data")
    print('-' * 30)
    return imgs_train, imgs_mask_train

def load_test_data(npy_path = "data/dataset", hist_equal = True):

    print('-' * 30)
    print('load test images...')

    imgs_test = np.load(npy_path + "/imgs_test.npy")

    if hist_equal: imgs_test = hist_equalization(imgs_test)

    imgs_test = imgs_test.astype('float32')

    if LCN_enable:
        imgs_test = imgs_test.astype('float64')
        imgs_test = LecunLCN(imgs_test, image_shape=imgs_test.shape).output.eval()
        imgs_test = imgs_test.astype('float32')

    if not LCN_enable: imgs_test /= 255

    imgs_test -= imgs_test.mean(axis=0)

    print("Done loading test data")
    print('-' * 30)
    return imgs_test

def load_val_5imgs(npy_path = "data/dataset"):
    print('-' * 30)
    print('load train images...')

    imgs_train = np.load(npy_path + "/imgs_val_5imgs.npy")
    imgs_mask_train = np.load(npy_path + "/imgs_mask_val_5imgs.npy")

    # imgs_train = hist_equalization(imgs_train)

    imgs_train = imgs_train.astype('float64')
    imgs_mask_train = imgs_mask_train.astype('float64')

    if LCN_enable: imgs_train = LecunLCN(imgs_train, image_shape=imgs_train.shape).output.eval()

    if not LCN_enable: imgs_train /= 255

    mean = imgs_train.mean(axis=0)
    imgs_train -= mean


    imgs_mask_train /= 255
    imgs_mask_train[imgs_mask_train > 0.5] = 1
    imgs_mask_train[imgs_mask_train <= 0.5] = 0

    # weight_map_train = self.create_weight_map(imgs_mask_train)

    print("Done loading traing data")
    print('-' * 30)
    return imgs_train, imgs_mask_train

def hist_equalization(inputs):      # inputs are uint8, 0-255, Nx1x636x636
    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))
    output = inputs.copy()
    for i in range(len(inputs)):
        img = inputs[i, 0, :, :]
        # res = cv2.equalizeHist(img)
        res = clahe.apply(img)
        output[i,0,:,:] = res
    return output

### BinaryCrossEntropyLoss2d().forward(logits, labels)
class BinaryCrossEntropyLoss2d(nn.Module):
    def __init__(self, weight=None, size_average=True):
        """
        Binary cross entropy loss 2D
        Args:
            weight:
            size_average:
        """
        super(BinaryCrossEntropyLoss2d, self).__init__()
        self.bce_loss = nn.BCELoss(weight, size_average)

    def forward(self, logits, targets):
        # probs = F.sigmoid(logits)
        probs = logits
        probs_flat = probs.view(-1)  # Flatten
        targets_flat = targets.view(-1)  # Flatten
        return self.bce_loss(probs_flat, targets_flat)      # (output, labels)

class BCE_with_Weights(nn.Module):
    def __init__(self, weights=None):
        """
        Binary cross entropy loss 2D
        Args:
            weights:
        """
        super(BCE_with_Weights, self).__init__()
        self.weights = weights

    def forward(self, output, target):
        if self.weights is not None:
            loss = self.weights * (target * torch.log(output) + (1 - target) * torch.log(1 - output))
        else:
            loss = target * torch.log(output) + (1 - target) * torch.log(1 - output)

        return torch.neg(torch.mean(loss))

class LRN(nn.Module):       # input x is Torch tensor
    def __init__(self, local_size=1, alpha=1.0, beta=0.75, ACROSS_CHANNELS=False):      #LRN(local_size=5, alpha=0.0001, beta=0.75),
        super(LRN, self).__init__()
        self.ACROSS_CHANNELS = ACROSS_CHANNELS
        if self.ACROSS_CHANNELS:
            self.average = nn.AvgPool3d(kernel_size=(local_size, 1, 1),
                                        stride=1, padding=(int((local_size - 1.0) / 2), 0, 0))
        else:
            self.average = nn.AvgPool2d(kernel_size=local_size,
                                        stride=1, padding=int((local_size - 1.0) / 2))
        self.alpha = alpha
        self.beta = beta

    def forward(self, x):
        if self.ACROSS_CHANNELS:
            div = x.pow(2).unsqueeze(1)
            div = self.average(div).squeeze(1)
            div = div.mul(self.alpha).add(1.0).pow(self.beta)
        else:
            div = x.pow(2)
            div = self.average(div)
            div = div.mul(self.alpha).add(1.0).pow(self.beta)
        x = x.div(div)
        return x


Sat Nov 18 04:03:46 2017
Leg12_droput_0_2_rmSigmoid_20aug_10ela_3inten_reflect
optim.SGD(net.parameters(), lr=1e-2, momentum=0.99)
Number of epoch max: 6
Epoch 1: Train loss: 0.223650, Val loss: 0.246297
Epoch 1_leg6: Train loss: 0.234447, Val loss: 0.222773
Epoch 2: Train loss: 0.158995, Val loss: 0.246248
Unet2_model_2epoch_Leg12_droput_0_2_rmSigmoid_20aug_10ela_3inten_reflect
Precision: 0.97107 
Recall: 0.92831 
F1_measure: 0.94921 
iou: 0.89235
Epoch 3: Train loss: 0.135699, Val loss: 0.297786
Epoch 4: Train loss: 0.114544, Val loss: 0.360595
Unet2_model_4epoch_Leg12_droput_0_2_rmSigmoid_20aug_10ela_3inten_reflect
Precision: 0.97104 
Recall: 0.92190 
F1_measure: 0.94583 
iou: 0.88755
Epoch 5: Train loss: 0.098760, Val loss: 0.402203
Epoch 6: Train loss: 0.088367, Val loss: 0.391745
Unet2_model_6epoch_Leg12_droput_0_2_rmSigmoid_20aug_10ela_3inten_reflect
Precision: 0.97152 
Recall: 0.91655 
F1_measure: 0.94323 
iou: 0.88450
Best model at epoch: 2
Total training time: 2.780175055
Unet2_model_Leg12_droput_0_2_rmSigmoid_20aug_10ela_3inten_reflect_min_val_loss
Precision: 0.97107 
Recall: 0.92831 
F1_measure: 0.94921 
iou: 0.89235
Sat Nov 18 06:56:48 2017
==========================================================================================

==========================================================================================
Sat Nov 18 07:06:54 2017
Leg14_rmSigmoid_20aug_10ela_3inten_reflect
Sat Nov 18 07:06:52 2017
import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.autograd import Variable
import math


class ConvBnRelu(nn.Module):
    def __init__(self, in_channels, out_channels, kernel_size, padding, stride):
        super(ConvBnRelu, self).__init__()
        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=kernel_size, padding=padding, stride=stride)
        self.bn = nn.BatchNorm2d(out_channels)
        self.relu = nn.ReLU()

    def forward(self, x):
        x = self.conv(x)
        # x = self.bn(x)
        x = self.relu(x)
        return x


class StackEncoder(nn.Module):
    def __init__(self, in_channels, out_channels):
        super(StackEncoder, self).__init__()
        self.convr1 = ConvBnRelu(in_channels, out_channels, kernel_size=(3, 3), stride=1, padding=0)
        self.convr2 = ConvBnRelu(out_channels, out_channels, kernel_size=(3, 3), stride=1, padding=0)
        self.maxPool = nn.MaxPool2d(kernel_size=(2, 2), stride=2)

    def forward(self, x):
        x = self.convr1(x)
        x = self.convr2(x)
        x_trace = x             # save x to use in concat in the Decoder path
        out = self.maxPool(x)
        return out, x_trace


class StackDecoder(nn.Module):
    def __init__(self, in_channels, out_channels, upsample_size, padding, drop_out=False):
        super(StackDecoder, self).__init__()

        self.drop_out = drop_out
        self.dropout_layer = nn.Dropout2d(p=0.5)

        ''' this is old version
        self.upSample = nn.Upsample(size=upsample_size, scale_factor=(2, 2), mode="bilinear")
        self.convr1 = ConvBnRelu(in_channels, out_channels, kernel_size=(3, 3), stride=1, padding=padding)
        # Crop + concat step between these 2
        self.convr2 = ConvBnRelu(in_channels, out_channels, kernel_size=(3, 3), stride=1, padding=padding)
        '''
        self.upSample = nn.ConvTranspose2d(in_channels, out_channels, 2, stride=2)
        self.convr1 = ConvBnRelu(in_channels, out_channels, kernel_size=(3, 3), stride=1, padding=padding)
        self.convr2 = ConvBnRelu(out_channels, out_channels, kernel_size=(3, 3), stride=1, padding=padding)

    def _crop_concat(self, upsampled, bypass):
        """
         Crop y to the (h, w) of x and concat them.
         Used for the expansive path.
        Returns:
            The concatenated tensor
        """
        c = (bypass.size()[2] - upsampled.size()[2]) // 2
        bypass = F.pad(bypass, (-c, -c, -c, -c))

        return torch.cat((bypass, upsampled), 1)

    def forward(self, x, down_tensor):
        '''old version
        x = self.upSample(x)
        x = self.convr1(x)
        x = self._crop_concat(x, down_tensor)
        x = self.convr2(x)
        '''

        x = self.upSample(x)
        x = self._crop_concat(x, down_tensor)
        x = self.convr1(x)
        if self.drop_out: x = self.dropout_layer(x)
        x = self.convr2(x)
        if self.drop_out: x = self.dropout_layer(x)
        return x


class UNet_BN(nn.Module):
    def __init__(self):
        super(UNet_BN, self).__init__()
        # channels, height, width = in_shape

        # self.dropout = dropout

        self.model_code = ""        # variable to save model and main function when loaded

        self.down1 = StackEncoder(1, 64)
        self.down2 = StackEncoder(64, 128)
        self.down3 = StackEncoder(128, 256)
        self.down4 = StackEncoder(256, 512)

        self.center = nn.Sequential(
            # nn.Dropout2d(p=0.2),
            ConvBnRelu(512, 1024, kernel_size=(3, 3), stride=1, padding=0),
            # nn.Dropout2d(p=0.2),
            ConvBnRelu(1024, 1024, kernel_size=(3, 3), stride=1, padding=0)
            # nn.Dropout2d(p=0.2)
        )

        self.up1 = StackDecoder(in_channels=1024, out_channels=512, upsample_size=(64,64), padding = 1)
        self.up2 = StackDecoder(in_channels=512, out_channels=256, upsample_size=(128,128), padding = 1)
        self.up3 = StackDecoder(in_channels=256, out_channels=128, upsample_size=(256,256), padding = 1)
        self.up4 = StackDecoder(in_channels=128, out_channels=64, upsample_size=(512,512), padding = 1)

        # 1x1 convolution at the last layer
        # Different from the paper is the output size here
        self.output_seg_map = nn.Conv2d(64, 1, kernel_size=(1, 1), padding=0, stride=1)

        self._initialize_weights()

    def forward(self, x):
        x, x_trace1 = self.down1(x)
        x, x_trace2 = self.down2(x)
        x, x_trace3 = self.down3(x)
        x, x_trace4 = self.down4(x)
        x = self.center(x)
        x = self.up1(x, x_trace4)
        x = self.up2(x, x_trace3)
        x = self.up3(x, x_trace2)
        x = self.up4(x, x_trace1)

        x = self.output_seg_map(x)
        # x = F.sigmoid(x)
        # out = torch.squeeze(out, dim=1)
        return x


    def _initialize_weights(self):
        for m in self.modules():
            if isinstance(m, nn.Conv2d):
                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels
                m.weight.data.normal_(0, math.sqrt(2. / n))
                if m.bias is not None:
                    m.bias.data.zero_()
            elif isinstance(m, nn.BatchNorm2d):
                m.weight.data.fill_(1)
                m.bias.data.zero_()

# x = Variable(torch.randn(1,1,636,636))       # simulate input image
# net = UNet_BN()
# out = net(x)
# print("input: ", x)
# print("output: ", out)

===============from __future__ import print_function, division
import torch
from torch import optim
from torch.autograd import Variable
from torch.utils.data import DataLoader
import numpy as np
import torch.nn as nn
import torch.nn.functional as F
import Unet
import Unet_BatchNorm
import tifffile as tiff
import Utils
import time
from sklearn.metrics import average_precision_score, recall_score, f1_score
import Analysis

def to_var(x):
    if torch.cuda.is_available():
        return Variable(x.cuda())
    else:
        return Variable(x)

### BinaryCrossEntropyLoss2d().forward(logits, labels)
class BinaryCrossEntropyLoss2d(nn.Module):
    def __init__(self, weight=None, size_average=True):
        """
        Binary cross entropy loss 2D
        Args:
            weight:
            size_average:
        """
        super(BinaryCrossEntropyLoss2d, self).__init__()
        self.bce_loss = nn.BCELoss(weight, size_average)

    def forward(self, probs, targets):
        probs = F.sigmoid(probs)
        probs_flat = probs.view(-1)  # Flatten
        targets_flat = targets.view(-1)  # Flatten
        return self.bce_loss(probs_flat, targets_flat)      # (output, labels)

class SoftDiceLoss(nn.Module):
    def __init__(self, weight=None, size_average=True):
        super(SoftDiceLoss, self).__init__()

    def forward(self, probs, targets):
        smooth = 1
        num = targets.size(0)
        probs = F.sigmoid(probs)
        m1 = probs.view(num, -1)
        m2 = targets.view(num, -1)
        intersection = (m1 * m2)
        score = 2. * (intersection.sum(1) + smooth) / (m1.sum(1) + m2.sum(1) + smooth)
        score = 1 - score.sum() / num
        return score

def _criterion(logits, labels):
    return BinaryCrossEntropyLoss2d().forward(logits, labels) + \
        SoftDiceLoss().forward(logits, labels)

def NetEval(net,valdata_loader,crit):
    loss = 0.
    count = 0
    net.eval()
    for i,data in enumerate(valdata_loader,0):
        inputs, labels = data
        inputs, labels = to_var(inputs), to_var(labels)
        out = net(inputs)
        l = crit(out, labels)
        loss += l.data[0]
        count += 1
    return loss/count

# calculate Precision, Recall, F1-measure, IoU over the validation set
def Net_performace_val(net,valdata_loader):
    precision_list = []
    recall_list = []
    iou_list = []
    net.eval()
    print("len of valdata: ", len(valdata_loader))
    for i,data in enumerate(valdata_loader,0):

        inputs, labels = data
        out = NetPredict(net, inputs)   # out is numpy array 512x512
        labels = labels.numpy()
        labels = labels[0,0,:,:]        # labels is numpy array 512x512
        # remove the case where the mask is plain black
        if np.sum(labels) < 0.01*np.shape(labels)[0]*np.shape(labels)[1]: continue

        precision = average_precision_score(labels, out)
        recall = recall_score(labels, out, average='weighted')
        iou = IoU(out, labels)
        precision_list.append(precision)
        recall_list.append(recall)
        iou_list.append(iou)

    precision, recall, iou = np.mean(precision_list), np.mean(recall_list), np.mean(iou_list)
    F1_measure = 2.0*precision*recall/(precision + recall)

    return precision, recall, F1_measure, iou

# calculate IoU
def IoU(pred, target):
    # Ignore IoU for background class
    cls = 0.5
    pred_inds = pred > cls
    target_inds = target > cls

    intersection = (pred_inds[target_inds]).sum()  # Cast to long to prevent overflows
    union = pred_inds.sum() + target_inds.sum() - intersection
    if union == 0:
        ious = float('nan')  # If there is no ground truth, do not include in evaluation
    else:
        ious = 1.0*intersection / max(union, 1)
    return ious

#process the test data and save to separate .tif image
def NetTest(net,testdata_loader,path = "data/results/"):
    net.eval()
    for i, data in enumerate(testdata_loader, 0):
        if i >= 30: return 1        # for debug
        data = to_var(data)
        out = net(data)

        out = F.sigmoid(out)

        imgname = path + str(i) + ".tif"
        img = out.cpu()
        img = img[0,0,:,:]
        img = img.data.numpy()
        img_shape = img.shape
        img = img.reshape(-1)
        img[img < 0.5] = 0; img[img >= 0.5] = 1
        img = img.reshape(img_shape)
        img = np.uint8(img * 255)
        tiff.imsave(imgname, img)

# return input image size like 512x512, numpy array
def NetPredict(net, data):
    net.eval()
    data = to_var(data)
    out = net(data)

    out = F.sigmoid(out)

    img = out.cpu()
    img = img[0, 0, :, :]
    img = img.data.numpy()
    img_shape = img.shape
    img = img.reshape(-1)
    img[img < 0.5] = 0;
    img[img >= 0.5] = 1
    img = img.reshape(img_shape)
    return img
def write_2_log(content):
    path = "log_file.txt"
    output = open(path, "a")
    output.write("\n")
    output.write(content)
    output.close()

if __name__ == '__main__':
    '''subjects to change for each exp:
    + path to the dataset
    + opt function
    + leg description
    + N_epoch
    + saved_model
    '''
    start_begining = time.time()

    # path = "data/dataset"
    path = "/home/anhxtuan/HanLe/dataset/20aug_10ela_3inten_reflect"

    import os
    print("Does the folder exist?: ", os.path.isdir(path))
    print("Does the path exist?: ", os.path.exists(path))

    imgs_train, imgs_mask_train = Utils.load_train_data(npy_path=path)
    imgs_val, imgs_mask_val = Utils.load_val_data(npy_path=path)
    batch_size = 1
    trainset = zip(imgs_train, imgs_mask_train)
    trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,
                                              shuffle=True, num_workers=2)
    valset = zip(imgs_val, imgs_mask_val)
    valloader = torch.utils.data.DataLoader(valset, batch_size=batch_size,
                                              shuffle=False, num_workers=2)
    # net = Unet.UNet()                     # Unet 1
    net = Unet_BatchNorm.UNet_BN()          # Unet 2 with batchNorm


    f1 = open("Unet_BatchNorm.py", 'r')     # embede code into the model to be saved later
    f2 = open("UnetTrain.py", 'r')
    f3 = open("Utils.py", 'r')
    model_notes = time.strftime("%c") + "\n" + f1.read() + "\n" + "==="*5 + f2.read() + "\n" + "==="*5 + f3.read()
    f1.close()
    f2.close()

    criterion = BinaryCrossEntropyLoss2d()
    # criterion = SoftDiceLoss()
    # criterion = nn.BCELoss()

    if torch.cuda.is_available():
        # torch.set_default_tensor_type('torch.cuda.FloatTensor')
        # net.load_state_dict(torch.load("Unet2_model_6epoch_Leg6_max_6epoch_20aug_10ela_3inten_reflect"))
        net.cuda()

    opt = optim.SGD(net.parameters(), lr=1e-2, momentum=0.99)       # subject to change
    # opt = optim.RMSprop(net.parameters(), lr=2e-4)
    # RMSprop[22](learning rate 0.001) with weight decay set to 0.001.
    # opt = optim.Adam(net.parameters(), lr=1e-3, weight_decay=1e-4)

    train_loss = []
    val_loss = []

    print("[epoch, #image] Loss")
    leg = "Leg14_rmSigmoid_20aug_10ela_3inten_reflect"
    print("Processing: ", leg)
    model_name = ""

    N_epoch = 6
    model_saved = np.arange(2,N_epoch+1,2)
    val_loss_min = 100

    write_2_log("==="*30)
    write_2_log(time.strftime("%c"))       # time, date of exp
    write_2_log(leg)
    write_2_log(model_notes)
    write_2_log(time.strftime("%c"))  # time, date of exp
    write_2_log(leg)
    write_2_log("optim.SGD(net.parameters(), lr=1e-2, momentum=0.99)")
    write_2_log("Number of epoch max: " + str(N_epoch))


    min_model_epoch = 0
    for epoch in range(N_epoch):
        running_loss = 0.0; count = 0
        net.train()
        for i, data in enumerate(trainloader, 0):
            inputs, labels = data
            temp = labels.numpy()
            temp = temp[0, 0, :, :]  # labels is numpy array 512x512
            # remove the case where the mask is plain black
            if np.sum(temp) < 0.01 * np.shape(temp)[0] * np.shape(temp)[1]: continue
            inputs, labels = to_var(inputs), to_var(labels)
            opt.zero_grad()
            out = net(inputs)
            loss = criterion(out, labels)
            loss.backward()
            opt.step()
            running_loss += loss.data[0]
            count += 1

        net.eval()
        val_loss_temp = NetEval(net, valloader, criterion)
        if epoch > 0 and val_loss_temp < val_loss_min:        # save the model which has the lowest val_loss, ignore first epoch
            val_loss_min = val_loss_temp
            torch.save(net.state_dict(), "Unet2_model_" + leg + "_min_val_loss")  # save model
            min_model_epoch = epoch + 1

        disp = 'Epoch %d: Train loss: %.6f, Val loss: %.6f' % (epoch + 1, running_loss/count, val_loss_temp)
        write_2_log(disp)
        print(disp)
        val_loss.append(val_loss_temp)
        train_loss.append(running_loss/count); running_loss = 0.0

        if (epoch + 1) in model_saved:        # save checkpoint
            model_name = "Unet2_model_" + str(epoch+1) + "epoch_" + leg
            torch.save(net.state_dict(), model_name)  # save model
            Analysis.analysis(model_file = model_name, valloader = valloader)

    write_2_log("Best model at epoch: " + str(min_model_epoch))
    write_2_log("Total training time: " + str((time.time() - start_begining) / 3600.0))

    val_loss_file = "data/results" + "/val_loss_" + str(N_epoch) + "epoch_" + leg + ".npy"
    train_loss_file = "data/results" + "/training_loss_" + str(N_epoch) + "epoch_" + leg + ".npy"

    np.save(val_loss_file, val_loss)
    np.save(train_loss_file, train_loss)
    print("total processing time in seconds: ", time.time() - start_begining)
    print("total processing time in mins: ", (time.time() - start_begining) / 60.0)
    print("total processing time in hours: ", (time.time() - start_begining) / 3600.0)

    Analysis.analysis(model_file="Unet2_model_" + leg + "_min_val_loss", valloader=valloader)

    Analysis.PlotLoss(model_file = model_name, loss_train_path = train_loss_file, loss_val_path = val_loss_file, epoch_No = N_epoch)

    write_2_log(time.strftime("%c"))  # time, date of exp
===============import numpy as np
import torch.nn as nn
import torch
import cv2
from lcn import LecunLCN

LCN_enable = False

def input_filled_mirroring(x):      # fill missing data by mirroring the input image
    '''input size 636 --> output size 512'''
    w, h = x.shape
    e = 62  # extra width on 1 edge
    y = np.zeros((h + e * 2, w + e * 2))
    y[e:h + e, e:w + e] = x
    y[e:e + h, 0:e] = np.flip(y[e:e + h, e:2 * e], 1)  # flip vertically
    y[e:e + h, e + w:2 * e + w] = np.flip(y[e:e + h, w:e + w], 1)  # flip vertically
    y[0:e, 0:2 * e + w] = np.flip(y[e:2 * e, 0:2 * e + w], 0)  # flip horizontally
    y[e + h:2 * e + h, 0:2 * e + w] = np.flip(y[h:e + h, 0:2 * e + w], 0)  # flip horizontally
    return y

def nearest_cells_distance(pos, img):
    # searching in 8 directions to find 2 nearest distances to neighbor cells
    curr_value = img[pos]
    w = img.shape[0];h = img.shape[1]
    count_detect = 0  # detect 2 nearest neighbors. break the search if count_detect = 2
    x, y = pos

    # print("w,h: ", (w, h))
    d1 = 9999999;d2 = 9999999;d3 = 9999999;d4 = 9999999
    d5 = 9999999;d6 = 9999999;d7 = 9999999;d8 = 9999999
    for i in range(1, max(w, h)):
        # (x+1, y), (x+1, y+1), (x+1, y-1),
        # (x, y+1), (x, y-1)
        # (x-1, y), (x-1,y+1), (x-1,y-1),
        if x + i < w:
            if img[(x + i, y)] != curr_value and d1 == 9999999:
                d1 = i; count_detect += 1
            if y + i < h:
                if img[(x + i, y + i)] != curr_value and d2 == 9999999:
                    d2 = i; count_detect += 1
            elif y - i >= 0:
                if img[(x + i, y - i)] != curr_value and d3 == 9999999:
                    d3 = i; count_detect += 1
        if y + i < h:
            if img[(x, y + i)] != curr_value and d4 == 9999999:
                d4 = i; count_detect += 1
        if y - i >= 0:
            if img[(x, y - i)] != curr_value and d5 == 9999999:
                d5 = i; count_detect += 1
        if x - i >= 0:
            if img[(x - i, y)] != curr_value and d6 == 9999999:
                d6 = i; count_detect += 1
            if y + i < h:
                if img[(x - i, y + i)] != curr_value and d7 == 9999999:
                    d7 = i; count_detect += 1
            elif y - i >= 0:
                if img[(x - i, y - i)] != curr_value and d8 == 9999999:
                    d8 = i; count_detect += 1
        if count_detect >= 2: break

    d = [d1, d2, d3, d4, d5, d6, d7, d8]
    min_index = np.argmin(d)
    dist1 = d[min_index]
    d.remove(dist1)
    min_index = np.argmin(d)
    dist2 = d[min_index]
    return dist1, dist2

def create_weight_map(imgs_mask):
        print('-' * 30)
        print('Creating weights for masks ...')
        print('-' * 30)
        weight_map = np.ndarray(
            (len(imgs_mask), 1, np.shape(imgs_mask)[2], np.shape(imgs_mask)[3]), dtype=np.float32)
        w_0 = 10; sigma = 4
        imgs_w, imgs_h = np.shape(imgs_mask)[2], np.shape(imgs_mask)[3]
        total_pixels = imgs_w*imgs_h
        import time
        start = time.time()
        for i in range(len(imgs_mask)):
            if i%10 == 0: print("Done processing: %d images, time passed: %.2f mins" % (i, (time.time() - start)/60.0))
            temp = imgs_mask[i,0,:,:]
            w_border = 1 - np.sum(temp)/total_pixels        # w_c of pixel on the border (black)
            for m in range(imgs_w):
                for n in range(imgs_h):
                    # loop through all pixel of the mask
                    d1,d2 = nearest_cells_distance((m,n), temp)
                    w_c = w_border
                    if temp[m,n] == 0: w_c = 1 - w_border
                    weight_map[i,0,m,n] = w_c*5 + w_0*np.exp(-(d1 + d2)**2/(2*sigma**2))
                    # print("w_0*np.exp(): ", w_0*np.exp(-(d1 + d2)**2/(2*sigma**2)))
                    # print("w_border: ", w_border)

        np.save('data/dataset/weight_map_train.npy', weight_map)

        return weight_map

def load_train_data(npy_path = "data/dataset", hist_equal = False):

    print('-' * 30)
    print('load train images...')

    imgs_train = np.load(npy_path + "/imgs_train.npy")
    imgs_mask_train = np.load(npy_path + "/imgs_mask_train.npy")

    if hist_equal: imgs_train = hist_equalization(imgs_train)

    # weight_map_train = np.load(npy_path + "/weight_map_train.npy")
    # weight_map_train = weight_map_train.astype('float32')

    imgs_train = imgs_train.astype('float32')
    imgs_mask_train = imgs_mask_train.astype('float32')

    if LCN_enable:
        imgs_train = imgs_train.astype('float64')
        imgs_train = LecunLCN(imgs_train, image_shape=imgs_train.shape).output.eval()
        imgs_train = imgs_train.astype('float32')

    if not LCN_enable: imgs_train /= 255

    imgs_train -= imgs_train.mean(axis=0)
    imgs_mask_train /= 255
    imgs_mask_train[imgs_mask_train > 0.5] = 1
    imgs_mask_train[imgs_mask_train <= 0.5] = 0

    # weight_map_train = create_weight_map(imgs_mask_train)

    print("Done loading traing data")
    print('-' * 30)
    return imgs_train, imgs_mask_train

def load_val_data(npy_path = "data/dataset", hist_equal = True):

    print('-' * 30)
    print('load validation images...')

    imgs_train = np.load(npy_path + "/imgs_val.npy")
    imgs_mask_train = np.load(npy_path + "/imgs_mask_val.npy")

    if hist_equal: imgs_train = hist_equalization(imgs_train)

    imgs_train = imgs_train.astype('float32')
    imgs_mask_train = imgs_mask_train.astype('float32')

    if LCN_enable:
        imgs_train = imgs_train.astype('float64')
        imgs_train = LecunLCN(imgs_train, image_shape=imgs_train.shape).output.eval()
        imgs_train = imgs_train.astype('float32')

    if not LCN_enable: imgs_train /= 255
    imgs_train -= imgs_train.mean(axis=0)
    imgs_mask_train /= 255
    imgs_mask_train[imgs_mask_train > 0.5] = 1
    imgs_mask_train[imgs_mask_train <= 0.5] = 0
    print("Done loading validation data")
    print('-' * 30)
    return imgs_train, imgs_mask_train

def load_test_data(npy_path = "data/dataset", hist_equal = True):

    print('-' * 30)
    print('load test images...')

    imgs_test = np.load(npy_path + "/imgs_test.npy")

    if hist_equal: imgs_test = hist_equalization(imgs_test)

    imgs_test = imgs_test.astype('float32')

    if LCN_enable:
        imgs_test = imgs_test.astype('float64')
        imgs_test = LecunLCN(imgs_test, image_shape=imgs_test.shape).output.eval()
        imgs_test = imgs_test.astype('float32')

    if not LCN_enable: imgs_test /= 255

    imgs_test -= imgs_test.mean(axis=0)

    print("Done loading test data")
    print('-' * 30)
    return imgs_test

def load_val_5imgs(npy_path = "data/dataset"):
    print('-' * 30)
    print('load train images...')

    imgs_train = np.load(npy_path + "/imgs_val_5imgs.npy")
    imgs_mask_train = np.load(npy_path + "/imgs_mask_val_5imgs.npy")

    # imgs_train = hist_equalization(imgs_train)

    imgs_train = imgs_train.astype('float64')
    imgs_mask_train = imgs_mask_train.astype('float64')

    if LCN_enable: imgs_train = LecunLCN(imgs_train, image_shape=imgs_train.shape).output.eval()

    if not LCN_enable: imgs_train /= 255

    mean = imgs_train.mean(axis=0)
    imgs_train -= mean


    imgs_mask_train /= 255
    imgs_mask_train[imgs_mask_train > 0.5] = 1
    imgs_mask_train[imgs_mask_train <= 0.5] = 0

    # weight_map_train = self.create_weight_map(imgs_mask_train)

    print("Done loading traing data")
    print('-' * 30)
    return imgs_train, imgs_mask_train

def hist_equalization(inputs):      # inputs are uint8, 0-255, Nx1x636x636
    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))
    output = inputs.copy()
    for i in range(len(inputs)):
        img = inputs[i, 0, :, :]
        # res = cv2.equalizeHist(img)
        res = clahe.apply(img)
        output[i,0,:,:] = res
    return output

### BinaryCrossEntropyLoss2d().forward(logits, labels)
class BinaryCrossEntropyLoss2d(nn.Module):
    def __init__(self, weight=None, size_average=True):
        """
        Binary cross entropy loss 2D
        Args:
            weight:
            size_average:
        """
        super(BinaryCrossEntropyLoss2d, self).__init__()
        self.bce_loss = nn.BCELoss(weight, size_average)

    def forward(self, logits, targets):
        # probs = F.sigmoid(logits)
        probs = logits
        probs_flat = probs.view(-1)  # Flatten
        targets_flat = targets.view(-1)  # Flatten
        return self.bce_loss(probs_flat, targets_flat)      # (output, labels)

class BCE_with_Weights(nn.Module):
    def __init__(self, weights=None):
        """
        Binary cross entropy loss 2D
        Args:
            weights:
        """
        super(BCE_with_Weights, self).__init__()
        self.weights = weights

    def forward(self, output, target):
        if self.weights is not None:
            loss = self.weights * (target * torch.log(output) + (1 - target) * torch.log(1 - output))
        else:
            loss = target * torch.log(output) + (1 - target) * torch.log(1 - output)

        return torch.neg(torch.mean(loss))

class LRN(nn.Module):       # input x is Torch tensor
    def __init__(self, local_size=1, alpha=1.0, beta=0.75, ACROSS_CHANNELS=False):      #LRN(local_size=5, alpha=0.0001, beta=0.75),
        super(LRN, self).__init__()
        self.ACROSS_CHANNELS = ACROSS_CHANNELS
        if self.ACROSS_CHANNELS:
            self.average = nn.AvgPool3d(kernel_size=(local_size, 1, 1),
                                        stride=1, padding=(int((local_size - 1.0) / 2), 0, 0))
        else:
            self.average = nn.AvgPool2d(kernel_size=local_size,
                                        stride=1, padding=int((local_size - 1.0) / 2))
        self.alpha = alpha
        self.beta = beta

    def forward(self, x):
        if self.ACROSS_CHANNELS:
            div = x.pow(2).unsqueeze(1)
            div = self.average(div).squeeze(1)
            div = div.mul(self.alpha).add(1.0).pow(self.beta)
        else:
            div = x.pow(2)
            div = self.average(div)
            div = div.mul(self.alpha).add(1.0).pow(self.beta)
        x = x.div(div)
        return x


Sat Nov 18 07:06:54 2017
Leg14_rmSigmoid_20aug_10ela_3inten_reflect
optim.SGD(net.parameters(), lr=1e-2, momentum=0.99)
Number of epoch max: 6
Epoch 1: Train loss: 0.372755, Val loss: 0.421903
Epoch 2: Train loss: 0.359744, Val loss: 0.409227
Unet2_model_2epoch_Leg14_rmSigmoid_20aug_10ela_3inten_reflect
Precision: 0.94742 
Recall: 0.72343 
F1_measure: 0.82041 
iou: 0.69686
Epoch 3: Train loss: 0.335556, Val loss: 0.470307
Epoch 4: Train loss: 0.312240, Val loss: 0.442503
Unet2_model_4epoch_Leg14_rmSigmoid_20aug_10ela_3inten_reflect
Precision: 0.94601 
Recall: 0.82929 
F1_measure: 0.88381 
iou: 0.77803
Epoch 5: Train loss: 0.305507, Val loss: 0.426437
Epoch 6: Train loss: 0.302030, Val loss: 0.372787
Unet2_model_6epoch_Leg14_rmSigmoid_20aug_10ela_3inten_reflect
Precision: 0.94947 
Recall: 0.86321 
F1_measure: 0.90429 
iou: 0.80826
Best model at epoch: 6
Total training time: 2.7543682958
Unet2_model_Leg14_rmSigmoid_20aug_10ela_3inten_reflect_min_val_loss
Precision: 0.94947 
Recall: 0.86321 
F1_measure: 0.90429 
iou: 0.80826
Sat Nov 18 09:58:39 2017
==========================================================================================
Sat Nov 18 11:00:59 2017
Leg12_dropout_0_2_rmSigmoid_20aug_10ela_3inten_reflect
Sat Nov 18 11:00:56 2017
import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.autograd import Variable
import math


class ConvBnRelu(nn.Module):
    def __init__(self, in_channels, out_channels, kernel_size, padding, stride):
        super(ConvBnRelu, self).__init__()
        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=kernel_size, padding=padding, stride=stride)
        self.bn = nn.BatchNorm2d(out_channels)
        self.relu = nn.ReLU()

    def forward(self, x):
        x = self.conv(x)
        # x = self.bn(x)
        x = self.relu(x)
        return x


class StackEncoder(nn.Module):
    def __init__(self, in_channels, out_channels):
        super(StackEncoder, self).__init__()
        self.convr1 = ConvBnRelu(in_channels, out_channels, kernel_size=(3, 3), stride=1, padding=0)
        self.convr2 = ConvBnRelu(out_channels, out_channels, kernel_size=(3, 3), stride=1, padding=0)
        self.maxPool = nn.MaxPool2d(kernel_size=(2, 2), stride=2)

    def forward(self, x):
        x = self.convr1(x)
        x = self.convr2(x)
        x_trace = x             # save x to use in concat in the Decoder path
        out = self.maxPool(x)
        return out, x_trace


class StackDecoder(nn.Module):
    def __init__(self, in_channels, out_channels, upsample_size, padding, drop_out=False):
        super(StackDecoder, self).__init__()

        self.drop_out = drop_out
        self.dropout_layer = nn.Dropout2d(p=0.5)

        ''' this is old version
        self.upSample = nn.Upsample(size=upsample_size, scale_factor=(2, 2), mode="bilinear")
        self.convr1 = ConvBnRelu(in_channels, out_channels, kernel_size=(3, 3), stride=1, padding=padding)
        # Crop + concat step between these 2
        self.convr2 = ConvBnRelu(in_channels, out_channels, kernel_size=(3, 3), stride=1, padding=padding)
        '''
        self.upSample = nn.ConvTranspose2d(in_channels, out_channels, 2, stride=2)
        self.convr1 = ConvBnRelu(in_channels, out_channels, kernel_size=(3, 3), stride=1, padding=padding)
        self.convr2 = ConvBnRelu(out_channels, out_channels, kernel_size=(3, 3), stride=1, padding=padding)

    def _crop_concat(self, upsampled, bypass):
        """
         Crop y to the (h, w) of x and concat them.
         Used for the expansive path.
        Returns:
            The concatenated tensor
        """
        c = (bypass.size()[2] - upsampled.size()[2]) // 2
        bypass = F.pad(bypass, (-c, -c, -c, -c))

        return torch.cat((bypass, upsampled), 1)

    def forward(self, x, down_tensor):
        '''old version
        x = self.upSample(x)
        x = self.convr1(x)
        x = self._crop_concat(x, down_tensor)
        x = self.convr2(x)
        '''

        x = self.upSample(x)
        x = self._crop_concat(x, down_tensor)
        x = self.convr1(x)
        if self.drop_out: x = self.dropout_layer(x)
        x = self.convr2(x)
        if self.drop_out: x = self.dropout_layer(x)
        return x


class UNet_BN(nn.Module):
    def __init__(self):
        super(UNet_BN, self).__init__()
        # channels, height, width = in_shape

        # self.dropout = dropout

        self.model_code = ""        # variable to save model and main function when loaded

        self.down1 = StackEncoder(1, 64)
        self.down2 = StackEncoder(64, 128)
        self.down3 = StackEncoder(128, 256)
        self.down4 = StackEncoder(256, 512)

        self.center = nn.Sequential(
            # nn.Dropout2d(p=0.2),
            ConvBnRelu(512, 1024, kernel_size=(3, 3), stride=1, padding=0),
            nn.Dropout2d(p=0.2),
            ConvBnRelu(1024, 1024, kernel_size=(3, 3), stride=1, padding=0),
            nn.Dropout2d(p=0.2)
        )

        self.up1 = StackDecoder(in_channels=1024, out_channels=512, upsample_size=(64,64), padding = 1)
        self.up2 = StackDecoder(in_channels=512, out_channels=256, upsample_size=(128,128), padding = 1)
        self.up3 = StackDecoder(in_channels=256, out_channels=128, upsample_size=(256,256), padding = 1)
        self.up4 = StackDecoder(in_channels=128, out_channels=64, upsample_size=(512,512), padding = 1)

        # 1x1 convolution at the last layer
        # Different from the paper is the output size here
        self.output_seg_map = nn.Conv2d(64, 1, kernel_size=(1, 1), padding=0, stride=1)

        self._initialize_weights()

    def forward(self, x):
        x, x_trace1 = self.down1(x)
        x, x_trace2 = self.down2(x)
        x, x_trace3 = self.down3(x)
        x, x_trace4 = self.down4(x)
        x = self.center(x)
        x = self.up1(x, x_trace4)
        x = self.up2(x, x_trace3)
        x = self.up3(x, x_trace2)
        x = self.up4(x, x_trace1)

        x = self.output_seg_map(x)
        # x = F.sigmoid(x)
        # out = torch.squeeze(out, dim=1)
        return x


    def _initialize_weights(self):
        for m in self.modules():
            if isinstance(m, nn.Conv2d):
                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels
                m.weight.data.normal_(0, math.sqrt(2. / n))
                if m.bias is not None:
                    m.bias.data.zero_()
            elif isinstance(m, nn.BatchNorm2d):
                m.weight.data.fill_(1)
                m.bias.data.zero_()

# x = Variable(torch.randn(1,1,636,636))       # simulate input image
# net = UNet_BN()
# out = net(x)
# print("input: ", x)
# print("output: ", out)

===============from __future__ import print_function, division
import torch
from torch import optim
from torch.autograd import Variable
from torch.utils.data import DataLoader
import numpy as np
import torch.nn as nn
import torch.nn.functional as F
import Unet
import Unet_BatchNorm
import tifffile as tiff
import Utils
import time
from sklearn.metrics import average_precision_score, recall_score, f1_score
import Analysis

def to_var(x):
    if torch.cuda.is_available():
        return Variable(x.cuda())
    else:
        return Variable(x)

### BinaryCrossEntropyLoss2d().forward(logits, labels)
class BinaryCrossEntropyLoss2d(nn.Module):
    def __init__(self, weight=None, size_average=True):
        """
        Binary cross entropy loss 2D
        Args:
            weight:
            size_average:
        """
        super(BinaryCrossEntropyLoss2d, self).__init__()
        self.bce_loss = nn.BCELoss(weight, size_average)

    def forward(self, probs, targets):
        probs = F.sigmoid(probs)
        probs_flat = probs.view(-1)  # Flatten
        targets_flat = targets.view(-1)  # Flatten
        return self.bce_loss(probs_flat, targets_flat)      # (output, labels)

class SoftDiceLoss(nn.Module):
    def __init__(self, weight=None, size_average=True):
        super(SoftDiceLoss, self).__init__()

    def forward(self, probs, targets):
        smooth = 1
        num = targets.size(0)
        probs = F.sigmoid(probs)
        m1 = probs.view(num, -1)
        m2 = targets.view(num, -1)
        intersection = (m1 * m2)
        score = 2. * (intersection.sum(1) + smooth) / (m1.sum(1) + m2.sum(1) + smooth)
        score = 1 - score.sum() / num
        return score

def _criterion(logits, labels):
    return BinaryCrossEntropyLoss2d().forward(logits, labels) + \
        SoftDiceLoss().forward(logits, labels)

def NetEval(net,valdata_loader,crit):
    loss = 0.
    count = 0
    net.eval()
    for i,data in enumerate(valdata_loader,0):
        inputs, labels = data
        inputs, labels = to_var(inputs), to_var(labels)
        out = net(inputs)
        l = crit(out, labels)
        loss += l.data[0]
        count += 1
    return loss/count

# calculate Precision, Recall, F1-measure, IoU over the validation set
def Net_performace_val(net,valdata_loader):
    precision_list = []
    recall_list = []
    iou_list = []
    net.eval()
    print("len of valdata: ", len(valdata_loader))
    for i,data in enumerate(valdata_loader,0):

        inputs, labels = data
        out = NetPredict(net, inputs)   # out is numpy array 512x512
        labels = labels.numpy()
        labels = labels[0,0,:,:]        # labels is numpy array 512x512
        # remove the case where the mask is plain black
        if np.sum(labels) < 0.01*np.shape(labels)[0]*np.shape(labels)[1]: continue

        precision = average_precision_score(labels, out)
        recall = recall_score(labels, out, average='weighted')
        iou = IoU(out, labels)
        precision_list.append(precision)
        recall_list.append(recall)
        iou_list.append(iou)

    precision, recall, iou = np.mean(precision_list), np.mean(recall_list), np.mean(iou_list)
    F1_measure = 2.0*precision*recall/(precision + recall)

    return precision, recall, F1_measure, iou

# calculate IoU
def IoU(pred, target):
    # Ignore IoU for background class
    cls = 0.5
    pred_inds = pred > cls
    target_inds = target > cls

    intersection = (pred_inds[target_inds]).sum()  # Cast to long to prevent overflows
    union = pred_inds.sum() + target_inds.sum() - intersection
    if union == 0:
        ious = float('nan')  # If there is no ground truth, do not include in evaluation
    else:
        ious = 1.0*intersection / max(union, 1)
    return ious

#process the test data and save to separate .tif image
def NetTest(net,testdata_loader,path = "data/results/"):
    net.eval()
    for i, data in enumerate(testdata_loader, 0):
        if i >= 30: return 1        # for debug
        data = to_var(data)
        out = net(data)

        out = F.sigmoid(out)

        imgname = path + str(i) + ".tif"
        img = out.cpu()
        img = img[0,0,:,:]
        img = img.data.numpy()
        img_shape = img.shape
        img = img.reshape(-1)
        img[img < 0.5] = 0; img[img >= 0.5] = 1
        img = img.reshape(img_shape)
        img = np.uint8(img * 255)
        tiff.imsave(imgname, img)

# return input image size like 512x512, numpy array
def NetPredict(net, data):
    net.eval()
    data = to_var(data)
    out = net(data)

    out = F.sigmoid(out)

    img = out.cpu()
    img = img[0, 0, :, :]
    img = img.data.numpy()
    img_shape = img.shape
    img = img.reshape(-1)
    img[img < 0.5] = 0;
    img[img >= 0.5] = 1
    img = img.reshape(img_shape)
    return img
def write_2_log(content):
    path = "log_file.txt"
    output = open(path, "a")
    output.write("\n")
    output.write(content)
    output.close()

if __name__ == '__main__':
    '''subjects to change for each exp:
    + path to the dataset
    + opt function
    + leg description
    + N_epoch
    + saved_model
    '''
    start_begining = time.time()

    # path = "data/dataset"
    path = "/home/anhxtuan/HanLe/dataset/20aug_10ela_3inten_reflect"

    import os
    print("Does the folder exist?: ", os.path.isdir(path))
    print("Does the path exist?: ", os.path.exists(path))

    imgs_train, imgs_mask_train = Utils.load_train_data(npy_path=path)
    imgs_val, imgs_mask_val = Utils.load_val_data(npy_path=path)
    batch_size = 1
    trainset = zip(imgs_train, imgs_mask_train)
    trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,
                                              shuffle=True, num_workers=2)
    valset = zip(imgs_val, imgs_mask_val)
    valloader = torch.utils.data.DataLoader(valset, batch_size=batch_size,
                                              shuffle=False, num_workers=2)
    # net = Unet.UNet()                     # Unet 1
    net = Unet_BatchNorm.UNet_BN()          # Unet 2 with batchNorm


    # if torch.cuda.is_available():
    #     torch.set_default_tensor_type('torch.cuda.FloatTensor')
    #     net.load_state_dict(torch.load(model_file))
    #     # net.eval()
    #     net.cuda()

    f1 = open("Unet_BatchNorm.py", 'r')     # embede code into the model to be saved later
    f2 = open("UnetTrain.py", 'r')
    f3 = open("Utils.py", 'r')
    model_notes = time.strftime("%c") + "\n" + f1.read() + "\n" + "==="*5 + f2.read() + "\n" + "==="*5 + f3.read()
    f1.close()
    f2.close()

    criterion = BinaryCrossEntropyLoss2d()
    # criterion = SoftDiceLoss()
    # criterion = nn.BCELoss()

    if torch.cuda.is_available():
        torch.set_default_tensor_type('torch.cuda.FloatTensor')
        net.load_state_dict(torch.load("Unet2_model_6epoch_Leg12_droput_0_2_rmSigmoid_20aug_10ela_3inten_reflect"))
        net.cuda()
        # criterion.cuda()

    opt = optim.SGD(net.parameters(), lr=1e-2, momentum=0.99)       # subject to change
    # opt = optim.RMSprop(net.parameters(), lr=2e-4)
    # RMSprop[22](learning rate 0.001) with weight decay set to 0.001.
    # opt = optim.Adam(net.parameters(), lr=1e-3, weight_decay=1e-4)

    train_loss = []
    val_loss = []

    print("[epoch, #image] Loss")
    leg = "Leg12_dropout_0_2_rmSigmoid_20aug_10ela_3inten_reflect"
    print("Processing: ", leg)
    model_name = ""

    N_epoch = 6
    model_saved = np.arange(2,N_epoch+1,2)
    val_loss_min = 100

    write_2_log("==="*30)
    write_2_log(time.strftime("%c"))       # time, date of exp
    write_2_log(leg)
    write_2_log(model_notes)
    write_2_log(time.strftime("%c"))  # time, date of exp
    write_2_log(leg)
    write_2_log("optim.SGD(net.parameters(), lr=1e-2, momentum=0.99)")
    write_2_log("Number of epoch max: " + str(N_epoch))


    min_model_epoch = 0
    for epoch in range(N_epoch):
        running_loss = 0.0; count = 0
        net.train()
        for i, data in enumerate(trainloader, 0):
            inputs, labels = data
            temp = labels.numpy()
            temp = temp[0, 0, :, :]  # labels is numpy array 512x512
            # remove the case where the mask is plain black
            if np.sum(temp) < 0.01 * np.shape(temp)[0] * np.shape(temp)[1]: continue
            inputs, labels = to_var(inputs), to_var(labels)
            opt.zero_grad()
            out = net(inputs)
            loss = criterion(out, labels)
            loss.backward()
            opt.step()
            running_loss += loss.data[0]
            count += 1

        net.eval()
        val_loss_temp = NetEval(net, valloader, criterion)
        if epoch > 0 and val_loss_temp < val_loss_min:        # save the model which has the lowest val_loss, ignore first epoch
            val_loss_min = val_loss_temp
            torch.save(net.state_dict(), "Unet2_model_" + leg + "_min_val_loss")  # save model
            min_model_epoch = epoch + 1

        disp = 'Epoch %d: Train loss: %.6f, Val loss: %.6f' % (epoch + 1, running_loss/count, val_loss_temp)
        write_2_log(disp)
        print(disp)
        val_loss.append(val_loss_temp)
        train_loss.append(running_loss/count); running_loss = 0.0

        if (epoch + 1) in model_saved:        # save checkpoint
            model_name = "Unet2_model_" + str(epoch+1+6) + "epoch_" + leg
            torch.save(net.state_dict(), model_name)  # save model
            Analysis.analysis(model_file = model_name, valloader = valloader)

    write_2_log("Best model at epoch: " + str(min_model_epoch))
    write_2_log("Total training time: " + str((time.time() - start_begining) / 3600.0))

    val_loss_file = "data/results" + "/val_loss_" + str(N_epoch) + "epoch_" + leg + ".npy"
    train_loss_file = "data/results" + "/training_loss_" + str(N_epoch) + "epoch_" + leg + ".npy"

    np.save(val_loss_file, val_loss)
    np.save(train_loss_file, train_loss)
    print("total processing time in seconds: ", time.time() - start_begining)
    print("total processing time in mins: ", (time.time() - start_begining) / 60.0)
    print("total processing time in hours: ", (time.time() - start_begining) / 3600.0)

    Analysis.analysis(model_file="Unet2_model_" + leg + "_min_val_loss", valloader=valloader)

    Analysis.PlotLoss(model_file = model_name, loss_train_path = train_loss_file, loss_val_path = val_loss_file, epoch_No = N_epoch)

    write_2_log(time.strftime("%c"))  # time, date of exp
===============import numpy as np
import torch.nn as nn
import torch
import cv2
from lcn import LecunLCN

LCN_enable = False

def input_filled_mirroring(x):      # fill missing data by mirroring the input image
    '''input size 636 --> output size 512'''
    w, h = x.shape
    e = 62  # extra width on 1 edge
    y = np.zeros((h + e * 2, w + e * 2))
    y[e:h + e, e:w + e] = x
    y[e:e + h, 0:e] = np.flip(y[e:e + h, e:2 * e], 1)  # flip vertically
    y[e:e + h, e + w:2 * e + w] = np.flip(y[e:e + h, w:e + w], 1)  # flip vertically
    y[0:e, 0:2 * e + w] = np.flip(y[e:2 * e, 0:2 * e + w], 0)  # flip horizontally
    y[e + h:2 * e + h, 0:2 * e + w] = np.flip(y[h:e + h, 0:2 * e + w], 0)  # flip horizontally
    return y

def nearest_cells_distance(pos, img):
    # searching in 8 directions to find 2 nearest distances to neighbor cells
    curr_value = img[pos]
    w = img.shape[0];h = img.shape[1]
    count_detect = 0  # detect 2 nearest neighbors. break the search if count_detect = 2
    x, y = pos

    # print("w,h: ", (w, h))
    d1 = 9999999;d2 = 9999999;d3 = 9999999;d4 = 9999999
    d5 = 9999999;d6 = 9999999;d7 = 9999999;d8 = 9999999
    for i in range(1, max(w, h)):
        # (x+1, y), (x+1, y+1), (x+1, y-1),
        # (x, y+1), (x, y-1)
        # (x-1, y), (x-1,y+1), (x-1,y-1),
        if x + i < w:
            if img[(x + i, y)] != curr_value and d1 == 9999999:
                d1 = i; count_detect += 1
            if y + i < h:
                if img[(x + i, y + i)] != curr_value and d2 == 9999999:
                    d2 = i; count_detect += 1
            elif y - i >= 0:
                if img[(x + i, y - i)] != curr_value and d3 == 9999999:
                    d3 = i; count_detect += 1
        if y + i < h:
            if img[(x, y + i)] != curr_value and d4 == 9999999:
                d4 = i; count_detect += 1
        if y - i >= 0:
            if img[(x, y - i)] != curr_value and d5 == 9999999:
                d5 = i; count_detect += 1
        if x - i >= 0:
            if img[(x - i, y)] != curr_value and d6 == 9999999:
                d6 = i; count_detect += 1
            if y + i < h:
                if img[(x - i, y + i)] != curr_value and d7 == 9999999:
                    d7 = i; count_detect += 1
            elif y - i >= 0:
                if img[(x - i, y - i)] != curr_value and d8 == 9999999:
                    d8 = i; count_detect += 1
        if count_detect >= 2: break

    d = [d1, d2, d3, d4, d5, d6, d7, d8]
    min_index = np.argmin(d)
    dist1 = d[min_index]
    d.remove(dist1)
    min_index = np.argmin(d)
    dist2 = d[min_index]
    return dist1, dist2

def create_weight_map(imgs_mask):
        print('-' * 30)
        print('Creating weights for masks ...')
        print('-' * 30)
        weight_map = np.ndarray(
            (len(imgs_mask), 1, np.shape(imgs_mask)[2], np.shape(imgs_mask)[3]), dtype=np.float32)
        w_0 = 10; sigma = 4
        imgs_w, imgs_h = np.shape(imgs_mask)[2], np.shape(imgs_mask)[3]
        total_pixels = imgs_w*imgs_h
        import time
        start = time.time()
        for i in range(len(imgs_mask)):
            if i%10 == 0: print("Done processing: %d images, time passed: %.2f mins" % (i, (time.time() - start)/60.0))
            temp = imgs_mask[i,0,:,:]
            w_border = 1 - np.sum(temp)/total_pixels        # w_c of pixel on the border (black)
            for m in range(imgs_w):
                for n in range(imgs_h):
                    # loop through all pixel of the mask
                    d1,d2 = nearest_cells_distance((m,n), temp)
                    w_c = w_border
                    if temp[m,n] == 0: w_c = 1 - w_border
                    weight_map[i,0,m,n] = w_c*5 + w_0*np.exp(-(d1 + d2)**2/(2*sigma**2))
                    # print("w_0*np.exp(): ", w_0*np.exp(-(d1 + d2)**2/(2*sigma**2)))
                    # print("w_border: ", w_border)

        np.save('data/dataset/weight_map_train.npy', weight_map)

        return weight_map

def load_train_data(npy_path = "data/dataset", hist_equal = False):

    print('-' * 30)
    print('load train images...')

    imgs_train = np.load(npy_path + "/imgs_train.npy")
    imgs_mask_train = np.load(npy_path + "/imgs_mask_train.npy")

    if hist_equal: imgs_train = hist_equalization(imgs_train)

    # weight_map_train = np.load(npy_path + "/weight_map_train.npy")
    # weight_map_train = weight_map_train.astype('float32')

    imgs_train = imgs_train.astype('float32')
    imgs_mask_train = imgs_mask_train.astype('float32')

    if LCN_enable:
        imgs_train = imgs_train.astype('float64')
        imgs_train = LecunLCN(imgs_train, image_shape=imgs_train.shape).output.eval()
        imgs_train = imgs_train.astype('float32')

    if not LCN_enable: imgs_train /= 255

    imgs_train -= imgs_train.mean(axis=0)
    imgs_mask_train /= 255
    imgs_mask_train[imgs_mask_train > 0.5] = 1
    imgs_mask_train[imgs_mask_train <= 0.5] = 0

    # weight_map_train = create_weight_map(imgs_mask_train)

    print("Done loading traing data")
    print('-' * 30)
    return imgs_train, imgs_mask_train

def load_val_data(npy_path = "data/dataset", hist_equal = True):

    print('-' * 30)
    print('load validation images...')

    imgs_train = np.load(npy_path + "/imgs_val.npy")
    imgs_mask_train = np.load(npy_path + "/imgs_mask_val.npy")

    if hist_equal: imgs_train = hist_equalization(imgs_train)

    imgs_train = imgs_train.astype('float32')
    imgs_mask_train = imgs_mask_train.astype('float32')

    if LCN_enable:
        imgs_train = imgs_train.astype('float64')
        imgs_train = LecunLCN(imgs_train, image_shape=imgs_train.shape).output.eval()
        imgs_train = imgs_train.astype('float32')

    if not LCN_enable: imgs_train /= 255
    imgs_train -= imgs_train.mean(axis=0)
    imgs_mask_train /= 255
    imgs_mask_train[imgs_mask_train > 0.5] = 1
    imgs_mask_train[imgs_mask_train <= 0.5] = 0
    print("Done loading validation data")
    print('-' * 30)
    return imgs_train, imgs_mask_train

def load_test_data(npy_path = "data/dataset", hist_equal = True):

    print('-' * 30)
    print('load test images...')

    imgs_test = np.load(npy_path + "/imgs_test.npy")

    if hist_equal: imgs_test = hist_equalization(imgs_test)

    imgs_test = imgs_test.astype('float32')

    if LCN_enable:
        imgs_test = imgs_test.astype('float64')
        imgs_test = LecunLCN(imgs_test, image_shape=imgs_test.shape).output.eval()
        imgs_test = imgs_test.astype('float32')

    if not LCN_enable: imgs_test /= 255

    imgs_test -= imgs_test.mean(axis=0)

    print("Done loading test data")
    print('-' * 30)
    return imgs_test

def load_val_5imgs(npy_path = "data/dataset"):
    print('-' * 30)
    print('load train images...')

    imgs_train = np.load(npy_path + "/imgs_val_5imgs.npy")
    imgs_mask_train = np.load(npy_path + "/imgs_mask_val_5imgs.npy")

    # imgs_train = hist_equalization(imgs_train)

    imgs_train = imgs_train.astype('float64')
    imgs_mask_train = imgs_mask_train.astype('float64')

    if LCN_enable: imgs_train = LecunLCN(imgs_train, image_shape=imgs_train.shape).output.eval()

    if not LCN_enable: imgs_train /= 255

    mean = imgs_train.mean(axis=0)
    imgs_train -= mean


    imgs_mask_train /= 255
    imgs_mask_train[imgs_mask_train > 0.5] = 1
    imgs_mask_train[imgs_mask_train <= 0.5] = 0

    # weight_map_train = self.create_weight_map(imgs_mask_train)

    print("Done loading traing data")
    print('-' * 30)
    return imgs_train, imgs_mask_train

def hist_equalization(inputs):      # inputs are uint8, 0-255, Nx1x636x636
    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))
    output = inputs.copy()
    for i in range(len(inputs)):
        img = inputs[i, 0, :, :]
        # res = cv2.equalizeHist(img)
        res = clahe.apply(img)
        output[i,0,:,:] = res
    return output

### BinaryCrossEntropyLoss2d().forward(logits, labels)
class BinaryCrossEntropyLoss2d(nn.Module):
    def __init__(self, weight=None, size_average=True):
        """
        Binary cross entropy loss 2D
        Args:
            weight:
            size_average:
        """
        super(BinaryCrossEntropyLoss2d, self).__init__()
        self.bce_loss = nn.BCELoss(weight, size_average)

    def forward(self, logits, targets):
        # probs = F.sigmoid(logits)
        probs = logits
        probs_flat = probs.view(-1)  # Flatten
        targets_flat = targets.view(-1)  # Flatten
        return self.bce_loss(probs_flat, targets_flat)      # (output, labels)

class BCE_with_Weights(nn.Module):
    def __init__(self, weights=None):
        """
        Binary cross entropy loss 2D
        Args:
            weights:
        """
        super(BCE_with_Weights, self).__init__()
        self.weights = weights

    def forward(self, output, target):
        if self.weights is not None:
            loss = self.weights * (target * torch.log(output) + (1 - target) * torch.log(1 - output))
        else:
            loss = target * torch.log(output) + (1 - target) * torch.log(1 - output)

        return torch.neg(torch.mean(loss))

class LRN(nn.Module):       # input x is Torch tensor
    def __init__(self, local_size=1, alpha=1.0, beta=0.75, ACROSS_CHANNELS=False):      #LRN(local_size=5, alpha=0.0001, beta=0.75),
        super(LRN, self).__init__()
        self.ACROSS_CHANNELS = ACROSS_CHANNELS
        if self.ACROSS_CHANNELS:
            self.average = nn.AvgPool3d(kernel_size=(local_size, 1, 1),
                                        stride=1, padding=(int((local_size - 1.0) / 2), 0, 0))
        else:
            self.average = nn.AvgPool2d(kernel_size=local_size,
                                        stride=1, padding=int((local_size - 1.0) / 2))
        self.alpha = alpha
        self.beta = beta

    def forward(self, x):
        if self.ACROSS_CHANNELS:
            div = x.pow(2).unsqueeze(1)
            div = self.average(div).squeeze(1)
            div = div.mul(self.alpha).add(1.0).pow(self.beta)
        else:
            div = x.pow(2)
            div = self.average(div)
            div = div.mul(self.alpha).add(1.0).pow(self.beta)
        x = x.div(div)
        return x


Sat Nov 18 11:00:59 2017
Leg12_dropout_0_2_rmSigmoid_20aug_10ela_3inten_reflect
optim.SGD(net.parameters(), lr=1e-2, momentum=0.99)
Number of epoch max: 6
Epoch 1: Train loss: 0.081017, Val loss: 0.372064
Epoch 2: Train loss: 0.075419, Val loss: 0.446041
Unet2_model_8epoch_Leg12_dropout_0_2_rmSigmoid_20aug_10ela_3inten_reflect
Precision: 0.97073 
Recall: 0.91801 
F1_measure: 0.94363 
iou: 0.88416
Epoch 3: Train loss: 0.070847, Val loss: 0.464434
Epoch 4: Train loss: 0.067041, Val loss: 0.523869
Unet2_model_10epoch_Leg12_dropout_0_2_rmSigmoid_20aug_10ela_3inten_reflect
Precision: 0.97081 
Recall: 0.91301 
F1_measure: 0.94102 
iou: 0.88049
Epoch 5: Train loss: 0.063981, Val loss: 0.516060
Epoch 6: Train loss: 0.061556, Val loss: 0.551249
Unet2_model_12epoch_Leg12_dropout_0_2_rmSigmoid_20aug_10ela_3inten_reflect
Precision: 0.97129 
Recall: 0.91404 
F1_measure: 0.94179 
iou: 0.88203
Best model at epoch: 2
Total training time: 2.79055617114
Unet2_model_Leg12_dropout_0_2_rmSigmoid_20aug_10ela_3inten_reflect_min_val_loss
Precision: 0.97073 
Recall: 0.91801 
F1_measure: 0.94363 
iou: 0.88416
Sat Nov 18 13:54:47 2017
==========================================================================================
Sat Nov 18 14:06:33 2017
Leg14_dropout_0_2_rmSigmoid_40aug_10ela_3inten_reflect
Sat Nov 18 14:02:33 2017
import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.autograd import Variable
import math


class ConvBnRelu(nn.Module):
    def __init__(self, in_channels, out_channels, kernel_size, padding, stride):
        super(ConvBnRelu, self).__init__()
        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=kernel_size, padding=padding, stride=stride)
        self.bn = nn.BatchNorm2d(out_channels)
        self.relu = nn.ReLU()

    def forward(self, x):
        x = self.conv(x)
        # x = self.bn(x)
        x = self.relu(x)
        return x


class StackEncoder(nn.Module):
    def __init__(self, in_channels, out_channels):
        super(StackEncoder, self).__init__()
        self.convr1 = ConvBnRelu(in_channels, out_channels, kernel_size=(3, 3), stride=1, padding=0)
        self.convr2 = ConvBnRelu(out_channels, out_channels, kernel_size=(3, 3), stride=1, padding=0)
        self.maxPool = nn.MaxPool2d(kernel_size=(2, 2), stride=2)

    def forward(self, x):
        x = self.convr1(x)
        x = self.convr2(x)
        x_trace = x             # save x to use in concat in the Decoder path
        out = self.maxPool(x)
        return out, x_trace


class StackDecoder(nn.Module):
    def __init__(self, in_channels, out_channels, upsample_size, padding, drop_out=False):
        super(StackDecoder, self).__init__()

        self.drop_out = drop_out
        self.dropout_layer = nn.Dropout2d(p=0.5)

        ''' this is old version
        self.upSample = nn.Upsample(size=upsample_size, scale_factor=(2, 2), mode="bilinear")
        self.convr1 = ConvBnRelu(in_channels, out_channels, kernel_size=(3, 3), stride=1, padding=padding)
        # Crop + concat step between these 2
        self.convr2 = ConvBnRelu(in_channels, out_channels, kernel_size=(3, 3), stride=1, padding=padding)
        '''
        self.upSample = nn.ConvTranspose2d(in_channels, out_channels, 2, stride=2)
        self.convr1 = ConvBnRelu(in_channels, out_channels, kernel_size=(3, 3), stride=1, padding=padding)
        self.convr2 = ConvBnRelu(out_channels, out_channels, kernel_size=(3, 3), stride=1, padding=padding)

    def _crop_concat(self, upsampled, bypass):
        """
         Crop y to the (h, w) of x and concat them.
         Used for the expansive path.
        Returns:
            The concatenated tensor
        """
        c = (bypass.size()[2] - upsampled.size()[2]) // 2
        bypass = F.pad(bypass, (-c, -c, -c, -c))

        return torch.cat((bypass, upsampled), 1)

    def forward(self, x, down_tensor):
        '''old version
        x = self.upSample(x)
        x = self.convr1(x)
        x = self._crop_concat(x, down_tensor)
        x = self.convr2(x)
        '''

        x = self.upSample(x)
        x = self._crop_concat(x, down_tensor)
        x = self.convr1(x)
        if self.drop_out: x = self.dropout_layer(x)
        x = self.convr2(x)
        if self.drop_out: x = self.dropout_layer(x)
        return x


class UNet_BN(nn.Module):
    def __init__(self):
        super(UNet_BN, self).__init__()
        # channels, height, width = in_shape

        # self.dropout = dropout

        self.model_code = ""        # variable to save model and main function when loaded

        self.down1 = StackEncoder(1, 64)
        self.down2 = StackEncoder(64, 128)
        self.down3 = StackEncoder(128, 256)
        self.down4 = StackEncoder(256, 512)

        self.center = nn.Sequential(
            # nn.Dropout2d(p=0.2),
            ConvBnRelu(512, 1024, kernel_size=(3, 3), stride=1, padding=0),
            nn.Dropout2d(p=0.2),
            ConvBnRelu(1024, 1024, kernel_size=(3, 3), stride=1, padding=0),
            nn.Dropout2d(p=0.2)
        )

        self.up1 = StackDecoder(in_channels=1024, out_channels=512, upsample_size=(64,64), padding = 1)
        self.up2 = StackDecoder(in_channels=512, out_channels=256, upsample_size=(128,128), padding = 1)
        self.up3 = StackDecoder(in_channels=256, out_channels=128, upsample_size=(256,256), padding = 1)
        self.up4 = StackDecoder(in_channels=128, out_channels=64, upsample_size=(512,512), padding = 1)

        # 1x1 convolution at the last layer
        # Different from the paper is the output size here
        self.output_seg_map = nn.Conv2d(64, 1, kernel_size=(1, 1), padding=0, stride=1)

        self._initialize_weights()

    def forward(self, x):
        x, x_trace1 = self.down1(x)
        x, x_trace2 = self.down2(x)
        x, x_trace3 = self.down3(x)
        x, x_trace4 = self.down4(x)
        x = self.center(x)
        x = self.up1(x, x_trace4)
        x = self.up2(x, x_trace3)
        x = self.up3(x, x_trace2)
        x = self.up4(x, x_trace1)

        x = self.output_seg_map(x)
        # x = F.sigmoid(x)
        # out = torch.squeeze(out, dim=1)
        return x


    def _initialize_weights(self):
        for m in self.modules():
            if isinstance(m, nn.Conv2d):
                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels
                m.weight.data.normal_(0, math.sqrt(2. / n))
                if m.bias is not None:
                    m.bias.data.zero_()
            elif isinstance(m, nn.BatchNorm2d):
                m.weight.data.fill_(1)
                m.bias.data.zero_()

# x = Variable(torch.randn(1,1,636,636))       # simulate input image
# net = UNet_BN()
# out = net(x)
# print("input: ", x)
# print("output: ", out)

===============from __future__ import print_function, division
import torch
from torch import optim
from torch.autograd import Variable
from torch.utils.data import DataLoader
import numpy as np
import torch.nn as nn
import torch.nn.functional as F
import Unet
import Unet_BatchNorm
import tifffile as tiff
import Utils
import time
from sklearn.metrics import average_precision_score, recall_score, f1_score
import Analysis

def to_var(x):
    if torch.cuda.is_available():
        return Variable(x.cuda())
    else:
        return Variable(x)

### BinaryCrossEntropyLoss2d().forward(logits, labels)
class BinaryCrossEntropyLoss2d(nn.Module):
    def __init__(self, weight=None, size_average=True):
        """
        Binary cross entropy loss 2D
        Args:
            weight:
            size_average:
        """
        super(BinaryCrossEntropyLoss2d, self).__init__()
        self.bce_loss = nn.BCELoss(weight, size_average)

    def forward(self, probs, targets):
        probs = F.sigmoid(probs)
        probs_flat = probs.view(-1)  # Flatten
        targets_flat = targets.view(-1)  # Flatten
        return self.bce_loss(probs_flat, targets_flat)      # (output, labels)

class SoftDiceLoss(nn.Module):
    def __init__(self, weight=None, size_average=True):
        super(SoftDiceLoss, self).__init__()

    def forward(self, probs, targets):
        smooth = 1
        num = targets.size(0)
        probs = F.sigmoid(probs)
        m1 = probs.view(num, -1)
        m2 = targets.view(num, -1)
        intersection = (m1 * m2)
        score = 2. * (intersection.sum(1) + smooth) / (m1.sum(1) + m2.sum(1) + smooth)
        score = 1 - score.sum() / num
        return score

def _criterion(logits, labels):
    return BinaryCrossEntropyLoss2d().forward(logits, labels) + \
        SoftDiceLoss().forward(logits, labels)

def NetEval(net,valdata_loader,crit):
    loss = 0.
    count = 0
    net.eval()
    for i,data in enumerate(valdata_loader,0):
        inputs, labels = data
        inputs, labels = to_var(inputs), to_var(labels)
        out = net(inputs)
        l = crit(out, labels)
        loss += l.data[0]
        count += 1
    return loss/count

# calculate Precision, Recall, F1-measure, IoU over the validation set
def Net_performace_val(net,valdata_loader):
    precision_list = []
    recall_list = []
    iou_list = []
    net.eval()
    print("len of valdata: ", len(valdata_loader))
    for i,data in enumerate(valdata_loader,0):

        inputs, labels = data
        out = NetPredict(net, inputs)   # out is numpy array 512x512
        labels = labels.numpy()
        labels = labels[0,0,:,:]        # labels is numpy array 512x512
        # remove the case where the mask is plain black
        if np.sum(labels) < 0.01*np.shape(labels)[0]*np.shape(labels)[1]: continue

        precision = average_precision_score(labels, out)
        recall = recall_score(labels, out, average='weighted')
        iou = IoU(out, labels)
        precision_list.append(precision)
        recall_list.append(recall)
        iou_list.append(iou)

    precision, recall, iou = np.mean(precision_list), np.mean(recall_list), np.mean(iou_list)
    F1_measure = 2.0*precision*recall/(precision + recall)

    return precision, recall, F1_measure, iou

# calculate IoU
def IoU(pred, target):
    # Ignore IoU for background class
    cls = 0.5
    pred_inds = pred > cls
    target_inds = target > cls

    intersection = (pred_inds[target_inds]).sum()  # Cast to long to prevent overflows
    union = pred_inds.sum() + target_inds.sum() - intersection
    if union == 0:
        ious = float('nan')  # If there is no ground truth, do not include in evaluation
    else:
        ious = 1.0*intersection / max(union, 1)
    return ious

#process the test data and save to separate .tif image
def NetTest(net,testdata_loader,path = "data/results/"):
    net.eval()
    for i, data in enumerate(testdata_loader, 0):
        if i >= 30: return 1        # for debug
        data = to_var(data)
        out = net(data)

        out = F.sigmoid(out)

        imgname = path + str(i) + ".tif"
        img = out.cpu()
        img = img[0,0,:,:]
        img = img.data.numpy()
        img_shape = img.shape
        img = img.reshape(-1)
        img[img < 0.5] = 0; img[img >= 0.5] = 1
        img = img.reshape(img_shape)
        img = np.uint8(img * 255)
        tiff.imsave(imgname, img)

# return input image size like 512x512, numpy array
def NetPredict(net, data):
    net.eval()
    data = to_var(data)
    out = net(data)

    out = F.sigmoid(out)

    img = out.cpu()
    img = img[0, 0, :, :]
    img = img.data.numpy()
    img_shape = img.shape
    img = img.reshape(-1)
    img[img < 0.5] = 0;
    img[img >= 0.5] = 1
    img = img.reshape(img_shape)
    return img
def write_2_log(content):
    path = "log_file.txt"
    output = open(path, "a")
    output.write("\n")
    output.write(content)
    output.close()

if __name__ == '__main__':
    '''subjects to change for each exp:
    + path to the dataset
    + opt function
    + leg description
    + N_epoch
    + saved_model
    '''
    start_begining = time.time()

    # path = "data/dataset"
    path = "/home/anhxtuan/HanLe/dataset/40aug_10ela_3inten_reflect"

    import os
    print("Does the folder exist?: ", os.path.isdir(path))
    print("Does the path exist?: ", os.path.exists(path))

    imgs_train, imgs_mask_train = Utils.load_train_data(npy_path=path)
    imgs_val, imgs_mask_val = Utils.load_val_data(npy_path=path)
    batch_size = 1
    trainset = zip(imgs_train, imgs_mask_train)
    trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,
                                              shuffle=True, num_workers=2)
    valset = zip(imgs_val, imgs_mask_val)
    valloader = torch.utils.data.DataLoader(valset, batch_size=batch_size,
                                              shuffle=False, num_workers=2)
    # net = Unet.UNet()                     # Unet 1
    net = Unet_BatchNorm.UNet_BN()          # Unet 2 with batchNorm


    # if torch.cuda.is_available():
    #     torch.set_default_tensor_type('torch.cuda.FloatTensor')
    #     net.load_state_dict(torch.load(model_file))
    #     # net.eval()
    #     net.cuda()

    f1 = open("Unet_BatchNorm.py", 'r')     # embede code into the model to be saved later
    f2 = open("UnetTrain.py", 'r')
    f3 = open("Utils.py", 'r')
    model_notes = time.strftime("%c") + "\n" + f1.read() + "\n" + "==="*5 + f2.read() + "\n" + "==="*5 + f3.read()
    f1.close()
    f2.close()

    criterion = BinaryCrossEntropyLoss2d()
    # criterion = SoftDiceLoss()
    # criterion = nn.BCELoss()

    if torch.cuda.is_available():
        # torch.set_default_tensor_type('torch.cuda.FloatTensor')
        # net.load_state_dict(torch.load("Unet2_model_6epoch_Leg12_droput_0_2_rmSigmoid_20aug_10ela_3inten_reflect"))
        net.cuda()
        # criterion.cuda()

    opt = optim.SGD(net.parameters(), lr=1e-2, momentum=0.99)       # subject to change
    # opt = optim.RMSprop(net.parameters(), lr=2e-4)
    # RMSprop[22](learning rate 0.001) with weight decay set to 0.001.
    # opt = optim.Adam(net.parameters(), lr=1e-3, weight_decay=1e-4)

    train_loss = []
    val_loss = []

    print("[epoch, #image] Loss")
    leg = "Leg14_dropout_0_2_rmSigmoid_40aug_10ela_3inten_reflect"
    print("Processing: ", leg)
    model_name = ""

    N_epoch = 12
    model_saved = np.arange(2,N_epoch+1,2)
    val_loss_min = 100

    write_2_log("==="*30)
    write_2_log(time.strftime("%c"))       # time, date of exp
    write_2_log(leg)
    write_2_log(model_notes)
    write_2_log(time.strftime("%c"))  # time, date of exp
    write_2_log(leg)
    write_2_log("optim.SGD(net.parameters(), lr=1e-2, momentum=0.99)")
    write_2_log("Number of epoch max: " + str(N_epoch))


    min_model_epoch = 0
    for epoch in range(N_epoch):
        running_loss = 0.0; count = 0
        net.train()
        for i, data in enumerate(trainloader, 0):
            inputs, labels = data
            temp = labels.numpy()
            temp = temp[0, 0, :, :]  # labels is numpy array 512x512
            # remove the case where the mask is plain black
            if np.sum(temp) < 0.01 * np.shape(temp)[0] * np.shape(temp)[1]: continue
            inputs, labels = to_var(inputs), to_var(labels)
            opt.zero_grad()
            out = net(inputs)
            loss = criterion(out, labels)
            loss.backward()
            opt.step()
            running_loss += loss.data[0]
            count += 1

        net.eval()
        val_loss_temp = NetEval(net, valloader, criterion)
        if epoch > 0 and val_loss_temp < val_loss_min:        # save the model which has the lowest val_loss, ignore first epoch
            val_loss_min = val_loss_temp
            torch.save(net.state_dict(), "Unet2_model_" + leg + "_min_val_loss")  # save model
            min_model_epoch = epoch + 1

        disp = 'Epoch %d: Train loss: %.6f, Val loss: %.6f' % (epoch + 1, running_loss/count, val_loss_temp)
        write_2_log(disp)
        print(disp)
        val_loss.append(val_loss_temp)
        train_loss.append(running_loss/count); running_loss = 0.0

        if (epoch + 1) in model_saved:        # save checkpoint
            model_name = "Unet2_model_" + str(epoch+1) + "epoch_" + leg
            torch.save(net.state_dict(), model_name)  # save model
            Analysis.analysis(model_file = model_name, valloader = valloader)

    write_2_log("Best model at epoch: " + str(min_model_epoch))
    write_2_log("Total training time: " + str((time.time() - start_begining) / 3600.0))

    val_loss_file = "data/results" + "/val_loss_" + str(N_epoch) + "epoch_" + leg + ".npy"
    train_loss_file = "data/results" + "/training_loss_" + str(N_epoch) + "epoch_" + leg + ".npy"

    np.save(val_loss_file, val_loss)
    np.save(train_loss_file, train_loss)
    print("total processing time in seconds: ", time.time() - start_begining)
    print("total processing time in mins: ", (time.time() - start_begining) / 60.0)
    print("total processing time in hours: ", (time.time() - start_begining) / 3600.0)

    Analysis.analysis(model_file="Unet2_model_" + leg + "_min_val_loss", valloader=valloader)

    Analysis.PlotLoss(model_file = model_name, loss_train_path = train_loss_file, loss_val_path = val_loss_file, epoch_No = N_epoch)

    write_2_log(time.strftime("%c"))  # time, date of exp
===============import numpy as np
import torch.nn as nn
import torch
import cv2
from lcn import LecunLCN

LCN_enable = False

def input_filled_mirroring(x):      # fill missing data by mirroring the input image
    '''input size 636 --> output size 512'''
    w, h = x.shape
    e = 62  # extra width on 1 edge
    y = np.zeros((h + e * 2, w + e * 2))
    y[e:h + e, e:w + e] = x
    y[e:e + h, 0:e] = np.flip(y[e:e + h, e:2 * e], 1)  # flip vertically
    y[e:e + h, e + w:2 * e + w] = np.flip(y[e:e + h, w:e + w], 1)  # flip vertically
    y[0:e, 0:2 * e + w] = np.flip(y[e:2 * e, 0:2 * e + w], 0)  # flip horizontally
    y[e + h:2 * e + h, 0:2 * e + w] = np.flip(y[h:e + h, 0:2 * e + w], 0)  # flip horizontally
    return y

def nearest_cells_distance(pos, img):
    # searching in 8 directions to find 2 nearest distances to neighbor cells
    curr_value = img[pos]
    w = img.shape[0];h = img.shape[1]
    count_detect = 0  # detect 2 nearest neighbors. break the search if count_detect = 2
    x, y = pos

    # print("w,h: ", (w, h))
    d1 = 9999999;d2 = 9999999;d3 = 9999999;d4 = 9999999
    d5 = 9999999;d6 = 9999999;d7 = 9999999;d8 = 9999999
    for i in range(1, max(w, h)):
        # (x+1, y), (x+1, y+1), (x+1, y-1),
        # (x, y+1), (x, y-1)
        # (x-1, y), (x-1,y+1), (x-1,y-1),
        if x + i < w:
            if img[(x + i, y)] != curr_value and d1 == 9999999:
                d1 = i; count_detect += 1
            if y + i < h:
                if img[(x + i, y + i)] != curr_value and d2 == 9999999:
                    d2 = i; count_detect += 1
            elif y - i >= 0:
                if img[(x + i, y - i)] != curr_value and d3 == 9999999:
                    d3 = i; count_detect += 1
        if y + i < h:
            if img[(x, y + i)] != curr_value and d4 == 9999999:
                d4 = i; count_detect += 1
        if y - i >= 0:
            if img[(x, y - i)] != curr_value and d5 == 9999999:
                d5 = i; count_detect += 1
        if x - i >= 0:
            if img[(x - i, y)] != curr_value and d6 == 9999999:
                d6 = i; count_detect += 1
            if y + i < h:
                if img[(x - i, y + i)] != curr_value and d7 == 9999999:
                    d7 = i; count_detect += 1
            elif y - i >= 0:
                if img[(x - i, y - i)] != curr_value and d8 == 9999999:
                    d8 = i; count_detect += 1
        if count_detect >= 2: break

    d = [d1, d2, d3, d4, d5, d6, d7, d8]
    min_index = np.argmin(d)
    dist1 = d[min_index]
    d.remove(dist1)
    min_index = np.argmin(d)
    dist2 = d[min_index]
    return dist1, dist2

def create_weight_map(imgs_mask):
        print('-' * 30)
        print('Creating weights for masks ...')
        print('-' * 30)
        weight_map = np.ndarray(
            (len(imgs_mask), 1, np.shape(imgs_mask)[2], np.shape(imgs_mask)[3]), dtype=np.float32)
        w_0 = 10; sigma = 4
        imgs_w, imgs_h = np.shape(imgs_mask)[2], np.shape(imgs_mask)[3]
        total_pixels = imgs_w*imgs_h
        import time
        start = time.time()
        for i in range(len(imgs_mask)):
            if i%10 == 0: print("Done processing: %d images, time passed: %.2f mins" % (i, (time.time() - start)/60.0))
            temp = imgs_mask[i,0,:,:]
            w_border = 1 - np.sum(temp)/total_pixels        # w_c of pixel on the border (black)
            for m in range(imgs_w):
                for n in range(imgs_h):
                    # loop through all pixel of the mask
                    d1,d2 = nearest_cells_distance((m,n), temp)
                    w_c = w_border
                    if temp[m,n] == 0: w_c = 1 - w_border
                    weight_map[i,0,m,n] = w_c*5 + w_0*np.exp(-(d1 + d2)**2/(2*sigma**2))
                    # print("w_0*np.exp(): ", w_0*np.exp(-(d1 + d2)**2/(2*sigma**2)))
                    # print("w_border: ", w_border)

        np.save('data/dataset/weight_map_train.npy', weight_map)

        return weight_map

def load_train_data(npy_path = "data/dataset", hist_equal = False):

    print('-' * 30)
    print('load train images...')

    imgs_train = np.load(npy_path + "/imgs_train.npy")
    imgs_mask_train = np.load(npy_path + "/imgs_mask_train.npy")

    if hist_equal: imgs_train = hist_equalization(imgs_train)

    # weight_map_train = np.load(npy_path + "/weight_map_train.npy")
    # weight_map_train = weight_map_train.astype('float32')

    imgs_train = imgs_train.astype('float32')
    imgs_mask_train = imgs_mask_train.astype('float32')

    if LCN_enable:
        imgs_train = imgs_train.astype('float64')
        imgs_train = LecunLCN(imgs_train, image_shape=imgs_train.shape).output.eval()
        imgs_train = imgs_train.astype('float32')

    if not LCN_enable: imgs_train /= 255

    imgs_train -= imgs_train.mean(axis=0)
    imgs_mask_train /= 255
    imgs_mask_train[imgs_mask_train > 0.5] = 1
    imgs_mask_train[imgs_mask_train <= 0.5] = 0

    # weight_map_train = create_weight_map(imgs_mask_train)

    print("Done loading traing data")
    print('-' * 30)
    return imgs_train, imgs_mask_train

def load_val_data(npy_path = "data/dataset", hist_equal = True):

    print('-' * 30)
    print('load validation images...')

    imgs_train = np.load(npy_path + "/imgs_val.npy")
    imgs_mask_train = np.load(npy_path + "/imgs_mask_val.npy")

    if hist_equal: imgs_train = hist_equalization(imgs_train)

    imgs_train = imgs_train.astype('float32')
    imgs_mask_train = imgs_mask_train.astype('float32')

    if LCN_enable:
        imgs_train = imgs_train.astype('float64')
        imgs_train = LecunLCN(imgs_train, image_shape=imgs_train.shape).output.eval()
        imgs_train = imgs_train.astype('float32')

    if not LCN_enable: imgs_train /= 255
    imgs_train -= imgs_train.mean(axis=0)
    imgs_mask_train /= 255
    imgs_mask_train[imgs_mask_train > 0.5] = 1
    imgs_mask_train[imgs_mask_train <= 0.5] = 0
    print("Done loading validation data")
    print('-' * 30)
    return imgs_train, imgs_mask_train

def load_test_data(npy_path = "data/dataset", hist_equal = True):

    print('-' * 30)
    print('load test images...')

    imgs_test = np.load(npy_path + "/imgs_test.npy")

    if hist_equal: imgs_test = hist_equalization(imgs_test)

    imgs_test = imgs_test.astype('float32')

    if LCN_enable:
        imgs_test = imgs_test.astype('float64')
        imgs_test = LecunLCN(imgs_test, image_shape=imgs_test.shape).output.eval()
        imgs_test = imgs_test.astype('float32')

    if not LCN_enable: imgs_test /= 255

    imgs_test -= imgs_test.mean(axis=0)

    print("Done loading test data")
    print('-' * 30)
    return imgs_test

def load_val_5imgs(npy_path = "data/dataset"):
    print('-' * 30)
    print('load train images...')

    imgs_train = np.load(npy_path + "/imgs_val_5imgs.npy")
    imgs_mask_train = np.load(npy_path + "/imgs_mask_val_5imgs.npy")

    # imgs_train = hist_equalization(imgs_train)

    imgs_train = imgs_train.astype('float64')
    imgs_mask_train = imgs_mask_train.astype('float64')

    if LCN_enable: imgs_train = LecunLCN(imgs_train, image_shape=imgs_train.shape).output.eval()

    if not LCN_enable: imgs_train /= 255

    mean = imgs_train.mean(axis=0)
    imgs_train -= mean


    imgs_mask_train /= 255
    imgs_mask_train[imgs_mask_train > 0.5] = 1
    imgs_mask_train[imgs_mask_train <= 0.5] = 0

    # weight_map_train = self.create_weight_map(imgs_mask_train)

    print("Done loading traing data")
    print('-' * 30)
    return imgs_train, imgs_mask_train

def hist_equalization(inputs):      # inputs are uint8, 0-255, Nx1x636x636
    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))
    output = inputs.copy()
    for i in range(len(inputs)):
        img = inputs[i, 0, :, :]
        # res = cv2.equalizeHist(img)
        res = clahe.apply(img)
        output[i,0,:,:] = res
    return output

### BinaryCrossEntropyLoss2d().forward(logits, labels)
class BinaryCrossEntropyLoss2d(nn.Module):
    def __init__(self, weight=None, size_average=True):
        """
        Binary cross entropy loss 2D
        Args:
            weight:
            size_average:
        """
        super(BinaryCrossEntropyLoss2d, self).__init__()
        self.bce_loss = nn.BCELoss(weight, size_average)

    def forward(self, logits, targets):
        # probs = F.sigmoid(logits)
        probs = logits
        probs_flat = probs.view(-1)  # Flatten
        targets_flat = targets.view(-1)  # Flatten
        return self.bce_loss(probs_flat, targets_flat)      # (output, labels)

class BCE_with_Weights(nn.Module):
    def __init__(self, weights=None):
        """
        Binary cross entropy loss 2D
        Args:
            weights:
        """
        super(BCE_with_Weights, self).__init__()
        self.weights = weights

    def forward(self, output, target):
        if self.weights is not None:
            loss = self.weights * (target * torch.log(output) + (1 - target) * torch.log(1 - output))
        else:
            loss = target * torch.log(output) + (1 - target) * torch.log(1 - output)

        return torch.neg(torch.mean(loss))

class LRN(nn.Module):       # input x is Torch tensor
    def __init__(self, local_size=1, alpha=1.0, beta=0.75, ACROSS_CHANNELS=False):      #LRN(local_size=5, alpha=0.0001, beta=0.75),
        super(LRN, self).__init__()
        self.ACROSS_CHANNELS = ACROSS_CHANNELS
        if self.ACROSS_CHANNELS:
            self.average = nn.AvgPool3d(kernel_size=(local_size, 1, 1),
                                        stride=1, padding=(int((local_size - 1.0) / 2), 0, 0))
        else:
            self.average = nn.AvgPool2d(kernel_size=local_size,
                                        stride=1, padding=int((local_size - 1.0) / 2))
        self.alpha = alpha
        self.beta = beta

    def forward(self, x):
        if self.ACROSS_CHANNELS:
            div = x.pow(2).unsqueeze(1)
            div = self.average(div).squeeze(1)
            div = div.mul(self.alpha).add(1.0).pow(self.beta)
        else:
            div = x.pow(2)
            div = self.average(div)
            div = div.mul(self.alpha).add(1.0).pow(self.beta)
        x = x.div(div)
        return x


Sat Nov 18 14:06:33 2017
Leg14_dropout_0_2_rmSigmoid_40aug_10ela_3inten_reflect
optim.SGD(net.parameters(), lr=1e-2, momentum=0.99)
Number of epoch max: 12
Epoch 1: Train loss: 0.195845, Val loss: 0.304446
Epoch 2: Train loss: 0.130290, Val loss: 0.341674
Unet2_model_2epoch_Leg14_dropout_0_2_rmSigmoid_40aug_10ela_3inten_reflect
Precision: 0.97117 
Recall: 0.92008 
F1_measure: 0.94494 
iou: 0.88640
Epoch 3: Train loss: 0.100043, Val loss: 0.356262
Epoch 4: Train loss: 0.084887, Val loss: 0.406230
Unet2_model_4epoch_Leg14_dropout_0_2_rmSigmoid_40aug_10ela_3inten_reflect
Precision: 0.97194 
Recall: 0.93197 
F1_measure: 0.95154 
iou: 0.89659
Epoch 5: Train loss: 0.075469, Val loss: 0.431983
Epoch 6: Train loss: 0.069268, Val loss: 0.444523
Unet2_model_6epoch_Leg14_dropout_0_2_rmSigmoid_40aug_10ela_3inten_reflect
Precision: 0.97275 
Recall: 0.92412 
F1_measure: 0.94781 
iou: 0.89195
Epoch 7: Train loss: 0.064697, Val loss: 0.457176
==========================================================================================
Sun Nov 19 01:48:48 2017
Leg14_dropout_0_2_rmSigmoid_40aug_10ela_3inten_reflect
Sun Nov 19 01:48:41 2017
import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.autograd import Variable
import math


class ConvBnRelu(nn.Module):
    def __init__(self, in_channels, out_channels, kernel_size, padding, stride):
        super(ConvBnRelu, self).__init__()
        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=kernel_size, padding=padding, stride=stride)
        self.bn = nn.BatchNorm2d(out_channels)
        self.relu = nn.ReLU()

    def forward(self, x):
        x = self.conv(x)
        # x = self.bn(x)
        x = self.relu(x)
        return x


class StackEncoder(nn.Module):
    def __init__(self, in_channels, out_channels):
        super(StackEncoder, self).__init__()
        self.convr1 = ConvBnRelu(in_channels, out_channels, kernel_size=(3, 3), stride=1, padding=0)
        self.convr2 = ConvBnRelu(out_channels, out_channels, kernel_size=(3, 3), stride=1, padding=0)
        self.maxPool = nn.MaxPool2d(kernel_size=(2, 2), stride=2)

    def forward(self, x):
        x = self.convr1(x)
        x = self.convr2(x)
        x_trace = x             # save x to use in concat in the Decoder path
        out = self.maxPool(x)
        return out, x_trace


class StackDecoder(nn.Module):
    def __init__(self, in_channels, out_channels, upsample_size, padding, drop_out=False):
        super(StackDecoder, self).__init__()

        self.drop_out = drop_out
        self.dropout_layer = nn.Dropout2d(p=0.5)

        ''' this is old version
        self.upSample = nn.Upsample(size=upsample_size, scale_factor=(2, 2), mode="bilinear")
        self.convr1 = ConvBnRelu(in_channels, out_channels, kernel_size=(3, 3), stride=1, padding=padding)
        # Crop + concat step between these 2
        self.convr2 = ConvBnRelu(in_channels, out_channels, kernel_size=(3, 3), stride=1, padding=padding)
        '''
        self.upSample = nn.ConvTranspose2d(in_channels, out_channels, 2, stride=2)
        self.convr1 = ConvBnRelu(in_channels, out_channels, kernel_size=(3, 3), stride=1, padding=padding)
        self.convr2 = ConvBnRelu(out_channels, out_channels, kernel_size=(3, 3), stride=1, padding=padding)

    def _crop_concat(self, upsampled, bypass):
        """
         Crop y to the (h, w) of x and concat them.
         Used for the expansive path.
        Returns:
            The concatenated tensor
        """
        c = (bypass.size()[2] - upsampled.size()[2]) // 2
        bypass = F.pad(bypass, (-c, -c, -c, -c))

        return torch.cat((bypass, upsampled), 1)

    def forward(self, x, down_tensor):
        '''old version
        x = self.upSample(x)
        x = self.convr1(x)
        x = self._crop_concat(x, down_tensor)
        x = self.convr2(x)
        '''

        x = self.upSample(x)
        x = self._crop_concat(x, down_tensor)
        x = self.convr1(x)
        if self.drop_out: x = self.dropout_layer(x)
        x = self.convr2(x)
        if self.drop_out: x = self.dropout_layer(x)
        return x


class UNet_BN(nn.Module):
    def __init__(self):
        super(UNet_BN, self).__init__()
        # channels, height, width = in_shape

        # self.dropout = dropout

        self.model_code = ""        # variable to save model and main function when loaded

        self.down1 = StackEncoder(1, 64)
        self.down2 = StackEncoder(64, 128)
        self.down3 = StackEncoder(128, 256)
        self.down4 = StackEncoder(256, 512)

        self.center = nn.Sequential(
            # nn.Dropout2d(p=0.2),
            ConvBnRelu(512, 1024, kernel_size=(3, 3), stride=1, padding=0),
            nn.Dropout2d(p=0.2),
            ConvBnRelu(1024, 1024, kernel_size=(3, 3), stride=1, padding=0),
            nn.Dropout2d(p=0.2)
        )

        self.up1 = StackDecoder(in_channels=1024, out_channels=512, upsample_size=(64,64), padding = 1)
        self.up2 = StackDecoder(in_channels=512, out_channels=256, upsample_size=(128,128), padding = 1)
        self.up3 = StackDecoder(in_channels=256, out_channels=128, upsample_size=(256,256), padding = 1)
        self.up4 = StackDecoder(in_channels=128, out_channels=64, upsample_size=(512,512), padding = 1)

        # 1x1 convolution at the last layer
        # Different from the paper is the output size here
        self.output_seg_map = nn.Conv2d(64, 1, kernel_size=(1, 1), padding=0, stride=1)

        self._initialize_weights()

    def forward(self, x):
        x, x_trace1 = self.down1(x)
        x, x_trace2 = self.down2(x)
        x, x_trace3 = self.down3(x)
        x, x_trace4 = self.down4(x)
        x = self.center(x)
        x = self.up1(x, x_trace4)
        x = self.up2(x, x_trace3)
        x = self.up3(x, x_trace2)
        x = self.up4(x, x_trace1)

        x = self.output_seg_map(x)
        # x = F.sigmoid(x)
        # out = torch.squeeze(out, dim=1)
        return x


    def _initialize_weights(self):
        for m in self.modules():
            if isinstance(m, nn.Conv2d):
                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels
                m.weight.data.normal_(0, math.sqrt(2. / n))
                if m.bias is not None:
                    m.bias.data.zero_()
            elif isinstance(m, nn.BatchNorm2d):
                m.weight.data.fill_(1)
                m.bias.data.zero_()

# x = Variable(torch.randn(1,1,636,636))       # simulate input image
# net = UNet_BN()
# out = net(x)
# print("input: ", x)
# print("output: ", out)

===============from __future__ import print_function, division
import torch
from torch import optim
from torch.autograd import Variable
from torch.utils.data import DataLoader
import numpy as np
import torch.nn as nn
import torch.nn.functional as F
import Unet
import Unet_BatchNorm
import tifffile as tiff
import Utils
import time
from sklearn.metrics import average_precision_score, recall_score, f1_score
import Analysis

def to_var(x):
    if torch.cuda.is_available():
        return Variable(x.cuda())
    else:
        return Variable(x)

### BinaryCrossEntropyLoss2d().forward(logits, labels)
class BinaryCrossEntropyLoss2d(nn.Module):
    def __init__(self, weight=None, size_average=True):
        """
        Binary cross entropy loss 2D
        Args:
            weight:
            size_average:
        """
        super(BinaryCrossEntropyLoss2d, self).__init__()
        self.bce_loss = nn.BCELoss(weight, size_average)

    def forward(self, probs, targets):
        probs = F.sigmoid(probs)
        probs_flat = probs.view(-1)  # Flatten
        targets_flat = targets.view(-1)  # Flatten
        return self.bce_loss(probs_flat, targets_flat)      # (output, labels)

class SoftDiceLoss(nn.Module):
    def __init__(self, weight=None, size_average=True):
        super(SoftDiceLoss, self).__init__()

    def forward(self, probs, targets):
        smooth = 1
        num = targets.size(0)
        probs = F.sigmoid(probs)
        m1 = probs.view(num, -1)
        m2 = targets.view(num, -1)
        intersection = (m1 * m2)
        score = 2. * (intersection.sum(1) + smooth) / (m1.sum(1) + m2.sum(1) + smooth)
        score = 1 - score.sum() / num
        return score

def _criterion(logits, labels):
    return BinaryCrossEntropyLoss2d().forward(logits, labels) + \
        SoftDiceLoss().forward(logits, labels)

def NetEval(net,valdata_loader,crit):
    loss = 0.
    count = 0
    net.eval()
    for i,data in enumerate(valdata_loader,0):
        inputs, labels = data
        inputs, labels = to_var(inputs), to_var(labels)
        out = net(inputs)
        l = crit(out, labels)
        loss += l.data[0]
        count += 1
    return loss/count

# calculate Precision, Recall, F1-measure, IoU over the validation set
def Net_performace_val(net,valdata_loader):
    precision_list = []
    recall_list = []
    iou_list = []
    net.eval()
    print("len of valdata: ", len(valdata_loader))
    for i,data in enumerate(valdata_loader,0):

        inputs, labels = data
        out = NetPredict(net, inputs)   # out is numpy array 512x512
        labels = labels.numpy()
        labels = labels[0,0,:,:]        # labels is numpy array 512x512
        # remove the case where the mask is plain black
        if np.sum(labels) < 0.01*np.shape(labels)[0]*np.shape(labels)[1]: continue

        precision = average_precision_score(labels, out)
        recall = recall_score(labels, out, average='weighted')
        iou = IoU(out, labels)
        precision_list.append(precision)
        recall_list.append(recall)
        iou_list.append(iou)

    precision, recall, iou = np.mean(precision_list), np.mean(recall_list), np.mean(iou_list)
    F1_measure = 2.0*precision*recall/(precision + recall)

    return precision, recall, F1_measure, iou

# calculate IoU
def IoU(pred, target):
    # Ignore IoU for background class
    cls = 0.5
    pred_inds = pred > cls
    target_inds = target > cls

    intersection = (pred_inds[target_inds]).sum()  # Cast to long to prevent overflows
    union = pred_inds.sum() + target_inds.sum() - intersection
    if union == 0:
        ious = float('nan')  # If there is no ground truth, do not include in evaluation
    else:
        ious = 1.0*intersection / max(union, 1)
    return ious

#process the test data and save to separate .tif image
def NetTest(net,testdata_loader,path = "data/results/"):
    net.eval()
    for i, data in enumerate(testdata_loader, 0):
        if i >= 30: return 1        # for debug
        data = to_var(data)
        out = net(data)

        out = F.sigmoid(out)

        imgname = path + str(i) + ".tif"
        img = out.cpu()
        img = img[0,0,:,:]
        img = img.data.numpy()
        img_shape = img.shape
        img = img.reshape(-1)
        img[img < 0.5] = 0; img[img >= 0.5] = 1
        img = img.reshape(img_shape)
        img = np.uint8(img * 255)
        tiff.imsave(imgname, img)

# return input image size like 512x512, numpy array
def NetPredict(net, data):
    net.eval()
    data = to_var(data)
    out = net(data)

    out = F.sigmoid(out)

    img = out.cpu()
    img = img[0, 0, :, :]
    img = img.data.numpy()
    img_shape = img.shape
    img = img.reshape(-1)
    img[img < 0.5] = 0;
    img[img >= 0.5] = 1
    img = img.reshape(img_shape)
    return img
def write_2_log(content):
    path = "log_file.txt"
    output = open(path, "a")
    output.write("\n")
    output.write(content)
    output.close()

if __name__ == '__main__':
    '''subjects to change for each exp:
    + path to the dataset
    + opt function
    + leg description
    + N_epoch
    + saved_model
    '''
    start_begining = time.time()

    # path = "data/dataset"
    path = "/home/anhxtuan/HanLe/dataset/40aug_10ela_3inten_reflect"

    import os
    print("Does the folder exist?: ", os.path.isdir(path))
    print("Does the path exist?: ", os.path.exists(path))

    # imgs_train, imgs_mask_train = Utils.load_train_data(npy_path=path)
    # trainset = zip(imgs_train, imgs_mask_train)
    # trainloader = torch.utils.data.DataLoader(trainset, batch_size=1,
    #                                           shuffle=True, num_workers=2)

    imgs_val, imgs_mask_val = Utils.load_val_data(npy_path=path)
    valset = zip(imgs_val, imgs_mask_val)
    valloader = torch.utils.data.DataLoader(valset, batch_size=1,
                                              shuffle=False, num_workers=2)
    # net = Unet.UNet()                     # Unet 1
    net = Unet_BatchNorm.UNet_BN()          # Unet 2 with batchNorm

    f1 = open("Unet_BatchNorm.py", 'r')     # embede code into the model to be saved later
    f2 = open("UnetTrain.py", 'r')
    f3 = open("Utils.py", 'r')
    model_notes = time.strftime("%c") + "\n" + f1.read() + "\n" + "==="*5 + f2.read() + "\n" + "==="*5 + f3.read()
    f1.close()
    f2.close()

    criterion = BinaryCrossEntropyLoss2d()
    # criterion = SoftDiceLoss()
    # criterion = nn.BCELoss()

    if torch.cuda.is_available():
        torch.set_default_tensor_type('torch.cuda.FloatTensor')
        net.load_state_dict(torch.load("Unet2_model_6epoch_Leg14_dropout_0_2_rmSigmoid_40aug_10ela_3inten_reflect"))
        net.cuda()
        # criterion.cuda()

    opt = optim.SGD(net.parameters(), lr=1e-2, momentum=0.99)       # subject to change
    # opt = optim.RMSprop(net.parameters(), lr=2e-4)
    # RMSprop[22](learning rate 0.001) with weight decay set to 0.001.
    # opt = optim.Adam(net.parameters(), lr=1e-3, weight_decay=1e-4)

    train_loss = []
    val_loss = []

    print("[epoch, #image] Loss")
    leg = "Leg14_dropout_0_2_rmSigmoid_40aug_10ela_3inten_reflect"
    print("Processing: ", leg)
    model_name = ""

    N_epoch = 6
    model_saved = np.arange(2,N_epoch+1,2)
    val_loss_min = 100

    write_2_log("==="*30)
    write_2_log(time.strftime("%c"))       # time, date of exp
    write_2_log(leg)
    write_2_log(model_notes)
    write_2_log(time.strftime("%c"))  # time, date of exp
    write_2_log(leg)
    write_2_log("optim.SGD(net.parameters(), lr=1e-2, momentum=0.99)")
    write_2_log("Number of epoch max: " + str(N_epoch))

    min_model_epoch = 0
    for epoch in range(N_epoch):
        running_loss = 0.0; count = 0
        net.train()

        N_files = 5
        for j in range(N_files):
            if N_files > 1:
                train_file = "/imgs_train_" + str(j + 1) + ".npy"
                mask_file = "/imgs_mask_train_" + str(j + 1) + ".npy"
            else:
                train_file = "/imgs_train.npy"
                mask_file = "/imgs_mask_train.npy"

            imgs_train, imgs_mask_train = Utils.load_train_data(npy_path=path, train_file=train_file, mask_file=mask_file)
            trainset = zip(imgs_train, imgs_mask_train)
            trainloader = torch.utils.data.DataLoader(trainset, batch_size=1,
                                                      shuffle=True, num_workers=2)
            for i, data in enumerate(trainloader, 0):
                inputs, labels = data
                temp = labels.numpy()
                temp = temp[0, 0, :, :]  # labels is numpy array 512x512
                # remove the case where the mask is plain black
                if np.sum(temp) < 0.01 * np.shape(temp)[0] * np.shape(temp)[1]: continue
                inputs, labels = to_var(inputs), to_var(labels)
                opt.zero_grad()
                out = net(inputs)
                loss = criterion(out, labels)
                loss.backward()
                opt.step()
                running_loss += loss.data[0]
                count += 1

        net.eval()
        val_loss_temp = NetEval(net, valloader, criterion)
        if epoch > 0 and val_loss_temp < val_loss_min:        # save the model which has the lowest val_loss, ignore first epoch
            val_loss_min = val_loss_temp
            torch.save(net.state_dict(), "Unet2_model_" + leg + "_min_val_loss")  # save model
            min_model_epoch = epoch + 1

        disp = 'Epoch %d: Train loss: %.6f, Val loss: %.6f' % (epoch + 1, running_loss/count, val_loss_temp)
        write_2_log(disp)
        print(disp)
        val_loss.append(val_loss_temp)
        train_loss.append(running_loss/count); running_loss = 0.0

        if (epoch + 1) in model_saved:        # save checkpoint
            model_name = "Unet2_model_" + str(epoch+1+6) + "epoch_" + leg
            torch.save(net.state_dict(), model_name)  # save model
            Analysis.analysis(model_file = model_name, valloader = valloader)

    write_2_log("Best model at epoch: " + str(min_model_epoch))
    write_2_log("Total training time: " + str((time.time() - start_begining) / 3600.0))

    val_loss_file = "data/results" + "/val_loss_" + str(N_epoch) + "epoch_" + leg + ".npy"
    train_loss_file = "data/results" + "/training_loss_" + str(N_epoch) + "epoch_" + leg + ".npy"

    np.save(val_loss_file, val_loss)
    np.save(train_loss_file, train_loss)
    print("total processing time in seconds: ", time.time() - start_begining)
    print("total processing time in mins: ", (time.time() - start_begining) / 60.0)
    print("total processing time in hours: ", (time.time() - start_begining) / 3600.0)

    Analysis.analysis(model_file="Unet2_model_" + leg + "_min_val_loss", valloader=valloader)

    Analysis.PlotLoss(model_file = model_name, loss_train_path = train_loss_file, loss_val_path = val_loss_file, epoch_No = N_epoch)

    write_2_log(time.strftime("%c"))  # time, date of exp
===============import numpy as np
import torch.nn as nn
import torch
import cv2
from lcn import LecunLCN

LCN_enable = False

def input_filled_mirroring(x):      # fill missing data by mirroring the input image
    '''input size 636 --> output size 512'''
    w, h = x.shape
    e = 62  # extra width on 1 edge
    y = np.zeros((h + e * 2, w + e * 2))
    y[e:h + e, e:w + e] = x
    y[e:e + h, 0:e] = np.flip(y[e:e + h, e:2 * e], 1)  # flip vertically
    y[e:e + h, e + w:2 * e + w] = np.flip(y[e:e + h, w:e + w], 1)  # flip vertically
    y[0:e, 0:2 * e + w] = np.flip(y[e:2 * e, 0:2 * e + w], 0)  # flip horizontally
    y[e + h:2 * e + h, 0:2 * e + w] = np.flip(y[h:e + h, 0:2 * e + w], 0)  # flip horizontally
    return y

def nearest_cells_distance(pos, img):
    # searching in 8 directions to find 2 nearest distances to neighbor cells
    curr_value = img[pos]
    w = img.shape[0];h = img.shape[1]
    count_detect = 0  # detect 2 nearest neighbors. break the search if count_detect = 2
    x, y = pos

    # print("w,h: ", (w, h))
    d1 = 9999999;d2 = 9999999;d3 = 9999999;d4 = 9999999
    d5 = 9999999;d6 = 9999999;d7 = 9999999;d8 = 9999999
    for i in range(1, max(w, h)):
        # (x+1, y), (x+1, y+1), (x+1, y-1),
        # (x, y+1), (x, y-1)
        # (x-1, y), (x-1,y+1), (x-1,y-1),
        if x + i < w:
            if img[(x + i, y)] != curr_value and d1 == 9999999:
                d1 = i; count_detect += 1
            if y + i < h:
                if img[(x + i, y + i)] != curr_value and d2 == 9999999:
                    d2 = i; count_detect += 1
            elif y - i >= 0:
                if img[(x + i, y - i)] != curr_value and d3 == 9999999:
                    d3 = i; count_detect += 1
        if y + i < h:
            if img[(x, y + i)] != curr_value and d4 == 9999999:
                d4 = i; count_detect += 1
        if y - i >= 0:
            if img[(x, y - i)] != curr_value and d5 == 9999999:
                d5 = i; count_detect += 1
        if x - i >= 0:
            if img[(x - i, y)] != curr_value and d6 == 9999999:
                d6 = i; count_detect += 1
            if y + i < h:
                if img[(x - i, y + i)] != curr_value and d7 == 9999999:
                    d7 = i; count_detect += 1
            elif y - i >= 0:
                if img[(x - i, y - i)] != curr_value and d8 == 9999999:
                    d8 = i; count_detect += 1
        if count_detect >= 2: break

    d = [d1, d2, d3, d4, d5, d6, d7, d8]
    min_index = np.argmin(d)
    dist1 = d[min_index]
    d.remove(dist1)
    min_index = np.argmin(d)
    dist2 = d[min_index]
    return dist1, dist2

def create_weight_map(imgs_mask):
        print('-' * 30)
        print('Creating weights for masks ...')
        print('-' * 30)
        weight_map = np.ndarray(
            (len(imgs_mask), 1, np.shape(imgs_mask)[2], np.shape(imgs_mask)[3]), dtype=np.float32)
        w_0 = 10; sigma = 4
        imgs_w, imgs_h = np.shape(imgs_mask)[2], np.shape(imgs_mask)[3]
        total_pixels = imgs_w*imgs_h
        import time
        start = time.time()
        for i in range(len(imgs_mask)):
            if i%10 == 0: print("Done processing: %d images, time passed: %.2f mins" % (i, (time.time() - start)/60.0))
            temp = imgs_mask[i,0,:,:]
            w_border = 1 - np.sum(temp)/total_pixels        # w_c of pixel on the border (black)
            for m in range(imgs_w):
                for n in range(imgs_h):
                    # loop through all pixel of the mask
                    d1,d2 = nearest_cells_distance((m,n), temp)
                    w_c = w_border
                    if temp[m,n] == 0: w_c = 1 - w_border
                    weight_map[i,0,m,n] = w_c*5 + w_0*np.exp(-(d1 + d2)**2/(2*sigma**2))
                    # print("w_0*np.exp(): ", w_0*np.exp(-(d1 + d2)**2/(2*sigma**2)))
                    # print("w_border: ", w_border)

        np.save('data/dataset/weight_map_train.npy', weight_map)

        return weight_map

def load_train_data(npy_path = "data/dataset", train_file = "/imgs_train.npy", mask_file = "/imgs_mask_train.npy", hist_equal = False):

    print('-' * 30)
    print('load train images...')

    imgs_train = np.load(npy_path + train_file)
    imgs_mask_train = np.load(npy_path + mask_file)

    if hist_equal: imgs_train = hist_equalization(imgs_train)

    # weight_map_train = np.load(npy_path + "/weight_map_train.npy")
    # weight_map_train = weight_map_train.astype('float32')

    imgs_train = imgs_train.astype('float32')
    imgs_mask_train = imgs_mask_train.astype('float32')

    if LCN_enable:
        imgs_train = imgs_train.astype('float64')
        imgs_train = LecunLCN(imgs_train, image_shape=imgs_train.shape).output.eval()
        imgs_train = imgs_train.astype('float32')

    if not LCN_enable: imgs_train /= 255

    imgs_train -= imgs_train.mean(axis=0)
    imgs_mask_train /= 255
    imgs_mask_train[imgs_mask_train > 0.5] = 1
    imgs_mask_train[imgs_mask_train <= 0.5] = 0

    # weight_map_train = create_weight_map(imgs_mask_train)

    print("Done loading traing data")
    print('-' * 30)
    return imgs_train, imgs_mask_train

def load_val_data(npy_path = "data/dataset", hist_equal = True):

    print('-' * 30)
    print('load validation images...')

    imgs_train = np.load(npy_path + "/imgs_val.npy")
    imgs_mask_train = np.load(npy_path + "/imgs_mask_val.npy")

    if hist_equal: imgs_train = hist_equalization(imgs_train)

    imgs_train = imgs_train.astype('float32')
    imgs_mask_train = imgs_mask_train.astype('float32')

    if LCN_enable:
        imgs_train = imgs_train.astype('float64')
        imgs_train = LecunLCN(imgs_train, image_shape=imgs_train.shape).output.eval()
        imgs_train = imgs_train.astype('float32')

    if not LCN_enable: imgs_train /= 255
    imgs_train -= imgs_train.mean(axis=0)
    imgs_mask_train /= 255
    imgs_mask_train[imgs_mask_train > 0.5] = 1
    imgs_mask_train[imgs_mask_train <= 0.5] = 0
    print("Done loading validation data")
    print('-' * 30)
    return imgs_train, imgs_mask_train

def load_test_data(npy_path = "data/dataset", hist_equal = True):

    print('-' * 30)
    print('load test images...')

    imgs_test = np.load(npy_path + "/imgs_test.npy")

    if hist_equal: imgs_test = hist_equalization(imgs_test)

    imgs_test = imgs_test.astype('float32')

    if LCN_enable:
        imgs_test = imgs_test.astype('float64')
        imgs_test = LecunLCN(imgs_test, image_shape=imgs_test.shape).output.eval()
        imgs_test = imgs_test.astype('float32')

    if not LCN_enable: imgs_test /= 255

    imgs_test -= imgs_test.mean(axis=0)

    print("Done loading test data")
    print('-' * 30)
    return imgs_test

def load_val_5imgs(npy_path = "data/dataset"):
    print('-' * 30)
    print('load train images...')

    imgs_train = np.load(npy_path + "/imgs_val_5imgs.npy")
    imgs_mask_train = np.load(npy_path + "/imgs_mask_val_5imgs.npy")

    # imgs_train = hist_equalization(imgs_train)

    imgs_train = imgs_train.astype('float64')
    imgs_mask_train = imgs_mask_train.astype('float64')

    if LCN_enable: imgs_train = LecunLCN(imgs_train, image_shape=imgs_train.shape).output.eval()

    if not LCN_enable: imgs_train /= 255

    mean = imgs_train.mean(axis=0)
    imgs_train -= mean


    imgs_mask_train /= 255
    imgs_mask_train[imgs_mask_train > 0.5] = 1
    imgs_mask_train[imgs_mask_train <= 0.5] = 0

    # weight_map_train = self.create_weight_map(imgs_mask_train)

    print("Done loading traing data")
    print('-' * 30)
    return imgs_train, imgs_mask_train

def hist_equalization(inputs):      # inputs are uint8, 0-255, Nx1x636x636
    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))
    output = inputs.copy()
    for i in range(len(inputs)):
        img = inputs[i, 0, :, :]
        # res = cv2.equalizeHist(img)
        res = clahe.apply(img)
        output[i,0,:,:] = res
    return output

### BinaryCrossEntropyLoss2d().forward(logits, labels)
class BinaryCrossEntropyLoss2d(nn.Module):
    def __init__(self, weight=None, size_average=True):
        """
        Binary cross entropy loss 2D
        Args:
            weight:
            size_average:
        """
        super(BinaryCrossEntropyLoss2d, self).__init__()
        self.bce_loss = nn.BCELoss(weight, size_average)

    def forward(self, logits, targets):
        # probs = F.sigmoid(logits)
        probs = logits
        probs_flat = probs.view(-1)  # Flatten
        targets_flat = targets.view(-1)  # Flatten
        return self.bce_loss(probs_flat, targets_flat)      # (output, labels)

class BCE_with_Weights(nn.Module):
    def __init__(self, weights=None):
        """
        Binary cross entropy loss 2D
        Args:
            weights:
        """
        super(BCE_with_Weights, self).__init__()
        self.weights = weights

    def forward(self, output, target):
        if self.weights is not None:
            loss = self.weights * (target * torch.log(output) + (1 - target) * torch.log(1 - output))
        else:
            loss = target * torch.log(output) + (1 - target) * torch.log(1 - output)

        return torch.neg(torch.mean(loss))

class LRN(nn.Module):       # input x is Torch tensor
    def __init__(self, local_size=1, alpha=1.0, beta=0.75, ACROSS_CHANNELS=False):      #LRN(local_size=5, alpha=0.0001, beta=0.75),
        super(LRN, self).__init__()
        self.ACROSS_CHANNELS = ACROSS_CHANNELS
        if self.ACROSS_CHANNELS:
            self.average = nn.AvgPool3d(kernel_size=(local_size, 1, 1),
                                        stride=1, padding=(int((local_size - 1.0) / 2), 0, 0))
        else:
            self.average = nn.AvgPool2d(kernel_size=local_size,
                                        stride=1, padding=int((local_size - 1.0) / 2))
        self.alpha = alpha
        self.beta = beta

    def forward(self, x):
        if self.ACROSS_CHANNELS:
            div = x.pow(2).unsqueeze(1)
            div = self.average(div).squeeze(1)
            div = div.mul(self.alpha).add(1.0).pow(self.beta)
        else:
            div = x.pow(2)
            div = self.average(div)
            div = div.mul(self.alpha).add(1.0).pow(self.beta)
        x = x.div(div)
        return x


Sun Nov 19 01:48:48 2017
Leg14_dropout_0_2_rmSigmoid_40aug_10ela_3inten_reflect
optim.SGD(net.parameters(), lr=1e-2, momentum=0.99)
Number of epoch max: 6
Epoch 1: Train loss: 0.063609, Val loss: 0.461171
Epoch 2: Train loss: 0.060487, Val loss: 0.487378
Unet2_model_8epoch_Leg14_dropout_0_2_rmSigmoid_40aug_10ela_3inten_reflect
Precision: 0.97282 
Recall: 0.91764 
F1_measure: 0.94443 
iou: 0.88727
Epoch 3: Train loss: 0.057708, Val loss: 0.496378
Epoch 4: Train loss: 0.055494, Val loss: 0.535181
Unet2_model_10epoch_Leg14_dropout_0_2_rmSigmoid_40aug_10ela_3inten_reflect
Precision: 0.97226 
Recall: 0.92236 
F1_measure: 0.94665 
iou: 0.88988
Epoch 5: Train loss: 0.053505, Val loss: 0.541860
Epoch 6: Train loss: 0.051860, Val loss: 0.592951
Unet2_model_12epoch_Leg14_dropout_0_2_rmSigmoid_40aug_10ela_3inten_reflect
Precision: 0.97200 
Recall: 0.92214 
F1_measure: 0.94641 
iou: 0.88925
Best model at epoch: 2
Total training time: 4.98387339135
Unet2_model_Leg14_dropout_0_2_rmSigmoid_40aug_10ela_3inten_reflect_min_val_loss
Precision: 0.97282 
Recall: 0.91764 
F1_measure: 0.94443 
iou: 0.88727
Sun Nov 19 06:59:41 2017
==========================================================================================
Sun Nov 19 07:01:15 2017
Leg15_DICE_dropout_0_2_rmSigmoid_40aug_10ela_3inten_reflect
Sun Nov 19 07:01:13 2017
import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.autograd import Variable
import math


class ConvBnRelu(nn.Module):
    def __init__(self, in_channels, out_channels, kernel_size, padding, stride):
        super(ConvBnRelu, self).__init__()
        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=kernel_size, padding=padding, stride=stride)
        self.bn = nn.BatchNorm2d(out_channels)
        self.relu = nn.ReLU()

    def forward(self, x):
        x = self.conv(x)
        # x = self.bn(x)
        x = self.relu(x)
        return x


class StackEncoder(nn.Module):
    def __init__(self, in_channels, out_channels):
        super(StackEncoder, self).__init__()
        self.convr1 = ConvBnRelu(in_channels, out_channels, kernel_size=(3, 3), stride=1, padding=0)
        self.convr2 = ConvBnRelu(out_channels, out_channels, kernel_size=(3, 3), stride=1, padding=0)
        self.maxPool = nn.MaxPool2d(kernel_size=(2, 2), stride=2)

    def forward(self, x):
        x = self.convr1(x)
        x = self.convr2(x)
        x_trace = x             # save x to use in concat in the Decoder path
        out = self.maxPool(x)
        return out, x_trace


class StackDecoder(nn.Module):
    def __init__(self, in_channels, out_channels, upsample_size, padding, drop_out=False):
        super(StackDecoder, self).__init__()

        self.drop_out = drop_out
        self.dropout_layer = nn.Dropout2d(p=0.5)

        ''' this is old version
        self.upSample = nn.Upsample(size=upsample_size, scale_factor=(2, 2), mode="bilinear")
        self.convr1 = ConvBnRelu(in_channels, out_channels, kernel_size=(3, 3), stride=1, padding=padding)
        # Crop + concat step between these 2
        self.convr2 = ConvBnRelu(in_channels, out_channels, kernel_size=(3, 3), stride=1, padding=padding)
        '''
        self.upSample = nn.ConvTranspose2d(in_channels, out_channels, 2, stride=2)
        self.convr1 = ConvBnRelu(in_channels, out_channels, kernel_size=(3, 3), stride=1, padding=padding)
        self.convr2 = ConvBnRelu(out_channels, out_channels, kernel_size=(3, 3), stride=1, padding=padding)

    def _crop_concat(self, upsampled, bypass):
        """
         Crop y to the (h, w) of x and concat them.
         Used for the expansive path.
        Returns:
            The concatenated tensor
        """
        c = (bypass.size()[2] - upsampled.size()[2]) // 2
        bypass = F.pad(bypass, (-c, -c, -c, -c))

        return torch.cat((bypass, upsampled), 1)

    def forward(self, x, down_tensor):
        '''old version
        x = self.upSample(x)
        x = self.convr1(x)
        x = self._crop_concat(x, down_tensor)
        x = self.convr2(x)
        '''

        x = self.upSample(x)
        x = self._crop_concat(x, down_tensor)
        x = self.convr1(x)
        if self.drop_out: x = self.dropout_layer(x)
        x = self.convr2(x)
        if self.drop_out: x = self.dropout_layer(x)
        return x


class UNet_BN(nn.Module):
    def __init__(self):
        super(UNet_BN, self).__init__()
        # channels, height, width = in_shape

        # self.dropout = dropout

        self.model_code = ""        # variable to save model and main function when loaded

        self.down1 = StackEncoder(1, 64)
        self.down2 = StackEncoder(64, 128)
        self.down3 = StackEncoder(128, 256)
        self.down4 = StackEncoder(256, 512)

        self.center = nn.Sequential(
            # nn.Dropout2d(p=0.2),
            ConvBnRelu(512, 1024, kernel_size=(3, 3), stride=1, padding=0),
            nn.Dropout2d(p=0.2),
            ConvBnRelu(1024, 1024, kernel_size=(3, 3), stride=1, padding=0),
            nn.Dropout2d(p=0.2)
        )

        self.up1 = StackDecoder(in_channels=1024, out_channels=512, upsample_size=(64,64), padding = 1)
        self.up2 = StackDecoder(in_channels=512, out_channels=256, upsample_size=(128,128), padding = 1)
        self.up3 = StackDecoder(in_channels=256, out_channels=128, upsample_size=(256,256), padding = 1)
        self.up4 = StackDecoder(in_channels=128, out_channels=64, upsample_size=(512,512), padding = 1)

        # 1x1 convolution at the last layer
        # Different from the paper is the output size here
        self.output_seg_map = nn.Conv2d(64, 1, kernel_size=(1, 1), padding=0, stride=1)

        self._initialize_weights()

    def forward(self, x):
        x, x_trace1 = self.down1(x)
        x, x_trace2 = self.down2(x)
        x, x_trace3 = self.down3(x)
        x, x_trace4 = self.down4(x)
        x = self.center(x)
        x = self.up1(x, x_trace4)
        x = self.up2(x, x_trace3)
        x = self.up3(x, x_trace2)
        x = self.up4(x, x_trace1)

        x = self.output_seg_map(x)
        # x = F.sigmoid(x)
        # out = torch.squeeze(out, dim=1)
        return x


    def _initialize_weights(self):
        for m in self.modules():
            if isinstance(m, nn.Conv2d):
                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels
                m.weight.data.normal_(0, math.sqrt(2. / n))
                if m.bias is not None:
                    m.bias.data.zero_()
            elif isinstance(m, nn.BatchNorm2d):
                m.weight.data.fill_(1)
                m.bias.data.zero_()

# x = Variable(torch.randn(1,1,636,636))       # simulate input image
# net = UNet_BN()
# out = net(x)
# print("input: ", x)
# print("output: ", out)

===============from __future__ import print_function, division
import torch
from torch import optim
from torch.autograd import Variable
from torch.utils.data import DataLoader
import numpy as np
import torch.nn as nn
import torch.nn.functional as F
import Unet
import Unet_BatchNorm
import tifffile as tiff
import Utils
import time
from sklearn.metrics import average_precision_score, recall_score, f1_score
import Analysis
import Unet_ResNet

def to_var(x):
    if torch.cuda.is_available():
        return Variable(x.cuda())
    else:
        return Variable(x)

### BinaryCrossEntropyLoss2d().forward(logits, labels)
class BinaryCrossEntropyLoss2d(nn.Module):
    def __init__(self, weight=None, size_average=True):
        """
        Binary cross entropy loss 2D
        Args:
            weight:
            size_average:
        """
        super(BinaryCrossEntropyLoss2d, self).__init__()
        self.bce_loss = nn.BCELoss(weight, size_average)

    def forward(self, probs, targets):
        probs = F.sigmoid(probs)
        probs_flat = probs.view(-1)  # Flatten
        targets_flat = targets.view(-1)  # Flatten
        return self.bce_loss(probs_flat, targets_flat)      # (output, labels)

class SoftDiceLoss(nn.Module):
    def __init__(self, weight=None, size_average=True):
        super(SoftDiceLoss, self).__init__()

    def forward(self, probs, targets):
        smooth = 1
        num = targets.size(0)
        probs = F.sigmoid(probs)
        m1 = probs.view(num, -1)
        m2 = targets.view(num, -1)
        intersection = (m1 * m2)
        score = 2. * (intersection.sum(1) + smooth) / (m1.sum(1) + m2.sum(1) + smooth)
        score = 1 - score.sum() / num
        return score

def _criterion(logits, labels):
    return BinaryCrossEntropyLoss2d().forward(logits, labels) + \
        SoftDiceLoss().forward(logits, labels)

def NetEval(net,valdata_loader,crit):
    loss = 0.
    count = 0
    net.eval()
    for i,data in enumerate(valdata_loader,0):
        inputs, labels = data
        inputs, labels = to_var(inputs), to_var(labels)
        out = net(inputs)
        l = crit(out, labels)
        loss += l.data[0]
        count += 1
    return loss/count

# calculate Precision, Recall, F1-measure, IoU over the validation set
def Net_performace_val(net,valdata_loader):
    precision_list = []
    recall_list = []
    iou_list = []
    net.eval()
    print("len of valdata: ", len(valdata_loader))
    for i,data in enumerate(valdata_loader,0):

        inputs, labels = data
        out = NetPredict(net, inputs)   # out is numpy array 512x512
        labels = labels.numpy()
        labels = labels[0,0,:,:]        # labels is numpy array 512x512
        # remove the case where the mask is plain black
        if np.sum(labels) < 0.01*np.shape(labels)[0]*np.shape(labels)[1]: continue

        precision = average_precision_score(labels, out)
        recall = recall_score(labels, out, average='weighted')
        iou = IoU(out, labels)
        precision_list.append(precision)
        recall_list.append(recall)
        iou_list.append(iou)

    precision, recall, iou = np.mean(precision_list), np.mean(recall_list), np.mean(iou_list)
    F1_measure = 2.0*precision*recall/(precision + recall)

    return precision, recall, F1_measure, iou

# calculate IoU
def IoU(pred, target):
    # Ignore IoU for background class
    cls = 0.5
    pred_inds = pred > cls
    target_inds = target > cls

    intersection = (pred_inds[target_inds]).sum()  # Cast to long to prevent overflows
    union = pred_inds.sum() + target_inds.sum() - intersection
    if union == 0:
        ious = float('nan')  # If there is no ground truth, do not include in evaluation
    else:
        ious = 1.0*intersection / max(union, 1)
    return ious

#process the test data and save to separate .tif image
def NetTest(net,testdata_loader,path = "data/results/"):
    net.eval()
    for i, data in enumerate(testdata_loader, 0):
        if i >= 30: return 1        # for debug
        data = to_var(data)
        out = net(data)

        out = F.sigmoid(out)

        imgname = path + str(i) + ".tif"
        img = out.cpu()
        img = img[0,0,:,:]
        img = img.data.numpy()
        img_shape = img.shape
        img = img.reshape(-1)
        img[img < 0.5] = 0; img[img >= 0.5] = 1
        img = img.reshape(img_shape)
        img = np.uint8(img * 255)
        tiff.imsave(imgname, img)

# return input image size like 512x512, numpy array
def NetPredict(net, data):
    net.eval()
    data = to_var(data)
    out = net(data)

    out = F.sigmoid(out)

    img = out.cpu()
    img = img[0, 0, :, :]
    img = img.data.numpy()
    img_shape = img.shape
    img = img.reshape(-1)
    img[img < 0.5] = 0;
    img[img >= 0.5] = 1
    img = img.reshape(img_shape)
    return img
def write_2_log(content):
    path = "log_file.txt"
    output = open(path, "a")
    output.write("\n")
    output.write(content)
    output.close()

if __name__ == '__main__':
    '''subjects to change for each exp:
    + path to the dataset
    + opt function
    + leg description
    + N_epoch
    + saved_model
    '''
    start_begining = time.time()

    # path = "data/dataset"
    path = "/home/anhxtuan/HanLe/dataset/40aug_10ela_3inten_reflect"

    import os
    print("Does the folder exist?: ", os.path.isdir(path))
    print("Does the path exist?: ", os.path.exists(path))

    # imgs_train, imgs_mask_train = Utils.load_train_data(npy_path=path)
    # trainset = zip(imgs_train, imgs_mask_train)
    # trainloader = torch.utils.data.DataLoader(trainset, batch_size=1,
    #                                           shuffle=True, num_workers=2)

    imgs_val, imgs_mask_val = Utils.load_val_data(npy_path=path)
    valset = zip(imgs_val, imgs_mask_val)
    valloader = torch.utils.data.DataLoader(valset, batch_size=1,
                                              shuffle=False, num_workers=2)
    # net = Unet.UNet()                     # Unet 1
    net = Unet_BatchNorm.UNet_BN()          # Unet 2 with batchNorm
    # net = Unet_ResNet.UNet_ResNet()

    f1 = open("Unet_BatchNorm.py", 'r')     # embede code into the model to be saved later
    f2 = open("UnetTrain.py", 'r')
    f3 = open("Utils.py", 'r')
    model_notes = time.strftime("%c") + "\n" + f1.read() + "\n" + "==="*5 + f2.read() + "\n" + "==="*5 + f3.read()
    f1.close()
    f2.close()

    # criterion = nn.BCELoss()
    # criterion = BinaryCrossEntropyLoss2d()
    criterion = SoftDiceLoss()

    if torch.cuda.is_available():
        # torch.set_default_tensor_type('torch.cuda.FloatTensor')
        # net.load_state_dict(torch.load("Unet2_model_6epoch_Leg14_dropout_0_2_rmSigmoid_40aug_10ela_3inten_reflect"))
        net.cuda()
        # criterion.cuda()

    opt = optim.SGD(net.parameters(), lr=1e-2, momentum=0.99)       # subject to change
    # opt = optim.RMSprop(net.parameters(), lr=2e-4)
    # RMSprop[22](learning rate 0.001) with weight decay set to 0.001.
    # opt = optim.Adam(net.parameters(), lr=1e-3, weight_decay=1e-4)

    train_loss = []
    val_loss = []

    print("[epoch, #image] Loss")
    leg = "Leg15_DICE_dropout_0_2_rmSigmoid_40aug_10ela_3inten_reflect"
    print("Processing: ", leg)
    model_name = ""

    N_epoch = 8
    model_saved = np.arange(2,N_epoch+1,2)
    val_loss_min = 100

    write_2_log("==="*30)
    write_2_log(time.strftime("%c"))       # time, date of exp
    write_2_log(leg)
    write_2_log(model_notes)
    write_2_log(time.strftime("%c"))  # time, date of exp
    write_2_log(leg)
    write_2_log("optim.SGD(net.parameters(), lr=1e-2, momentum=0.99)")
    write_2_log("Number of epoch max: " + str(N_epoch))

    min_model_epoch = 0
    for epoch in range(N_epoch):
        running_loss = 0.0; count = 0
        net.train()

        N_files = 5
        for j in range(N_files):
            if N_files > 1:
                train_file = "/imgs_train_" + str(j + 1) + ".npy"
                mask_file = "/imgs_mask_train_" + str(j + 1) + ".npy"
            else:
                train_file = "/imgs_train.npy"
                mask_file = "/imgs_mask_train.npy"

            imgs_train, imgs_mask_train = Utils.load_train_data(npy_path=path, train_file=train_file, mask_file=mask_file)
            trainset = zip(imgs_train, imgs_mask_train)
            trainloader = torch.utils.data.DataLoader(trainset, batch_size=1,
                                                      shuffle=True, num_workers=2)
            for i, data in enumerate(trainloader, 0):
                inputs, labels = data
                temp = labels.numpy()
                temp = temp[0, 0, :, :]  # labels is numpy array 512x512
                # remove the case where the mask is plain black
                if np.sum(temp) < 0.01 * np.shape(temp)[0] * np.shape(temp)[1]: continue
                inputs, labels = to_var(inputs), to_var(labels)
                opt.zero_grad()
                out = net(inputs)
                loss = criterion(out, labels)
                loss.backward()
                opt.step()
                running_loss += loss.data[0]
                count += 1

        net.eval()
        val_loss_temp = NetEval(net, valloader, criterion)
        if epoch > 0 and val_loss_temp < val_loss_min:        # save the model which has the lowest val_loss, ignore first epoch
            val_loss_min = val_loss_temp
            torch.save(net.state_dict(), "Unet2_model_" + leg + "_min_val_loss")  # save model
            min_model_epoch = epoch + 1

        disp = 'Epoch %d: Train loss: %.6f, Val loss: %.6f' % (epoch + 1, running_loss/count, val_loss_temp)
        write_2_log(disp)
        print(disp)
        val_loss.append(val_loss_temp)
        train_loss.append(running_loss/count); running_loss = 0.0

        if (epoch + 1) in model_saved:        # save checkpoint
            model_name = "Unet2_model_" + str(epoch+1) + "epoch_" + leg
            torch.save(net.state_dict(), model_name)  # save model
            Analysis.analysis(model_file = model_name, valloader = valloader)

    write_2_log("Best model at epoch: " + str(min_model_epoch))
    write_2_log("Total training time: " + str((time.time() - start_begining) / 3600.0))

    val_loss_file = "data/results" + "/val_loss_" + str(N_epoch) + "epoch_" + leg + ".npy"
    train_loss_file = "data/results" + "/training_loss_" + str(N_epoch) + "epoch_" + leg + ".npy"

    np.save(val_loss_file, val_loss)
    np.save(train_loss_file, train_loss)
    print("total processing time in seconds: ", time.time() - start_begining)
    print("total processing time in mins: ", (time.time() - start_begining) / 60.0)
    print("total processing time in hours: ", (time.time() - start_begining) / 3600.0)

    Analysis.analysis(model_file="Unet2_model_" + leg + "_min_val_loss", valloader=valloader)

    Analysis.PlotLoss(model_file = model_name, loss_train_path = train_loss_file, loss_val_path = val_loss_file, epoch_No = N_epoch)

    write_2_log(time.strftime("%c"))  # time, date of exp
===============import numpy as np
import torch.nn as nn
import torch
import cv2
from lcn import LecunLCN

LCN_enable = False

def input_filled_mirroring(x):      # fill missing data by mirroring the input image
    '''input size 636 --> output size 512'''
    w, h = x.shape
    e = 62  # extra width on 1 edge
    y = np.zeros((h + e * 2, w + e * 2))
    y[e:h + e, e:w + e] = x
    y[e:e + h, 0:e] = np.flip(y[e:e + h, e:2 * e], 1)  # flip vertically
    y[e:e + h, e + w:2 * e + w] = np.flip(y[e:e + h, w:e + w], 1)  # flip vertically
    y[0:e, 0:2 * e + w] = np.flip(y[e:2 * e, 0:2 * e + w], 0)  # flip horizontally
    y[e + h:2 * e + h, 0:2 * e + w] = np.flip(y[h:e + h, 0:2 * e + w], 0)  # flip horizontally
    return y

def nearest_cells_distance(pos, img):
    # searching in 8 directions to find 2 nearest distances to neighbor cells
    curr_value = img[pos]
    w = img.shape[0];h = img.shape[1]
    count_detect = 0  # detect 2 nearest neighbors. break the search if count_detect = 2
    x, y = pos

    # print("w,h: ", (w, h))
    d1 = 9999999;d2 = 9999999;d3 = 9999999;d4 = 9999999
    d5 = 9999999;d6 = 9999999;d7 = 9999999;d8 = 9999999
    for i in range(1, max(w, h)):
        # (x+1, y), (x+1, y+1), (x+1, y-1),
        # (x, y+1), (x, y-1)
        # (x-1, y), (x-1,y+1), (x-1,y-1),
        if x + i < w:
            if img[(x + i, y)] != curr_value and d1 == 9999999:
                d1 = i; count_detect += 1
            if y + i < h:
                if img[(x + i, y + i)] != curr_value and d2 == 9999999:
                    d2 = i; count_detect += 1
            elif y - i >= 0:
                if img[(x + i, y - i)] != curr_value and d3 == 9999999:
                    d3 = i; count_detect += 1
        if y + i < h:
            if img[(x, y + i)] != curr_value and d4 == 9999999:
                d4 = i; count_detect += 1
        if y - i >= 0:
            if img[(x, y - i)] != curr_value and d5 == 9999999:
                d5 = i; count_detect += 1
        if x - i >= 0:
            if img[(x - i, y)] != curr_value and d6 == 9999999:
                d6 = i; count_detect += 1
            if y + i < h:
                if img[(x - i, y + i)] != curr_value and d7 == 9999999:
                    d7 = i; count_detect += 1
            elif y - i >= 0:
                if img[(x - i, y - i)] != curr_value and d8 == 9999999:
                    d8 = i; count_detect += 1
        if count_detect >= 2: break

    d = [d1, d2, d3, d4, d5, d6, d7, d8]
    min_index = np.argmin(d)
    dist1 = d[min_index]
    d.remove(dist1)
    min_index = np.argmin(d)
    dist2 = d[min_index]
    return dist1, dist2

def create_weight_map(imgs_mask):
        print('-' * 30)
        print('Creating weights for masks ...')
        print('-' * 30)
        weight_map = np.ndarray(
            (len(imgs_mask), 1, np.shape(imgs_mask)[2], np.shape(imgs_mask)[3]), dtype=np.float32)
        w_0 = 10; sigma = 4
        imgs_w, imgs_h = np.shape(imgs_mask)[2], np.shape(imgs_mask)[3]
        total_pixels = imgs_w*imgs_h
        import time
        start = time.time()
        for i in range(len(imgs_mask)):
            if i%10 == 0: print("Done processing: %d images, time passed: %.2f mins" % (i, (time.time() - start)/60.0))
            temp = imgs_mask[i,0,:,:]
            w_border = 1 - np.sum(temp)/total_pixels        # w_c of pixel on the border (black)
            for m in range(imgs_w):
                for n in range(imgs_h):
                    # loop through all pixel of the mask
                    d1,d2 = nearest_cells_distance((m,n), temp)
                    w_c = w_border
                    if temp[m,n] == 0: w_c = 1 - w_border
                    weight_map[i,0,m,n] = w_c*5 + w_0*np.exp(-(d1 + d2)**2/(2*sigma**2))
                    # print("w_0*np.exp(): ", w_0*np.exp(-(d1 + d2)**2/(2*sigma**2)))
                    # print("w_border: ", w_border)

        np.save('data/dataset/weight_map_train.npy', weight_map)

        return weight_map

def load_train_data(npy_path = "data/dataset", train_file = "/imgs_train.npy", mask_file = "/imgs_mask_train.npy", hist_equal = False):

    print('-' * 30)
    print('load train images...')

    imgs_train = np.load(npy_path + train_file)
    imgs_mask_train = np.load(npy_path + mask_file)

    if hist_equal: imgs_train = hist_equalization(imgs_train)

    # weight_map_train = np.load(npy_path + "/weight_map_train.npy")
    # weight_map_train = weight_map_train.astype('float32')

    imgs_train = imgs_train.astype('float32')
    imgs_mask_train = imgs_mask_train.astype('float32')

    if LCN_enable:
        imgs_train = imgs_train.astype('float64')
        imgs_train = LecunLCN(imgs_train, image_shape=imgs_train.shape).output.eval()
        imgs_train = imgs_train.astype('float32')

    if not LCN_enable: imgs_train /= 255

    imgs_train -= imgs_train.mean(axis=0)
    imgs_mask_train /= 255
    imgs_mask_train[imgs_mask_train > 0.5] = 1
    imgs_mask_train[imgs_mask_train <= 0.5] = 0

    # weight_map_train = create_weight_map(imgs_mask_train)

    print("Done loading traing data")
    print('-' * 30)
    return imgs_train, imgs_mask_train

def load_val_data(npy_path = "data/dataset", hist_equal = True):

    print('-' * 30)
    print('load validation images...')

    imgs_train = np.load(npy_path + "/imgs_val.npy")
    imgs_mask_train = np.load(npy_path + "/imgs_mask_val.npy")

    if hist_equal: imgs_train = hist_equalization(imgs_train)

    imgs_train = imgs_train.astype('float32')
    imgs_mask_train = imgs_mask_train.astype('float32')

    if LCN_enable:
        imgs_train = imgs_train.astype('float64')
        imgs_train = LecunLCN(imgs_train, image_shape=imgs_train.shape).output.eval()
        imgs_train = imgs_train.astype('float32')

    if not LCN_enable: imgs_train /= 255
    imgs_train -= imgs_train.mean(axis=0)
    imgs_mask_train /= 255
    imgs_mask_train[imgs_mask_train > 0.5] = 1
    imgs_mask_train[imgs_mask_train <= 0.5] = 0
    print("Done loading validation data")
    print('-' * 30)
    return imgs_train, imgs_mask_train

def load_test_data(npy_path = "data/dataset", hist_equal = True):

    print('-' * 30)
    print('load test images...')

    imgs_test = np.load(npy_path + "/imgs_test.npy")

    if hist_equal: imgs_test = hist_equalization(imgs_test)

    imgs_test = imgs_test.astype('float32')

    if LCN_enable:
        imgs_test = imgs_test.astype('float64')
        imgs_test = LecunLCN(imgs_test, image_shape=imgs_test.shape).output.eval()
        imgs_test = imgs_test.astype('float32')

    if not LCN_enable: imgs_test /= 255

    imgs_test -= imgs_test.mean(axis=0)

    print("Done loading test data")
    print('-' * 30)
    return imgs_test

def load_val_5imgs(npy_path = "data/dataset"):
    print('-' * 30)
    print('load train images...')

    imgs_train = np.load(npy_path + "/imgs_val_5imgs.npy")
    imgs_mask_train = np.load(npy_path + "/imgs_mask_val_5imgs.npy")

    # imgs_train = hist_equalization(imgs_train)

    imgs_train = imgs_train.astype('float64')
    imgs_mask_train = imgs_mask_train.astype('float64')

    if LCN_enable: imgs_train = LecunLCN(imgs_train, image_shape=imgs_train.shape).output.eval()

    if not LCN_enable: imgs_train /= 255

    mean = imgs_train.mean(axis=0)
    imgs_train -= mean


    imgs_mask_train /= 255
    imgs_mask_train[imgs_mask_train > 0.5] = 1
    imgs_mask_train[imgs_mask_train <= 0.5] = 0

    # weight_map_train = self.create_weight_map(imgs_mask_train)

    print("Done loading traing data")
    print('-' * 30)
    return imgs_train, imgs_mask_train

def hist_equalization(inputs):      # inputs are uint8, 0-255, Nx1x636x636
    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))
    output = inputs.copy()
    for i in range(len(inputs)):
        img = inputs[i, 0, :, :]
        # res = cv2.equalizeHist(img)
        res = clahe.apply(img)
        output[i,0,:,:] = res
    return output

### BinaryCrossEntropyLoss2d().forward(logits, labels)
class BinaryCrossEntropyLoss2d(nn.Module):
    def __init__(self, weight=None, size_average=True):
        """
        Binary cross entropy loss 2D
        Args:
            weight:
            size_average:
        """
        super(BinaryCrossEntropyLoss2d, self).__init__()
        self.bce_loss = nn.BCELoss(weight, size_average)

    def forward(self, logits, targets):
        # probs = F.sigmoid(logits)
        probs = logits
        probs_flat = probs.view(-1)  # Flatten
        targets_flat = targets.view(-1)  # Flatten
        return self.bce_loss(probs_flat, targets_flat)      # (output, labels)

class BCE_with_Weights(nn.Module):
    def __init__(self, weights=None):
        """
        Binary cross entropy loss 2D
        Args:
            weights:
        """
        super(BCE_with_Weights, self).__init__()
        self.weights = weights

    def forward(self, output, target):
        if self.weights is not None:
            loss = self.weights * (target * torch.log(output) + (1 - target) * torch.log(1 - output))
        else:
            loss = target * torch.log(output) + (1 - target) * torch.log(1 - output)

        return torch.neg(torch.mean(loss))

class LRN(nn.Module):       # input x is Torch tensor
    def __init__(self, local_size=1, alpha=1.0, beta=0.75, ACROSS_CHANNELS=False):      #LRN(local_size=5, alpha=0.0001, beta=0.75),
        super(LRN, self).__init__()
        self.ACROSS_CHANNELS = ACROSS_CHANNELS
        if self.ACROSS_CHANNELS:
            self.average = nn.AvgPool3d(kernel_size=(local_size, 1, 1),
                                        stride=1, padding=(int((local_size - 1.0) / 2), 0, 0))
        else:
            self.average = nn.AvgPool2d(kernel_size=local_size,
                                        stride=1, padding=int((local_size - 1.0) / 2))
        self.alpha = alpha
        self.beta = beta

    def forward(self, x):
        if self.ACROSS_CHANNELS:
            div = x.pow(2).unsqueeze(1)
            div = self.average(div).squeeze(1)
            div = div.mul(self.alpha).add(1.0).pow(self.beta)
        else:
            div = x.pow(2)
            div = self.average(div)
            div = div.mul(self.alpha).add(1.0).pow(self.beta)
        x = x.div(div)
        return x


Sun Nov 19 07:01:15 2017
Leg15_DICE_dropout_0_2_rmSigmoid_40aug_10ela_3inten_reflect
optim.SGD(net.parameters(), lr=1e-2, momentum=0.99)
Number of epoch max: 8
Epoch 1: Train loss: 0.126531, Val loss: 0.127992
Epoch 2: Train loss: 0.126466, Val loss: 0.127992
Unet2_model_2epoch_Leg15_DICE_dropout_0_2_rmSigmoid_40aug_10ela_3inten_reflect
Precision: 0.90048 
Recall: 1.00000 
F1_measure: 0.94763 
iou: 0.80096
==========================================================================================
Sun Nov 19 09:08:53 2017
Leg16_ResNet_dropout_0_2_rmSigmoid_40aug_10ela_3inten_reflect
Sun Nov 19 09:08:51 2017
import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.autograd import Variable
import math


class ConvBnRelu(nn.Module):
    def __init__(self, in_channels, out_channels, kernel_size, padding, stride):
        super(ConvBnRelu, self).__init__()
        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=kernel_size, padding=padding, stride=stride)
        self.bn = nn.BatchNorm2d(out_channels)
        self.relu = nn.ReLU()

    def forward(self, x):
        x = self.conv(x)
        # x = self.bn(x)
        x = self.relu(x)
        return x


class StackEncoder(nn.Module):
    def __init__(self, in_channels, out_channels):
        super(StackEncoder, self).__init__()
        self.convr1 = ConvBnRelu(in_channels, out_channels, kernel_size=(3, 3), stride=1, padding=0)
        self.convr2 = ConvBnRelu(out_channels, out_channels, kernel_size=(3, 3), stride=1, padding=0)
        self.maxPool = nn.MaxPool2d(kernel_size=(2, 2), stride=2)

    def forward(self, x):
        x = self.convr1(x)
        x = self.convr2(x)
        x_trace = x             # save x to use in concat in the Decoder path
        out = self.maxPool(x)
        return out, x_trace


class StackDecoder(nn.Module):
    def __init__(self, in_channels, out_channels, upsample_size, padding, drop_out=False):
        super(StackDecoder, self).__init__()

        self.drop_out = drop_out
        self.dropout_layer = nn.Dropout2d(p=0.5)

        ''' this is old version
        self.upSample = nn.Upsample(size=upsample_size, scale_factor=(2, 2), mode="bilinear")
        self.convr1 = ConvBnRelu(in_channels, out_channels, kernel_size=(3, 3), stride=1, padding=padding)
        # Crop + concat step between these 2
        self.convr2 = ConvBnRelu(in_channels, out_channels, kernel_size=(3, 3), stride=1, padding=padding)
        '''
        self.upSample = nn.ConvTranspose2d(in_channels, out_channels, 2, stride=2)
        self.convr1 = ConvBnRelu(in_channels, out_channels, kernel_size=(3, 3), stride=1, padding=padding)
        self.convr2 = ConvBnRelu(out_channels, out_channels, kernel_size=(3, 3), stride=1, padding=padding)

    def _crop_concat(self, upsampled, bypass):
        """
         Crop y to the (h, w) of x and concat them.
         Used for the expansive path.
        Returns:
            The concatenated tensor
        """
        c = (bypass.size()[2] - upsampled.size()[2]) // 2
        bypass = F.pad(bypass, (-c, -c, -c, -c))

        return torch.cat((bypass, upsampled), 1)

    def forward(self, x, down_tensor):
        '''old version
        x = self.upSample(x)
        x = self.convr1(x)
        x = self._crop_concat(x, down_tensor)
        x = self.convr2(x)
        '''

        x = self.upSample(x)
        x = self._crop_concat(x, down_tensor)
        x = self.convr1(x)
        if self.drop_out: x = self.dropout_layer(x)
        x = self.convr2(x)
        if self.drop_out: x = self.dropout_layer(x)
        return x


class UNet_BN(nn.Module):
    def __init__(self):
        super(UNet_BN, self).__init__()
        # channels, height, width = in_shape

        # self.dropout = dropout

        self.model_code = ""        # variable to save model and main function when loaded

        self.down1 = StackEncoder(1, 64)
        self.down2 = StackEncoder(64, 128)
        self.down3 = StackEncoder(128, 256)
        self.down4 = StackEncoder(256, 512)

        self.center = nn.Sequential(
            # nn.Dropout2d(p=0.2),
            ConvBnRelu(512, 1024, kernel_size=(3, 3), stride=1, padding=0),
            nn.Dropout2d(p=0.2),
            ConvBnRelu(1024, 1024, kernel_size=(3, 3), stride=1, padding=0),
            nn.Dropout2d(p=0.2)
        )

        self.up1 = StackDecoder(in_channels=1024, out_channels=512, upsample_size=(64,64), padding = 1)
        self.up2 = StackDecoder(in_channels=512, out_channels=256, upsample_size=(128,128), padding = 1)
        self.up3 = StackDecoder(in_channels=256, out_channels=128, upsample_size=(256,256), padding = 1)
        self.up4 = StackDecoder(in_channels=128, out_channels=64, upsample_size=(512,512), padding = 1)

        # 1x1 convolution at the last layer
        # Different from the paper is the output size here
        self.output_seg_map = nn.Conv2d(64, 1, kernel_size=(1, 1), padding=0, stride=1)

        self._initialize_weights()

    def forward(self, x):
        x, x_trace1 = self.down1(x)
        x, x_trace2 = self.down2(x)
        x, x_trace3 = self.down3(x)
        x, x_trace4 = self.down4(x)
        x = self.center(x)
        x = self.up1(x, x_trace4)
        x = self.up2(x, x_trace3)
        x = self.up3(x, x_trace2)
        x = self.up4(x, x_trace1)

        x = self.output_seg_map(x)
        # x = F.sigmoid(x)
        # out = torch.squeeze(out, dim=1)
        return x


    def _initialize_weights(self):
        for m in self.modules():
            if isinstance(m, nn.Conv2d):
                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels
                m.weight.data.normal_(0, math.sqrt(2. / n))
                if m.bias is not None:
                    m.bias.data.zero_()
            elif isinstance(m, nn.BatchNorm2d):
                m.weight.data.fill_(1)
                m.bias.data.zero_()

# x = Variable(torch.randn(1,1,636,636))       # simulate input image
# net = UNet_BN()
# out = net(x)
# print("input: ", x)
# print("output: ", out)

===============from __future__ import print_function, division
import torch
from torch import optim
from torch.autograd import Variable
from torch.utils.data import DataLoader
import numpy as np
import torch.nn as nn
import torch.nn.functional as F
import Unet
import Unet_BatchNorm
import tifffile as tiff
import Utils
import time
from sklearn.metrics import average_precision_score, recall_score, f1_score
import Analysis
import Unet_ResNet

def to_var(x):
    if torch.cuda.is_available():
        return Variable(x.cuda())
    else:
        return Variable(x)

### BinaryCrossEntropyLoss2d().forward(logits, labels)
class BinaryCrossEntropyLoss2d(nn.Module):
    def __init__(self, weight=None, size_average=True):
        """
        Binary cross entropy loss 2D
        Args:
            weight:
            size_average:
        """
        super(BinaryCrossEntropyLoss2d, self).__init__()
        self.bce_loss = nn.BCELoss(weight, size_average)

    def forward(self, probs, targets):
        probs = F.sigmoid(probs)
        probs_flat = probs.view(-1)  # Flatten
        targets_flat = targets.view(-1)  # Flatten
        return self.bce_loss(probs_flat, targets_flat)      # (output, labels)

class SoftDiceLoss(nn.Module):
    def __init__(self, weight=None, size_average=True):
        super(SoftDiceLoss, self).__init__()

    def forward(self, probs, targets):
        smooth = 1
        num = targets.size(0)
        probs = F.sigmoid(probs)
        m1 = probs.view(num, -1)
        m2 = targets.view(num, -1)
        intersection = (m1 * m2)
        score = 2. * (intersection.sum(1) + smooth) / (m1.sum(1) + m2.sum(1) + smooth)
        score = 1 - score.sum() / num
        return score

def _criterion(logits, labels):
    return BinaryCrossEntropyLoss2d().forward(logits, labels) + \
        SoftDiceLoss().forward(logits, labels)

def NetEval(net,valdata_loader,crit):
    loss = 0.
    count = 0
    net.eval()
    for i,data in enumerate(valdata_loader,0):
        inputs, labels = data
        inputs, labels = to_var(inputs), to_var(labels)
        out = net(inputs)
        l = crit(out, labels)
        loss += l.data[0]
        count += 1
    return loss/count

# calculate Precision, Recall, F1-measure, IoU over the validation set
def Net_performace_val(net,valdata_loader):
    precision_list = []
    recall_list = []
    iou_list = []
    net.eval()
    print("len of valdata: ", len(valdata_loader))
    for i,data in enumerate(valdata_loader,0):

        inputs, labels = data
        out = NetPredict(net, inputs)   # out is numpy array 512x512
        labels = labels.numpy()
        labels = labels[0,0,:,:]        # labels is numpy array 512x512
        # remove the case where the mask is plain black
        if np.sum(labels) < 0.01*np.shape(labels)[0]*np.shape(labels)[1]: continue

        precision = average_precision_score(labels, out)
        recall = recall_score(labels, out, average='weighted')
        iou = IoU(out, labels)
        precision_list.append(precision)
        recall_list.append(recall)
        iou_list.append(iou)

    precision, recall, iou = np.mean(precision_list), np.mean(recall_list), np.mean(iou_list)
    F1_measure = 2.0*precision*recall/(precision + recall)

    return precision, recall, F1_measure, iou

# calculate IoU
def IoU(pred, target):
    # Ignore IoU for background class
    cls = 0.5
    pred_inds = pred > cls
    target_inds = target > cls

    intersection = (pred_inds[target_inds]).sum()  # Cast to long to prevent overflows
    union = pred_inds.sum() + target_inds.sum() - intersection
    if union == 0:
        ious = float('nan')  # If there is no ground truth, do not include in evaluation
    else:
        ious = 1.0*intersection / max(union, 1)
    return ious

#process the test data and save to separate .tif image
def NetTest(net,testdata_loader,path = "data/results/"):
    net.eval()
    for i, data in enumerate(testdata_loader, 0):
        if i >= 30: return 1        # for debug
        data = to_var(data)
        out = net(data)

        out = F.sigmoid(out)

        imgname = path + str(i) + ".tif"
        img = out.cpu()
        img = img[0,0,:,:]
        img = img.data.numpy()
        img_shape = img.shape
        img = img.reshape(-1)
        img[img < 0.5] = 0; img[img >= 0.5] = 1
        img = img.reshape(img_shape)
        img = np.uint8(img * 255)
        tiff.imsave(imgname, img)

# return input image size like 512x512, numpy array
def NetPredict(net, data):
    net.eval()
    data = to_var(data)
    out = net(data)

    out = F.sigmoid(out)

    img = out.cpu()
    img = img[0, 0, :, :]
    img = img.data.numpy()
    img_shape = img.shape
    img = img.reshape(-1)
    img[img < 0.5] = 0;
    img[img >= 0.5] = 1
    img = img.reshape(img_shape)
    return img
def write_2_log(content):
    path = "log_file.txt"
    output = open(path, "a")
    output.write("\n")
    output.write(content)
    output.close()

if __name__ == '__main__':
    '''subjects to change for each exp:
    + path to the dataset
    + opt function
    + leg description
    + N_epoch
    + saved_model
    '''
    start_begining = time.time()

    # path = "data/dataset"
    path = "/home/anhxtuan/HanLe/dataset/40aug_10ela_3inten_reflect"

    import os
    print("Does the folder exist?: ", os.path.isdir(path))
    print("Does the path exist?: ", os.path.exists(path))

    # imgs_train, imgs_mask_train = Utils.load_train_data(npy_path=path)
    # trainset = zip(imgs_train, imgs_mask_train)
    # trainloader = torch.utils.data.DataLoader(trainset, batch_size=1,
    #                                           shuffle=True, num_workers=2)

    imgs_val, imgs_mask_val = Utils.load_val_data(npy_path=path)
    valset = zip(imgs_val, imgs_mask_val)
    valloader = torch.utils.data.DataLoader(valset, batch_size=1,
                                              shuffle=False, num_workers=2)
    # net = Unet.UNet()                     # Unet 1
    net = Unet_BatchNorm.UNet_BN()          # Unet 2 with batchNorm
    # net = Unet_ResNet.UNet_ResNet()

    f1 = open("Unet_BatchNorm.py", 'r')     # embede code into the model to be saved later
    f2 = open("UnetTrain.py", 'r')
    f3 = open("Utils.py", 'r')
    model_notes = time.strftime("%c") + "\n" + f1.read() + "\n" + "==="*5 + f2.read() + "\n" + "==="*5 + f3.read()
    f1.close()
    f2.close()

    # criterion = nn.BCELoss()
    criterion = BinaryCrossEntropyLoss2d()
    # criterion = SoftDiceLoss()

    if torch.cuda.is_available():
        # torch.set_default_tensor_type('torch.cuda.FloatTensor')
        # net.load_state_dict(torch.load("Unet2_model_6epoch_Leg14_dropout_0_2_rmSigmoid_40aug_10ela_3inten_reflect"))
        net.cuda()
        # criterion.cuda()

    opt = optim.SGD(net.parameters(), lr=1e-2, momentum=0.99)       # subject to change
    # opt = optim.RMSprop(net.parameters(), lr=2e-4)
    # RMSprop[22](learning rate 0.001) with weight decay set to 0.001.
    # opt = optim.Adam(net.parameters(), lr=1e-3, weight_decay=1e-4)

    train_loss = []
    val_loss = []

    print("[epoch, #image] Loss")
    leg = "Leg16_ResNet_dropout_0_2_rmSigmoid_40aug_10ela_3inten_reflect"
    print("Processing: ", leg)
    model_name = ""

    N_epoch = 8
    model_saved = np.arange(2,N_epoch+1,2)
    val_loss_min = 100

    write_2_log("==="*30)
    write_2_log(time.strftime("%c"))       # time, date of exp
    write_2_log(leg)
    write_2_log(model_notes)
    write_2_log(time.strftime("%c"))  # time, date of exp
    write_2_log(leg)
    write_2_log("optim.SGD(net.parameters(), lr=1e-2, momentum=0.99)")
    write_2_log("Number of epoch max: " + str(N_epoch))

    min_model_epoch = 0
    for epoch in range(N_epoch):
        running_loss = 0.0; count = 0
        net.train()

        N_files = 5
        for j in range(N_files):
            if N_files > 1:
                train_file = "/imgs_train_" + str(j + 1) + ".npy"
                mask_file = "/imgs_mask_train_" + str(j + 1) + ".npy"
            else:
                train_file = "/imgs_train.npy"
                mask_file = "/imgs_mask_train.npy"

            imgs_train, imgs_mask_train = Utils.load_train_data(npy_path=path, train_file=train_file, mask_file=mask_file)
            trainset = zip(imgs_train, imgs_mask_train)
            trainloader = torch.utils.data.DataLoader(trainset, batch_size=1,
                                                      shuffle=True, num_workers=2)
            for i, data in enumerate(trainloader, 0):
                inputs, labels = data
                temp = labels.numpy()
                temp = temp[0, 0, :, :]  # labels is numpy array 512x512
                # remove the case where the mask is plain black
                if np.sum(temp) < 0.01 * np.shape(temp)[0] * np.shape(temp)[1]: continue
                inputs, labels = to_var(inputs), to_var(labels)
                opt.zero_grad()
                out = net(inputs)
                loss = criterion(out, labels)
                loss.backward()
                opt.step()
                running_loss += loss.data[0]
                count += 1

        net.eval()
        val_loss_temp = NetEval(net, valloader, criterion)
        if epoch > 0 and val_loss_temp < val_loss_min:        # save the model which has the lowest val_loss, ignore first epoch
            val_loss_min = val_loss_temp
            torch.save(net.state_dict(), "UnetRes_model_" + leg + "_min_val_loss")  # save model
            min_model_epoch = epoch + 1

        disp = 'Epoch %d: Train loss: %.6f, Val loss: %.6f' % (epoch + 1, running_loss/count, val_loss_temp)
        write_2_log(disp)
        print(disp)
        val_loss.append(val_loss_temp)
        train_loss.append(running_loss/count); running_loss = 0.0

        if (epoch + 1) in model_saved:        # save checkpoint
            model_name = "UnetRes_model_" + str(epoch+1) + "epoch_" + leg
            torch.save(net.state_dict(), model_name)  # save model
            Analysis.analysis(model_file = model_name, valloader = valloader)

    write_2_log("Best model at epoch: " + str(min_model_epoch))
    write_2_log("Total training time: " + str((time.time() - start_begining) / 3600.0))

    val_loss_file = "data/results" + "/val_loss_" + str(N_epoch) + "epoch_" + leg + ".npy"
    train_loss_file = "data/results" + "/training_loss_" + str(N_epoch) + "epoch_" + leg + ".npy"

    np.save(val_loss_file, val_loss)
    np.save(train_loss_file, train_loss)
    print("total processing time in seconds: ", time.time() - start_begining)
    print("total processing time in mins: ", (time.time() - start_begining) / 60.0)
    print("total processing time in hours: ", (time.time() - start_begining) / 3600.0)

    Analysis.analysis(model_file="UnetRes_model_" + leg + "_min_val_loss", valloader=valloader)

    Analysis.PlotLoss(model_file = model_name, loss_train_path = train_loss_file, loss_val_path = val_loss_file, epoch_No = N_epoch)

    write_2_log(time.strftime("%c"))  # time, date of exp
===============import numpy as np
import torch.nn as nn
import torch
import cv2
from lcn import LecunLCN

LCN_enable = False

def input_filled_mirroring(x):      # fill missing data by mirroring the input image
    '''input size 636 --> output size 512'''
    w, h = x.shape
    e = 62  # extra width on 1 edge
    y = np.zeros((h + e * 2, w + e * 2))
    y[e:h + e, e:w + e] = x
    y[e:e + h, 0:e] = np.flip(y[e:e + h, e:2 * e], 1)  # flip vertically
    y[e:e + h, e + w:2 * e + w] = np.flip(y[e:e + h, w:e + w], 1)  # flip vertically
    y[0:e, 0:2 * e + w] = np.flip(y[e:2 * e, 0:2 * e + w], 0)  # flip horizontally
    y[e + h:2 * e + h, 0:2 * e + w] = np.flip(y[h:e + h, 0:2 * e + w], 0)  # flip horizontally
    return y

def nearest_cells_distance(pos, img):
    # searching in 8 directions to find 2 nearest distances to neighbor cells
    curr_value = img[pos]
    w = img.shape[0];h = img.shape[1]
    count_detect = 0  # detect 2 nearest neighbors. break the search if count_detect = 2
    x, y = pos

    # print("w,h: ", (w, h))
    d1 = 9999999;d2 = 9999999;d3 = 9999999;d4 = 9999999
    d5 = 9999999;d6 = 9999999;d7 = 9999999;d8 = 9999999
    for i in range(1, max(w, h)):
        # (x+1, y), (x+1, y+1), (x+1, y-1),
        # (x, y+1), (x, y-1)
        # (x-1, y), (x-1,y+1), (x-1,y-1),
        if x + i < w:
            if img[(x + i, y)] != curr_value and d1 == 9999999:
                d1 = i; count_detect += 1
            if y + i < h:
                if img[(x + i, y + i)] != curr_value and d2 == 9999999:
                    d2 = i; count_detect += 1
            elif y - i >= 0:
                if img[(x + i, y - i)] != curr_value and d3 == 9999999:
                    d3 = i; count_detect += 1
        if y + i < h:
            if img[(x, y + i)] != curr_value and d4 == 9999999:
                d4 = i; count_detect += 1
        if y - i >= 0:
            if img[(x, y - i)] != curr_value and d5 == 9999999:
                d5 = i; count_detect += 1
        if x - i >= 0:
            if img[(x - i, y)] != curr_value and d6 == 9999999:
                d6 = i; count_detect += 1
            if y + i < h:
                if img[(x - i, y + i)] != curr_value and d7 == 9999999:
                    d7 = i; count_detect += 1
            elif y - i >= 0:
                if img[(x - i, y - i)] != curr_value and d8 == 9999999:
                    d8 = i; count_detect += 1
        if count_detect >= 2: break

    d = [d1, d2, d3, d4, d5, d6, d7, d8]
    min_index = np.argmin(d)
    dist1 = d[min_index]
    d.remove(dist1)
    min_index = np.argmin(d)
    dist2 = d[min_index]
    return dist1, dist2

def create_weight_map(imgs_mask):
        print('-' * 30)
        print('Creating weights for masks ...')
        print('-' * 30)
        weight_map = np.ndarray(
            (len(imgs_mask), 1, np.shape(imgs_mask)[2], np.shape(imgs_mask)[3]), dtype=np.float32)
        w_0 = 10; sigma = 4
        imgs_w, imgs_h = np.shape(imgs_mask)[2], np.shape(imgs_mask)[3]
        total_pixels = imgs_w*imgs_h
        import time
        start = time.time()
        for i in range(len(imgs_mask)):
            if i%10 == 0: print("Done processing: %d images, time passed: %.2f mins" % (i, (time.time() - start)/60.0))
            temp = imgs_mask[i,0,:,:]
            w_border = 1 - np.sum(temp)/total_pixels        # w_c of pixel on the border (black)
            for m in range(imgs_w):
                for n in range(imgs_h):
                    # loop through all pixel of the mask
                    d1,d2 = nearest_cells_distance((m,n), temp)
                    w_c = w_border
                    if temp[m,n] == 0: w_c = 1 - w_border
                    weight_map[i,0,m,n] = w_c*5 + w_0*np.exp(-(d1 + d2)**2/(2*sigma**2))
                    # print("w_0*np.exp(): ", w_0*np.exp(-(d1 + d2)**2/(2*sigma**2)))
                    # print("w_border: ", w_border)

        np.save('data/dataset/weight_map_train.npy', weight_map)

        return weight_map

def load_train_data(npy_path = "data/dataset", train_file = "/imgs_train.npy", mask_file = "/imgs_mask_train.npy", hist_equal = False):

    print('-' * 30)
    print('load train images...')

    imgs_train = np.load(npy_path + train_file)
    imgs_mask_train = np.load(npy_path + mask_file)

    if hist_equal: imgs_train = hist_equalization(imgs_train)

    # weight_map_train = np.load(npy_path + "/weight_map_train.npy")
    # weight_map_train = weight_map_train.astype('float32')

    imgs_train = imgs_train.astype('float32')
    imgs_mask_train = imgs_mask_train.astype('float32')

    if LCN_enable:
        imgs_train = imgs_train.astype('float64')
        imgs_train = LecunLCN(imgs_train, image_shape=imgs_train.shape).output.eval()
        imgs_train = imgs_train.astype('float32')

    if not LCN_enable: imgs_train /= 255

    imgs_train -= imgs_train.mean(axis=0)
    imgs_mask_train /= 255
    imgs_mask_train[imgs_mask_train > 0.5] = 1
    imgs_mask_train[imgs_mask_train <= 0.5] = 0

    # weight_map_train = create_weight_map(imgs_mask_train)

    print("Done loading traing data")
    print('-' * 30)
    return imgs_train, imgs_mask_train

def load_val_data(npy_path = "data/dataset", hist_equal = True):

    print('-' * 30)
    print('load validation images...')

    imgs_train = np.load(npy_path + "/imgs_val.npy")
    imgs_mask_train = np.load(npy_path + "/imgs_mask_val.npy")

    if hist_equal: imgs_train = hist_equalization(imgs_train)

    imgs_train = imgs_train.astype('float32')
    imgs_mask_train = imgs_mask_train.astype('float32')

    if LCN_enable:
        imgs_train = imgs_train.astype('float64')
        imgs_train = LecunLCN(imgs_train, image_shape=imgs_train.shape).output.eval()
        imgs_train = imgs_train.astype('float32')

    if not LCN_enable: imgs_train /= 255
    imgs_train -= imgs_train.mean(axis=0)
    imgs_mask_train /= 255
    imgs_mask_train[imgs_mask_train > 0.5] = 1
    imgs_mask_train[imgs_mask_train <= 0.5] = 0
    print("Done loading validation data")
    print('-' * 30)
    return imgs_train, imgs_mask_train

def load_test_data(npy_path = "data/dataset", hist_equal = True):

    print('-' * 30)
    print('load test images...')

    imgs_test = np.load(npy_path + "/imgs_test.npy")

    if hist_equal: imgs_test = hist_equalization(imgs_test)

    imgs_test = imgs_test.astype('float32')

    if LCN_enable:
        imgs_test = imgs_test.astype('float64')
        imgs_test = LecunLCN(imgs_test, image_shape=imgs_test.shape).output.eval()
        imgs_test = imgs_test.astype('float32')

    if not LCN_enable: imgs_test /= 255

    imgs_test -= imgs_test.mean(axis=0)

    print("Done loading test data")
    print('-' * 30)
    return imgs_test

def load_val_5imgs(npy_path = "data/dataset"):
    print('-' * 30)
    print('load train images...')

    imgs_train = np.load(npy_path + "/imgs_val_5imgs.npy")
    imgs_mask_train = np.load(npy_path + "/imgs_mask_val_5imgs.npy")

    # imgs_train = hist_equalization(imgs_train)

    imgs_train = imgs_train.astype('float64')
    imgs_mask_train = imgs_mask_train.astype('float64')

    if LCN_enable: imgs_train = LecunLCN(imgs_train, image_shape=imgs_train.shape).output.eval()

    if not LCN_enable: imgs_train /= 255

    mean = imgs_train.mean(axis=0)
    imgs_train -= mean


    imgs_mask_train /= 255
    imgs_mask_train[imgs_mask_train > 0.5] = 1
    imgs_mask_train[imgs_mask_train <= 0.5] = 0

    # weight_map_train = self.create_weight_map(imgs_mask_train)

    print("Done loading traing data")
    print('-' * 30)
    return imgs_train, imgs_mask_train

def hist_equalization(inputs):      # inputs are uint8, 0-255, Nx1x636x636
    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))
    output = inputs.copy()
    for i in range(len(inputs)):
        img = inputs[i, 0, :, :]
        # res = cv2.equalizeHist(img)
        res = clahe.apply(img)
        output[i,0,:,:] = res
    return output

### BinaryCrossEntropyLoss2d().forward(logits, labels)
class BinaryCrossEntropyLoss2d(nn.Module):
    def __init__(self, weight=None, size_average=True):
        """
        Binary cross entropy loss 2D
        Args:
            weight:
            size_average:
        """
        super(BinaryCrossEntropyLoss2d, self).__init__()
        self.bce_loss = nn.BCELoss(weight, size_average)

    def forward(self, logits, targets):
        # probs = F.sigmoid(logits)
        probs = logits
        probs_flat = probs.view(-1)  # Flatten
        targets_flat = targets.view(-1)  # Flatten
        return self.bce_loss(probs_flat, targets_flat)      # (output, labels)

class BCE_with_Weights(nn.Module):
    def __init__(self, weights=None):
        """
        Binary cross entropy loss 2D
        Args:
            weights:
        """
        super(BCE_with_Weights, self).__init__()
        self.weights = weights

    def forward(self, output, target):
        if self.weights is not None:
            loss = self.weights * (target * torch.log(output) + (1 - target) * torch.log(1 - output))
        else:
            loss = target * torch.log(output) + (1 - target) * torch.log(1 - output)

        return torch.neg(torch.mean(loss))

class LRN(nn.Module):       # input x is Torch tensor
    def __init__(self, local_size=1, alpha=1.0, beta=0.75, ACROSS_CHANNELS=False):      #LRN(local_size=5, alpha=0.0001, beta=0.75),
        super(LRN, self).__init__()
        self.ACROSS_CHANNELS = ACROSS_CHANNELS
        if self.ACROSS_CHANNELS:
            self.average = nn.AvgPool3d(kernel_size=(local_size, 1, 1),
                                        stride=1, padding=(int((local_size - 1.0) / 2), 0, 0))
        else:
            self.average = nn.AvgPool2d(kernel_size=local_size,
                                        stride=1, padding=int((local_size - 1.0) / 2))
        self.alpha = alpha
        self.beta = beta

    def forward(self, x):
        if self.ACROSS_CHANNELS:
            div = x.pow(2).unsqueeze(1)
            div = self.average(div).squeeze(1)
            div = div.mul(self.alpha).add(1.0).pow(self.beta)
        else:
            div = x.pow(2)
            div = self.average(div)
            div = div.mul(self.alpha).add(1.0).pow(self.beta)
        x = x.div(div)
        return x


Sun Nov 19 09:08:53 2017
Leg16_ResNet_dropout_0_2_rmSigmoid_40aug_10ela_3inten_reflect
optim.SGD(net.parameters(), lr=1e-2, momentum=0.99)
Number of epoch max: 8
==========================================================================================
Sun Nov 19 09:12:49 2017
Leg16_ResNet_dropout_0_2_rmSigmoid_40aug_10ela_3inten_reflect
Sun Nov 19 09:12:47 2017
import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.autograd import Variable
import math


class ConvBnRelu(nn.Module):
    def __init__(self, in_channels, out_channels, kernel_size, padding, stride):
        super(ConvBnRelu, self).__init__()
        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=kernel_size, padding=padding, stride=stride)
        self.bn = nn.BatchNorm2d(out_channels)
        self.relu = nn.ReLU()

    def forward(self, x):
        x = self.conv(x)
        # x = self.bn(x)
        x = self.relu(x)
        return x


class StackEncoder(nn.Module):
    def __init__(self, in_channels, out_channels):
        super(StackEncoder, self).__init__()
        self.convr1 = ConvBnRelu(in_channels, out_channels, kernel_size=(3, 3), stride=1, padding=0)
        self.convr2 = ConvBnRelu(out_channels, out_channels, kernel_size=(3, 3), stride=1, padding=0)
        self.maxPool = nn.MaxPool2d(kernel_size=(2, 2), stride=2)

    def forward(self, x):
        x = self.convr1(x)
        x = self.convr2(x)
        x_trace = x             # save x to use in concat in the Decoder path
        out = self.maxPool(x)
        return out, x_trace


class StackDecoder(nn.Module):
    def __init__(self, in_channels, out_channels, upsample_size, padding, drop_out=False):
        super(StackDecoder, self).__init__()

        self.drop_out = drop_out
        self.dropout_layer = nn.Dropout2d(p=0.5)

        ''' this is old version
        self.upSample = nn.Upsample(size=upsample_size, scale_factor=(2, 2), mode="bilinear")
        self.convr1 = ConvBnRelu(in_channels, out_channels, kernel_size=(3, 3), stride=1, padding=padding)
        # Crop + concat step between these 2
        self.convr2 = ConvBnRelu(in_channels, out_channels, kernel_size=(3, 3), stride=1, padding=padding)
        '''
        self.upSample = nn.ConvTranspose2d(in_channels, out_channels, 2, stride=2)
        self.convr1 = ConvBnRelu(in_channels, out_channels, kernel_size=(3, 3), stride=1, padding=padding)
        self.convr2 = ConvBnRelu(out_channels, out_channels, kernel_size=(3, 3), stride=1, padding=padding)

    def _crop_concat(self, upsampled, bypass):
        """
         Crop y to the (h, w) of x and concat them.
         Used for the expansive path.
        Returns:
            The concatenated tensor
        """
        c = (bypass.size()[2] - upsampled.size()[2]) // 2
        bypass = F.pad(bypass, (-c, -c, -c, -c))

        return torch.cat((bypass, upsampled), 1)

    def forward(self, x, down_tensor):
        '''old version
        x = self.upSample(x)
        x = self.convr1(x)
        x = self._crop_concat(x, down_tensor)
        x = self.convr2(x)
        '''

        x = self.upSample(x)
        x = self._crop_concat(x, down_tensor)
        x = self.convr1(x)
        if self.drop_out: x = self.dropout_layer(x)
        x = self.convr2(x)
        if self.drop_out: x = self.dropout_layer(x)
        return x


class UNet_BN(nn.Module):
    def __init__(self):
        super(UNet_BN, self).__init__()
        # channels, height, width = in_shape

        # self.dropout = dropout

        self.model_code = ""        # variable to save model and main function when loaded

        self.down1 = StackEncoder(1, 64)
        self.down2 = StackEncoder(64, 128)
        self.down3 = StackEncoder(128, 256)
        self.down4 = StackEncoder(256, 512)

        self.center = nn.Sequential(
            # nn.Dropout2d(p=0.2),
            ConvBnRelu(512, 1024, kernel_size=(3, 3), stride=1, padding=0),
            nn.Dropout2d(p=0.2),
            ConvBnRelu(1024, 1024, kernel_size=(3, 3), stride=1, padding=0),
            nn.Dropout2d(p=0.2)
        )

        self.up1 = StackDecoder(in_channels=1024, out_channels=512, upsample_size=(64,64), padding = 1)
        self.up2 = StackDecoder(in_channels=512, out_channels=256, upsample_size=(128,128), padding = 1)
        self.up3 = StackDecoder(in_channels=256, out_channels=128, upsample_size=(256,256), padding = 1)
        self.up4 = StackDecoder(in_channels=128, out_channels=64, upsample_size=(512,512), padding = 1)

        # 1x1 convolution at the last layer
        # Different from the paper is the output size here
        self.output_seg_map = nn.Conv2d(64, 1, kernel_size=(1, 1), padding=0, stride=1)

        self._initialize_weights()

    def forward(self, x):
        x, x_trace1 = self.down1(x)
        x, x_trace2 = self.down2(x)
        x, x_trace3 = self.down3(x)
        x, x_trace4 = self.down4(x)
        x = self.center(x)
        x = self.up1(x, x_trace4)
        x = self.up2(x, x_trace3)
        x = self.up3(x, x_trace2)
        x = self.up4(x, x_trace1)

        x = self.output_seg_map(x)
        # x = F.sigmoid(x)
        # out = torch.squeeze(out, dim=1)
        return x


    def _initialize_weights(self):
        for m in self.modules():
            if isinstance(m, nn.Conv2d):
                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels
                m.weight.data.normal_(0, math.sqrt(2. / n))
                if m.bias is not None:
                    m.bias.data.zero_()
            elif isinstance(m, nn.BatchNorm2d):
                m.weight.data.fill_(1)
                m.bias.data.zero_()

# x = Variable(torch.randn(1,1,636,636))       # simulate input image
# net = UNet_BN()
# out = net(x)
# print("input: ", x)
# print("output: ", out)

===============from __future__ import print_function, division
import torch
from torch import optim
from torch.autograd import Variable
from torch.utils.data import DataLoader
import numpy as np
import torch.nn as nn
import torch.nn.functional as F
import Unet
import Unet_BatchNorm
import tifffile as tiff
import Utils
import time
from sklearn.metrics import average_precision_score, recall_score, f1_score
import Analysis
import Unet_ResNet

def to_var(x):
    if torch.cuda.is_available():
        return Variable(x.cuda())
    else:
        return Variable(x)

### BinaryCrossEntropyLoss2d().forward(logits, labels)
class BinaryCrossEntropyLoss2d(nn.Module):
    def __init__(self, weight=None, size_average=True):
        """
        Binary cross entropy loss 2D
        Args:
            weight:
            size_average:
        """
        super(BinaryCrossEntropyLoss2d, self).__init__()
        self.bce_loss = nn.BCELoss(weight, size_average)

    def forward(self, probs, targets):
        probs = F.sigmoid(probs)
        probs_flat = probs.view(-1)  # Flatten
        targets_flat = targets.view(-1)  # Flatten
        return self.bce_loss(probs_flat, targets_flat)      # (output, labels)

class SoftDiceLoss(nn.Module):
    def __init__(self, weight=None, size_average=True):
        super(SoftDiceLoss, self).__init__()

    def forward(self, probs, targets):
        smooth = 1
        num = targets.size(0)
        probs = F.sigmoid(probs)
        m1 = probs.view(num, -1)
        m2 = targets.view(num, -1)
        intersection = (m1 * m2)
        score = 2. * (intersection.sum(1) + smooth) / (m1.sum(1) + m2.sum(1) + smooth)
        score = 1 - score.sum() / num
        return score

def _criterion(logits, labels):
    return BinaryCrossEntropyLoss2d().forward(logits, labels) + \
        SoftDiceLoss().forward(logits, labels)

def NetEval(net,valdata_loader,crit):
    loss = 0.
    count = 0
    net.eval()
    for i,data in enumerate(valdata_loader,0):
        inputs, labels = data
        inputs, labels = to_var(inputs), to_var(labels)
        out = net(inputs)
        l = crit(out, labels)
        loss += l.data[0]
        count += 1
    return loss/count

# calculate Precision, Recall, F1-measure, IoU over the validation set
def Net_performace_val(net,valdata_loader):
    precision_list = []
    recall_list = []
    iou_list = []
    net.eval()
    print("len of valdata: ", len(valdata_loader))
    for i,data in enumerate(valdata_loader,0):

        inputs, labels = data
        out = NetPredict(net, inputs)   # out is numpy array 512x512
        labels = labels.numpy()
        labels = labels[0,0,:,:]        # labels is numpy array 512x512
        # remove the case where the mask is plain black
        if np.sum(labels) < 0.01*np.shape(labels)[0]*np.shape(labels)[1]: continue

        precision = average_precision_score(labels, out)
        recall = recall_score(labels, out, average='weighted')
        iou = IoU(out, labels)
        precision_list.append(precision)
        recall_list.append(recall)
        iou_list.append(iou)

    precision, recall, iou = np.mean(precision_list), np.mean(recall_list), np.mean(iou_list)
    F1_measure = 2.0*precision*recall/(precision + recall)

    return precision, recall, F1_measure, iou

# calculate IoU
def IoU(pred, target):
    # Ignore IoU for background class
    cls = 0.5
    pred_inds = pred > cls
    target_inds = target > cls

    intersection = (pred_inds[target_inds]).sum()  # Cast to long to prevent overflows
    union = pred_inds.sum() + target_inds.sum() - intersection
    if union == 0:
        ious = float('nan')  # If there is no ground truth, do not include in evaluation
    else:
        ious = 1.0*intersection / max(union, 1)
    return ious

#process the test data and save to separate .tif image
def NetTest(net,testdata_loader,path = "data/results/"):
    net.eval()
    for i, data in enumerate(testdata_loader, 0):
        if i >= 30: return 1        # for debug
        data = to_var(data)
        out = net(data)

        out = F.sigmoid(out)

        imgname = path + str(i) + ".tif"
        img = out.cpu()
        img = img[0,0,:,:]
        img = img.data.numpy()
        img_shape = img.shape
        img = img.reshape(-1)
        img[img < 0.5] = 0; img[img >= 0.5] = 1
        img = img.reshape(img_shape)
        img = np.uint8(img * 255)
        tiff.imsave(imgname, img)

# return input image size like 512x512, numpy array
def NetPredict(net, data):
    net.eval()
    data = to_var(data)
    out = net(data)

    out = F.sigmoid(out)

    img = out.cpu()
    img = img[0, 0, :, :]
    img = img.data.numpy()
    img_shape = img.shape
    img = img.reshape(-1)
    img[img < 0.5] = 0;
    img[img >= 0.5] = 1
    img = img.reshape(img_shape)
    return img
def write_2_log(content):
    path = "log_file.txt"
    output = open(path, "a")
    output.write("\n")
    output.write(content)
    output.close()

if __name__ == '__main__':
    '''subjects to change for each exp:
    + path to the dataset
    + opt function
    + leg description
    + N_epoch
    + saved_model
    '''
    start_begining = time.time()

    # path = "data/dataset"
    path = "/home/anhxtuan/HanLe/dataset/40aug_10ela_3inten_reflect"

    import os
    print("Does the folder exist?: ", os.path.isdir(path))
    print("Does the path exist?: ", os.path.exists(path))

    # imgs_train, imgs_mask_train = Utils.load_train_data(npy_path=path)
    # trainset = zip(imgs_train, imgs_mask_train)
    # trainloader = torch.utils.data.DataLoader(trainset, batch_size=1,
    #                                           shuffle=True, num_workers=2)

    imgs_val, imgs_mask_val = Utils.load_val_data(npy_path=path)
    valset = zip(imgs_val, imgs_mask_val)
    valloader = torch.utils.data.DataLoader(valset, batch_size=1,
                                              shuffle=False, num_workers=2)
    # net = Unet.UNet()                     # Unet 1
    net = Unet_BatchNorm.UNet_BN()          # Unet 2 with batchNorm
    # net = Unet_ResNet.UNet_ResNet()

    f1 = open("Unet_BatchNorm.py", 'r')     # embede code into the model to be saved later
    f2 = open("UnetTrain.py", 'r')
    f3 = open("Utils.py", 'r')
    model_notes = time.strftime("%c") + "\n" + f1.read() + "\n" + "==="*5 + f2.read() + "\n" + "==="*5 + f3.read()
    f1.close()
    f2.close()

    # criterion = nn.BCELoss()
    criterion = BinaryCrossEntropyLoss2d()
    # criterion = SoftDiceLoss()

    if torch.cuda.is_available():
        # torch.set_default_tensor_type('torch.cuda.FloatTensor')
        # net.load_state_dict(torch.load("Unet2_model_6epoch_Leg14_dropout_0_2_rmSigmoid_40aug_10ela_3inten_reflect"))
        net.cuda()
        # criterion.cuda()

    opt = optim.SGD(net.parameters(), lr=1e-2, momentum=0.99)       # subject to change
    # opt = optim.RMSprop(net.parameters(), lr=2e-4)
    # RMSprop[22](learning rate 0.001) with weight decay set to 0.001.
    # opt = optim.Adam(net.parameters(), lr=1e-3, weight_decay=1e-4)

    train_loss = []
    val_loss = []

    print("[epoch, #image] Loss")
    leg = "Leg16_ResNet_dropout_0_2_rmSigmoid_40aug_10ela_3inten_reflect"
    print("Processing: ", leg)
    model_name = ""

    N_epoch = 8
    model_saved = np.arange(2,N_epoch+1,2)
    val_loss_min = 100

    write_2_log("==="*30)
    write_2_log(time.strftime("%c"))       # time, date of exp
    write_2_log(leg)
    write_2_log(model_notes)
    write_2_log(time.strftime("%c"))  # time, date of exp
    write_2_log(leg)
    write_2_log("optim.SGD(net.parameters(), lr=1e-2, momentum=0.99)")
    write_2_log("Number of epoch max: " + str(N_epoch))

    min_model_epoch = 0
    for epoch in range(N_epoch):
        running_loss = 0.0; count = 0
        net.train()

        N_files = 1
        if N_files > 0:
            for j in range(N_files):
                train_file = "/imgs_train_" + str(j + 1) + ".npy"
                mask_file = "/imgs_mask_train_" + str(j + 1) + ".npy"
        else:
            train_file = "/imgs_train.npy"
            mask_file = "/imgs_mask_train.npy"

            imgs_train, imgs_mask_train = Utils.load_train_data(npy_path=path, train_file=train_file, mask_file=mask_file)
            trainset = zip(imgs_train, imgs_mask_train)
            trainloader = torch.utils.data.DataLoader(trainset, batch_size=1,
                                                      shuffle=True, num_workers=2)
            for i, data in enumerate(trainloader, 0):
                inputs, labels = data
                temp = labels.numpy()
                temp = temp[0, 0, :, :]  # labels is numpy array 512x512
                # remove the case where the mask is plain black
                if np.sum(temp) < 0.01 * np.shape(temp)[0] * np.shape(temp)[1]: continue
                inputs, labels = to_var(inputs), to_var(labels)
                opt.zero_grad()
                out = net(inputs)
                loss = criterion(out, labels)
                loss.backward()
                opt.step()
                running_loss += loss.data[0]
                count += 1
        net.eval()
        val_loss_temp = NetEval(net, valloader, criterion)
        if epoch > 0 and val_loss_temp < val_loss_min:        # save the model which has the lowest val_loss, ignore first epoch
            val_loss_min = val_loss_temp
            torch.save(net.state_dict(), "UnetRes_model_" + leg + "_min_val_loss")  # save model
            min_model_epoch = epoch + 1

        disp = 'Epoch %d: Train loss: %.6f, Val loss: %.6f' % (epoch + 1, running_loss/count, val_loss_temp)
        write_2_log(disp)
        print(disp)
        val_loss.append(val_loss_temp)
        train_loss.append(running_loss/count); running_loss = 0.0

        if (epoch + 1) in model_saved:        # save checkpoint
            model_name = "UnetRes_model_" + str(epoch+1) + "epoch_" + leg
            torch.save(net.state_dict(), model_name)  # save model
            Analysis.analysis(model_file = model_name, valloader = valloader)

    write_2_log("Best model at epoch: " + str(min_model_epoch))
    write_2_log("Total training time: " + str((time.time() - start_begining) / 3600.0))

    val_loss_file = "data/results" + "/val_loss_" + str(N_epoch) + "epoch_" + leg + ".npy"
    train_loss_file = "data/results" + "/training_loss_" + str(N_epoch) + "epoch_" + leg + ".npy"

    np.save(val_loss_file, val_loss)
    np.save(train_loss_file, train_loss)
    print("total processing time in seconds: ", time.time() - start_begining)
    print("total processing time in mins: ", (time.time() - start_begining) / 60.0)
    print("total processing time in hours: ", (time.time() - start_begining) / 3600.0)

    Analysis.analysis(model_file="UnetRes_model_" + leg + "_min_val_loss", valloader=valloader)

    Analysis.PlotLoss(model_file = model_name, loss_train_path = train_loss_file, loss_val_path = val_loss_file, epoch_No = N_epoch)

    write_2_log(time.strftime("%c"))  # time, date of exp
===============import numpy as np
import torch.nn as nn
import torch
import cv2
from lcn import LecunLCN

LCN_enable = False

def input_filled_mirroring(x):      # fill missing data by mirroring the input image
    '''input size 636 --> output size 512'''
    w, h = x.shape
    e = 62  # extra width on 1 edge
    y = np.zeros((h + e * 2, w + e * 2))
    y[e:h + e, e:w + e] = x
    y[e:e + h, 0:e] = np.flip(y[e:e + h, e:2 * e], 1)  # flip vertically
    y[e:e + h, e + w:2 * e + w] = np.flip(y[e:e + h, w:e + w], 1)  # flip vertically
    y[0:e, 0:2 * e + w] = np.flip(y[e:2 * e, 0:2 * e + w], 0)  # flip horizontally
    y[e + h:2 * e + h, 0:2 * e + w] = np.flip(y[h:e + h, 0:2 * e + w], 0)  # flip horizontally
    return y

def nearest_cells_distance(pos, img):
    # searching in 8 directions to find 2 nearest distances to neighbor cells
    curr_value = img[pos]
    w = img.shape[0];h = img.shape[1]
    count_detect = 0  # detect 2 nearest neighbors. break the search if count_detect = 2
    x, y = pos

    # print("w,h: ", (w, h))
    d1 = 9999999;d2 = 9999999;d3 = 9999999;d4 = 9999999
    d5 = 9999999;d6 = 9999999;d7 = 9999999;d8 = 9999999
    for i in range(1, max(w, h)):
        # (x+1, y), (x+1, y+1), (x+1, y-1),
        # (x, y+1), (x, y-1)
        # (x-1, y), (x-1,y+1), (x-1,y-1),
        if x + i < w:
            if img[(x + i, y)] != curr_value and d1 == 9999999:
                d1 = i; count_detect += 1
            if y + i < h:
                if img[(x + i, y + i)] != curr_value and d2 == 9999999:
                    d2 = i; count_detect += 1
            elif y - i >= 0:
                if img[(x + i, y - i)] != curr_value and d3 == 9999999:
                    d3 = i; count_detect += 1
        if y + i < h:
            if img[(x, y + i)] != curr_value and d4 == 9999999:
                d4 = i; count_detect += 1
        if y - i >= 0:
            if img[(x, y - i)] != curr_value and d5 == 9999999:
                d5 = i; count_detect += 1
        if x - i >= 0:
            if img[(x - i, y)] != curr_value and d6 == 9999999:
                d6 = i; count_detect += 1
            if y + i < h:
                if img[(x - i, y + i)] != curr_value and d7 == 9999999:
                    d7 = i; count_detect += 1
            elif y - i >= 0:
                if img[(x - i, y - i)] != curr_value and d8 == 9999999:
                    d8 = i; count_detect += 1
        if count_detect >= 2: break

    d = [d1, d2, d3, d4, d5, d6, d7, d8]
    min_index = np.argmin(d)
    dist1 = d[min_index]
    d.remove(dist1)
    min_index = np.argmin(d)
    dist2 = d[min_index]
    return dist1, dist2

def create_weight_map(imgs_mask):
        print('-' * 30)
        print('Creating weights for masks ...')
        print('-' * 30)
        weight_map = np.ndarray(
            (len(imgs_mask), 1, np.shape(imgs_mask)[2], np.shape(imgs_mask)[3]), dtype=np.float32)
        w_0 = 10; sigma = 4
        imgs_w, imgs_h = np.shape(imgs_mask)[2], np.shape(imgs_mask)[3]
        total_pixels = imgs_w*imgs_h
        import time
        start = time.time()
        for i in range(len(imgs_mask)):
            if i%10 == 0: print("Done processing: %d images, time passed: %.2f mins" % (i, (time.time() - start)/60.0))
            temp = imgs_mask[i,0,:,:]
            w_border = 1 - np.sum(temp)/total_pixels        # w_c of pixel on the border (black)
            for m in range(imgs_w):
                for n in range(imgs_h):
                    # loop through all pixel of the mask
                    d1,d2 = nearest_cells_distance((m,n), temp)
                    w_c = w_border
                    if temp[m,n] == 0: w_c = 1 - w_border
                    weight_map[i,0,m,n] = w_c*5 + w_0*np.exp(-(d1 + d2)**2/(2*sigma**2))
                    # print("w_0*np.exp(): ", w_0*np.exp(-(d1 + d2)**2/(2*sigma**2)))
                    # print("w_border: ", w_border)

        np.save('data/dataset/weight_map_train.npy', weight_map)

        return weight_map

def load_train_data(npy_path = "data/dataset", train_file = "/imgs_train.npy", mask_file = "/imgs_mask_train.npy", hist_equal = False):

    print('-' * 30)
    print('load train images...')

    imgs_train = np.load(npy_path + train_file)
    imgs_mask_train = np.load(npy_path + mask_file)

    if hist_equal: imgs_train = hist_equalization(imgs_train)

    # weight_map_train = np.load(npy_path + "/weight_map_train.npy")
    # weight_map_train = weight_map_train.astype('float32')

    imgs_train = imgs_train.astype('float32')
    imgs_mask_train = imgs_mask_train.astype('float32')

    if LCN_enable:
        imgs_train = imgs_train.astype('float64')
        imgs_train = LecunLCN(imgs_train, image_shape=imgs_train.shape).output.eval()
        imgs_train = imgs_train.astype('float32')

    if not LCN_enable: imgs_train /= 255

    imgs_train -= imgs_train.mean(axis=0)
    imgs_mask_train /= 255
    imgs_mask_train[imgs_mask_train > 0.5] = 1
    imgs_mask_train[imgs_mask_train <= 0.5] = 0

    # weight_map_train = create_weight_map(imgs_mask_train)

    print("Done loading traing data")
    print('-' * 30)
    return imgs_train, imgs_mask_train

def load_val_data(npy_path = "data/dataset", hist_equal = True):

    print('-' * 30)
    print('load validation images...')

    imgs_train = np.load(npy_path + "/imgs_val.npy")
    imgs_mask_train = np.load(npy_path + "/imgs_mask_val.npy")

    if hist_equal: imgs_train = hist_equalization(imgs_train)

    imgs_train = imgs_train.astype('float32')
    imgs_mask_train = imgs_mask_train.astype('float32')

    if LCN_enable:
        imgs_train = imgs_train.astype('float64')
        imgs_train = LecunLCN(imgs_train, image_shape=imgs_train.shape).output.eval()
        imgs_train = imgs_train.astype('float32')

    if not LCN_enable: imgs_train /= 255
    imgs_train -= imgs_train.mean(axis=0)
    imgs_mask_train /= 255
    imgs_mask_train[imgs_mask_train > 0.5] = 1
    imgs_mask_train[imgs_mask_train <= 0.5] = 0
    print("Done loading validation data")
    print('-' * 30)
    return imgs_train, imgs_mask_train

def load_test_data(npy_path = "data/dataset", hist_equal = True):

    print('-' * 30)
    print('load test images...')

    imgs_test = np.load(npy_path + "/imgs_test.npy")

    if hist_equal: imgs_test = hist_equalization(imgs_test)

    imgs_test = imgs_test.astype('float32')

    if LCN_enable:
        imgs_test = imgs_test.astype('float64')
        imgs_test = LecunLCN(imgs_test, image_shape=imgs_test.shape).output.eval()
        imgs_test = imgs_test.astype('float32')

    if not LCN_enable: imgs_test /= 255

    imgs_test -= imgs_test.mean(axis=0)

    print("Done loading test data")
    print('-' * 30)
    return imgs_test

def load_val_5imgs(npy_path = "data/dataset"):
    print('-' * 30)
    print('load train images...')

    imgs_train = np.load(npy_path + "/imgs_val_5imgs.npy")
    imgs_mask_train = np.load(npy_path + "/imgs_mask_val_5imgs.npy")

    # imgs_train = hist_equalization(imgs_train)

    imgs_train = imgs_train.astype('float64')
    imgs_mask_train = imgs_mask_train.astype('float64')

    if LCN_enable: imgs_train = LecunLCN(imgs_train, image_shape=imgs_train.shape).output.eval()

    if not LCN_enable: imgs_train /= 255

    mean = imgs_train.mean(axis=0)
    imgs_train -= mean


    imgs_mask_train /= 255
    imgs_mask_train[imgs_mask_train > 0.5] = 1
    imgs_mask_train[imgs_mask_train <= 0.5] = 0

    # weight_map_train = self.create_weight_map(imgs_mask_train)

    print("Done loading traing data")
    print('-' * 30)
    return imgs_train, imgs_mask_train

def hist_equalization(inputs):      # inputs are uint8, 0-255, Nx1x636x636
    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))
    output = inputs.copy()
    for i in range(len(inputs)):
        img = inputs[i, 0, :, :]
        # res = cv2.equalizeHist(img)
        res = clahe.apply(img)
        output[i,0,:,:] = res
    return output

### BinaryCrossEntropyLoss2d().forward(logits, labels)
class BinaryCrossEntropyLoss2d(nn.Module):
    def __init__(self, weight=None, size_average=True):
        """
        Binary cross entropy loss 2D
        Args:
            weight:
            size_average:
        """
        super(BinaryCrossEntropyLoss2d, self).__init__()
        self.bce_loss = nn.BCELoss(weight, size_average)

    def forward(self, logits, targets):
        # probs = F.sigmoid(logits)
        probs = logits
        probs_flat = probs.view(-1)  # Flatten
        targets_flat = targets.view(-1)  # Flatten
        return self.bce_loss(probs_flat, targets_flat)      # (output, labels)

class BCE_with_Weights(nn.Module):
    def __init__(self, weights=None):
        """
        Binary cross entropy loss 2D
        Args:
            weights:
        """
        super(BCE_with_Weights, self).__init__()
        self.weights = weights

    def forward(self, output, target):
        if self.weights is not None:
            loss = self.weights * (target * torch.log(output) + (1 - target) * torch.log(1 - output))
        else:
            loss = target * torch.log(output) + (1 - target) * torch.log(1 - output)

        return torch.neg(torch.mean(loss))

class LRN(nn.Module):       # input x is Torch tensor
    def __init__(self, local_size=1, alpha=1.0, beta=0.75, ACROSS_CHANNELS=False):      #LRN(local_size=5, alpha=0.0001, beta=0.75),
        super(LRN, self).__init__()
        self.ACROSS_CHANNELS = ACROSS_CHANNELS
        if self.ACROSS_CHANNELS:
            self.average = nn.AvgPool3d(kernel_size=(local_size, 1, 1),
                                        stride=1, padding=(int((local_size - 1.0) / 2), 0, 0))
        else:
            self.average = nn.AvgPool2d(kernel_size=local_size,
                                        stride=1, padding=int((local_size - 1.0) / 2))
        self.alpha = alpha
        self.beta = beta

    def forward(self, x):
        if self.ACROSS_CHANNELS:
            div = x.pow(2).unsqueeze(1)
            div = self.average(div).squeeze(1)
            div = div.mul(self.alpha).add(1.0).pow(self.beta)
        else:
            div = x.pow(2)
            div = self.average(div)
            div = div.mul(self.alpha).add(1.0).pow(self.beta)
        x = x.div(div)
        return x


Sun Nov 19 09:12:49 2017
Leg16_ResNet_dropout_0_2_rmSigmoid_40aug_10ela_3inten_reflect
optim.SGD(net.parameters(), lr=1e-2, momentum=0.99)
Number of epoch max: 8
==========================================================================================
Sun Nov 19 09:21:20 2017
Leg16_ResNet_dropout_0_2_rmSigmoid_40aug_10ela_3inten_reflect
Sun Nov 19 09:21:18 2017
import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.autograd import Variable
import math


class ConvBnRelu(nn.Module):
    def __init__(self, in_channels, out_channels, kernel_size, padding, stride):
        super(ConvBnRelu, self).__init__()
        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=kernel_size, padding=padding, stride=stride)
        self.bn = nn.BatchNorm2d(out_channels)
        self.relu = nn.ReLU()

    def forward(self, x):
        x = self.conv(x)
        # x = self.bn(x)
        x = self.relu(x)
        return x


class StackEncoder(nn.Module):
    def __init__(self, in_channels, out_channels):
        super(StackEncoder, self).__init__()
        self.convr1 = ConvBnRelu(in_channels, out_channels, kernel_size=(3, 3), stride=1, padding=0)
        self.convr2 = ConvBnRelu(out_channels, out_channels, kernel_size=(3, 3), stride=1, padding=0)
        self.maxPool = nn.MaxPool2d(kernel_size=(2, 2), stride=2)

    def forward(self, x):
        x = self.convr1(x)
        x = self.convr2(x)
        x_trace = x             # save x to use in concat in the Decoder path
        out = self.maxPool(x)
        return out, x_trace


class StackDecoder(nn.Module):
    def __init__(self, in_channels, out_channels, upsample_size, padding, drop_out=False):
        super(StackDecoder, self).__init__()

        self.drop_out = drop_out
        self.dropout_layer = nn.Dropout2d(p=0.5)

        ''' this is old version
        self.upSample = nn.Upsample(size=upsample_size, scale_factor=(2, 2), mode="bilinear")
        self.convr1 = ConvBnRelu(in_channels, out_channels, kernel_size=(3, 3), stride=1, padding=padding)
        # Crop + concat step between these 2
        self.convr2 = ConvBnRelu(in_channels, out_channels, kernel_size=(3, 3), stride=1, padding=padding)
        '''
        self.upSample = nn.ConvTranspose2d(in_channels, out_channels, 2, stride=2)
        self.convr1 = ConvBnRelu(in_channels, out_channels, kernel_size=(3, 3), stride=1, padding=padding)
        self.convr2 = ConvBnRelu(out_channels, out_channels, kernel_size=(3, 3), stride=1, padding=padding)

    def _crop_concat(self, upsampled, bypass):
        """
         Crop y to the (h, w) of x and concat them.
         Used for the expansive path.
        Returns:
            The concatenated tensor
        """
        c = (bypass.size()[2] - upsampled.size()[2]) // 2
        bypass = F.pad(bypass, (-c, -c, -c, -c))

        return torch.cat((bypass, upsampled), 1)

    def forward(self, x, down_tensor):
        '''old version
        x = self.upSample(x)
        x = self.convr1(x)
        x = self._crop_concat(x, down_tensor)
        x = self.convr2(x)
        '''

        x = self.upSample(x)
        x = self._crop_concat(x, down_tensor)
        x = self.convr1(x)
        if self.drop_out: x = self.dropout_layer(x)
        x = self.convr2(x)
        if self.drop_out: x = self.dropout_layer(x)
        return x


class UNet_BN(nn.Module):
    def __init__(self):
        super(UNet_BN, self).__init__()
        # channels, height, width = in_shape

        # self.dropout = dropout

        self.model_code = ""        # variable to save model and main function when loaded

        self.down1 = StackEncoder(1, 64)
        self.down2 = StackEncoder(64, 128)
        self.down3 = StackEncoder(128, 256)
        self.down4 = StackEncoder(256, 512)

        self.center = nn.Sequential(
            # nn.Dropout2d(p=0.2),
            ConvBnRelu(512, 1024, kernel_size=(3, 3), stride=1, padding=0),
            nn.Dropout2d(p=0.2),
            ConvBnRelu(1024, 1024, kernel_size=(3, 3), stride=1, padding=0),
            nn.Dropout2d(p=0.2)
        )

        self.up1 = StackDecoder(in_channels=1024, out_channels=512, upsample_size=(64,64), padding = 1)
        self.up2 = StackDecoder(in_channels=512, out_channels=256, upsample_size=(128,128), padding = 1)
        self.up3 = StackDecoder(in_channels=256, out_channels=128, upsample_size=(256,256), padding = 1)
        self.up4 = StackDecoder(in_channels=128, out_channels=64, upsample_size=(512,512), padding = 1)

        # 1x1 convolution at the last layer
        # Different from the paper is the output size here
        self.output_seg_map = nn.Conv2d(64, 1, kernel_size=(1, 1), padding=0, stride=1)

        self._initialize_weights()

    def forward(self, x):
        x, x_trace1 = self.down1(x)
        x, x_trace2 = self.down2(x)
        x, x_trace3 = self.down3(x)
        x, x_trace4 = self.down4(x)
        x = self.center(x)
        x = self.up1(x, x_trace4)
        x = self.up2(x, x_trace3)
        x = self.up3(x, x_trace2)
        x = self.up4(x, x_trace1)

        x = self.output_seg_map(x)
        # x = F.sigmoid(x)
        # out = torch.squeeze(out, dim=1)
        return x


    def _initialize_weights(self):
        for m in self.modules():
            if isinstance(m, nn.Conv2d):
                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels
                m.weight.data.normal_(0, math.sqrt(2. / n))
                if m.bias is not None:
                    m.bias.data.zero_()
            elif isinstance(m, nn.BatchNorm2d):
                m.weight.data.fill_(1)
                m.bias.data.zero_()

# x = Variable(torch.randn(1,1,636,636))       # simulate input image
# net = UNet_BN()
# out = net(x)
# print("input: ", x)
# print("output: ", out)

===============from __future__ import print_function, division
import torch
from torch import optim
from torch.autograd import Variable
from torch.utils.data import DataLoader
import numpy as np
import torch.nn as nn
import torch.nn.functional as F
import Unet
import Unet_BatchNorm
import tifffile as tiff
import Utils
import time
from sklearn.metrics import average_precision_score, recall_score, f1_score
import Analysis
import Unet_ResNet

def to_var(x):
    if torch.cuda.is_available():
        return Variable(x.cuda())
    else:
        return Variable(x)

### BinaryCrossEntropyLoss2d().forward(logits, labels)
class BinaryCrossEntropyLoss2d(nn.Module):
    def __init__(self, weight=None, size_average=True):
        """
        Binary cross entropy loss 2D
        Args:
            weight:
            size_average:
        """
        super(BinaryCrossEntropyLoss2d, self).__init__()
        self.bce_loss = nn.BCELoss(weight, size_average)

    def forward(self, probs, targets):
        probs = F.sigmoid(probs)
        probs_flat = probs.view(-1)  # Flatten
        targets_flat = targets.view(-1)  # Flatten
        return self.bce_loss(probs_flat, targets_flat)      # (output, labels)

class SoftDiceLoss(nn.Module):
    def __init__(self, weight=None, size_average=True):
        super(SoftDiceLoss, self).__init__()

    def forward(self, probs, targets):
        smooth = 1
        num = targets.size(0)
        probs = F.sigmoid(probs)
        m1 = probs.view(num, -1)
        m2 = targets.view(num, -1)
        intersection = (m1 * m2)
        score = 2. * (intersection.sum(1) + smooth) / (m1.sum(1) + m2.sum(1) + smooth)
        score = 1 - score.sum() / num
        return score

def _criterion(logits, labels):
    return BinaryCrossEntropyLoss2d().forward(logits, labels) + \
        SoftDiceLoss().forward(logits, labels)

def NetEval(net,valdata_loader,crit):
    loss = 0.
    count = 0
    net.eval()
    for i,data in enumerate(valdata_loader,0):
        inputs, labels = data
        inputs, labels = to_var(inputs), to_var(labels)
        out = net(inputs)
        l = crit(out, labels)
        loss += l.data[0]
        count += 1
    return loss/count

# calculate Precision, Recall, F1-measure, IoU over the validation set
def Net_performace_val(net,valdata_loader):
    precision_list = []
    recall_list = []
    iou_list = []
    net.eval()
    print("len of valdata: ", len(valdata_loader))
    for i,data in enumerate(valdata_loader,0):

        inputs, labels = data
        out = NetPredict(net, inputs)   # out is numpy array 512x512
        labels = labels.numpy()
        labels = labels[0,0,:,:]        # labels is numpy array 512x512
        # remove the case where the mask is plain black
        if np.sum(labels) < 0.01*np.shape(labels)[0]*np.shape(labels)[1]: continue

        precision = average_precision_score(labels, out)
        recall = recall_score(labels, out, average='weighted')
        iou = IoU(out, labels)
        precision_list.append(precision)
        recall_list.append(recall)
        iou_list.append(iou)

    precision, recall, iou = np.mean(precision_list), np.mean(recall_list), np.mean(iou_list)
    F1_measure = 2.0*precision*recall/(precision + recall)

    return precision, recall, F1_measure, iou

# calculate IoU
def IoU(pred, target):
    # Ignore IoU for background class
    cls = 0.5
    pred_inds = pred > cls
    target_inds = target > cls

    intersection = (pred_inds[target_inds]).sum()  # Cast to long to prevent overflows
    union = pred_inds.sum() + target_inds.sum() - intersection
    if union == 0:
        ious = float('nan')  # If there is no ground truth, do not include in evaluation
    else:
        ious = 1.0*intersection / max(union, 1)
    return ious

#process the test data and save to separate .tif image
def NetTest(net,testdata_loader,path = "data/results/"):
    net.eval()
    for i, data in enumerate(testdata_loader, 0):
        if i >= 30: return 1        # for debug
        data = to_var(data)
        out = net(data)

        out = F.sigmoid(out)

        imgname = path + str(i) + ".tif"
        img = out.cpu()
        img = img[0,0,:,:]
        img = img.data.numpy()
        img_shape = img.shape
        img = img.reshape(-1)
        img[img < 0.5] = 0; img[img >= 0.5] = 1
        img = img.reshape(img_shape)
        img = np.uint8(img * 255)
        tiff.imsave(imgname, img)

# return input image size like 512x512, numpy array
def NetPredict(net, data):
    net.eval()
    data = to_var(data)
    out = net(data)

    out = F.sigmoid(out)

    img = out.cpu()
    img = img[0, 0, :, :]
    img = img.data.numpy()
    img_shape = img.shape
    img = img.reshape(-1)
    img[img < 0.5] = 0;
    img[img >= 0.5] = 1
    img = img.reshape(img_shape)
    return img
def write_2_log(content):
    path = "log_file.txt"
    output = open(path, "a")
    output.write("\n")
    output.write(content)
    output.close()

if __name__ == '__main__':
    '''subjects to change for each exp:
    + path to the dataset
    + opt function
    + leg description
    + N_epoch
    + saved_model
    '''
    start_begining = time.time()

    # path = "data/dataset"
    path = "/home/anhxtuan/HanLe/dataset/40aug_10ela_3inten_reflect"

    import os
    print("Does the folder exist?: ", os.path.isdir(path))
    print("Does the path exist?: ", os.path.exists(path))

    # imgs_train, imgs_mask_train = Utils.load_train_data(npy_path=path)
    # trainset = zip(imgs_train, imgs_mask_train)
    # trainloader = torch.utils.data.DataLoader(trainset, batch_size=1,
    #                                           shuffle=True, num_workers=2)

    imgs_val, imgs_mask_val = Utils.load_val_data(npy_path=path)
    valset = zip(imgs_val, imgs_mask_val)
    valloader = torch.utils.data.DataLoader(valset, batch_size=1,
                                              shuffle=False, num_workers=2)
    # net = Unet.UNet()                     # Unet 1
    # net = Unet_BatchNorm.UNet_BN()          # Unet 2 with batchNorm
    net = Unet_ResNet.UNet_ResNet()

    f1 = open("Unet_BatchNorm.py", 'r')     # embede code into the model to be saved later
    f2 = open("UnetTrain.py", 'r')
    f3 = open("Utils.py", 'r')
    model_notes = time.strftime("%c") + "\n" + f1.read() + "\n" + "==="*5 + f2.read() + "\n" + "==="*5 + f3.read()
    f1.close()
    f2.close()

    # criterion = nn.BCELoss()
    criterion = BinaryCrossEntropyLoss2d()
    # criterion = SoftDiceLoss()

    if torch.cuda.is_available():
        # torch.set_default_tensor_type('torch.cuda.FloatTensor')
        # net.load_state_dict(torch.load("Unet2_model_6epoch_Leg14_dropout_0_2_rmSigmoid_40aug_10ela_3inten_reflect"))
        net.cuda()
        # criterion.cuda()

    opt = optim.SGD(net.parameters(), lr=1e-2, momentum=0.99)       # subject to change
    # opt = optim.RMSprop(net.parameters(), lr=2e-4)
    # RMSprop[22](learning rate 0.001) with weight decay set to 0.001.
    # opt = optim.Adam(net.parameters(), lr=1e-3, weight_decay=1e-4)

    train_loss = []
    val_loss = []

    print("[epoch, #image] Loss")
    leg = "Leg16_ResNet_dropout_0_2_rmSigmoid_40aug_10ela_3inten_reflect"
    print("Processing: ", leg)
    model_name = ""

    N_epoch = 8
    model_saved = np.arange(2,N_epoch+1,2)
    val_loss_min = 100

    write_2_log("==="*30)
    write_2_log(time.strftime("%c"))       # time, date of exp
    write_2_log(leg)
    write_2_log(model_notes)
    write_2_log(time.strftime("%c"))  # time, date of exp
    write_2_log(leg)
    write_2_log("optim.SGD(net.parameters(), lr=1e-2, momentum=0.99)")
    write_2_log("Number of epoch max: " + str(N_epoch))

    min_model_epoch = 0
    for epoch in range(N_epoch):
        running_loss = 0.0; count = 0
        net.train()

        N_files = 1
        for j in range(N_files):
            if N_files > 0:
                train_file = "/imgs_train_" + str(j + 1) + ".npy"
                mask_file = "/imgs_mask_train_" + str(j + 1) + ".npy"
            else:
                train_file = "/imgs_train.npy"
                mask_file = "/imgs_mask_train.npy"

            imgs_train, imgs_mask_train = Utils.load_train_data(npy_path=path, train_file=train_file, mask_file=mask_file)
            trainset = zip(imgs_train, imgs_mask_train)
            trainloader = torch.utils.data.DataLoader(trainset, batch_size=1,
                                                      shuffle=True, num_workers=2)
            for i, data in enumerate(trainloader, 0):
                inputs, labels = data
                temp = labels.numpy()
                temp = temp[0, 0, :, :]  # labels is numpy array 512x512
                # remove the case where the mask is plain black
                if np.sum(temp) < 0.01 * np.shape(temp)[0] * np.shape(temp)[1]: continue
                inputs, labels = to_var(inputs), to_var(labels)
                opt.zero_grad()
                out = net(inputs)
                loss = criterion(out, labels)
                loss.backward()
                opt.step()
                running_loss += loss.data[0]
                count += 1

        net.eval()
        val_loss_temp = NetEval(net, valloader, criterion)
        if epoch > 0 and val_loss_temp < val_loss_min:        # save the model which has the lowest val_loss, ignore first epoch
            val_loss_min = val_loss_temp
            torch.save(net.state_dict(), "UnetRes_model_" + leg + "_min_val_loss")  # save model
            min_model_epoch = epoch + 1

        disp = 'Epoch %d: Train loss: %.6f, Val loss: %.6f' % (epoch + 1, running_loss/count, val_loss_temp)
        write_2_log(disp)
        print(disp)
        val_loss.append(val_loss_temp)
        train_loss.append(running_loss/count); running_loss = 0.0

        if (epoch + 1) in model_saved:        # save checkpoint
            model_name = "UnetRes_model_" + str(epoch+1) + "epoch_" + leg
            torch.save(net.state_dict(), model_name)  # save model
            Analysis.analysis(model_file = model_name, valloader = valloader)

    write_2_log("Best model at epoch: " + str(min_model_epoch))
    write_2_log("Total training time: " + str((time.time() - start_begining) / 3600.0))

    val_loss_file = "data/results" + "/val_loss_" + str(N_epoch) + "epoch_" + leg + ".npy"
    train_loss_file = "data/results" + "/training_loss_" + str(N_epoch) + "epoch_" + leg + ".npy"

    np.save(val_loss_file, val_loss)
    np.save(train_loss_file, train_loss)
    print("total processing time in seconds: ", time.time() - start_begining)
    print("total processing time in mins: ", (time.time() - start_begining) / 60.0)
    print("total processing time in hours: ", (time.time() - start_begining) / 3600.0)

    Analysis.analysis(model_file="UnetRes_model_" + leg + "_min_val_loss", valloader=valloader)

    Analysis.PlotLoss(model_file = model_name, loss_train_path = train_loss_file, loss_val_path = val_loss_file, epoch_No = N_epoch)

    write_2_log(time.strftime("%c"))  # time, date of exp
===============import numpy as np
import torch.nn as nn
import torch
import cv2
from lcn import LecunLCN

LCN_enable = False

def input_filled_mirroring(x):      # fill missing data by mirroring the input image
    '''input size 636 --> output size 512'''
    w, h = x.shape
    e = 62  # extra width on 1 edge
    y = np.zeros((h + e * 2, w + e * 2))
    y[e:h + e, e:w + e] = x
    y[e:e + h, 0:e] = np.flip(y[e:e + h, e:2 * e], 1)  # flip vertically
    y[e:e + h, e + w:2 * e + w] = np.flip(y[e:e + h, w:e + w], 1)  # flip vertically
    y[0:e, 0:2 * e + w] = np.flip(y[e:2 * e, 0:2 * e + w], 0)  # flip horizontally
    y[e + h:2 * e + h, 0:2 * e + w] = np.flip(y[h:e + h, 0:2 * e + w], 0)  # flip horizontally
    return y

def nearest_cells_distance(pos, img):
    # searching in 8 directions to find 2 nearest distances to neighbor cells
    curr_value = img[pos]
    w = img.shape[0];h = img.shape[1]
    count_detect = 0  # detect 2 nearest neighbors. break the search if count_detect = 2
    x, y = pos

    # print("w,h: ", (w, h))
    d1 = 9999999;d2 = 9999999;d3 = 9999999;d4 = 9999999
    d5 = 9999999;d6 = 9999999;d7 = 9999999;d8 = 9999999
    for i in range(1, max(w, h)):
        # (x+1, y), (x+1, y+1), (x+1, y-1),
        # (x, y+1), (x, y-1)
        # (x-1, y), (x-1,y+1), (x-1,y-1),
        if x + i < w:
            if img[(x + i, y)] != curr_value and d1 == 9999999:
                d1 = i; count_detect += 1
            if y + i < h:
                if img[(x + i, y + i)] != curr_value and d2 == 9999999:
                    d2 = i; count_detect += 1
            elif y - i >= 0:
                if img[(x + i, y - i)] != curr_value and d3 == 9999999:
                    d3 = i; count_detect += 1
        if y + i < h:
            if img[(x, y + i)] != curr_value and d4 == 9999999:
                d4 = i; count_detect += 1
        if y - i >= 0:
            if img[(x, y - i)] != curr_value and d5 == 9999999:
                d5 = i; count_detect += 1
        if x - i >= 0:
            if img[(x - i, y)] != curr_value and d6 == 9999999:
                d6 = i; count_detect += 1
            if y + i < h:
                if img[(x - i, y + i)] != curr_value and d7 == 9999999:
                    d7 = i; count_detect += 1
            elif y - i >= 0:
                if img[(x - i, y - i)] != curr_value and d8 == 9999999:
                    d8 = i; count_detect += 1
        if count_detect >= 2: break

    d = [d1, d2, d3, d4, d5, d6, d7, d8]
    min_index = np.argmin(d)
    dist1 = d[min_index]
    d.remove(dist1)
    min_index = np.argmin(d)
    dist2 = d[min_index]
    return dist1, dist2

def create_weight_map(imgs_mask):
        print('-' * 30)
        print('Creating weights for masks ...')
        print('-' * 30)
        weight_map = np.ndarray(
            (len(imgs_mask), 1, np.shape(imgs_mask)[2], np.shape(imgs_mask)[3]), dtype=np.float32)
        w_0 = 10; sigma = 4
        imgs_w, imgs_h = np.shape(imgs_mask)[2], np.shape(imgs_mask)[3]
        total_pixels = imgs_w*imgs_h
        import time
        start = time.time()
        for i in range(len(imgs_mask)):
            if i%10 == 0: print("Done processing: %d images, time passed: %.2f mins" % (i, (time.time() - start)/60.0))
            temp = imgs_mask[i,0,:,:]
            w_border = 1 - np.sum(temp)/total_pixels        # w_c of pixel on the border (black)
            for m in range(imgs_w):
                for n in range(imgs_h):
                    # loop through all pixel of the mask
                    d1,d2 = nearest_cells_distance((m,n), temp)
                    w_c = w_border
                    if temp[m,n] == 0: w_c = 1 - w_border
                    weight_map[i,0,m,n] = w_c*5 + w_0*np.exp(-(d1 + d2)**2/(2*sigma**2))
                    # print("w_0*np.exp(): ", w_0*np.exp(-(d1 + d2)**2/(2*sigma**2)))
                    # print("w_border: ", w_border)

        np.save('data/dataset/weight_map_train.npy', weight_map)

        return weight_map

def load_train_data(npy_path = "data/dataset", train_file = "/imgs_train.npy", mask_file = "/imgs_mask_train.npy", hist_equal = False):

    print('-' * 30)
    print('load train images...')

    imgs_train = np.load(npy_path + train_file)
    imgs_mask_train = np.load(npy_path + mask_file)

    if hist_equal: imgs_train = hist_equalization(imgs_train)

    # weight_map_train = np.load(npy_path + "/weight_map_train.npy")
    # weight_map_train = weight_map_train.astype('float32')

    imgs_train = imgs_train.astype('float32')
    imgs_mask_train = imgs_mask_train.astype('float32')

    if LCN_enable:
        imgs_train = imgs_train.astype('float64')
        imgs_train = LecunLCN(imgs_train, image_shape=imgs_train.shape).output.eval()
        imgs_train = imgs_train.astype('float32')

    if not LCN_enable: imgs_train /= 255

    imgs_train -= imgs_train.mean(axis=0)
    imgs_mask_train /= 255
    imgs_mask_train[imgs_mask_train > 0.5] = 1
    imgs_mask_train[imgs_mask_train <= 0.5] = 0

    # weight_map_train = create_weight_map(imgs_mask_train)

    print("Done loading traing data")
    print('-' * 30)
    return imgs_train, imgs_mask_train

def load_val_data(npy_path = "data/dataset", hist_equal = True):

    print('-' * 30)
    print('load validation images...')

    imgs_train = np.load(npy_path + "/imgs_val.npy")
    imgs_mask_train = np.load(npy_path + "/imgs_mask_val.npy")

    if hist_equal: imgs_train = hist_equalization(imgs_train)

    imgs_train = imgs_train.astype('float32')
    imgs_mask_train = imgs_mask_train.astype('float32')

    if LCN_enable:
        imgs_train = imgs_train.astype('float64')
        imgs_train = LecunLCN(imgs_train, image_shape=imgs_train.shape).output.eval()
        imgs_train = imgs_train.astype('float32')

    if not LCN_enable: imgs_train /= 255
    imgs_train -= imgs_train.mean(axis=0)
    imgs_mask_train /= 255
    imgs_mask_train[imgs_mask_train > 0.5] = 1
    imgs_mask_train[imgs_mask_train <= 0.5] = 0
    print("Done loading validation data")
    print('-' * 30)
    return imgs_train, imgs_mask_train

def load_test_data(npy_path = "data/dataset", hist_equal = True):

    print('-' * 30)
    print('load test images...')

    imgs_test = np.load(npy_path + "/imgs_test.npy")

    if hist_equal: imgs_test = hist_equalization(imgs_test)

    imgs_test = imgs_test.astype('float32')

    if LCN_enable:
        imgs_test = imgs_test.astype('float64')
        imgs_test = LecunLCN(imgs_test, image_shape=imgs_test.shape).output.eval()
        imgs_test = imgs_test.astype('float32')

    if not LCN_enable: imgs_test /= 255

    imgs_test -= imgs_test.mean(axis=0)

    print("Done loading test data")
    print('-' * 30)
    return imgs_test

def load_val_5imgs(npy_path = "data/dataset"):
    print('-' * 30)
    print('load train images...')

    imgs_train = np.load(npy_path + "/imgs_val_5imgs.npy")
    imgs_mask_train = np.load(npy_path + "/imgs_mask_val_5imgs.npy")

    # imgs_train = hist_equalization(imgs_train)

    imgs_train = imgs_train.astype('float64')
    imgs_mask_train = imgs_mask_train.astype('float64')

    if LCN_enable: imgs_train = LecunLCN(imgs_train, image_shape=imgs_train.shape).output.eval()

    if not LCN_enable: imgs_train /= 255

    mean = imgs_train.mean(axis=0)
    imgs_train -= mean


    imgs_mask_train /= 255
    imgs_mask_train[imgs_mask_train > 0.5] = 1
    imgs_mask_train[imgs_mask_train <= 0.5] = 0

    # weight_map_train = self.create_weight_map(imgs_mask_train)

    print("Done loading traing data")
    print('-' * 30)
    return imgs_train, imgs_mask_train

def hist_equalization(inputs):      # inputs are uint8, 0-255, Nx1x636x636
    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))
    output = inputs.copy()
    for i in range(len(inputs)):
        img = inputs[i, 0, :, :]
        # res = cv2.equalizeHist(img)
        res = clahe.apply(img)
        output[i,0,:,:] = res
    return output

### BinaryCrossEntropyLoss2d().forward(logits, labels)
class BinaryCrossEntropyLoss2d(nn.Module):
    def __init__(self, weight=None, size_average=True):
        """
        Binary cross entropy loss 2D
        Args:
            weight:
            size_average:
        """
        super(BinaryCrossEntropyLoss2d, self).__init__()
        self.bce_loss = nn.BCELoss(weight, size_average)

    def forward(self, logits, targets):
        # probs = F.sigmoid(logits)
        probs = logits
        probs_flat = probs.view(-1)  # Flatten
        targets_flat = targets.view(-1)  # Flatten
        return self.bce_loss(probs_flat, targets_flat)      # (output, labels)

class BCE_with_Weights(nn.Module):
    def __init__(self, weights=None):
        """
        Binary cross entropy loss 2D
        Args:
            weights:
        """
        super(BCE_with_Weights, self).__init__()
        self.weights = weights

    def forward(self, output, target):
        if self.weights is not None:
            loss = self.weights * (target * torch.log(output) + (1 - target) * torch.log(1 - output))
        else:
            loss = target * torch.log(output) + (1 - target) * torch.log(1 - output)

        return torch.neg(torch.mean(loss))

class LRN(nn.Module):       # input x is Torch tensor
    def __init__(self, local_size=1, alpha=1.0, beta=0.75, ACROSS_CHANNELS=False):      #LRN(local_size=5, alpha=0.0001, beta=0.75),
        super(LRN, self).__init__()
        self.ACROSS_CHANNELS = ACROSS_CHANNELS
        if self.ACROSS_CHANNELS:
            self.average = nn.AvgPool3d(kernel_size=(local_size, 1, 1),
                                        stride=1, padding=(int((local_size - 1.0) / 2), 0, 0))
        else:
            self.average = nn.AvgPool2d(kernel_size=local_size,
                                        stride=1, padding=int((local_size - 1.0) / 2))
        self.alpha = alpha
        self.beta = beta

    def forward(self, x):
        if self.ACROSS_CHANNELS:
            div = x.pow(2).unsqueeze(1)
            div = self.average(div).squeeze(1)
            div = div.mul(self.alpha).add(1.0).pow(self.beta)
        else:
            div = x.pow(2)
            div = self.average(div)
            div = div.mul(self.alpha).add(1.0).pow(self.beta)
        x = x.div(div)
        return x


Sun Nov 19 09:21:20 2017
Leg16_ResNet_dropout_0_2_rmSigmoid_40aug_10ela_3inten_reflect
optim.SGD(net.parameters(), lr=1e-2, momentum=0.99)
Number of epoch max: 8
Epoch 1: Train loss: 0.250367, Val loss: 0.285632
Epoch 2: Train loss: 0.162621, Val loss: 0.304489
UnetRes_model_2epoch_Leg16_ResNet_dropout_0_2_rmSigmoid_40aug_10ela_3inten_reflect
Precision: 0.97003 
Recall: 0.90130 
F1_measure: 0.93440 
iou: 0.86964
==========================================================================================
Sun Nov 19 10:48:38 2017
Leg16_ResNet_dropout_0_2_rmSigmoid_40aug_10ela_3inten_reflect
Sun Nov 19 10:48:36 2017
import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.autograd import Variable
import math


class ConvBnRelu(nn.Module):
    def __init__(self, in_channels, out_channels, kernel_size, padding, stride):
        super(ConvBnRelu, self).__init__()
        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=kernel_size, padding=padding, stride=stride)
        self.bn = nn.BatchNorm2d(out_channels)
        self.relu = nn.ReLU()

    def forward(self, x):
        x = self.conv(x)
        # x = self.bn(x)
        x = self.relu(x)
        return x


class StackEncoder(nn.Module):
    def __init__(self, in_channels, out_channels):
        super(StackEncoder, self).__init__()
        self.convr1 = ConvBnRelu(in_channels, out_channels, kernel_size=(3, 3), stride=1, padding=0)
        self.convr2 = ConvBnRelu(out_channels, out_channels, kernel_size=(3, 3), stride=1, padding=0)
        self.maxPool = nn.MaxPool2d(kernel_size=(2, 2), stride=2)

    def forward(self, x):
        x = self.convr1(x)
        x = self.convr2(x)
        x_trace = x             # save x to use in concat in the Decoder path
        out = self.maxPool(x)
        return out, x_trace


class StackDecoder(nn.Module):
    def __init__(self, in_channels, out_channels, upsample_size, padding, drop_out=False):
        super(StackDecoder, self).__init__()

        self.drop_out = drop_out
        self.dropout_layer = nn.Dropout2d(p=0.5)

        ''' this is old version
        self.upSample = nn.Upsample(size=upsample_size, scale_factor=(2, 2), mode="bilinear")
        self.convr1 = ConvBnRelu(in_channels, out_channels, kernel_size=(3, 3), stride=1, padding=padding)
        # Crop + concat step between these 2
        self.convr2 = ConvBnRelu(in_channels, out_channels, kernel_size=(3, 3), stride=1, padding=padding)
        '''
        self.upSample = nn.ConvTranspose2d(in_channels, out_channels, 2, stride=2)
        self.convr1 = ConvBnRelu(in_channels, out_channels, kernel_size=(3, 3), stride=1, padding=padding)
        self.convr2 = ConvBnRelu(out_channels, out_channels, kernel_size=(3, 3), stride=1, padding=padding)

    def _crop_concat(self, upsampled, bypass):
        """
         Crop y to the (h, w) of x and concat them.
         Used for the expansive path.
        Returns:
            The concatenated tensor
        """
        c = (bypass.size()[2] - upsampled.size()[2]) // 2
        bypass = F.pad(bypass, (-c, -c, -c, -c))

        return torch.cat((bypass, upsampled), 1)

    def forward(self, x, down_tensor):
        '''old version
        x = self.upSample(x)
        x = self.convr1(x)
        x = self._crop_concat(x, down_tensor)
        x = self.convr2(x)
        '''

        x = self.upSample(x)
        x = self._crop_concat(x, down_tensor)
        x = self.convr1(x)
        if self.drop_out: x = self.dropout_layer(x)
        x = self.convr2(x)
        if self.drop_out: x = self.dropout_layer(x)
        return x


class UNet_BN(nn.Module):
    def __init__(self):
        super(UNet_BN, self).__init__()
        # channels, height, width = in_shape

        # self.dropout = dropout

        self.model_code = ""        # variable to save model and main function when loaded

        self.down1 = StackEncoder(1, 64)
        self.down2 = StackEncoder(64, 128)
        self.down3 = StackEncoder(128, 256)
        self.down4 = StackEncoder(256, 512)

        self.center = nn.Sequential(
            # nn.Dropout2d(p=0.2),
            ConvBnRelu(512, 1024, kernel_size=(3, 3), stride=1, padding=0),
            nn.Dropout2d(p=0.2),
            ConvBnRelu(1024, 1024, kernel_size=(3, 3), stride=1, padding=0),
            nn.Dropout2d(p=0.2)
        )

        self.up1 = StackDecoder(in_channels=1024, out_channels=512, upsample_size=(64,64), padding = 1)
        self.up2 = StackDecoder(in_channels=512, out_channels=256, upsample_size=(128,128), padding = 1)
        self.up3 = StackDecoder(in_channels=256, out_channels=128, upsample_size=(256,256), padding = 1)
        self.up4 = StackDecoder(in_channels=128, out_channels=64, upsample_size=(512,512), padding = 1)

        # 1x1 convolution at the last layer
        # Different from the paper is the output size here
        self.output_seg_map = nn.Conv2d(64, 1, kernel_size=(1, 1), padding=0, stride=1)

        self._initialize_weights()

    def forward(self, x):
        x, x_trace1 = self.down1(x)
        x, x_trace2 = self.down2(x)
        x, x_trace3 = self.down3(x)
        x, x_trace4 = self.down4(x)
        x = self.center(x)
        x = self.up1(x, x_trace4)
        x = self.up2(x, x_trace3)
        x = self.up3(x, x_trace2)
        x = self.up4(x, x_trace1)

        x = self.output_seg_map(x)
        # x = F.sigmoid(x)
        # out = torch.squeeze(out, dim=1)
        return x


    def _initialize_weights(self):
        for m in self.modules():
            if isinstance(m, nn.Conv2d):
                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels
                m.weight.data.normal_(0, math.sqrt(2. / n))
                if m.bias is not None:
                    m.bias.data.zero_()
            elif isinstance(m, nn.BatchNorm2d):
                m.weight.data.fill_(1)
                m.bias.data.zero_()

# x = Variable(torch.randn(1,1,636,636))       # simulate input image
# net = UNet_BN()
# out = net(x)
# print("input: ", x)
# print("output: ", out)

===============from __future__ import print_function, division
import torch
from torch import optim
from torch.autograd import Variable
from torch.utils.data import DataLoader
import numpy as np
import torch.nn as nn
import torch.nn.functional as F
import Unet
import Unet_BatchNorm
import tifffile as tiff
import Utils
import time
from sklearn.metrics import average_precision_score, recall_score, f1_score
import Analysis
import Unet_ResNet

def to_var(x):
    if torch.cuda.is_available():
        return Variable(x.cuda())
    else:
        return Variable(x)

### BinaryCrossEntropyLoss2d().forward(logits, labels)
class BinaryCrossEntropyLoss2d(nn.Module):
    def __init__(self, weight=None, size_average=True):
        """
        Binary cross entropy loss 2D
        Args:
            weight:
            size_average:
        """
        super(BinaryCrossEntropyLoss2d, self).__init__()
        self.bce_loss = nn.BCELoss(weight, size_average)

    def forward(self, probs, targets):
        probs = F.sigmoid(probs)
        probs_flat = probs.view(-1)  # Flatten
        targets_flat = targets.view(-1)  # Flatten
        return self.bce_loss(probs_flat, targets_flat)      # (output, labels)

class SoftDiceLoss(nn.Module):
    def __init__(self, weight=None, size_average=True):
        super(SoftDiceLoss, self).__init__()

    def forward(self, probs, targets):
        smooth = 1
        # num = targets.size(0)
        probs = F.sigmoid(probs)
        m1 = probs.view(-1)
        m2 = targets.view(-1)
        intersection = (m1 * m2)
        score = 2. * (intersection.sum(1) + smooth) / (m1.sum(1) + m2.sum(1) + smooth)
        score = 1 - score.sum()
        return score

def _criterion(logits, labels):
    return BinaryCrossEntropyLoss2d().forward(logits, labels) + \
        SoftDiceLoss().forward(logits, labels)

def NetEval(net,valdata_loader,crit):
    loss = 0.
    count = 0
    net.eval()
    for i,data in enumerate(valdata_loader,0):
        inputs, labels = data
        inputs, labels = to_var(inputs), to_var(labels)
        out = net(inputs)
        l = crit(out, labels)
        loss += l.data[0]
        count += 1
    return loss/count

# calculate Precision, Recall, F1-measure, IoU over the validation set
def Net_performace_val(net,valdata_loader):
    precision_list = []
    recall_list = []
    iou_list = []
    net.eval()
    print("len of valdata: ", len(valdata_loader))
    for i,data in enumerate(valdata_loader,0):

        inputs, labels = data
        out = NetPredict(net, inputs)   # out is numpy array 512x512
        labels = labels.numpy()
        labels = labels[0,0,:,:]        # labels is numpy array 512x512
        # remove the case where the mask is plain black
        if np.sum(labels) < 0.01*np.shape(labels)[0]*np.shape(labels)[1]: continue

        precision = average_precision_score(labels, out)
        recall = recall_score(labels, out, average='weighted')
        iou = IoU(out, labels)
        precision_list.append(precision)
        recall_list.append(recall)
        iou_list.append(iou)

    precision, recall, iou = np.mean(precision_list), np.mean(recall_list), np.mean(iou_list)
    F1_measure = 2.0*precision*recall/(precision + recall)

    return precision, recall, F1_measure, iou

# calculate IoU
def IoU(pred, target):
    # Ignore IoU for background class
    cls = 0.5
    pred_inds = pred > cls
    target_inds = target > cls

    intersection = (pred_inds[target_inds]).sum()  # Cast to long to prevent overflows
    union = pred_inds.sum() + target_inds.sum() - intersection
    if union == 0:
        ious = float('nan')  # If there is no ground truth, do not include in evaluation
    else:
        ious = 1.0*intersection / max(union, 1)
    return ious

#process the test data and save to separate .tif image
def NetTest(net,testdata_loader,path = "data/results/"):
    net.eval()
    for i, data in enumerate(testdata_loader, 0):
        if i >= 30: return 1        # for debug
        data = to_var(data)
        out = net(data)

        out = F.sigmoid(out)

        imgname = path + str(i) + ".tif"
        img = out.cpu()
        img = img[0,0,:,:]
        img = img.data.numpy()
        img_shape = img.shape
        img = img.reshape(-1)
        img[img < 0.5] = 0; img[img >= 0.5] = 1
        img = img.reshape(img_shape)
        img = np.uint8(img * 255)
        tiff.imsave(imgname, img)

# return input image size like 512x512, numpy array
def NetPredict(net, data):
    net.eval()
    data = to_var(data)
    out = net(data)

    out = F.sigmoid(out)

    img = out.cpu()
    img = img[0, 0, :, :]
    img = img.data.numpy()
    img_shape = img.shape
    img = img.reshape(-1)
    img[img < 0.5] = 0;
    img[img >= 0.5] = 1
    img = img.reshape(img_shape)
    return img
def write_2_log(content):
    path = "log_file.txt"
    output = open(path, "a")
    output.write("\n")
    output.write(content)
    output.close()

if __name__ == '__main__':
    '''subjects to change for each exp:
    + path to the dataset
    + opt function
    + leg description
    + N_epoch
    + saved_model
    '''
    start_begining = time.time()

    # path = "data/dataset"
    path = "/home/anhxtuan/HanLe/dataset/40aug_10ela_3inten_reflect"

    import os
    print("Does the folder exist?: ", os.path.isdir(path))
    print("Does the path exist?: ", os.path.exists(path))

    # imgs_train, imgs_mask_train = Utils.load_train_data(npy_path=path)
    # trainset = zip(imgs_train, imgs_mask_train)
    # trainloader = torch.utils.data.DataLoader(trainset, batch_size=1,
    #                                           shuffle=True, num_workers=2)

    imgs_val, imgs_mask_val = Utils.load_val_data(npy_path=path)
    valset = zip(imgs_val, imgs_mask_val)
    valloader = torch.utils.data.DataLoader(valset, batch_size=1,
                                              shuffle=False, num_workers=2)
    # net = Unet.UNet()                     # Unet 1
    # net = Unet_BatchNorm.UNet_BN()          # Unet 2 with batchNorm
    net = Unet_ResNet.UNet_ResNet()

    f1 = open("Unet_BatchNorm.py", 'r')     # embede code into the model to be saved later
    f2 = open("UnetTrain.py", 'r')
    f3 = open("Utils.py", 'r')
    model_notes = time.strftime("%c") + "\n" + f1.read() + "\n" + "==="*5 + f2.read() + "\n" + "==="*5 + f3.read()
    f1.close()
    f2.close()

    # criterion = nn.BCELoss()
    criterion = BinaryCrossEntropyLoss2d()
    # criterion = SoftDiceLoss()

    if torch.cuda.is_available():
        # torch.set_default_tensor_type('torch.cuda.FloatTensor')
        # net.load_state_dict(torch.load("Unet2_model_6epoch_Leg14_dropout_0_2_rmSigmoid_40aug_10ela_3inten_reflect"))
        net.cuda()
        # criterion.cuda()

    opt = optim.SGD(net.parameters(), lr=1e-2, momentum=0.99)       # subject to change
    # opt = optim.RMSprop(net.parameters(), lr=2e-4)
    # RMSprop[22](learning rate 0.001) with weight decay set to 0.001.
    # opt = optim.Adam(net.parameters(), lr=1e-3, weight_decay=1e-4)

    train_loss = []
    val_loss = []

    print("[epoch, #image] Loss")
    leg = "Leg16_ResNet_dropout_0_2_rmSigmoid_40aug_10ela_3inten_reflect"
    print("Processing: ", leg)
    model_name = ""

    N_epoch = 8
    model_saved = np.arange(2,N_epoch+1,2)
    val_loss_min = 100

    write_2_log("==="*30)
    write_2_log(time.strftime("%c"))       # time, date of exp
    write_2_log(leg)
    write_2_log(model_notes)
    write_2_log(time.strftime("%c"))  # time, date of exp
    write_2_log(leg)
    write_2_log("optim.SGD(net.parameters(), lr=1e-2, momentum=0.99)")
    write_2_log("Number of epoch max: " + str(N_epoch))

    min_model_epoch = 0
    for epoch in range(N_epoch):
        running_loss = 0.0; count = 0
        net.train()

        N_files = 5
        for j in range(N_files):
            if N_files > 0:
                train_file = "/imgs_train_" + str(j + 1) + ".npy"
                mask_file = "/imgs_mask_train_" + str(j + 1) + ".npy"
            else:
                train_file = "/imgs_train.npy"
                mask_file = "/imgs_mask_train.npy"

            imgs_train, imgs_mask_train = Utils.load_train_data(npy_path=path, train_file=train_file, mask_file=mask_file)
            trainset = zip(imgs_train, imgs_mask_train)
            trainloader = torch.utils.data.DataLoader(trainset, batch_size=1,
                                                      shuffle=True, num_workers=2)
            for i, data in enumerate(trainloader, 0):
                inputs, labels = data
                temp = labels.numpy()
                temp = temp[0, 0, :, :]  # labels is numpy array 512x512
                # remove the case where the mask is plain black
                if np.sum(temp) < 0.01 * np.shape(temp)[0] * np.shape(temp)[1]: continue
                inputs, labels = to_var(inputs), to_var(labels)
                opt.zero_grad()
                out = net(inputs)
                loss = criterion(out, labels)
                loss.backward()
                opt.step()
                running_loss += loss.data[0]
                count += 1

        net.eval()
        val_loss_temp = NetEval(net, valloader, criterion)
        if epoch > 0 and val_loss_temp < val_loss_min:        # save the model which has the lowest val_loss, ignore first epoch
            val_loss_min = val_loss_temp
            torch.save(net.state_dict(), "UnetRes_model_" + leg + "_min_val_loss")  # save model
            min_model_epoch = epoch + 1

        disp = 'Epoch %d: Train loss: %.6f, Val loss: %.6f' % (epoch + 1, running_loss/count, val_loss_temp)
        write_2_log(disp)
        print(disp)
        val_loss.append(val_loss_temp)
        train_loss.append(running_loss/count); running_loss = 0.0

        if (epoch + 1) in model_saved:        # save checkpoint
            model_name = "UnetRes_model_" + str(epoch+1) + "epoch_" + leg
            torch.save(net.state_dict(), model_name)  # save model
            Analysis.analysis(model_file = model_name, valloader = valloader)

    write_2_log("Best model at epoch: " + str(min_model_epoch))
    write_2_log("Total training time: " + str((time.time() - start_begining) / 3600.0))

    val_loss_file = "data/results" + "/val_loss_" + str(N_epoch) + "epoch_" + leg + ".npy"
    train_loss_file = "data/results" + "/training_loss_" + str(N_epoch) + "epoch_" + leg + ".npy"

    np.save(val_loss_file, val_loss)
    np.save(train_loss_file, train_loss)
    print("total processing time in seconds: ", time.time() - start_begining)
    print("total processing time in mins: ", (time.time() - start_begining) / 60.0)
    print("total processing time in hours: ", (time.time() - start_begining) / 3600.0)

    Analysis.analysis(model_file="UnetRes_model_" + leg + "_min_val_loss", valloader=valloader)

    Analysis.PlotLoss(model_file = model_name, loss_train_path = train_loss_file, loss_val_path = val_loss_file, epoch_No = N_epoch)

    write_2_log(time.strftime("%c"))  # time, date of exp
===============import numpy as np
import torch.nn as nn
import torch
import cv2
from lcn import LecunLCN

LCN_enable = False

def input_filled_mirroring(x):      # fill missing data by mirroring the input image
    '''input size 636 --> output size 512'''
    w, h = x.shape
    e = 62  # extra width on 1 edge
    y = np.zeros((h + e * 2, w + e * 2))
    y[e:h + e, e:w + e] = x
    y[e:e + h, 0:e] = np.flip(y[e:e + h, e:2 * e], 1)  # flip vertically
    y[e:e + h, e + w:2 * e + w] = np.flip(y[e:e + h, w:e + w], 1)  # flip vertically
    y[0:e, 0:2 * e + w] = np.flip(y[e:2 * e, 0:2 * e + w], 0)  # flip horizontally
    y[e + h:2 * e + h, 0:2 * e + w] = np.flip(y[h:e + h, 0:2 * e + w], 0)  # flip horizontally
    return y

def nearest_cells_distance(pos, img):
    # searching in 8 directions to find 2 nearest distances to neighbor cells
    curr_value = img[pos]
    w = img.shape[0];h = img.shape[1]
    count_detect = 0  # detect 2 nearest neighbors. break the search if count_detect = 2
    x, y = pos

    # print("w,h: ", (w, h))
    d1 = 9999999;d2 = 9999999;d3 = 9999999;d4 = 9999999
    d5 = 9999999;d6 = 9999999;d7 = 9999999;d8 = 9999999
    for i in range(1, max(w, h)):
        # (x+1, y), (x+1, y+1), (x+1, y-1),
        # (x, y+1), (x, y-1)
        # (x-1, y), (x-1,y+1), (x-1,y-1),
        if x + i < w:
            if img[(x + i, y)] != curr_value and d1 == 9999999:
                d1 = i; count_detect += 1
            if y + i < h:
                if img[(x + i, y + i)] != curr_value and d2 == 9999999:
                    d2 = i; count_detect += 1
            elif y - i >= 0:
                if img[(x + i, y - i)] != curr_value and d3 == 9999999:
                    d3 = i; count_detect += 1
        if y + i < h:
            if img[(x, y + i)] != curr_value and d4 == 9999999:
                d4 = i; count_detect += 1
        if y - i >= 0:
            if img[(x, y - i)] != curr_value and d5 == 9999999:
                d5 = i; count_detect += 1
        if x - i >= 0:
            if img[(x - i, y)] != curr_value and d6 == 9999999:
                d6 = i; count_detect += 1
            if y + i < h:
                if img[(x - i, y + i)] != curr_value and d7 == 9999999:
                    d7 = i; count_detect += 1
            elif y - i >= 0:
                if img[(x - i, y - i)] != curr_value and d8 == 9999999:
                    d8 = i; count_detect += 1
        if count_detect >= 2: break

    d = [d1, d2, d3, d4, d5, d6, d7, d8]
    min_index = np.argmin(d)
    dist1 = d[min_index]
    d.remove(dist1)
    min_index = np.argmin(d)
    dist2 = d[min_index]
    return dist1, dist2

def create_weight_map(imgs_mask):
        print('-' * 30)
        print('Creating weights for masks ...')
        print('-' * 30)
        weight_map = np.ndarray(
            (len(imgs_mask), 1, np.shape(imgs_mask)[2], np.shape(imgs_mask)[3]), dtype=np.float32)
        w_0 = 10; sigma = 4
        imgs_w, imgs_h = np.shape(imgs_mask)[2], np.shape(imgs_mask)[3]
        total_pixels = imgs_w*imgs_h
        import time
        start = time.time()
        for i in range(len(imgs_mask)):
            if i%10 == 0: print("Done processing: %d images, time passed: %.2f mins" % (i, (time.time() - start)/60.0))
            temp = imgs_mask[i,0,:,:]
            w_border = 1 - np.sum(temp)/total_pixels        # w_c of pixel on the border (black)
            for m in range(imgs_w):
                for n in range(imgs_h):
                    # loop through all pixel of the mask
                    d1,d2 = nearest_cells_distance((m,n), temp)
                    w_c = w_border
                    if temp[m,n] == 0: w_c = 1 - w_border
                    weight_map[i,0,m,n] = w_c*5 + w_0*np.exp(-(d1 + d2)**2/(2*sigma**2))
                    # print("w_0*np.exp(): ", w_0*np.exp(-(d1 + d2)**2/(2*sigma**2)))
                    # print("w_border: ", w_border)

        np.save('data/dataset/weight_map_train.npy', weight_map)

        return weight_map

def load_train_data(npy_path = "data/dataset", train_file = "/imgs_train.npy", mask_file = "/imgs_mask_train.npy", hist_equal = False):

    print('-' * 30)
    print('load train images...')

    imgs_train = np.load(npy_path + train_file)
    imgs_mask_train = np.load(npy_path + mask_file)

    if hist_equal: imgs_train = hist_equalization(imgs_train)

    # weight_map_train = np.load(npy_path + "/weight_map_train.npy")
    # weight_map_train = weight_map_train.astype('float32')

    imgs_train = imgs_train.astype('float32')
    imgs_mask_train = imgs_mask_train.astype('float32')

    if LCN_enable:
        imgs_train = imgs_train.astype('float64')
        imgs_train = LecunLCN(imgs_train, image_shape=imgs_train.shape).output.eval()
        imgs_train = imgs_train.astype('float32')

    if not LCN_enable: imgs_train /= 255

    imgs_train -= imgs_train.mean(axis=0)
    imgs_mask_train /= 255
    imgs_mask_train[imgs_mask_train > 0.5] = 1
    imgs_mask_train[imgs_mask_train <= 0.5] = 0

    # weight_map_train = create_weight_map(imgs_mask_train)

    print("Done loading traing data")
    print('-' * 30)
    return imgs_train, imgs_mask_train

def load_val_data(npy_path = "data/dataset", hist_equal = True):

    print('-' * 30)
    print('load validation images...')

    imgs_train = np.load(npy_path + "/imgs_val.npy")
    imgs_mask_train = np.load(npy_path + "/imgs_mask_val.npy")

    if hist_equal: imgs_train = hist_equalization(imgs_train)

    imgs_train = imgs_train.astype('float32')
    imgs_mask_train = imgs_mask_train.astype('float32')

    if LCN_enable:
        imgs_train = imgs_train.astype('float64')
        imgs_train = LecunLCN(imgs_train, image_shape=imgs_train.shape).output.eval()
        imgs_train = imgs_train.astype('float32')

    if not LCN_enable: imgs_train /= 255
    imgs_train -= imgs_train.mean(axis=0)
    imgs_mask_train /= 255
    imgs_mask_train[imgs_mask_train > 0.5] = 1
    imgs_mask_train[imgs_mask_train <= 0.5] = 0
    print("Done loading validation data")
    print('-' * 30)
    return imgs_train, imgs_mask_train

def load_test_data(npy_path = "data/dataset", hist_equal = True):

    print('-' * 30)
    print('load test images...')

    imgs_test = np.load(npy_path + "/imgs_test.npy")

    if hist_equal: imgs_test = hist_equalization(imgs_test)

    imgs_test = imgs_test.astype('float32')

    if LCN_enable:
        imgs_test = imgs_test.astype('float64')
        imgs_test = LecunLCN(imgs_test, image_shape=imgs_test.shape).output.eval()
        imgs_test = imgs_test.astype('float32')

    if not LCN_enable: imgs_test /= 255

    imgs_test -= imgs_test.mean(axis=0)

    print("Done loading test data")
    print('-' * 30)
    return imgs_test

def load_val_5imgs(npy_path = "data/dataset"):
    print('-' * 30)
    print('load train images...')

    imgs_train = np.load(npy_path + "/imgs_val_5imgs.npy")
    imgs_mask_train = np.load(npy_path + "/imgs_mask_val_5imgs.npy")

    # imgs_train = hist_equalization(imgs_train)

    imgs_train = imgs_train.astype('float64')
    imgs_mask_train = imgs_mask_train.astype('float64')

    if LCN_enable: imgs_train = LecunLCN(imgs_train, image_shape=imgs_train.shape).output.eval()

    if not LCN_enable: imgs_train /= 255

    mean = imgs_train.mean(axis=0)
    imgs_train -= mean


    imgs_mask_train /= 255
    imgs_mask_train[imgs_mask_train > 0.5] = 1
    imgs_mask_train[imgs_mask_train <= 0.5] = 0

    # weight_map_train = self.create_weight_map(imgs_mask_train)

    print("Done loading traing data")
    print('-' * 30)
    return imgs_train, imgs_mask_train

def hist_equalization(inputs):      # inputs are uint8, 0-255, Nx1x636x636
    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))
    output = inputs.copy()
    for i in range(len(inputs)):
        img = inputs[i, 0, :, :]
        # res = cv2.equalizeHist(img)
        res = clahe.apply(img)
        output[i,0,:,:] = res
    return output

### BinaryCrossEntropyLoss2d().forward(logits, labels)
class BinaryCrossEntropyLoss2d(nn.Module):
    def __init__(self, weight=None, size_average=True):
        """
        Binary cross entropy loss 2D
        Args:
            weight:
            size_average:
        """
        super(BinaryCrossEntropyLoss2d, self).__init__()
        self.bce_loss = nn.BCELoss(weight, size_average)

    def forward(self, logits, targets):
        # probs = F.sigmoid(logits)
        probs = logits
        probs_flat = probs.view(-1)  # Flatten
        targets_flat = targets.view(-1)  # Flatten
        return self.bce_loss(probs_flat, targets_flat)      # (output, labels)

class BCE_with_Weights(nn.Module):
    def __init__(self, weights=None):
        """
        Binary cross entropy loss 2D
        Args:
            weights:
        """
        super(BCE_with_Weights, self).__init__()
        self.weights = weights

    def forward(self, output, target):
        if self.weights is not None:
            loss = self.weights * (target * torch.log(output) + (1 - target) * torch.log(1 - output))
        else:
            loss = target * torch.log(output) + (1 - target) * torch.log(1 - output)

        return torch.neg(torch.mean(loss))

class LRN(nn.Module):       # input x is Torch tensor
    def __init__(self, local_size=1, alpha=1.0, beta=0.75, ACROSS_CHANNELS=False):      #LRN(local_size=5, alpha=0.0001, beta=0.75),
        super(LRN, self).__init__()
        self.ACROSS_CHANNELS = ACROSS_CHANNELS
        if self.ACROSS_CHANNELS:
            self.average = nn.AvgPool3d(kernel_size=(local_size, 1, 1),
                                        stride=1, padding=(int((local_size - 1.0) / 2), 0, 0))
        else:
            self.average = nn.AvgPool2d(kernel_size=local_size,
                                        stride=1, padding=int((local_size - 1.0) / 2))
        self.alpha = alpha
        self.beta = beta

    def forward(self, x):
        if self.ACROSS_CHANNELS:
            div = x.pow(2).unsqueeze(1)
            div = self.average(div).squeeze(1)
            div = div.mul(self.alpha).add(1.0).pow(self.beta)
        else:
            div = x.pow(2)
            div = self.average(div)
            div = div.mul(self.alpha).add(1.0).pow(self.beta)
        x = x.div(div)
        return x


Sun Nov 19 10:48:38 2017
Leg16_ResNet_dropout_0_2_rmSigmoid_40aug_10ela_3inten_reflect
optim.SGD(net.parameters(), lr=1e-2, momentum=0.99)
Number of epoch max: 8
==========================================================================================
Sun Nov 19 10:50:46 2017
Leg16_ResNet_dropout_0_2_rmSigmoid_40aug_10ela_3inten_reflect
Sun Nov 19 10:50:44 2017
import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.autograd import Variable
import math


class ConvBnRelu(nn.Module):
    def __init__(self, in_channels, out_channels, kernel_size, padding, stride):
        super(ConvBnRelu, self).__init__()
        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=kernel_size, padding=padding, stride=stride)
        self.bn = nn.BatchNorm2d(out_channels)
        self.relu = nn.ReLU()

    def forward(self, x):
        x = self.conv(x)
        # x = self.bn(x)
        x = self.relu(x)
        return x

class StackEncoder(nn.Module):
    def __init__(self, in_channels, out_channels):
        super(StackEncoder, self).__init__()
        self.convr1 = ConvBnRelu(in_channels, out_channels, kernel_size=(3, 3), stride=1, padding=0)
        self.convr2 = ConvBnRelu(out_channels, out_channels, kernel_size=(3, 3), stride=1, padding=0)
        self.maxPool = nn.MaxPool2d(kernel_size=(2, 2), stride=2)

    def forward(self, x):
        x = self.convr1(x)
        x = self.convr2(x)
        x_trace = x             # save x to use in concat in the Decoder path
        x = self.maxPool(x)
        return x, x_trace


class StackDecoder(nn.Module):
    def __init__(self, in_channels, out_channels, padding):
        super(StackDecoder, self).__init__()

        self.upSample = nn.ConvTranspose2d(in_channels, out_channels, 2, stride=2)      # 1024 --> 512 for example
        self.convr1 = ConvBnRelu(in_channels, in_channels, kernel_size=(1,1), stride=1, padding=0)     # conv1x1
        self.convr2 = ConvBnRelu(in_channels, in_channels, kernel_size=(3, 3), stride=1, padding=padding)  # conv1x1
        self.convr3 = nn.Conv2d(in_channels, in_channels, kernel_size=(1, 1), stride=1, padding=0)  # conv1x1  # no ReLU
        self.convr4 = ConvBnRelu(in_channels, out_channels, kernel_size=(1, 1), stride=1, padding=0)
        self.relu = nn.ReLU()

    def _crop_concat(self, upsampled, bypass):
        """
         Crop y to the (h, w) of x and concat them.
         Used for the expansive path.
        Returns:
            The concatenated tensor
        """
        c = (bypass.size()[2] - upsampled.size()[2]) // 2
        bypass = F.pad(bypass, (-c, -c, -c, -c))

        return torch.cat((upsampled, bypass), 1)

    def forward(self, x, down_tensor):
        x = self.upSample(x)
        x_origin = self._crop_concat(x, down_tensor)

        x = self.convr1(x_origin)
        x = self.convr2(x)
        x = self.convr3(x)
        x += x_origin
        x = self.relu(x)
        x = self.convr4(x)
        return x


class UNet_ResNet(nn.Module):
    def __init__(self):
        super(UNet_ResNet, self).__init__()
        # channels, height, width = in_shape

        self.down1 = StackEncoder(1, 64)
        self.down2 = StackEncoder(64, 128)
        self.down3 = StackEncoder(128, 256)
        self.down4 = StackEncoder(256, 512)

        self.center = nn.Sequential(
            # nn.Dropout2d(p=0.2),
            ConvBnRelu(512, 1024, kernel_size=(3, 3), stride=1, padding=0),
            nn.Dropout2d(p=0.2),
            ConvBnRelu(1024, 1024, kernel_size=(3, 3), stride=1, padding=0),
            nn.Dropout2d(p=0.2)
        )

        self.up1 = StackDecoder(in_channels=1024, out_channels=512, padding = 1)
        self.up2 = StackDecoder(in_channels=512, out_channels=256, padding = 1)
        self.up3 = StackDecoder(in_channels=256, out_channels=128, padding = 1)
        self.up4 = StackDecoder(in_channels=128, out_channels=64, padding = 1)

        # 1x1 convolution at the last layer
        # Different from the paper is the output size here
        self.output_seg_map = nn.Conv2d(64, 1, kernel_size=(1, 1), padding=0, stride=1)

        self._initialize_weights()

    def forward(self, x):
        x, x_trace1 = self.down1(x)  # Calls the forward() method of each layer
        x, x_trace2 = self.down2(x)
        x, x_trace3 = self.down3(x)
        x, x_trace4 = self.down4(x)

        # if self.dropout > 0: x = F.dropout(x, p=self.dropout, training=self.training)
        x = self.center(x)
        # if self.dropout > 0: x = F.dropout(x, p=self.dropout, training=self.training)

        x = self.up1(x, x_trace4)
        x = self.up2(x, x_trace3)
        x = self.up3(x, x_trace2)
        x = self.up4(x, x_trace1)

        x = self.output_seg_map(x)

        # out = F.sigmoid(out)
        # out = torch.squeeze(out, dim=1)
        return x


    def _initialize_weights(self):
        for m in self.modules():
            if isinstance(m, nn.Conv2d):
                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels
                m.weight.data.normal_(0, math.sqrt(2. / n))
                if m.bias is not None:
                    m.bias.data.zero_()
            elif isinstance(m, nn.BatchNorm2d):
                m.weight.data.fill_(1)
                m.bias.data.zero_()

# x = Variable(torch.randn(1,1,636,636))       # simulate input image
# net = UNet_ResNet()
# out = net(x)
# print("input: ", x)
# print("output: ", out)

===============from __future__ import print_function, division
import torch
from torch import optim
from torch.autograd import Variable
from torch.utils.data import DataLoader
import numpy as np
import torch.nn as nn
import torch.nn.functional as F
import Unet
import Unet_BatchNorm
import tifffile as tiff
import Utils
import time
from sklearn.metrics import average_precision_score, recall_score, f1_score
import Analysis
import Unet_ResNet

def to_var(x):
    if torch.cuda.is_available():
        return Variable(x.cuda())
    else:
        return Variable(x)

### BinaryCrossEntropyLoss2d().forward(logits, labels)
class BinaryCrossEntropyLoss2d(nn.Module):
    def __init__(self, weight=None, size_average=True):
        """
        Binary cross entropy loss 2D
        Args:
            weight:
            size_average:
        """
        super(BinaryCrossEntropyLoss2d, self).__init__()
        self.bce_loss = nn.BCELoss(weight, size_average)

    def forward(self, probs, targets):
        probs = F.sigmoid(probs)
        probs_flat = probs.view(-1)  # Flatten
        targets_flat = targets.view(-1)  # Flatten
        return self.bce_loss(probs_flat, targets_flat)      # (output, labels)

class SoftDiceLoss(nn.Module):
    def __init__(self, weight=None, size_average=True):
        super(SoftDiceLoss, self).__init__()

    def forward(self, probs, targets):
        smooth = 1
        # num = targets.size(0)
        probs = F.sigmoid(probs)
        m1 = probs.view(-1)
        m2 = targets.view(-1)
        intersection = (m1 * m2)
        score = 2. * (intersection.sum(1) + smooth) / (m1.sum(1) + m2.sum(1) + smooth)
        score = 1 - score.sum()
        return score

def _criterion(logits, labels):
    return BinaryCrossEntropyLoss2d().forward(logits, labels) + \
        SoftDiceLoss().forward(logits, labels)

def NetEval(net,valdata_loader,crit):
    loss = 0.
    count = 0
    net.eval()
    for i,data in enumerate(valdata_loader,0):
        inputs, labels = data
        inputs, labels = to_var(inputs), to_var(labels)
        out = net(inputs)
        l = crit(out, labels)
        loss += l.data[0]
        count += 1
    return loss/count

# calculate Precision, Recall, F1-measure, IoU over the validation set
def Net_performace_val(net,valdata_loader):
    precision_list = []
    recall_list = []
    iou_list = []
    net.eval()
    print("len of valdata: ", len(valdata_loader))
    for i,data in enumerate(valdata_loader,0):

        inputs, labels = data
        out = NetPredict(net, inputs)   # out is numpy array 512x512
        labels = labels.numpy()
        labels = labels[0,0,:,:]        # labels is numpy array 512x512
        # remove the case where the mask is plain black
        if np.sum(labels) < 0.01*np.shape(labels)[0]*np.shape(labels)[1]: continue

        precision = average_precision_score(labels, out)
        recall = recall_score(labels, out, average='weighted')
        iou = IoU(out, labels)
        precision_list.append(precision)
        recall_list.append(recall)
        iou_list.append(iou)

    precision, recall, iou = np.mean(precision_list), np.mean(recall_list), np.mean(iou_list)
    F1_measure = 2.0*precision*recall/(precision + recall)

    return precision, recall, F1_measure, iou

# calculate IoU
def IoU(pred, target):
    # Ignore IoU for background class
    cls = 0.5
    pred_inds = pred > cls
    target_inds = target > cls

    intersection = (pred_inds[target_inds]).sum()  # Cast to long to prevent overflows
    union = pred_inds.sum() + target_inds.sum() - intersection
    if union == 0:
        ious = float('nan')  # If there is no ground truth, do not include in evaluation
    else:
        ious = 1.0*intersection / max(union, 1)
    return ious

#process the test data and save to separate .tif image
def NetTest(net,testdata_loader,path = "data/results/"):
    net.eval()
    for i, data in enumerate(testdata_loader, 0):
        if i >= 30: return 1        # for debug
        data = to_var(data)
        out = net(data)

        out = F.sigmoid(out)

        imgname = path + str(i) + ".tif"
        img = out.cpu()
        img = img[0,0,:,:]
        img = img.data.numpy()
        img_shape = img.shape
        img = img.reshape(-1)
        img[img < 0.5] = 0; img[img >= 0.5] = 1
        img = img.reshape(img_shape)
        img = np.uint8(img * 255)
        tiff.imsave(imgname, img)

# return input image size like 512x512, numpy array
def NetPredict(net, data):
    net.eval()
    data = to_var(data)
    out = net(data)

    out = F.sigmoid(out)

    img = out.cpu()
    img = img[0, 0, :, :]
    img = img.data.numpy()
    img_shape = img.shape
    img = img.reshape(-1)
    img[img < 0.5] = 0;
    img[img >= 0.5] = 1
    img = img.reshape(img_shape)
    return img
def write_2_log(content):
    path = "log_file.txt"
    output = open(path, "a")
    output.write("\n")
    output.write(content)
    output.close()

if __name__ == '__main__':
    '''subjects to change for each exp:
    + path to the dataset
    + opt function
    + leg description
    + N_epoch
    + saved_model
    '''
    start_begining = time.time()

    # path = "data/dataset"
    path = "/home/anhxtuan/HanLe/dataset/40aug_10ela_3inten_reflect"

    import os
    print("Does the folder exist?: ", os.path.isdir(path))
    print("Does the path exist?: ", os.path.exists(path))

    # imgs_train, imgs_mask_train = Utils.load_train_data(npy_path=path)
    # trainset = zip(imgs_train, imgs_mask_train)
    # trainloader = torch.utils.data.DataLoader(trainset, batch_size=1,
    #                                           shuffle=True, num_workers=2)

    imgs_val, imgs_mask_val = Utils.load_val_data(npy_path=path)
    valset = zip(imgs_val, imgs_mask_val)
    valloader = torch.utils.data.DataLoader(valset, batch_size=1,
                                              shuffle=False, num_workers=2)
    # net = Unet.UNet()                     # Unet 1
    # net = Unet_BatchNorm.UNet_BN()          # Unet 2 with batchNorm
    net = Unet_ResNet.UNet_ResNet()

    # f1 = open("Unet_BatchNorm.py", 'r')     # embede code into the model to be saved later
    f1 = open("Unet_ResNet.py", 'r')
    f2 = open("UnetTrain.py", 'r')
    f3 = open("Utils.py", 'r')
    model_notes = time.strftime("%c") + "\n" + f1.read() + "\n" + "==="*5 + f2.read() + "\n" + "==="*5 + f3.read()
    f1.close()
    f2.close()

    # criterion = nn.BCELoss()
    criterion = BinaryCrossEntropyLoss2d()
    # criterion = SoftDiceLoss()

    if torch.cuda.is_available():
        # torch.set_default_tensor_type('torch.cuda.FloatTensor')
        # net.load_state_dict(torch.load("Unet2_model_6epoch_Leg14_dropout_0_2_rmSigmoid_40aug_10ela_3inten_reflect"))
        net.cuda()
        # criterion.cuda()

    opt = optim.SGD(net.parameters(), lr=1e-2, momentum=0.99)       # subject to change
    # opt = optim.RMSprop(net.parameters(), lr=2e-4)
    # RMSprop[22](learning rate 0.001) with weight decay set to 0.001.
    # opt = optim.Adam(net.parameters(), lr=1e-3, weight_decay=1e-4)

    train_loss = []
    val_loss = []

    print("[epoch, #image] Loss")
    leg = "Leg16_ResNet_dropout_0_2_rmSigmoid_40aug_10ela_3inten_reflect"
    print("Processing: ", leg)
    model_name = ""

    N_epoch = 8
    model_saved = np.arange(2,N_epoch+1,2)
    val_loss_min = 100

    write_2_log("==="*30)
    write_2_log(time.strftime("%c"))       # time, date of exp
    write_2_log(leg)
    write_2_log(model_notes)
    write_2_log(time.strftime("%c"))  # time, date of exp
    write_2_log(leg)
    write_2_log("optim.SGD(net.parameters(), lr=1e-2, momentum=0.99)")
    write_2_log("Number of epoch max: " + str(N_epoch))

    min_model_epoch = 0
    for epoch in range(N_epoch):
        running_loss = 0.0; count = 0
        net.train()

        N_files = 5
        for j in range(N_files):
            if N_files > 0:
                train_file = "/imgs_train_" + str(j + 1) + ".npy"
                mask_file = "/imgs_mask_train_" + str(j + 1) + ".npy"
            else:
                train_file = "/imgs_train.npy"
                mask_file = "/imgs_mask_train.npy"

            imgs_train, imgs_mask_train = Utils.load_train_data(npy_path=path, train_file=train_file, mask_file=mask_file)
            trainset = zip(imgs_train, imgs_mask_train)
            trainloader = torch.utils.data.DataLoader(trainset, batch_size=1,
                                                      shuffle=True, num_workers=2)
            for i, data in enumerate(trainloader, 0):
                inputs, labels = data
                temp = labels.numpy()
                temp = temp[0, 0, :, :]  # labels is numpy array 512x512
                # remove the case where the mask is plain black
                if np.sum(temp) < 0.01 * np.shape(temp)[0] * np.shape(temp)[1]: continue
                inputs, labels = to_var(inputs), to_var(labels)
                opt.zero_grad()
                out = net(inputs)
                loss = criterion(out, labels)
                loss.backward()
                opt.step()
                running_loss += loss.data[0]
                count += 1

        net.eval()
        val_loss_temp = NetEval(net, valloader, criterion)
        if epoch > 0 and val_loss_temp < val_loss_min:        # save the model which has the lowest val_loss, ignore first epoch
            val_loss_min = val_loss_temp
            torch.save(net.state_dict(), "UnetRes_model_" + leg + "_min_val_loss")  # save model
            min_model_epoch = epoch + 1

        disp = 'Epoch %d: Train loss: %.6f, Val loss: %.6f' % (epoch + 1, running_loss/count, val_loss_temp)
        write_2_log(disp)
        print(disp)
        val_loss.append(val_loss_temp)
        train_loss.append(running_loss/count); running_loss = 0.0

        if (epoch + 1) in model_saved:        # save checkpoint
            model_name = "UnetRes_model_" + str(epoch+1) + "epoch_" + leg
            torch.save(net.state_dict(), model_name)  # save model
            Analysis.analysis(model_file = model_name, valloader = valloader)

    write_2_log("Best model at epoch: " + str(min_model_epoch))
    write_2_log("Total training time: " + str((time.time() - start_begining) / 3600.0))

    val_loss_file = "data/results" + "/val_loss_" + str(N_epoch) + "epoch_" + leg + ".npy"
    train_loss_file = "data/results" + "/training_loss_" + str(N_epoch) + "epoch_" + leg + ".npy"

    np.save(val_loss_file, val_loss)
    np.save(train_loss_file, train_loss)
    print("total processing time in seconds: ", time.time() - start_begining)
    print("total processing time in mins: ", (time.time() - start_begining) / 60.0)
    print("total processing time in hours: ", (time.time() - start_begining) / 3600.0)

    Analysis.analysis(model_file="UnetRes_model_" + leg + "_min_val_loss", valloader=valloader)

    Analysis.PlotLoss(model_file = model_name, loss_train_path = train_loss_file, loss_val_path = val_loss_file, epoch_No = N_epoch)

    write_2_log(time.strftime("%c"))  # time, date of exp
===============import numpy as np
import torch.nn as nn
import torch
import cv2
from lcn import LecunLCN

LCN_enable = False

def input_filled_mirroring(x):      # fill missing data by mirroring the input image
    '''input size 636 --> output size 512'''
    w, h = x.shape
    e = 62  # extra width on 1 edge
    y = np.zeros((h + e * 2, w + e * 2))
    y[e:h + e, e:w + e] = x
    y[e:e + h, 0:e] = np.flip(y[e:e + h, e:2 * e], 1)  # flip vertically
    y[e:e + h, e + w:2 * e + w] = np.flip(y[e:e + h, w:e + w], 1)  # flip vertically
    y[0:e, 0:2 * e + w] = np.flip(y[e:2 * e, 0:2 * e + w], 0)  # flip horizontally
    y[e + h:2 * e + h, 0:2 * e + w] = np.flip(y[h:e + h, 0:2 * e + w], 0)  # flip horizontally
    return y

def nearest_cells_distance(pos, img):
    # searching in 8 directions to find 2 nearest distances to neighbor cells
    curr_value = img[pos]
    w = img.shape[0];h = img.shape[1]
    count_detect = 0  # detect 2 nearest neighbors. break the search if count_detect = 2
    x, y = pos

    # print("w,h: ", (w, h))
    d1 = 9999999;d2 = 9999999;d3 = 9999999;d4 = 9999999
    d5 = 9999999;d6 = 9999999;d7 = 9999999;d8 = 9999999
    for i in range(1, max(w, h)):
        # (x+1, y), (x+1, y+1), (x+1, y-1),
        # (x, y+1), (x, y-1)
        # (x-1, y), (x-1,y+1), (x-1,y-1),
        if x + i < w:
            if img[(x + i, y)] != curr_value and d1 == 9999999:
                d1 = i; count_detect += 1
            if y + i < h:
                if img[(x + i, y + i)] != curr_value and d2 == 9999999:
                    d2 = i; count_detect += 1
            elif y - i >= 0:
                if img[(x + i, y - i)] != curr_value and d3 == 9999999:
                    d3 = i; count_detect += 1
        if y + i < h:
            if img[(x, y + i)] != curr_value and d4 == 9999999:
                d4 = i; count_detect += 1
        if y - i >= 0:
            if img[(x, y - i)] != curr_value and d5 == 9999999:
                d5 = i; count_detect += 1
        if x - i >= 0:
            if img[(x - i, y)] != curr_value and d6 == 9999999:
                d6 = i; count_detect += 1
            if y + i < h:
                if img[(x - i, y + i)] != curr_value and d7 == 9999999:
                    d7 = i; count_detect += 1
            elif y - i >= 0:
                if img[(x - i, y - i)] != curr_value and d8 == 9999999:
                    d8 = i; count_detect += 1
        if count_detect >= 2: break

    d = [d1, d2, d3, d4, d5, d6, d7, d8]
    min_index = np.argmin(d)
    dist1 = d[min_index]
    d.remove(dist1)
    min_index = np.argmin(d)
    dist2 = d[min_index]
    return dist1, dist2

def create_weight_map(imgs_mask):
        print('-' * 30)
        print('Creating weights for masks ...')
        print('-' * 30)
        weight_map = np.ndarray(
            (len(imgs_mask), 1, np.shape(imgs_mask)[2], np.shape(imgs_mask)[3]), dtype=np.float32)
        w_0 = 10; sigma = 4
        imgs_w, imgs_h = np.shape(imgs_mask)[2], np.shape(imgs_mask)[3]
        total_pixels = imgs_w*imgs_h
        import time
        start = time.time()
        for i in range(len(imgs_mask)):
            if i%10 == 0: print("Done processing: %d images, time passed: %.2f mins" % (i, (time.time() - start)/60.0))
            temp = imgs_mask[i,0,:,:]
            w_border = 1 - np.sum(temp)/total_pixels        # w_c of pixel on the border (black)
            for m in range(imgs_w):
                for n in range(imgs_h):
                    # loop through all pixel of the mask
                    d1,d2 = nearest_cells_distance((m,n), temp)
                    w_c = w_border
                    if temp[m,n] == 0: w_c = 1 - w_border
                    weight_map[i,0,m,n] = w_c*5 + w_0*np.exp(-(d1 + d2)**2/(2*sigma**2))
                    # print("w_0*np.exp(): ", w_0*np.exp(-(d1 + d2)**2/(2*sigma**2)))
                    # print("w_border: ", w_border)

        np.save('data/dataset/weight_map_train.npy', weight_map)

        return weight_map

def load_train_data(npy_path = "data/dataset", train_file = "/imgs_train.npy", mask_file = "/imgs_mask_train.npy", hist_equal = False):

    print('-' * 30)
    print('load train images...')

    imgs_train = np.load(npy_path + train_file)
    imgs_mask_train = np.load(npy_path + mask_file)

    if hist_equal: imgs_train = hist_equalization(imgs_train)

    # weight_map_train = np.load(npy_path + "/weight_map_train.npy")
    # weight_map_train = weight_map_train.astype('float32')

    imgs_train = imgs_train.astype('float32')
    imgs_mask_train = imgs_mask_train.astype('float32')

    if LCN_enable:
        imgs_train = imgs_train.astype('float64')
        imgs_train = LecunLCN(imgs_train, image_shape=imgs_train.shape).output.eval()
        imgs_train = imgs_train.astype('float32')

    if not LCN_enable: imgs_train /= 255

    imgs_train -= imgs_train.mean(axis=0)
    imgs_mask_train /= 255
    imgs_mask_train[imgs_mask_train > 0.5] = 1
    imgs_mask_train[imgs_mask_train <= 0.5] = 0

    # weight_map_train = create_weight_map(imgs_mask_train)

    print("Done loading traing data")
    print('-' * 30)
    return imgs_train, imgs_mask_train

def load_val_data(npy_path = "data/dataset", hist_equal = True):

    print('-' * 30)
    print('load validation images...')

    imgs_train = np.load(npy_path + "/imgs_val.npy")
    imgs_mask_train = np.load(npy_path + "/imgs_mask_val.npy")

    if hist_equal: imgs_train = hist_equalization(imgs_train)

    imgs_train = imgs_train.astype('float32')
    imgs_mask_train = imgs_mask_train.astype('float32')

    if LCN_enable:
        imgs_train = imgs_train.astype('float64')
        imgs_train = LecunLCN(imgs_train, image_shape=imgs_train.shape).output.eval()
        imgs_train = imgs_train.astype('float32')

    if not LCN_enable: imgs_train /= 255
    imgs_train -= imgs_train.mean(axis=0)
    imgs_mask_train /= 255
    imgs_mask_train[imgs_mask_train > 0.5] = 1
    imgs_mask_train[imgs_mask_train <= 0.5] = 0
    print("Done loading validation data")
    print('-' * 30)
    return imgs_train, imgs_mask_train

def load_test_data(npy_path = "data/dataset", hist_equal = True):

    print('-' * 30)
    print('load test images...')

    imgs_test = np.load(npy_path + "/imgs_test.npy")

    if hist_equal: imgs_test = hist_equalization(imgs_test)

    imgs_test = imgs_test.astype('float32')

    if LCN_enable:
        imgs_test = imgs_test.astype('float64')
        imgs_test = LecunLCN(imgs_test, image_shape=imgs_test.shape).output.eval()
        imgs_test = imgs_test.astype('float32')

    if not LCN_enable: imgs_test /= 255

    imgs_test -= imgs_test.mean(axis=0)

    print("Done loading test data")
    print('-' * 30)
    return imgs_test

def load_val_5imgs(npy_path = "data/dataset"):
    print('-' * 30)
    print('load train images...')

    imgs_train = np.load(npy_path + "/imgs_val_5imgs.npy")
    imgs_mask_train = np.load(npy_path + "/imgs_mask_val_5imgs.npy")

    # imgs_train = hist_equalization(imgs_train)

    imgs_train = imgs_train.astype('float64')
    imgs_mask_train = imgs_mask_train.astype('float64')

    if LCN_enable: imgs_train = LecunLCN(imgs_train, image_shape=imgs_train.shape).output.eval()

    if not LCN_enable: imgs_train /= 255

    mean = imgs_train.mean(axis=0)
    imgs_train -= mean


    imgs_mask_train /= 255
    imgs_mask_train[imgs_mask_train > 0.5] = 1
    imgs_mask_train[imgs_mask_train <= 0.5] = 0

    # weight_map_train = self.create_weight_map(imgs_mask_train)

    print("Done loading traing data")
    print('-' * 30)
    return imgs_train, imgs_mask_train

def hist_equalization(inputs):      # inputs are uint8, 0-255, Nx1x636x636
    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))
    output = inputs.copy()
    for i in range(len(inputs)):
        img = inputs[i, 0, :, :]
        # res = cv2.equalizeHist(img)
        res = clahe.apply(img)
        output[i,0,:,:] = res
    return output

### BinaryCrossEntropyLoss2d().forward(logits, labels)
class BinaryCrossEntropyLoss2d(nn.Module):
    def __init__(self, weight=None, size_average=True):
        """
        Binary cross entropy loss 2D
        Args:
            weight:
            size_average:
        """
        super(BinaryCrossEntropyLoss2d, self).__init__()
        self.bce_loss = nn.BCELoss(weight, size_average)

    def forward(self, logits, targets):
        # probs = F.sigmoid(logits)
        probs = logits
        probs_flat = probs.view(-1)  # Flatten
        targets_flat = targets.view(-1)  # Flatten
        return self.bce_loss(probs_flat, targets_flat)      # (output, labels)

class BCE_with_Weights(nn.Module):
    def __init__(self, weights=None):
        """
        Binary cross entropy loss 2D
        Args:
            weights:
        """
        super(BCE_with_Weights, self).__init__()
        self.weights = weights

    def forward(self, output, target):
        if self.weights is not None:
            loss = self.weights * (target * torch.log(output) + (1 - target) * torch.log(1 - output))
        else:
            loss = target * torch.log(output) + (1 - target) * torch.log(1 - output)

        return torch.neg(torch.mean(loss))

class LRN(nn.Module):       # input x is Torch tensor
    def __init__(self, local_size=1, alpha=1.0, beta=0.75, ACROSS_CHANNELS=False):      #LRN(local_size=5, alpha=0.0001, beta=0.75),
        super(LRN, self).__init__()
        self.ACROSS_CHANNELS = ACROSS_CHANNELS
        if self.ACROSS_CHANNELS:
            self.average = nn.AvgPool3d(kernel_size=(local_size, 1, 1),
                                        stride=1, padding=(int((local_size - 1.0) / 2), 0, 0))
        else:
            self.average = nn.AvgPool2d(kernel_size=local_size,
                                        stride=1, padding=int((local_size - 1.0) / 2))
        self.alpha = alpha
        self.beta = beta

    def forward(self, x):
        if self.ACROSS_CHANNELS:
            div = x.pow(2).unsqueeze(1)
            div = self.average(div).squeeze(1)
            div = div.mul(self.alpha).add(1.0).pow(self.beta)
        else:
            div = x.pow(2)
            div = self.average(div)
            div = div.mul(self.alpha).add(1.0).pow(self.beta)
        x = x.div(div)
        return x


Sun Nov 19 10:50:46 2017
Leg16_ResNet_dropout_0_2_rmSigmoid_40aug_10ela_3inten_reflect
optim.SGD(net.parameters(), lr=1e-2, momentum=0.99)
Number of epoch max: 8
Epoch 1: Train loss: 0.172000, Val loss: 0.277839
Epoch 2: Train loss: 0.126785, Val loss: 0.316316
UnetRes_model_2epoch_Leg16_ResNet_dropout_0_2_rmSigmoid_40aug_10ela_3inten_reflect
Precision: 0.97285 
Recall: 0.91171 
F1_measure: 0.94129 
iou: 0.88282
Epoch 3: Train loss: 0.103561, Val loss: 0.316246
Epoch 4: Train loss: 0.089307, Val loss: 0.380552
UnetRes_model_4epoch_Leg16_ResNet_dropout_0_2_rmSigmoid_40aug_10ela_3inten_reflect
Precision: 0.97229 
Recall: 0.91270 
F1_measure: 0.94155 
iou: 0.88252
Epoch 5: Train loss: 0.080210, Val loss: 0.377587
Epoch 6: Train loss: 0.073422, Val loss: 0.453096
UnetRes_model_6epoch_Leg16_ResNet_dropout_0_2_rmSigmoid_40aug_10ela_3inten_reflect
Precision: 0.97199 
Recall: 0.91261 
F1_measure: 0.94136 
iou: 0.88195
Epoch 7: Train loss: 0.068518, Val loss: 0.436463
Epoch 8: Train loss: 0.064356, Val loss: 0.455886
UnetRes_model_8epoch_Leg16_ResNet_dropout_0_2_rmSigmoid_40aug_10ela_3inten_reflect
Precision: 0.97171 
Recall: 0.90996 
F1_measure: 0.93982 
iou: 0.87942
Best model at epoch: 3
Total training time: 9.51928647002
UnetRes_model_Leg16_ResNet_dropout_0_2_rmSigmoid_40aug_10ela_3inten_reflect_min_val_loss
Precision: 0.97112 
Recall: 0.91927 
F1_measure: 0.94449 
iou: 0.88559
Sun Nov 19 20:34:58 2017
==========================================================================================
Sun Nov 19 21:33:24 2017
Leg15_DICE_dropout_0_2_rmSigmoid_40aug_10ela_3inten_reflect
Sun Nov 19 21:33:21 2017
import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.autograd import Variable
import math


class ConvBnRelu(nn.Module):
    def __init__(self, in_channels, out_channels, kernel_size, padding, stride):
        super(ConvBnRelu, self).__init__()
        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=kernel_size, padding=padding, stride=stride)
        self.bn = nn.BatchNorm2d(out_channels)
        self.relu = nn.ReLU()

    def forward(self, x):
        x = self.conv(x)
        # x = self.bn(x)
        x = self.relu(x)
        return x


class StackEncoder(nn.Module):
    def __init__(self, in_channels, out_channels):
        super(StackEncoder, self).__init__()
        self.convr1 = ConvBnRelu(in_channels, out_channels, kernel_size=(3, 3), stride=1, padding=0)
        self.convr2 = ConvBnRelu(out_channels, out_channels, kernel_size=(3, 3), stride=1, padding=0)
        self.maxPool = nn.MaxPool2d(kernel_size=(2, 2), stride=2)

    def forward(self, x):
        x = self.convr1(x)
        x = self.convr2(x)
        x_trace = x             # save x to use in concat in the Decoder path
        out = self.maxPool(x)
        return out, x_trace


class StackDecoder(nn.Module):
    def __init__(self, in_channels, out_channels, upsample_size, padding, drop_out=False):
        super(StackDecoder, self).__init__()

        self.drop_out = drop_out
        self.dropout_layer = nn.Dropout2d(p=0.5)

        ''' this is old version
        self.upSample = nn.Upsample(size=upsample_size, scale_factor=(2, 2), mode="bilinear")
        self.convr1 = ConvBnRelu(in_channels, out_channels, kernel_size=(3, 3), stride=1, padding=padding)
        # Crop + concat step between these 2
        self.convr2 = ConvBnRelu(in_channels, out_channels, kernel_size=(3, 3), stride=1, padding=padding)
        '''
        self.upSample = nn.ConvTranspose2d(in_channels, out_channels, 2, stride=2)
        self.convr1 = ConvBnRelu(in_channels, out_channels, kernel_size=(3, 3), stride=1, padding=padding)
        self.convr2 = ConvBnRelu(out_channels, out_channels, kernel_size=(3, 3), stride=1, padding=padding)

    def _crop_concat(self, upsampled, bypass):
        """
         Crop y to the (h, w) of x and concat them.
         Used for the expansive path.
        Returns:
            The concatenated tensor
        """
        c = (bypass.size()[2] - upsampled.size()[2]) // 2
        bypass = F.pad(bypass, (-c, -c, -c, -c))

        return torch.cat((bypass, upsampled), 1)

    def forward(self, x, down_tensor):
        '''old version
        x = self.upSample(x)
        x = self.convr1(x)
        x = self._crop_concat(x, down_tensor)
        x = self.convr2(x)
        '''

        x = self.upSample(x)
        x = self._crop_concat(x, down_tensor)
        x = self.convr1(x)
        if self.drop_out: x = self.dropout_layer(x)
        x = self.convr2(x)
        if self.drop_out: x = self.dropout_layer(x)
        return x


class UNet_BN(nn.Module):
    def __init__(self):
        super(UNet_BN, self).__init__()
        # channels, height, width = in_shape

        # self.dropout = dropout

        self.model_code = ""        # variable to save model and main function when loaded

        self.down1 = StackEncoder(1, 64)
        self.down2 = StackEncoder(64, 128)
        self.down3 = StackEncoder(128, 256)
        self.down4 = StackEncoder(256, 512)

        self.center = nn.Sequential(
            # nn.Dropout2d(p=0.2),
            ConvBnRelu(512, 1024, kernel_size=(3, 3), stride=1, padding=0),
            nn.Dropout2d(p=0.2),
            ConvBnRelu(1024, 1024, kernel_size=(3, 3), stride=1, padding=0),
            nn.Dropout2d(p=0.2)
        )

        self.up1 = StackDecoder(in_channels=1024, out_channels=512, upsample_size=(64,64), padding = 1)
        self.up2 = StackDecoder(in_channels=512, out_channels=256, upsample_size=(128,128), padding = 1)
        self.up3 = StackDecoder(in_channels=256, out_channels=128, upsample_size=(256,256), padding = 1)
        self.up4 = StackDecoder(in_channels=128, out_channels=64, upsample_size=(512,512), padding = 1)

        # 1x1 convolution at the last layer
        # Different from the paper is the output size here
        self.output_seg_map = nn.Conv2d(64, 1, kernel_size=(1, 1), padding=0, stride=1)

        self._initialize_weights()

    def forward(self, x):
        x, x_trace1 = self.down1(x)
        x, x_trace2 = self.down2(x)
        x, x_trace3 = self.down3(x)
        x, x_trace4 = self.down4(x)
        x = self.center(x)
        x = self.up1(x, x_trace4)
        x = self.up2(x, x_trace3)
        x = self.up3(x, x_trace2)
        x = self.up4(x, x_trace1)

        x = self.output_seg_map(x)
        # x = F.sigmoid(x)
        # out = torch.squeeze(out, dim=1)
        return x


    def _initialize_weights(self):
        for m in self.modules():
            if isinstance(m, nn.Conv2d):
                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels
                m.weight.data.normal_(0, math.sqrt(2. / n))
                if m.bias is not None:
                    m.bias.data.zero_()
            elif isinstance(m, nn.BatchNorm2d):
                m.weight.data.fill_(1)
                m.bias.data.zero_()

# x = Variable(torch.randn(1,1,636,636))       # simulate input image
# net = UNet_BN()
# out = net(x)
# print("input: ", x)
# print("output: ", out)

===============from __future__ import print_function, division
import torch
from torch import optim
from torch.autograd import Variable
from torch.utils.data import DataLoader
import numpy as np
import torch.nn as nn
import torch.nn.functional as F
import Unet
import Unet_BatchNorm
import tifffile as tiff
import Utils
import time
from sklearn.metrics import average_precision_score, recall_score, f1_score
import Analysis
import Unet_ResNet

def to_var(x):
    if torch.cuda.is_available():
        return Variable(x.cuda())
    else:
        return Variable(x)

### BinaryCrossEntropyLoss2d().forward(logits, labels)
class BinaryCrossEntropyLoss2d(nn.Module):
    def __init__(self, weight=None, size_average=True):
        """
        Binary cross entropy loss 2D
        Args:
            weight:
            size_average:
        """
        super(BinaryCrossEntropyLoss2d, self).__init__()
        self.bce_loss = nn.BCELoss(weight, size_average)

    def forward(self, probs, targets):
        probs = F.sigmoid(probs)
        probs_flat = probs.view(-1)  # Flatten
        targets_flat = targets.view(-1)  # Flatten
        return self.bce_loss(probs_flat, targets_flat)      # (output, labels)

class SoftDiceLoss(nn.Module):
    def __init__(self, weight=None, size_average=True):
        super(SoftDiceLoss, self).__init__()

    def forward(self, probs, targets):
        smooth = 1
        # num = targets.size(0)
        probs = F.sigmoid(probs)
        m1 = probs.view(-1)
        m2 = targets.view(-1)
        intersection = (m1 * m2)
        score = 2. * (intersection.sum() + smooth) / (m1.sum() + m2.sum() + smooth)
        score = 1 - score.sum()
        return score

def _criterion(logits, labels):
    return BinaryCrossEntropyLoss2d().forward(logits, labels) + \
        SoftDiceLoss().forward(logits, labels)

def NetEval(net,valdata_loader,crit):
    loss = 0.
    count = 0
    net.eval()
    for i,data in enumerate(valdata_loader,0):
        inputs, labels = data
        inputs, labels = to_var(inputs), to_var(labels)
        out = net(inputs)
        l = crit(out, labels)
        loss += l.data[0]
        count += 1
    return loss/count

# calculate Precision, Recall, F1-measure, IoU over the validation set
def Net_performace_val(net,valdata_loader):
    precision_list = []
    recall_list = []
    iou_list = []
    net.eval()
    print("len of valdata: ", len(valdata_loader))
    for i,data in enumerate(valdata_loader,0):

        inputs, labels = data
        out = NetPredict(net, inputs)   # out is numpy array 512x512
        labels = labels.numpy()
        labels = labels[0,0,:,:]        # labels is numpy array 512x512
        # remove the case where the mask is plain black
        if np.sum(labels) < 0.01*np.shape(labels)[0]*np.shape(labels)[1]: continue

        precision = average_precision_score(labels, out)
        recall = recall_score(labels, out, average='weighted')
        iou = IoU(out, labels)
        precision_list.append(precision)
        recall_list.append(recall)
        iou_list.append(iou)

    precision, recall, iou = np.mean(precision_list), np.mean(recall_list), np.mean(iou_list)
    F1_measure = 2.0*precision*recall/(precision + recall)

    return precision, recall, F1_measure, iou

# calculate IoU
def IoU(pred, target):
    # Ignore IoU for background class
    cls = 0.5
    pred_inds = pred > cls
    target_inds = target > cls

    intersection = (pred_inds[target_inds]).sum()  # Cast to long to prevent overflows
    union = pred_inds.sum() + target_inds.sum() - intersection
    if union == 0:
        ious = float('nan')  # If there is no ground truth, do not include in evaluation
    else:
        ious = 1.0*intersection / max(union, 1)
    return ious

#process the test data and save to separate .tif image
def NetTest(net,testdata_loader,path = "data/results/"):
    net.eval()
    for i, data in enumerate(testdata_loader, 0):
        if i >= 30: return 1        # for debug
        data = to_var(data)
        out = net(data)

        out = F.sigmoid(out)

        imgname = path + str(i) + ".tif"
        img = out.cpu()
        img = img[0,0,:,:]
        img = img.data.numpy()
        img_shape = img.shape
        img = img.reshape(-1)
        img[img < 0.5] = 0; img[img >= 0.5] = 1
        img = img.reshape(img_shape)
        img = np.uint8(img * 255)
        tiff.imsave(imgname, img)

# return input image size like 512x512, numpy array
def NetPredict(net, data):
    net.eval()
    data = to_var(data)
    out = net(data)

    out = F.sigmoid(out)

    img = out.cpu()
    img = img[0, 0, :, :]
    img = img.data.numpy()
    img_shape = img.shape
    img = img.reshape(-1)
    img[img < 0.5] = 0;
    img[img >= 0.5] = 1
    img = img.reshape(img_shape)
    return img
def write_2_log(content):
    path = "log_file.txt"
    output = open(path, "a")
    output.write("\n")
    output.write(content)
    output.close()

if __name__ == '__main__':
    '''subjects to change for each exp:
    + path to the dataset
    + opt function
    + leg description
    + N_epoch
    + saved_model
    '''
    start_begining = time.time()

    # path = "data/dataset"
    path = "/home/anhxtuan/HanLe/dataset/40aug_10ela_3inten_reflect"

    import os
    print("Does the folder exist?: ", os.path.isdir(path))
    print("Does the path exist?: ", os.path.exists(path))

    # imgs_train, imgs_mask_train = Utils.load_train_data(npy_path=path)
    # trainset = zip(imgs_train, imgs_mask_train)
    # trainloader = torch.utils.data.DataLoader(trainset, batch_size=1,
    #                                           shuffle=True, num_workers=2)

    imgs_val, imgs_mask_val = Utils.load_val_data(npy_path=path)
    valset = zip(imgs_val, imgs_mask_val)
    valloader = torch.utils.data.DataLoader(valset, batch_size=1,
                                              shuffle=False, num_workers=2)
    # net = Unet.UNet()                     # Unet 1
    net = Unet_BatchNorm.UNet_BN()          # Unet 2 with batchNorm
    # net = Unet_ResNet.UNet_ResNet()

    f1 = open("Unet_BatchNorm.py", 'r')     # embede code into the model to be saved later
    # f1 = open("Unet_ResNet.py", 'r')
    f2 = open("UnetTrain.py", 'r')
    f3 = open("Utils.py", 'r')
    model_notes = time.strftime("%c") + "\n" + f1.read() + "\n" + "==="*5 + f2.read() + "\n" + "==="*5 + f3.read()
    f1.close()
    f2.close()
    f3.close()

    # criterion = nn.BCELoss()
    # criterion = BinaryCrossEntropyLoss2d()
    criterion = SoftDiceLoss()

    if torch.cuda.is_available():
        # torch.set_default_tensor_type('torch.cuda.FloatTensor')
        # net.load_state_dict(torch.load("Unet2_model_6epoch_Leg14_dropout_0_2_rmSigmoid_40aug_10ela_3inten_reflect"))
        net.cuda()
        # criterion.cuda()

    opt = optim.SGD(net.parameters(), lr=1e-2, momentum=0.99)       # subject to change
    # opt = optim.RMSprop(net.parameters(), lr=2e-4)
    # RMSprop[22](learning rate 0.001) with weight decay set to 0.001.
    # opt = optim.Adam(net.parameters(), lr=1e-3, weight_decay=1e-4)

    train_loss = []
    val_loss = []

    print("[epoch, #image] Loss")
    leg = "Leg15_DICE_dropout_0_2_rmSigmoid_40aug_10ela_3inten_reflect"
    print("Processing: ", leg)
    model_name = ""

    N_epoch = 8
    model_saved = np.arange(2,N_epoch+1,2)
    val_loss_min = 100

    write_2_log("==="*30)
    write_2_log(time.strftime("%c"))       # time, date of exp
    write_2_log(leg)
    write_2_log(model_notes)
    write_2_log(time.strftime("%c"))  # time, date of exp
    write_2_log(leg)
    write_2_log("optim.SGD(net.parameters(), lr=1e-2, momentum=0.99)")
    write_2_log("Number of epoch max: " + str(N_epoch))

    min_model_epoch = 0
    for epoch in range(N_epoch):
        running_loss = 0.0; count = 0
        net.train()

        N_files = 1
        for j in range(N_files):
            if N_files > 0:
                train_file = "/imgs_train_" + str(j + 1) + ".npy"
                mask_file = "/imgs_mask_train_" + str(j + 1) + ".npy"
            else:
                train_file = "/imgs_train.npy"
                mask_file = "/imgs_mask_train.npy"

            imgs_train, imgs_mask_train = Utils.load_train_data(npy_path=path, train_file=train_file, mask_file=mask_file)
            trainset = zip(imgs_train, imgs_mask_train)
            trainloader = torch.utils.data.DataLoader(trainset, batch_size=1,
                                                      shuffle=True, num_workers=2)
            for i, data in enumerate(trainloader, 0):
                inputs, labels = data
                temp = labels.numpy()
                temp = temp[0, 0, :, :]  # labels is numpy array 512x512
                # remove the case where the mask is plain black
                if np.sum(temp) < 0.01 * np.shape(temp)[0] * np.shape(temp)[1]: continue
                inputs, labels = to_var(inputs), to_var(labels)
                opt.zero_grad()
                out = net(inputs)
                loss = criterion(out, labels)
                loss.backward()
                opt.step()
                running_loss += loss.data[0]
                count += 1

        net.eval()
        val_loss_temp = NetEval(net, valloader, criterion)
        if epoch > 0 and val_loss_temp < val_loss_min:        # save the model which has the lowest val_loss, ignore first epoch
            val_loss_min = val_loss_temp
            torch.save(net.state_dict(), "Unet2_model_" + leg + "_min_val_loss")  # save model
            min_model_epoch = epoch + 1

        disp = 'Epoch %d: Train loss: %.6f, Val loss: %.6f' % (epoch + 1, running_loss/count, val_loss_temp)
        write_2_log(disp)
        print(disp)
        val_loss.append(val_loss_temp)
        train_loss.append(running_loss/count); running_loss = 0.0

        if (epoch + 1) in model_saved:        # save checkpoint
            model_name = "Unet2_model_" + str(epoch+1) + "epoch_" + leg
            torch.save(net.state_dict(), model_name)  # save model
            Analysis.analysis(model_file = model_name, valloader = valloader)

    write_2_log("Best model at epoch: " + str(min_model_epoch))
    write_2_log("Total training time: " + str((time.time() - start_begining) / 3600.0))

    val_loss_file = "data/results" + "/val_loss_" + str(N_epoch) + "epoch_" + leg + ".npy"
    train_loss_file = "data/results" + "/training_loss_" + str(N_epoch) + "epoch_" + leg + ".npy"

    np.save(val_loss_file, val_loss)
    np.save(train_loss_file, train_loss)
    print("total processing time in seconds: ", time.time() - start_begining)
    print("total processing time in mins: ", (time.time() - start_begining) / 60.0)
    print("total processing time in hours: ", (time.time() - start_begining) / 3600.0)

    Analysis.analysis(model_file="Unet2_model_" + leg + "_min_val_loss", valloader=valloader)

    Analysis.PlotLoss(model_file = model_name, loss_train_path = train_loss_file, loss_val_path = val_loss_file, epoch_No = N_epoch)

    write_2_log(time.strftime("%c"))  # time, date of exp
===============import numpy as np
import torch.nn as nn
import torch
import cv2
from lcn import LecunLCN

LCN_enable = False

def input_filled_mirroring(x):      # fill missing data by mirroring the input image
    '''input size 636 --> output size 512'''
    w, h = x.shape
    e = 62  # extra width on 1 edge
    y = np.zeros((h + e * 2, w + e * 2))
    y[e:h + e, e:w + e] = x
    y[e:e + h, 0:e] = np.flip(y[e:e + h, e:2 * e], 1)  # flip vertically
    y[e:e + h, e + w:2 * e + w] = np.flip(y[e:e + h, w:e + w], 1)  # flip vertically
    y[0:e, 0:2 * e + w] = np.flip(y[e:2 * e, 0:2 * e + w], 0)  # flip horizontally
    y[e + h:2 * e + h, 0:2 * e + w] = np.flip(y[h:e + h, 0:2 * e + w], 0)  # flip horizontally
    return y

def nearest_cells_distance(pos, img):
    # searching in 8 directions to find 2 nearest distances to neighbor cells
    curr_value = img[pos]
    w = img.shape[0];h = img.shape[1]
    count_detect = 0  # detect 2 nearest neighbors. break the search if count_detect = 2
    x, y = pos

    # print("w,h: ", (w, h))
    d1 = 9999999;d2 = 9999999;d3 = 9999999;d4 = 9999999
    d5 = 9999999;d6 = 9999999;d7 = 9999999;d8 = 9999999
    for i in range(1, max(w, h)):
        # (x+1, y), (x+1, y+1), (x+1, y-1),
        # (x, y+1), (x, y-1)
        # (x-1, y), (x-1,y+1), (x-1,y-1),
        if x + i < w:
            if img[(x + i, y)] != curr_value and d1 == 9999999:
                d1 = i; count_detect += 1
            if y + i < h:
                if img[(x + i, y + i)] != curr_value and d2 == 9999999:
                    d2 = i; count_detect += 1
            elif y - i >= 0:
                if img[(x + i, y - i)] != curr_value and d3 == 9999999:
                    d3 = i; count_detect += 1
        if y + i < h:
            if img[(x, y + i)] != curr_value and d4 == 9999999:
                d4 = i; count_detect += 1
        if y - i >= 0:
            if img[(x, y - i)] != curr_value and d5 == 9999999:
                d5 = i; count_detect += 1
        if x - i >= 0:
            if img[(x - i, y)] != curr_value and d6 == 9999999:
                d6 = i; count_detect += 1
            if y + i < h:
                if img[(x - i, y + i)] != curr_value and d7 == 9999999:
                    d7 = i; count_detect += 1
            elif y - i >= 0:
                if img[(x - i, y - i)] != curr_value and d8 == 9999999:
                    d8 = i; count_detect += 1
        if count_detect >= 2: break

    d = [d1, d2, d3, d4, d5, d6, d7, d8]
    min_index = np.argmin(d)
    dist1 = d[min_index]
    d.remove(dist1)
    min_index = np.argmin(d)
    dist2 = d[min_index]
    return dist1, dist2

def create_weight_map(imgs_mask):
        print('-' * 30)
        print('Creating weights for masks ...')
        print('-' * 30)
        weight_map = np.ndarray(
            (len(imgs_mask), 1, np.shape(imgs_mask)[2], np.shape(imgs_mask)[3]), dtype=np.float32)
        w_0 = 10; sigma = 4
        imgs_w, imgs_h = np.shape(imgs_mask)[2], np.shape(imgs_mask)[3]
        total_pixels = imgs_w*imgs_h
        import time
        start = time.time()
        for i in range(len(imgs_mask)):
            if i%10 == 0: print("Done processing: %d images, time passed: %.2f mins" % (i, (time.time() - start)/60.0))
            temp = imgs_mask[i,0,:,:]
            w_border = 1 - np.sum(temp)/total_pixels        # w_c of pixel on the border (black)
            for m in range(imgs_w):
                for n in range(imgs_h):
                    # loop through all pixel of the mask
                    d1,d2 = nearest_cells_distance((m,n), temp)
                    w_c = w_border
                    if temp[m,n] == 0: w_c = 1 - w_border
                    weight_map[i,0,m,n] = w_c*5 + w_0*np.exp(-(d1 + d2)**2/(2*sigma**2))
                    # print("w_0*np.exp(): ", w_0*np.exp(-(d1 + d2)**2/(2*sigma**2)))
                    # print("w_border: ", w_border)

        np.save('data/dataset/weight_map_train.npy', weight_map)

        return weight_map

def load_train_data(npy_path = "data/dataset", train_file = "/imgs_train.npy", mask_file = "/imgs_mask_train.npy", hist_equal = False):

    print('-' * 30)
    print('load train images...')

    imgs_train = np.load(npy_path + train_file)
    imgs_mask_train = np.load(npy_path + mask_file)

    if hist_equal: imgs_train = hist_equalization(imgs_train)

    # weight_map_train = np.load(npy_path + "/weight_map_train.npy")
    # weight_map_train = weight_map_train.astype('float32')

    imgs_train = imgs_train.astype('float32')
    imgs_mask_train = imgs_mask_train.astype('float32')

    if LCN_enable:
        imgs_train = imgs_train.astype('float64')
        imgs_train = LecunLCN(imgs_train, image_shape=imgs_train.shape).output.eval()
        imgs_train = imgs_train.astype('float32')

    if not LCN_enable: imgs_train /= 255

    imgs_train -= imgs_train.mean(axis=0)
    imgs_mask_train /= 255
    imgs_mask_train[imgs_mask_train > 0.5] = 1
    imgs_mask_train[imgs_mask_train <= 0.5] = 0

    # weight_map_train = create_weight_map(imgs_mask_train)

    print("Done loading traing data")
    print('-' * 30)
    return imgs_train, imgs_mask_train

def load_val_data(npy_path = "data/dataset", hist_equal = True):

    print('-' * 30)
    print('load validation images...')

    imgs_train = np.load(npy_path + "/imgs_val.npy")
    imgs_mask_train = np.load(npy_path + "/imgs_mask_val.npy")

    if hist_equal: imgs_train = hist_equalization(imgs_train)

    imgs_train = imgs_train.astype('float32')
    imgs_mask_train = imgs_mask_train.astype('float32')

    if LCN_enable:
        imgs_train = imgs_train.astype('float64')
        imgs_train = LecunLCN(imgs_train, image_shape=imgs_train.shape).output.eval()
        imgs_train = imgs_train.astype('float32')

    if not LCN_enable: imgs_train /= 255
    imgs_train -= imgs_train.mean(axis=0)
    imgs_mask_train /= 255
    imgs_mask_train[imgs_mask_train > 0.5] = 1
    imgs_mask_train[imgs_mask_train <= 0.5] = 0
    print("Done loading validation data")
    print('-' * 30)
    return imgs_train, imgs_mask_train

def load_test_data(npy_path = "data/dataset", hist_equal = True):

    print('-' * 30)
    print('load test images...')

    imgs_test = np.load(npy_path + "/imgs_test.npy")

    if hist_equal: imgs_test = hist_equalization(imgs_test)

    imgs_test = imgs_test.astype('float32')

    if LCN_enable:
        imgs_test = imgs_test.astype('float64')
        imgs_test = LecunLCN(imgs_test, image_shape=imgs_test.shape).output.eval()
        imgs_test = imgs_test.astype('float32')

    if not LCN_enable: imgs_test /= 255

    imgs_test -= imgs_test.mean(axis=0)

    print("Done loading test data")
    print('-' * 30)
    return imgs_test

def load_val_5imgs(npy_path = "data/dataset"):
    print('-' * 30)
    print('load train images...')

    imgs_train = np.load(npy_path + "/imgs_val_5imgs.npy")
    imgs_mask_train = np.load(npy_path + "/imgs_mask_val_5imgs.npy")

    # imgs_train = hist_equalization(imgs_train)

    imgs_train = imgs_train.astype('float64')
    imgs_mask_train = imgs_mask_train.astype('float64')

    if LCN_enable: imgs_train = LecunLCN(imgs_train, image_shape=imgs_train.shape).output.eval()

    if not LCN_enable: imgs_train /= 255

    mean = imgs_train.mean(axis=0)
    imgs_train -= mean


    imgs_mask_train /= 255
    imgs_mask_train[imgs_mask_train > 0.5] = 1
    imgs_mask_train[imgs_mask_train <= 0.5] = 0

    # weight_map_train = self.create_weight_map(imgs_mask_train)

    print("Done loading traing data")
    print('-' * 30)
    return imgs_train, imgs_mask_train

def hist_equalization(inputs):      # inputs are uint8, 0-255, Nx1x636x636
    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))
    output = inputs.copy()
    for i in range(len(inputs)):
        img = inputs[i, 0, :, :]
        # res = cv2.equalizeHist(img)
        res = clahe.apply(img)
        output[i,0,:,:] = res
    return output

### BinaryCrossEntropyLoss2d().forward(logits, labels)
class BinaryCrossEntropyLoss2d(nn.Module):
    def __init__(self, weight=None, size_average=True):
        """
        Binary cross entropy loss 2D
        Args:
            weight:
            size_average:
        """
        super(BinaryCrossEntropyLoss2d, self).__init__()
        self.bce_loss = nn.BCELoss(weight, size_average)

    def forward(self, logits, targets):
        # probs = F.sigmoid(logits)
        probs = logits
        probs_flat = probs.view(-1)  # Flatten
        targets_flat = targets.view(-1)  # Flatten
        return self.bce_loss(probs_flat, targets_flat)      # (output, labels)

class BCE_with_Weights(nn.Module):
    def __init__(self, weights=None):
        """
        Binary cross entropy loss 2D
        Args:
            weights:
        """
        super(BCE_with_Weights, self).__init__()
        self.weights = weights

    def forward(self, output, target):
        if self.weights is not None:
            loss = self.weights * (target * torch.log(output) + (1 - target) * torch.log(1 - output))
        else:
            loss = target * torch.log(output) + (1 - target) * torch.log(1 - output)

        return torch.neg(torch.mean(loss))

class LRN(nn.Module):       # input x is Torch tensor
    def __init__(self, local_size=1, alpha=1.0, beta=0.75, ACROSS_CHANNELS=False):      #LRN(local_size=5, alpha=0.0001, beta=0.75),
        super(LRN, self).__init__()
        self.ACROSS_CHANNELS = ACROSS_CHANNELS
        if self.ACROSS_CHANNELS:
            self.average = nn.AvgPool3d(kernel_size=(local_size, 1, 1),
                                        stride=1, padding=(int((local_size - 1.0) / 2), 0, 0))
        else:
            self.average = nn.AvgPool2d(kernel_size=local_size,
                                        stride=1, padding=int((local_size - 1.0) / 2))
        self.alpha = alpha
        self.beta = beta

    def forward(self, x):
        if self.ACROSS_CHANNELS:
            div = x.pow(2).unsqueeze(1)
            div = self.average(div).squeeze(1)
            div = div.mul(self.alpha).add(1.0).pow(self.beta)
        else:
            div = x.pow(2)
            div = self.average(div)
            div = div.mul(self.alpha).add(1.0).pow(self.beta)
        x = x.div(div)
        return x


Sun Nov 19 21:33:24 2017
Leg15_DICE_dropout_0_2_rmSigmoid_40aug_10ela_3inten_reflect
optim.SGD(net.parameters(), lr=1e-2, momentum=0.99)
Number of epoch max: 8
Epoch 1: Train loss: 0.137708, Val loss: 0.127992
Epoch 2: Train loss: 0.137354, Val loss: 0.127992
Unet2_model_2epoch_Leg15_DICE_dropout_0_2_rmSigmoid_40aug_10ela_3inten_reflect
Precision: 0.90048 
Recall: 1.00000 
F1_measure: 0.94763 
iou: 0.80096
==========================================================================================
Sun Nov 19 22:10:21 2017
Leg17_RMSprop_dropout_0_2_rmSigmoid_40aug_10ela_3inten_reflect
Sun Nov 19 22:10:19 2017
import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.autograd import Variable
import math


class ConvBnRelu(nn.Module):
    def __init__(self, in_channels, out_channels, kernel_size, padding, stride):
        super(ConvBnRelu, self).__init__()
        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=kernel_size, padding=padding, stride=stride)
        self.bn = nn.BatchNorm2d(out_channels)
        self.relu = nn.ReLU()

    def forward(self, x):
        x = self.conv(x)
        # x = self.bn(x)
        x = self.relu(x)
        return x


class StackEncoder(nn.Module):
    def __init__(self, in_channels, out_channels):
        super(StackEncoder, self).__init__()
        self.convr1 = ConvBnRelu(in_channels, out_channels, kernel_size=(3, 3), stride=1, padding=0)
        self.convr2 = ConvBnRelu(out_channels, out_channels, kernel_size=(3, 3), stride=1, padding=0)
        self.maxPool = nn.MaxPool2d(kernel_size=(2, 2), stride=2)

    def forward(self, x):
        x = self.convr1(x)
        x = self.convr2(x)
        x_trace = x             # save x to use in concat in the Decoder path
        out = self.maxPool(x)
        return out, x_trace


class StackDecoder(nn.Module):
    def __init__(self, in_channels, out_channels, upsample_size, padding, drop_out=False):
        super(StackDecoder, self).__init__()

        self.drop_out = drop_out
        self.dropout_layer = nn.Dropout2d(p=0.5)

        ''' this is old version
        self.upSample = nn.Upsample(size=upsample_size, scale_factor=(2, 2), mode="bilinear")
        self.convr1 = ConvBnRelu(in_channels, out_channels, kernel_size=(3, 3), stride=1, padding=padding)
        # Crop + concat step between these 2
        self.convr2 = ConvBnRelu(in_channels, out_channels, kernel_size=(3, 3), stride=1, padding=padding)
        '''
        self.upSample = nn.ConvTranspose2d(in_channels, out_channels, 2, stride=2)
        self.convr1 = ConvBnRelu(in_channels, out_channels, kernel_size=(3, 3), stride=1, padding=padding)
        self.convr2 = ConvBnRelu(out_channels, out_channels, kernel_size=(3, 3), stride=1, padding=padding)

    def _crop_concat(self, upsampled, bypass):
        """
         Crop y to the (h, w) of x and concat them.
         Used for the expansive path.
        Returns:
            The concatenated tensor
        """
        c = (bypass.size()[2] - upsampled.size()[2]) // 2
        bypass = F.pad(bypass, (-c, -c, -c, -c))

        return torch.cat((bypass, upsampled), 1)

    def forward(self, x, down_tensor):
        '''old version
        x = self.upSample(x)
        x = self.convr1(x)
        x = self._crop_concat(x, down_tensor)
        x = self.convr2(x)
        '''

        x = self.upSample(x)
        x = self._crop_concat(x, down_tensor)
        x = self.convr1(x)
        if self.drop_out: x = self.dropout_layer(x)
        x = self.convr2(x)
        if self.drop_out: x = self.dropout_layer(x)
        return x


class UNet_BN(nn.Module):
    def __init__(self):
        super(UNet_BN, self).__init__()
        # channels, height, width = in_shape

        # self.dropout = dropout

        self.model_code = ""        # variable to save model and main function when loaded

        self.down1 = StackEncoder(1, 64)
        self.down2 = StackEncoder(64, 128)
        self.down3 = StackEncoder(128, 256)
        self.down4 = StackEncoder(256, 512)

        self.center = nn.Sequential(
            # nn.Dropout2d(p=0.2),
            ConvBnRelu(512, 1024, kernel_size=(3, 3), stride=1, padding=0),
            nn.Dropout2d(p=0.2),
            ConvBnRelu(1024, 1024, kernel_size=(3, 3), stride=1, padding=0),
            nn.Dropout2d(p=0.2)
        )

        self.up1 = StackDecoder(in_channels=1024, out_channels=512, upsample_size=(64,64), padding = 1)
        self.up2 = StackDecoder(in_channels=512, out_channels=256, upsample_size=(128,128), padding = 1)
        self.up3 = StackDecoder(in_channels=256, out_channels=128, upsample_size=(256,256), padding = 1)
        self.up4 = StackDecoder(in_channels=128, out_channels=64, upsample_size=(512,512), padding = 1)

        # 1x1 convolution at the last layer
        # Different from the paper is the output size here
        self.output_seg_map = nn.Conv2d(64, 1, kernel_size=(1, 1), padding=0, stride=1)

        self._initialize_weights()

    def forward(self, x):
        x, x_trace1 = self.down1(x)
        x, x_trace2 = self.down2(x)
        x, x_trace3 = self.down3(x)
        x, x_trace4 = self.down4(x)
        x = self.center(x)
        x = self.up1(x, x_trace4)
        x = self.up2(x, x_trace3)
        x = self.up3(x, x_trace2)
        x = self.up4(x, x_trace1)

        x = self.output_seg_map(x)
        # x = F.sigmoid(x)
        # out = torch.squeeze(out, dim=1)
        return x


    def _initialize_weights(self):
        for m in self.modules():
            if isinstance(m, nn.Conv2d):
                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels
                m.weight.data.normal_(0, math.sqrt(2. / n))
                if m.bias is not None:
                    m.bias.data.zero_()
            elif isinstance(m, nn.BatchNorm2d):
                m.weight.data.fill_(1)
                m.bias.data.zero_()

# x = Variable(torch.randn(1,1,636,636))       # simulate input image
# net = UNet_BN()
# out = net(x)
# print("input: ", x)
# print("output: ", out)

===============from __future__ import print_function, division
import torch
from torch import optim
from torch.autograd import Variable
from torch.utils.data import DataLoader
import numpy as np
import torch.nn as nn
import torch.nn.functional as F
import Unet
import Unet_BatchNorm
import tifffile as tiff
import Utils
import time
from sklearn.metrics import average_precision_score, recall_score, f1_score
import Analysis
import Unet_ResNet

def to_var(x):
    if torch.cuda.is_available():
        return Variable(x.cuda())
    else:
        return Variable(x)

### BinaryCrossEntropyLoss2d().forward(logits, labels)
class BinaryCrossEntropyLoss2d(nn.Module):
    def __init__(self, weight=None, size_average=True):
        """
        Binary cross entropy loss 2D
        Args:
            weight:
            size_average:
        """
        super(BinaryCrossEntropyLoss2d, self).__init__()
        self.bce_loss = nn.BCELoss(weight, size_average)

    def forward(self, probs, targets):
        probs = F.sigmoid(probs)
        probs_flat = probs.view(-1)  # Flatten
        targets_flat = targets.view(-1)  # Flatten
        return self.bce_loss(probs_flat, targets_flat)      # (output, labels)

class SoftDiceLoss(nn.Module):
    def __init__(self, weight=None, size_average=True):
        super(SoftDiceLoss, self).__init__()

    def forward(self, probs, targets):
        smooth = 1
        # num = targets.size(0)
        probs = F.sigmoid(probs)
        m1 = probs.view(-1)
        m2 = targets.view(-1)
        intersection = (m1 * m2)
        score = 2. * (intersection.sum() + smooth) / (m1.sum() + m2.sum() + smooth)
        score = 1 - score.sum()
        return score

def _criterion(logits, labels):
    return BinaryCrossEntropyLoss2d().forward(logits, labels) + \
        SoftDiceLoss().forward(logits, labels)

def NetEval(net,valdata_loader,crit):
    loss = 0.
    count = 0
    net.eval()
    for i,data in enumerate(valdata_loader,0):
        inputs, labels = data
        inputs, labels = to_var(inputs), to_var(labels)
        out = net(inputs)
        l = crit(out, labels)
        loss += l.data[0]
        count += 1
    return loss/count

# calculate Precision, Recall, F1-measure, IoU over the validation set
def Net_performace_val(net,valdata_loader):
    precision_list = []
    recall_list = []
    iou_list = []
    net.eval()
    print("len of valdata: ", len(valdata_loader))
    for i,data in enumerate(valdata_loader,0):

        inputs, labels = data
        out = NetPredict(net, inputs)   # out is numpy array 512x512
        labels = labels.numpy()
        labels = labels[0,0,:,:]        # labels is numpy array 512x512
        # remove the case where the mask is plain black
        if np.sum(labels) < 0.01*np.shape(labels)[0]*np.shape(labels)[1]: continue

        precision = average_precision_score(labels, out)
        recall = recall_score(labels, out, average='weighted')
        iou = IoU(out, labels)
        precision_list.append(precision)
        recall_list.append(recall)
        iou_list.append(iou)

    precision, recall, iou = np.mean(precision_list), np.mean(recall_list), np.mean(iou_list)
    F1_measure = 2.0*precision*recall/(precision + recall)

    return precision, recall, F1_measure, iou

# calculate IoU
def IoU(pred, target):
    # Ignore IoU for background class
    cls = 0.5
    pred_inds = pred > cls
    target_inds = target > cls

    intersection = (pred_inds[target_inds]).sum()  # Cast to long to prevent overflows
    union = pred_inds.sum() + target_inds.sum() - intersection
    if union == 0:
        ious = float('nan')  # If there is no ground truth, do not include in evaluation
    else:
        ious = 1.0*intersection / max(union, 1)
    return ious

#process the test data and save to separate .tif image
def NetTest(net,testdata_loader,path = "data/results/"):
    net.eval()
    for i, data in enumerate(testdata_loader, 0):
        if i >= 30: return 1        # for debug
        data = to_var(data)
        out = net(data)

        out = F.sigmoid(out)

        imgname = path + str(i) + ".tif"
        img = out.cpu()
        img = img[0,0,:,:]
        img = img.data.numpy()
        img_shape = img.shape
        img = img.reshape(-1)
        img[img < 0.5] = 0; img[img >= 0.5] = 1
        img = img.reshape(img_shape)
        img = np.uint8(img * 255)
        tiff.imsave(imgname, img)

# return input image size like 512x512, numpy array
def NetPredict(net, data):
    net.eval()
    data = to_var(data)
    out = net(data)

    out = F.sigmoid(out)

    img = out.cpu()
    img = img[0, 0, :, :]
    img = img.data.numpy()
    img_shape = img.shape
    img = img.reshape(-1)
    img[img < 0.5] = 0;
    img[img >= 0.5] = 1
    img = img.reshape(img_shape)
    return img
def write_2_log(content):
    path = "log_file.txt"
    output = open(path, "a")
    output.write("\n")
    output.write(content)
    output.close()

if __name__ == '__main__':
    '''subjects to change for each exp:
    + path to the dataset
    + opt function
    + leg description
    + N_epoch
    + saved_model
    '''
    start_begining = time.time()

    # path = "data/dataset"
    path = "/home/anhxtuan/HanLe/dataset/40aug_10ela_3inten_reflect"

    import os
    print("Does the folder exist?: ", os.path.isdir(path))
    print("Does the path exist?: ", os.path.exists(path))

    # imgs_train, imgs_mask_train = Utils.load_train_data(npy_path=path)
    # trainset = zip(imgs_train, imgs_mask_train)
    # trainloader = torch.utils.data.DataLoader(trainset, batch_size=1,
    #                                           shuffle=True, num_workers=2)

    imgs_val, imgs_mask_val = Utils.load_val_data(npy_path=path)
    valset = zip(imgs_val, imgs_mask_val)
    valloader = torch.utils.data.DataLoader(valset, batch_size=1,
                                              shuffle=False, num_workers=2)
    # net = Unet.UNet()                     # Unet 1
    net = Unet_BatchNorm.UNet_BN()          # Unet 2 with batchNorm
    # net = Unet_ResNet.UNet_ResNet()

    f1 = open("Unet_BatchNorm.py", 'r')     # embede code into the model to be saved later
    # f1 = open("Unet_ResNet.py", 'r')
    f2 = open("UnetTrain.py", 'r')
    f3 = open("Utils.py", 'r')
    model_notes = time.strftime("%c") + "\n" + f1.read() + "\n" + "==="*5 + f2.read() + "\n" + "==="*5 + f3.read()
    f1.close()
    f2.close()
    f3.close()

    # criterion = nn.BCELoss()
    criterion = BinaryCrossEntropyLoss2d()
    # criterion = SoftDiceLoss()

    if torch.cuda.is_available():
        # torch.set_default_tensor_type('torch.cuda.FloatTensor')
        # net.load_state_dict(torch.load("Unet2_model_6epoch_Leg14_dropout_0_2_rmSigmoid_40aug_10ela_3inten_reflect"))
        net.cuda()
        # criterion.cuda()

    # opt = optim.SGD(net.parameters(), lr=1e-2, momentum=0.99)       # subject to change
    opt = optim.RMSprop(net.parameters(), lr=1e-3, weight_decay=1e-3)
    # RMSprop[22](learning rate 0.001) with weight decay set to 0.001.
    # opt = optim.Adam(net.parameters(), lr=1e-3, weight_decay=1e-4)

    train_loss = []
    val_loss = []

    print("[epoch, #image] Loss")
    leg = "Leg17_RMSprop_dropout_0_2_rmSigmoid_40aug_10ela_3inten_reflect"
    print("Processing: ", leg)
    model_name = ""

    N_epoch = 8
    model_saved = np.arange(2,N_epoch+1,2)
    val_loss_min = 100

    write_2_log("==="*30)
    write_2_log(time.strftime("%c"))       # time, date of exp
    write_2_log(leg)
    write_2_log(model_notes)
    write_2_log(time.strftime("%c"))  # time, date of exp
    write_2_log(leg)
    write_2_log("RMSprop(net.parameters(), lr=1e-3, weight_decay=1e-3)")
    write_2_log("Number of epoch max: " + str(N_epoch))

    min_model_epoch = 0
    for epoch in range(N_epoch):
        running_loss = 0.0; count = 0
        net.train()

        N_files = 1
        for j in range(N_files):
            if N_files > 0:
                train_file = "/imgs_train_" + str(j + 1) + ".npy"
                mask_file = "/imgs_mask_train_" + str(j + 1) + ".npy"
            else:
                train_file = "/imgs_train.npy"
                mask_file = "/imgs_mask_train.npy"

            imgs_train, imgs_mask_train = Utils.load_train_data(npy_path=path, train_file=train_file, mask_file=mask_file)
            trainset = zip(imgs_train, imgs_mask_train)
            trainloader = torch.utils.data.DataLoader(trainset, batch_size=1,
                                                      shuffle=True, num_workers=2)
            for i, data in enumerate(trainloader, 0):
                inputs, labels = data
                temp = labels.numpy()
                temp = temp[0, 0, :, :]  # labels is numpy array 512x512
                # remove the case where the mask is plain black
                if np.sum(temp) < 0.01 * np.shape(temp)[0] * np.shape(temp)[1]: continue
                inputs, labels = to_var(inputs), to_var(labels)
                opt.zero_grad()
                out = net(inputs)
                loss = criterion(out, labels)
                loss.backward()
                opt.step()
                running_loss += loss.data[0]
                count += 1

        net.eval()
        val_loss_temp = NetEval(net, valloader, criterion)
        if epoch > 0 and val_loss_temp < val_loss_min:        # save the model which has the lowest val_loss, ignore first epoch
            val_loss_min = val_loss_temp
            torch.save(net.state_dict(), "Unet2_model_" + leg + "_min_val_loss")  # save model
            min_model_epoch = epoch + 1

        disp = 'Epoch %d: Train loss: %.6f, Val loss: %.6f' % (epoch + 1, running_loss/count, val_loss_temp)
        write_2_log(disp)
        print(disp)
        val_loss.append(val_loss_temp)
        train_loss.append(running_loss/count); running_loss = 0.0

        if (epoch + 1) in model_saved:        # save checkpoint
            model_name = "Unet2_model_" + str(epoch+1) + "epoch_" + leg
            torch.save(net.state_dict(), model_name)  # save model
            Analysis.analysis(model_file = model_name, valloader = valloader)

    write_2_log("Best model at epoch: " + str(min_model_epoch))
    write_2_log("Total training time: " + str((time.time() - start_begining) / 3600.0))

    val_loss_file = "data/results" + "/val_loss_" + str(N_epoch) + "epoch_" + leg + ".npy"
    train_loss_file = "data/results" + "/training_loss_" + str(N_epoch) + "epoch_" + leg + ".npy"

    np.save(val_loss_file, val_loss)
    np.save(train_loss_file, train_loss)
    print("total processing time in seconds: ", time.time() - start_begining)
    print("total processing time in mins: ", (time.time() - start_begining) / 60.0)
    print("total processing time in hours: ", (time.time() - start_begining) / 3600.0)

    Analysis.analysis(model_file="Unet2_model_" + leg + "_min_val_loss", valloader=valloader)

    Analysis.PlotLoss(model_file = model_name, loss_train_path = train_loss_file, loss_val_path = val_loss_file, epoch_No = N_epoch)

    write_2_log(time.strftime("%c"))  # time, date of exp
===============import numpy as np
import torch.nn as nn
import torch
import cv2
from lcn import LecunLCN

LCN_enable = False

def input_filled_mirroring(x):      # fill missing data by mirroring the input image
    '''input size 636 --> output size 512'''
    w, h = x.shape
    e = 62  # extra width on 1 edge
    y = np.zeros((h + e * 2, w + e * 2))
    y[e:h + e, e:w + e] = x
    y[e:e + h, 0:e] = np.flip(y[e:e + h, e:2 * e], 1)  # flip vertically
    y[e:e + h, e + w:2 * e + w] = np.flip(y[e:e + h, w:e + w], 1)  # flip vertically
    y[0:e, 0:2 * e + w] = np.flip(y[e:2 * e, 0:2 * e + w], 0)  # flip horizontally
    y[e + h:2 * e + h, 0:2 * e + w] = np.flip(y[h:e + h, 0:2 * e + w], 0)  # flip horizontally
    return y

def nearest_cells_distance(pos, img):
    # searching in 8 directions to find 2 nearest distances to neighbor cells
    curr_value = img[pos]
    w = img.shape[0];h = img.shape[1]
    count_detect = 0  # detect 2 nearest neighbors. break the search if count_detect = 2
    x, y = pos

    # print("w,h: ", (w, h))
    d1 = 9999999;d2 = 9999999;d3 = 9999999;d4 = 9999999
    d5 = 9999999;d6 = 9999999;d7 = 9999999;d8 = 9999999
    for i in range(1, max(w, h)):
        # (x+1, y), (x+1, y+1), (x+1, y-1),
        # (x, y+1), (x, y-1)
        # (x-1, y), (x-1,y+1), (x-1,y-1),
        if x + i < w:
            if img[(x + i, y)] != curr_value and d1 == 9999999:
                d1 = i; count_detect += 1
            if y + i < h:
                if img[(x + i, y + i)] != curr_value and d2 == 9999999:
                    d2 = i; count_detect += 1
            elif y - i >= 0:
                if img[(x + i, y - i)] != curr_value and d3 == 9999999:
                    d3 = i; count_detect += 1
        if y + i < h:
            if img[(x, y + i)] != curr_value and d4 == 9999999:
                d4 = i; count_detect += 1
        if y - i >= 0:
            if img[(x, y - i)] != curr_value and d5 == 9999999:
                d5 = i; count_detect += 1
        if x - i >= 0:
            if img[(x - i, y)] != curr_value and d6 == 9999999:
                d6 = i; count_detect += 1
            if y + i < h:
                if img[(x - i, y + i)] != curr_value and d7 == 9999999:
                    d7 = i; count_detect += 1
            elif y - i >= 0:
                if img[(x - i, y - i)] != curr_value and d8 == 9999999:
                    d8 = i; count_detect += 1
        if count_detect >= 2: break

    d = [d1, d2, d3, d4, d5, d6, d7, d8]
    min_index = np.argmin(d)
    dist1 = d[min_index]
    d.remove(dist1)
    min_index = np.argmin(d)
    dist2 = d[min_index]
    return dist1, dist2

def create_weight_map(imgs_mask):
        print('-' * 30)
        print('Creating weights for masks ...')
        print('-' * 30)
        weight_map = np.ndarray(
            (len(imgs_mask), 1, np.shape(imgs_mask)[2], np.shape(imgs_mask)[3]), dtype=np.float32)
        w_0 = 10; sigma = 4
        imgs_w, imgs_h = np.shape(imgs_mask)[2], np.shape(imgs_mask)[3]
        total_pixels = imgs_w*imgs_h
        import time
        start = time.time()
        for i in range(len(imgs_mask)):
            if i%10 == 0: print("Done processing: %d images, time passed: %.2f mins" % (i, (time.time() - start)/60.0))
            temp = imgs_mask[i,0,:,:]
            w_border = 1 - np.sum(temp)/total_pixels        # w_c of pixel on the border (black)
            for m in range(imgs_w):
                for n in range(imgs_h):
                    # loop through all pixel of the mask
                    d1,d2 = nearest_cells_distance((m,n), temp)
                    w_c = w_border
                    if temp[m,n] == 0: w_c = 1 - w_border
                    weight_map[i,0,m,n] = w_c*5 + w_0*np.exp(-(d1 + d2)**2/(2*sigma**2))
                    # print("w_0*np.exp(): ", w_0*np.exp(-(d1 + d2)**2/(2*sigma**2)))
                    # print("w_border: ", w_border)

        np.save('data/dataset/weight_map_train.npy', weight_map)

        return weight_map

def load_train_data(npy_path = "data/dataset", train_file = "/imgs_train.npy", mask_file = "/imgs_mask_train.npy", hist_equal = False):

    print('-' * 30)
    print('load train images...')

    imgs_train = np.load(npy_path + train_file)
    imgs_mask_train = np.load(npy_path + mask_file)

    if hist_equal: imgs_train = hist_equalization(imgs_train)

    # weight_map_train = np.load(npy_path + "/weight_map_train.npy")
    # weight_map_train = weight_map_train.astype('float32')

    imgs_train = imgs_train.astype('float32')
    imgs_mask_train = imgs_mask_train.astype('float32')

    if LCN_enable:
        imgs_train = imgs_train.astype('float64')
        imgs_train = LecunLCN(imgs_train, image_shape=imgs_train.shape).output.eval()
        imgs_train = imgs_train.astype('float32')

    if not LCN_enable: imgs_train /= 255

    imgs_train -= imgs_train.mean(axis=0)
    imgs_mask_train /= 255
    imgs_mask_train[imgs_mask_train > 0.5] = 1
    imgs_mask_train[imgs_mask_train <= 0.5] = 0

    # weight_map_train = create_weight_map(imgs_mask_train)

    print("Done loading traing data")
    print('-' * 30)
    return imgs_train, imgs_mask_train

def load_val_data(npy_path = "data/dataset", hist_equal = True):

    print('-' * 30)
    print('load validation images...')

    imgs_train = np.load(npy_path + "/imgs_val.npy")
    imgs_mask_train = np.load(npy_path + "/imgs_mask_val.npy")

    if hist_equal: imgs_train = hist_equalization(imgs_train)

    imgs_train = imgs_train.astype('float32')
    imgs_mask_train = imgs_mask_train.astype('float32')

    if LCN_enable:
        imgs_train = imgs_train.astype('float64')
        imgs_train = LecunLCN(imgs_train, image_shape=imgs_train.shape).output.eval()
        imgs_train = imgs_train.astype('float32')

    if not LCN_enable: imgs_train /= 255
    imgs_train -= imgs_train.mean(axis=0)
    imgs_mask_train /= 255
    imgs_mask_train[imgs_mask_train > 0.5] = 1
    imgs_mask_train[imgs_mask_train <= 0.5] = 0
    print("Done loading validation data")
    print('-' * 30)
    return imgs_train, imgs_mask_train

def load_test_data(npy_path = "data/dataset", hist_equal = True):

    print('-' * 30)
    print('load test images...')

    imgs_test = np.load(npy_path + "/imgs_test.npy")

    if hist_equal: imgs_test = hist_equalization(imgs_test)

    imgs_test = imgs_test.astype('float32')

    if LCN_enable:
        imgs_test = imgs_test.astype('float64')
        imgs_test = LecunLCN(imgs_test, image_shape=imgs_test.shape).output.eval()
        imgs_test = imgs_test.astype('float32')

    if not LCN_enable: imgs_test /= 255

    imgs_test -= imgs_test.mean(axis=0)

    print("Done loading test data")
    print('-' * 30)
    return imgs_test

def load_val_5imgs(npy_path = "data/dataset"):
    print('-' * 30)
    print('load train images...')

    imgs_train = np.load(npy_path + "/imgs_val_5imgs.npy")
    imgs_mask_train = np.load(npy_path + "/imgs_mask_val_5imgs.npy")

    # imgs_train = hist_equalization(imgs_train)

    imgs_train = imgs_train.astype('float64')
    imgs_mask_train = imgs_mask_train.astype('float64')

    if LCN_enable: imgs_train = LecunLCN(imgs_train, image_shape=imgs_train.shape).output.eval()

    if not LCN_enable: imgs_train /= 255

    mean = imgs_train.mean(axis=0)
    imgs_train -= mean


    imgs_mask_train /= 255
    imgs_mask_train[imgs_mask_train > 0.5] = 1
    imgs_mask_train[imgs_mask_train <= 0.5] = 0

    # weight_map_train = self.create_weight_map(imgs_mask_train)

    print("Done loading traing data")
    print('-' * 30)
    return imgs_train, imgs_mask_train

def hist_equalization(inputs):      # inputs are uint8, 0-255, Nx1x636x636
    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))
    output = inputs.copy()
    for i in range(len(inputs)):
        img = inputs[i, 0, :, :]
        # res = cv2.equalizeHist(img)
        res = clahe.apply(img)
        output[i,0,:,:] = res
    return output

### BinaryCrossEntropyLoss2d().forward(logits, labels)
class BinaryCrossEntropyLoss2d(nn.Module):
    def __init__(self, weight=None, size_average=True):
        """
        Binary cross entropy loss 2D
        Args:
            weight:
            size_average:
        """
        super(BinaryCrossEntropyLoss2d, self).__init__()
        self.bce_loss = nn.BCELoss(weight, size_average)

    def forward(self, logits, targets):
        # probs = F.sigmoid(logits)
        probs = logits
        probs_flat = probs.view(-1)  # Flatten
        targets_flat = targets.view(-1)  # Flatten
        return self.bce_loss(probs_flat, targets_flat)      # (output, labels)

class BCE_with_Weights(nn.Module):
    def __init__(self, weights=None):
        """
        Binary cross entropy loss 2D
        Args:
            weights:
        """
        super(BCE_with_Weights, self).__init__()
        self.weights = weights

    def forward(self, output, target):
        if self.weights is not None:
            loss = self.weights * (target * torch.log(output) + (1 - target) * torch.log(1 - output))
        else:
            loss = target * torch.log(output) + (1 - target) * torch.log(1 - output)

        return torch.neg(torch.mean(loss))

class LRN(nn.Module):       # input x is Torch tensor
    def __init__(self, local_size=1, alpha=1.0, beta=0.75, ACROSS_CHANNELS=False):      #LRN(local_size=5, alpha=0.0001, beta=0.75),
        super(LRN, self).__init__()
        self.ACROSS_CHANNELS = ACROSS_CHANNELS
        if self.ACROSS_CHANNELS:
            self.average = nn.AvgPool3d(kernel_size=(local_size, 1, 1),
                                        stride=1, padding=(int((local_size - 1.0) / 2), 0, 0))
        else:
            self.average = nn.AvgPool2d(kernel_size=local_size,
                                        stride=1, padding=int((local_size - 1.0) / 2))
        self.alpha = alpha
        self.beta = beta

    def forward(self, x):
        if self.ACROSS_CHANNELS:
            div = x.pow(2).unsqueeze(1)
            div = self.average(div).squeeze(1)
            div = div.mul(self.alpha).add(1.0).pow(self.beta)
        else:
            div = x.pow(2)
            div = self.average(div)
            div = div.mul(self.alpha).add(1.0).pow(self.beta)
        x = x.div(div)
        return x


Sun Nov 19 22:10:21 2017
Leg17_RMSprop_dropout_0_2_rmSigmoid_40aug_10ela_3inten_reflect
RMSprop(net.parameters(), lr=1e-3, weight_decay=1e-3)
Number of epoch max: 8
==========================================================================================
Sun Nov 19 22:11:55 2017
Leg17_RMSprop_dropout_0_2_rmSigmoid_40aug_10ela_3inten_reflect
Sun Nov 19 22:11:52 2017
import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.autograd import Variable
import math


class ConvBnRelu(nn.Module):
    def __init__(self, in_channels, out_channels, kernel_size, padding, stride):
        super(ConvBnRelu, self).__init__()
        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=kernel_size, padding=padding, stride=stride)
        self.bn = nn.BatchNorm2d(out_channels)
        self.relu = nn.ReLU()

    def forward(self, x):
        x = self.conv(x)
        # x = self.bn(x)
        x = self.relu(x)
        return x


class StackEncoder(nn.Module):
    def __init__(self, in_channels, out_channels):
        super(StackEncoder, self).__init__()
        self.convr1 = ConvBnRelu(in_channels, out_channels, kernel_size=(3, 3), stride=1, padding=0)
        self.convr2 = ConvBnRelu(out_channels, out_channels, kernel_size=(3, 3), stride=1, padding=0)
        self.maxPool = nn.MaxPool2d(kernel_size=(2, 2), stride=2)

    def forward(self, x):
        x = self.convr1(x)
        x = self.convr2(x)
        x_trace = x             # save x to use in concat in the Decoder path
        out = self.maxPool(x)
        return out, x_trace


class StackDecoder(nn.Module):
    def __init__(self, in_channels, out_channels, upsample_size, padding, drop_out=False):
        super(StackDecoder, self).__init__()

        self.drop_out = drop_out
        self.dropout_layer = nn.Dropout2d(p=0.5)

        ''' this is old version
        self.upSample = nn.Upsample(size=upsample_size, scale_factor=(2, 2), mode="bilinear")
        self.convr1 = ConvBnRelu(in_channels, out_channels, kernel_size=(3, 3), stride=1, padding=padding)
        # Crop + concat step between these 2
        self.convr2 = ConvBnRelu(in_channels, out_channels, kernel_size=(3, 3), stride=1, padding=padding)
        '''
        self.upSample = nn.ConvTranspose2d(in_channels, out_channels, 2, stride=2)
        self.convr1 = ConvBnRelu(in_channels, out_channels, kernel_size=(3, 3), stride=1, padding=padding)
        self.convr2 = ConvBnRelu(out_channels, out_channels, kernel_size=(3, 3), stride=1, padding=padding)

    def _crop_concat(self, upsampled, bypass):
        """
         Crop y to the (h, w) of x and concat them.
         Used for the expansive path.
        Returns:
            The concatenated tensor
        """
        c = (bypass.size()[2] - upsampled.size()[2]) // 2
        bypass = F.pad(bypass, (-c, -c, -c, -c))

        return torch.cat((bypass, upsampled), 1)

    def forward(self, x, down_tensor):
        '''old version
        x = self.upSample(x)
        x = self.convr1(x)
        x = self._crop_concat(x, down_tensor)
        x = self.convr2(x)
        '''

        x = self.upSample(x)
        x = self._crop_concat(x, down_tensor)
        x = self.convr1(x)
        if self.drop_out: x = self.dropout_layer(x)
        x = self.convr2(x)
        if self.drop_out: x = self.dropout_layer(x)
        return x


class UNet_BN(nn.Module):
    def __init__(self):
        super(UNet_BN, self).__init__()
        # channels, height, width = in_shape

        # self.dropout = dropout

        self.model_code = ""        # variable to save model and main function when loaded

        self.down1 = StackEncoder(1, 64)
        self.down2 = StackEncoder(64, 128)
        self.down3 = StackEncoder(128, 256)
        self.down4 = StackEncoder(256, 512)

        self.center = nn.Sequential(
            # nn.Dropout2d(p=0.2),
            ConvBnRelu(512, 1024, kernel_size=(3, 3), stride=1, padding=0),
            nn.Dropout2d(p=0.2),
            ConvBnRelu(1024, 1024, kernel_size=(3, 3), stride=1, padding=0),
            nn.Dropout2d(p=0.2)
        )

        self.up1 = StackDecoder(in_channels=1024, out_channels=512, upsample_size=(64,64), padding = 1)
        self.up2 = StackDecoder(in_channels=512, out_channels=256, upsample_size=(128,128), padding = 1)
        self.up3 = StackDecoder(in_channels=256, out_channels=128, upsample_size=(256,256), padding = 1)
        self.up4 = StackDecoder(in_channels=128, out_channels=64, upsample_size=(512,512), padding = 1)

        # 1x1 convolution at the last layer
        # Different from the paper is the output size here
        self.output_seg_map = nn.Conv2d(64, 1, kernel_size=(1, 1), padding=0, stride=1)

        self._initialize_weights()

    def forward(self, x):
        x, x_trace1 = self.down1(x)
        x, x_trace2 = self.down2(x)
        x, x_trace3 = self.down3(x)
        x, x_trace4 = self.down4(x)
        x = self.center(x)
        x = self.up1(x, x_trace4)
        x = self.up2(x, x_trace3)
        x = self.up3(x, x_trace2)
        x = self.up4(x, x_trace1)

        x = self.output_seg_map(x)
        # x = F.sigmoid(x)
        # out = torch.squeeze(out, dim=1)
        return x


    def _initialize_weights(self):
        for m in self.modules():
            if isinstance(m, nn.Conv2d):
                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels
                m.weight.data.normal_(0, math.sqrt(2. / n))
                if m.bias is not None:
                    m.bias.data.zero_()
            elif isinstance(m, nn.BatchNorm2d):
                m.weight.data.fill_(1)
                m.bias.data.zero_()

# x = Variable(torch.randn(1,1,636,636))       # simulate input image
# net = UNet_BN()
# out = net(x)
# print("input: ", x)
# print("output: ", out)

===============from __future__ import print_function, division
import torch
from torch import optim
from torch.autograd import Variable
from torch.utils.data import DataLoader
import numpy as np
import torch.nn as nn
import torch.nn.functional as F
import Unet
import Unet_BatchNorm
import tifffile as tiff
import Utils
import time
from sklearn.metrics import average_precision_score, recall_score, f1_score
import Analysis
import Unet_ResNet

def to_var(x):
    if torch.cuda.is_available():
        return Variable(x.cuda())
    else:
        return Variable(x)

### BinaryCrossEntropyLoss2d().forward(logits, labels)
class BinaryCrossEntropyLoss2d(nn.Module):
    def __init__(self, weight=None, size_average=True):
        """
        Binary cross entropy loss 2D
        Args:
            weight:
            size_average:
        """
        super(BinaryCrossEntropyLoss2d, self).__init__()
        self.bce_loss = nn.BCELoss(weight, size_average)

    def forward(self, probs, targets):
        probs = F.sigmoid(probs)
        probs_flat = probs.view(-1)  # Flatten
        targets_flat = targets.view(-1)  # Flatten
        return self.bce_loss(probs_flat, targets_flat)      # (output, labels)

class SoftDiceLoss(nn.Module):
    def __init__(self, weight=None, size_average=True):
        super(SoftDiceLoss, self).__init__()

    def forward(self, probs, targets):
        smooth = 1
        # num = targets.size(0)
        probs = F.sigmoid(probs)
        m1 = probs.view(-1)
        m2 = targets.view(-1)
        intersection = (m1 * m2)
        score = 2. * (intersection.sum() + smooth) / (m1.sum() + m2.sum() + smooth)
        score = 1 - score.sum()
        return score

def _criterion(logits, labels):
    return BinaryCrossEntropyLoss2d().forward(logits, labels) + \
        SoftDiceLoss().forward(logits, labels)

def NetEval(net,valdata_loader,crit):
    loss = 0.
    count = 0
    net.eval()
    for i,data in enumerate(valdata_loader,0):
        inputs, labels = data
        inputs, labels = to_var(inputs), to_var(labels)
        out = net(inputs)
        l = crit(out, labels)
        loss += l.data[0]
        count += 1
    return loss/count

# calculate Precision, Recall, F1-measure, IoU over the validation set
def Net_performace_val(net,valdata_loader):
    precision_list = []
    recall_list = []
    iou_list = []
    net.eval()
    print("len of valdata: ", len(valdata_loader))
    for i,data in enumerate(valdata_loader,0):

        inputs, labels = data
        out = NetPredict(net, inputs)   # out is numpy array 512x512
        labels = labels.numpy()
        labels = labels[0,0,:,:]        # labels is numpy array 512x512
        # remove the case where the mask is plain black
        if np.sum(labels) < 0.01*np.shape(labels)[0]*np.shape(labels)[1]: continue

        precision = average_precision_score(labels, out)
        recall = recall_score(labels, out, average='weighted')
        iou = IoU(out, labels)
        precision_list.append(precision)
        recall_list.append(recall)
        iou_list.append(iou)

    precision, recall, iou = np.mean(precision_list), np.mean(recall_list), np.mean(iou_list)
    F1_measure = 2.0*precision*recall/(precision + recall)

    return precision, recall, F1_measure, iou

# calculate IoU
def IoU(pred, target):
    # Ignore IoU for background class
    cls = 0.5
    pred_inds = pred > cls
    target_inds = target > cls

    intersection = (pred_inds[target_inds]).sum()  # Cast to long to prevent overflows
    union = pred_inds.sum() + target_inds.sum() - intersection
    if union == 0:
        ious = float('nan')  # If there is no ground truth, do not include in evaluation
    else:
        ious = 1.0*intersection / max(union, 1)
    return ious

#process the test data and save to separate .tif image
def NetTest(net,testdata_loader,path = "data/results/"):
    net.eval()
    for i, data in enumerate(testdata_loader, 0):
        if i >= 30: return 1        # for debug
        data = to_var(data)
        out = net(data)

        out = F.sigmoid(out)

        imgname = path + str(i) + ".tif"
        img = out.cpu()
        img = img[0,0,:,:]
        img = img.data.numpy()
        img_shape = img.shape
        img = img.reshape(-1)
        img[img < 0.5] = 0; img[img >= 0.5] = 1
        img = img.reshape(img_shape)
        img = np.uint8(img * 255)
        tiff.imsave(imgname, img)

# return input image size like 512x512, numpy array
def NetPredict(net, data):
    net.eval()
    data = to_var(data)
    out = net(data)

    out = F.sigmoid(out)

    img = out.cpu()
    img = img[0, 0, :, :]
    img = img.data.numpy()
    img_shape = img.shape
    img = img.reshape(-1)
    img[img < 0.5] = 0;
    img[img >= 0.5] = 1
    img = img.reshape(img_shape)
    return img
def write_2_log(content):
    path = "log_file.txt"
    output = open(path, "a")
    output.write("\n")
    output.write(content)
    output.close()

if __name__ == '__main__':
    '''subjects to change for each exp:
    + path to the dataset
    + opt function
    + leg description
    + N_epoch
    + saved_model
    '''
    start_begining = time.time()

    # path = "data/dataset"
    path = "/home/anhxtuan/HanLe/dataset/40aug_10ela_3inten_reflect"

    import os
    print("Does the folder exist?: ", os.path.isdir(path))
    print("Does the path exist?: ", os.path.exists(path))

    # imgs_train, imgs_mask_train = Utils.load_train_data(npy_path=path)
    # trainset = zip(imgs_train, imgs_mask_train)
    # trainloader = torch.utils.data.DataLoader(trainset, batch_size=1,
    #                                           shuffle=True, num_workers=2)

    imgs_val, imgs_mask_val = Utils.load_val_data(npy_path=path)
    valset = zip(imgs_val, imgs_mask_val)
    valloader = torch.utils.data.DataLoader(valset, batch_size=1,
                                              shuffle=False, num_workers=2)
    # net = Unet.UNet()                     # Unet 1
    net = Unet_BatchNorm.UNet_BN()          # Unet 2 with batchNorm
    # net = Unet_ResNet.UNet_ResNet()

    f1 = open("Unet_BatchNorm.py", 'r')     # embede code into the model to be saved later
    # f1 = open("Unet_ResNet.py", 'r')
    f2 = open("UnetTrain.py", 'r')
    f3 = open("Utils.py", 'r')
    model_notes = time.strftime("%c") + "\n" + f1.read() + "\n" + "==="*5 + f2.read() + "\n" + "==="*5 + f3.read()
    f1.close()
    f2.close()
    f3.close()

    # criterion = nn.BCELoss()
    criterion = BinaryCrossEntropyLoss2d()
    # criterion = SoftDiceLoss()

    if torch.cuda.is_available():
        # torch.set_default_tensor_type('torch.cuda.FloatTensor')
        # net.load_state_dict(torch.load("Unet2_model_6epoch_Leg14_dropout_0_2_rmSigmoid_40aug_10ela_3inten_reflect"))
        net.cuda()
        # criterion.cuda()

    # opt = optim.SGD(net.parameters(), lr=1e-2, momentum=0.99)       # subject to change
    opt = optim.RMSprop(net.parameters(), lr=1e-3, weight_decay=1e-3)
    # RMSprop[22](learning rate 0.001) with weight decay set to 0.001.
    # opt = optim.Adam(net.parameters(), lr=1e-3, weight_decay=1e-4)

    train_loss = []
    val_loss = []

    print("[epoch, #image] Loss")
    leg = "Leg17_RMSprop_dropout_0_2_rmSigmoid_40aug_10ela_3inten_reflect"
    print("Processing: ", leg)
    model_name = ""

    N_epoch = 8
    model_saved = np.arange(2,N_epoch+1,2)
    val_loss_min = 100

    write_2_log("==="*30)
    write_2_log(time.strftime("%c"))       # time, date of exp
    write_2_log(leg)
    write_2_log(model_notes)
    write_2_log(time.strftime("%c"))  # time, date of exp
    write_2_log(leg)
    write_2_log("RMSprop(net.parameters(), lr=1e-3, weight_decay=1e-3)")
    write_2_log("Number of epoch max: " + str(N_epoch))

    min_model_epoch = 0
    for epoch in range(N_epoch):
        running_loss = 0.0; count = 0
        net.train()

        N_files = 1
        for j in range(N_files):
            if N_files > 0:
                train_file = "/imgs_train_" + str(j + 1) + ".npy"
                mask_file = "/imgs_mask_train_" + str(j + 1) + ".npy"
            else:
                train_file = "/imgs_train.npy"
                mask_file = "/imgs_mask_train.npy"

            imgs_train, imgs_mask_train = Utils.load_train_data(npy_path=path, train_file=train_file, mask_file=mask_file)
            trainset = zip(imgs_train, imgs_mask_train)
            trainloader = torch.utils.data.DataLoader(trainset, batch_size=1,
                                                      shuffle=True, num_workers=2)
            for i, data in enumerate(trainloader, 0):
                inputs, labels = data
                temp = labels.numpy()
                temp = temp[0, 0, :, :]  # labels is numpy array 512x512
                # remove the case where the mask is plain black
                if np.sum(temp) < 0.01 * np.shape(temp)[0] * np.shape(temp)[1]: continue
                inputs, labels = to_var(inputs), to_var(labels)
                opt.zero_grad()
                out = net(inputs)
                loss = criterion(out, labels)
                loss.backward()
                opt.step()
                running_loss += loss.data[0]
                count += 1

        net.eval()
        val_loss_temp = NetEval(net, valloader, criterion)
        if epoch > 0 and val_loss_temp < val_loss_min:        # save the model which has the lowest val_loss, ignore first epoch
            val_loss_min = val_loss_temp
            torch.save(net.state_dict(), "Unet2_model_" + leg + "_min_val_loss")  # save model
            min_model_epoch = epoch + 1

        disp = 'Epoch %d: Train loss: %.6f, Val loss: %.6f' % (epoch + 1, running_loss/count, val_loss_temp)
        write_2_log(disp)
        print(disp)
        val_loss.append(val_loss_temp)
        train_loss.append(running_loss/count); running_loss = 0.0

        if (epoch + 2) in model_saved:        # save checkpoint
            model_name = "Unet2_model_" + str(epoch+1) + "epoch_" + leg
            torch.save(net.state_dict(), model_name)  # save model
            Analysis.analysis(model_file = model_name, valloader = valloader)

    write_2_log("Best model at epoch: " + str(min_model_epoch))
    write_2_log("Total training time: " + str((time.time() - start_begining) / 3600.0))

    val_loss_file = "data/results" + "/val_loss_" + str(N_epoch) + "epoch_" + leg + ".npy"
    train_loss_file = "data/results" + "/training_loss_" + str(N_epoch) + "epoch_" + leg + ".npy"

    np.save(val_loss_file, val_loss)
    np.save(train_loss_file, train_loss)
    print("total processing time in seconds: ", time.time() - start_begining)
    print("total processing time in mins: ", (time.time() - start_begining) / 60.0)
    print("total processing time in hours: ", (time.time() - start_begining) / 3600.0)

    Analysis.analysis(model_file="Unet2_model_" + leg + "_min_val_loss", valloader=valloader)

    Analysis.PlotLoss(model_file = model_name, loss_train_path = train_loss_file, loss_val_path = val_loss_file, epoch_No = N_epoch)

    write_2_log(time.strftime("%c"))  # time, date of exp
===============import numpy as np
import torch.nn as nn
import torch
import cv2
from lcn import LecunLCN

LCN_enable = False

def input_filled_mirroring(x):      # fill missing data by mirroring the input image
    '''input size 636 --> output size 512'''
    w, h = x.shape
    e = 62  # extra width on 1 edge
    y = np.zeros((h + e * 2, w + e * 2))
    y[e:h + e, e:w + e] = x
    y[e:e + h, 0:e] = np.flip(y[e:e + h, e:2 * e], 1)  # flip vertically
    y[e:e + h, e + w:2 * e + w] = np.flip(y[e:e + h, w:e + w], 1)  # flip vertically
    y[0:e, 0:2 * e + w] = np.flip(y[e:2 * e, 0:2 * e + w], 0)  # flip horizontally
    y[e + h:2 * e + h, 0:2 * e + w] = np.flip(y[h:e + h, 0:2 * e + w], 0)  # flip horizontally
    return y

def nearest_cells_distance(pos, img):
    # searching in 8 directions to find 2 nearest distances to neighbor cells
    curr_value = img[pos]
    w = img.shape[0];h = img.shape[1]
    count_detect = 0  # detect 2 nearest neighbors. break the search if count_detect = 2
    x, y = pos

    # print("w,h: ", (w, h))
    d1 = 9999999;d2 = 9999999;d3 = 9999999;d4 = 9999999
    d5 = 9999999;d6 = 9999999;d7 = 9999999;d8 = 9999999
    for i in range(1, max(w, h)):
        # (x+1, y), (x+1, y+1), (x+1, y-1),
        # (x, y+1), (x, y-1)
        # (x-1, y), (x-1,y+1), (x-1,y-1),
        if x + i < w:
            if img[(x + i, y)] != curr_value and d1 == 9999999:
                d1 = i; count_detect += 1
            if y + i < h:
                if img[(x + i, y + i)] != curr_value and d2 == 9999999:
                    d2 = i; count_detect += 1
            elif y - i >= 0:
                if img[(x + i, y - i)] != curr_value and d3 == 9999999:
                    d3 = i; count_detect += 1
        if y + i < h:
            if img[(x, y + i)] != curr_value and d4 == 9999999:
                d4 = i; count_detect += 1
        if y - i >= 0:
            if img[(x, y - i)] != curr_value and d5 == 9999999:
                d5 = i; count_detect += 1
        if x - i >= 0:
            if img[(x - i, y)] != curr_value and d6 == 9999999:
                d6 = i; count_detect += 1
            if y + i < h:
                if img[(x - i, y + i)] != curr_value and d7 == 9999999:
                    d7 = i; count_detect += 1
            elif y - i >= 0:
                if img[(x - i, y - i)] != curr_value and d8 == 9999999:
                    d8 = i; count_detect += 1
        if count_detect >= 2: break

    d = [d1, d2, d3, d4, d5, d6, d7, d8]
    min_index = np.argmin(d)
    dist1 = d[min_index]
    d.remove(dist1)
    min_index = np.argmin(d)
    dist2 = d[min_index]
    return dist1, dist2

def create_weight_map(imgs_mask):
        print('-' * 30)
        print('Creating weights for masks ...')
        print('-' * 30)
        weight_map = np.ndarray(
            (len(imgs_mask), 1, np.shape(imgs_mask)[2], np.shape(imgs_mask)[3]), dtype=np.float32)
        w_0 = 10; sigma = 4
        imgs_w, imgs_h = np.shape(imgs_mask)[2], np.shape(imgs_mask)[3]
        total_pixels = imgs_w*imgs_h
        import time
        start = time.time()
        for i in range(len(imgs_mask)):
            if i%10 == 0: print("Done processing: %d images, time passed: %.2f mins" % (i, (time.time() - start)/60.0))
            temp = imgs_mask[i,0,:,:]
            w_border = 1 - np.sum(temp)/total_pixels        # w_c of pixel on the border (black)
            for m in range(imgs_w):
                for n in range(imgs_h):
                    # loop through all pixel of the mask
                    d1,d2 = nearest_cells_distance((m,n), temp)
                    w_c = w_border
                    if temp[m,n] == 0: w_c = 1 - w_border
                    weight_map[i,0,m,n] = w_c*5 + w_0*np.exp(-(d1 + d2)**2/(2*sigma**2))
                    # print("w_0*np.exp(): ", w_0*np.exp(-(d1 + d2)**2/(2*sigma**2)))
                    # print("w_border: ", w_border)

        np.save('data/dataset/weight_map_train.npy', weight_map)

        return weight_map

def load_train_data(npy_path = "data/dataset", train_file = "/imgs_train.npy", mask_file = "/imgs_mask_train.npy", hist_equal = False):

    print('-' * 30)
    print('load train images...')

    imgs_train = np.load(npy_path + train_file)
    imgs_mask_train = np.load(npy_path + mask_file)

    if hist_equal: imgs_train = hist_equalization(imgs_train)

    # weight_map_train = np.load(npy_path + "/weight_map_train.npy")
    # weight_map_train = weight_map_train.astype('float32')

    imgs_train = imgs_train.astype('float32')
    imgs_mask_train = imgs_mask_train.astype('float32')

    if LCN_enable:
        imgs_train = imgs_train.astype('float64')
        imgs_train = LecunLCN(imgs_train, image_shape=imgs_train.shape).output.eval()
        imgs_train = imgs_train.astype('float32')

    if not LCN_enable: imgs_train /= 255

    imgs_train -= imgs_train.mean(axis=0)
    imgs_mask_train /= 255
    imgs_mask_train[imgs_mask_train > 0.5] = 1
    imgs_mask_train[imgs_mask_train <= 0.5] = 0

    # weight_map_train = create_weight_map(imgs_mask_train)

    print("Done loading traing data")
    print('-' * 30)
    return imgs_train, imgs_mask_train

def load_val_data(npy_path = "data/dataset", hist_equal = True):

    print('-' * 30)
    print('load validation images...')

    imgs_train = np.load(npy_path + "/imgs_val.npy")
    imgs_mask_train = np.load(npy_path + "/imgs_mask_val.npy")

    if hist_equal: imgs_train = hist_equalization(imgs_train)

    imgs_train = imgs_train.astype('float32')
    imgs_mask_train = imgs_mask_train.astype('float32')

    if LCN_enable:
        imgs_train = imgs_train.astype('float64')
        imgs_train = LecunLCN(imgs_train, image_shape=imgs_train.shape).output.eval()
        imgs_train = imgs_train.astype('float32')

    if not LCN_enable: imgs_train /= 255
    imgs_train -= imgs_train.mean(axis=0)
    imgs_mask_train /= 255
    imgs_mask_train[imgs_mask_train > 0.5] = 1
    imgs_mask_train[imgs_mask_train <= 0.5] = 0
    print("Done loading validation data")
    print('-' * 30)
    return imgs_train, imgs_mask_train

def load_test_data(npy_path = "data/dataset", hist_equal = True):

    print('-' * 30)
    print('load test images...')

    imgs_test = np.load(npy_path + "/imgs_test.npy")

    if hist_equal: imgs_test = hist_equalization(imgs_test)

    imgs_test = imgs_test.astype('float32')

    if LCN_enable:
        imgs_test = imgs_test.astype('float64')
        imgs_test = LecunLCN(imgs_test, image_shape=imgs_test.shape).output.eval()
        imgs_test = imgs_test.astype('float32')

    if not LCN_enable: imgs_test /= 255

    imgs_test -= imgs_test.mean(axis=0)

    print("Done loading test data")
    print('-' * 30)
    return imgs_test

def load_val_5imgs(npy_path = "data/dataset"):
    print('-' * 30)
    print('load train images...')

    imgs_train = np.load(npy_path + "/imgs_val_5imgs.npy")
    imgs_mask_train = np.load(npy_path + "/imgs_mask_val_5imgs.npy")

    # imgs_train = hist_equalization(imgs_train)

    imgs_train = imgs_train.astype('float64')
    imgs_mask_train = imgs_mask_train.astype('float64')

    if LCN_enable: imgs_train = LecunLCN(imgs_train, image_shape=imgs_train.shape).output.eval()

    if not LCN_enable: imgs_train /= 255

    mean = imgs_train.mean(axis=0)
    imgs_train -= mean


    imgs_mask_train /= 255
    imgs_mask_train[imgs_mask_train > 0.5] = 1
    imgs_mask_train[imgs_mask_train <= 0.5] = 0

    # weight_map_train = self.create_weight_map(imgs_mask_train)

    print("Done loading traing data")
    print('-' * 30)
    return imgs_train, imgs_mask_train

def hist_equalization(inputs):      # inputs are uint8, 0-255, Nx1x636x636
    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))
    output = inputs.copy()
    for i in range(len(inputs)):
        img = inputs[i, 0, :, :]
        # res = cv2.equalizeHist(img)
        res = clahe.apply(img)
        output[i,0,:,:] = res
    return output

### BinaryCrossEntropyLoss2d().forward(logits, labels)
class BinaryCrossEntropyLoss2d(nn.Module):
    def __init__(self, weight=None, size_average=True):
        """
        Binary cross entropy loss 2D
        Args:
            weight:
            size_average:
        """
        super(BinaryCrossEntropyLoss2d, self).__init__()
        self.bce_loss = nn.BCELoss(weight, size_average)

    def forward(self, logits, targets):
        # probs = F.sigmoid(logits)
        probs = logits
        probs_flat = probs.view(-1)  # Flatten
        targets_flat = targets.view(-1)  # Flatten
        return self.bce_loss(probs_flat, targets_flat)      # (output, labels)

class BCE_with_Weights(nn.Module):
    def __init__(self, weights=None):
        """
        Binary cross entropy loss 2D
        Args:
            weights:
        """
        super(BCE_with_Weights, self).__init__()
        self.weights = weights

    def forward(self, output, target):
        if self.weights is not None:
            loss = self.weights * (target * torch.log(output) + (1 - target) * torch.log(1 - output))
        else:
            loss = target * torch.log(output) + (1 - target) * torch.log(1 - output)

        return torch.neg(torch.mean(loss))

class LRN(nn.Module):       # input x is Torch tensor
    def __init__(self, local_size=1, alpha=1.0, beta=0.75, ACROSS_CHANNELS=False):      #LRN(local_size=5, alpha=0.0001, beta=0.75),
        super(LRN, self).__init__()
        self.ACROSS_CHANNELS = ACROSS_CHANNELS
        if self.ACROSS_CHANNELS:
            self.average = nn.AvgPool3d(kernel_size=(local_size, 1, 1),
                                        stride=1, padding=(int((local_size - 1.0) / 2), 0, 0))
        else:
            self.average = nn.AvgPool2d(kernel_size=local_size,
                                        stride=1, padding=int((local_size - 1.0) / 2))
        self.alpha = alpha
        self.beta = beta

    def forward(self, x):
        if self.ACROSS_CHANNELS:
            div = x.pow(2).unsqueeze(1)
            div = self.average(div).squeeze(1)
            div = div.mul(self.alpha).add(1.0).pow(self.beta)
        else:
            div = x.pow(2)
            div = self.average(div)
            div = div.mul(self.alpha).add(1.0).pow(self.beta)
        x = x.div(div)
        return x


Sun Nov 19 22:11:55 2017
Leg17_RMSprop_dropout_0_2_rmSigmoid_40aug_10ela_3inten_reflect
RMSprop(net.parameters(), lr=1e-3, weight_decay=1e-3)
Number of epoch max: 8
Epoch 1: Train loss: 7.425154, Val loss: 5.931555
Unet2_model_1epoch_Leg17_RMSprop_dropout_0_2_rmSigmoid_40aug_10ela_3inten_reflect
Precision: 0.90048 
Recall: 1.00000 
F1_measure: 0.94763 
iou: 0.80096
==========================================================================================
Sun Nov 19 22:45:17 2017
Leg18_ResNet_more_dropout_0_2_rmSigmoid_40aug_10ela_3inten_reflect
Sun Nov 19 22:45:15 2017
import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.autograd import Variable
import math


class ConvBnRelu(nn.Module):
    def __init__(self, in_channels, out_channels, kernel_size, padding, stride):
        super(ConvBnRelu, self).__init__()
        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=kernel_size, padding=padding, stride=stride)
        self.bn = nn.BatchNorm2d(out_channels)
        self.relu = nn.ReLU()

    def forward(self, x):
        x = self.conv(x)
        # x = self.bn(x)
        x = self.relu(x)
        return x

class StackEncoder(nn.Module):
    def __init__(self, in_channels, out_channels):
        super(StackEncoder, self).__init__()
        self.convr1 = ConvBnRelu(in_channels, out_channels, kernel_size=(3, 3), stride=1, padding=0)
        self.convr2 = ConvBnRelu(out_channels, out_channels, kernel_size=(3, 3), stride=1, padding=0)
        self.maxPool = nn.MaxPool2d(kernel_size=(2, 2), stride=2)

    def forward(self, x):
        x = self.convr1(x)
        x = self.convr2(x)
        x_trace = x             # save x to use in concat in the Decoder path
        x = self.maxPool(x)
        return x, x_trace


class StackDecoder(nn.Module):
    def __init__(self, in_channels, out_channels, padding, drop_out = False):
        super(StackDecoder, self).__init__()

        self.upSample = nn.ConvTranspose2d(in_channels, out_channels, 2, stride=2)      # 1024 --> 512 for example
        self.convr1 = ConvBnRelu(in_channels, in_channels, kernel_size=(1,1), stride=1, padding=0)     # conv1x1
        self.convr2 = ConvBnRelu(in_channels, in_channels, kernel_size=(3, 3), stride=1, padding=padding)  # conv1x1
        self.convr3 = nn.Conv2d(in_channels, in_channels, kernel_size=(1, 1), stride=1, padding=0)  # conv1x1  # no ReLU
        self.convr4 = ConvBnRelu(in_channels, out_channels, kernel_size=(1, 1), stride=1, padding=0)
        self.relu = nn.ReLU()
        self.drop_out = drop_out
        self.drop_layer = nn.Dropout2d(p=0.2)

    def _crop_concat(self, upsampled, bypass):
        """
         Crop y to the (h, w) of x and concat them.
         Used for the expansive path.
        Returns:
            The concatenated tensor
        """
        c = (bypass.size()[2] - upsampled.size()[2]) // 2
        bypass = F.pad(bypass, (-c, -c, -c, -c))

        return torch.cat((upsampled, bypass), 1)

    def forward(self, x, down_tensor):
        x = self.upSample(x)
        x_origin = self._crop_concat(x, down_tensor)

        x = self.convr1(x_origin)
        if self.drop_out: x = self.drop_layer(x)
        x = self.convr2(x)
        x = self.convr3(x)
        x += x_origin
        x = self.relu(x)
        x = self.convr4(x)
        if self.drop_out: x = self.drop_layer(x)
        return x


class UNet_ResNet(nn.Module):
    def __init__(self):
        super(UNet_ResNet, self).__init__()
        # channels, height, width = in_shape

        self.down1 = StackEncoder(1, 64)
        self.down2 = StackEncoder(64, 128)
        self.down3 = StackEncoder(128, 256)
        self.down4 = StackEncoder(256, 512)

        self.center = nn.Sequential(
            # nn.Dropout2d(p=0.2),
            ConvBnRelu(512, 1024, kernel_size=(3, 3), stride=1, padding=0),
            nn.Dropout2d(p=0.2),
            ConvBnRelu(1024, 1024, kernel_size=(3, 3), stride=1, padding=0),
            nn.Dropout2d(p=0.2)
        )

        self.up1 = StackDecoder(in_channels=1024, out_channels=512, padding = 1, drop_out=True)
        self.up2 = StackDecoder(in_channels=512, out_channels=256, padding = 1, drop_out=True)
        self.up3 = StackDecoder(in_channels=256, out_channels=128, padding = 1)
        self.up4 = StackDecoder(in_channels=128, out_channels=64, padding = 1)

        # 1x1 convolution at the last layer
        # Different from the paper is the output size here
        self.output_seg_map = nn.Conv2d(64, 1, kernel_size=(1, 1), padding=0, stride=1)

        self._initialize_weights()

    def forward(self, x):
        x, x_trace1 = self.down1(x)  # Calls the forward() method of each layer
        x, x_trace2 = self.down2(x)
        x, x_trace3 = self.down3(x)
        x, x_trace4 = self.down4(x)

        # if self.dropout > 0: x = F.dropout(x, p=self.dropout, training=self.training)
        x = self.center(x)
        # if self.dropout > 0: x = F.dropout(x, p=self.dropout, training=self.training)

        x = self.up1(x, x_trace4)
        x = self.up2(x, x_trace3)
        x = self.up3(x, x_trace2)
        x = self.up4(x, x_trace1)

        x = self.output_seg_map(x)

        # out = F.sigmoid(out)
        # out = torch.squeeze(out, dim=1)
        return x


    def _initialize_weights(self):
        for m in self.modules():
            if isinstance(m, nn.Conv2d):
                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels
                m.weight.data.normal_(0, math.sqrt(2. / n))
                if m.bias is not None:
                    m.bias.data.zero_()
            elif isinstance(m, nn.BatchNorm2d):
                m.weight.data.fill_(1)
                m.bias.data.zero_()

# x = Variable(torch.randn(1,1,636,636))       # simulate input image
# net = UNet_ResNet()
# out = net(x)
# print("input: ", x)
# print("output: ", out)

===============from __future__ import print_function, division
import torch
from torch import optim
from torch.autograd import Variable
from torch.utils.data import DataLoader
import numpy as np
import torch.nn as nn
import torch.nn.functional as F
import Unet
import Unet_BatchNorm
import tifffile as tiff
import Utils
import time
from sklearn.metrics import average_precision_score, recall_score, f1_score
import Analysis
import Unet_ResNet

def to_var(x):
    if torch.cuda.is_available():
        return Variable(x.cuda())
    else:
        return Variable(x)

### BinaryCrossEntropyLoss2d().forward(logits, labels)
class BinaryCrossEntropyLoss2d(nn.Module):
    def __init__(self, weight=None, size_average=True):
        """
        Binary cross entropy loss 2D
        Args:
            weight:
            size_average:
        """
        super(BinaryCrossEntropyLoss2d, self).__init__()
        self.bce_loss = nn.BCELoss(weight, size_average)

    def forward(self, probs, targets):
        probs = F.sigmoid(probs)
        probs_flat = probs.view(-1)  # Flatten
        targets_flat = targets.view(-1)  # Flatten
        return self.bce_loss(probs_flat, targets_flat)      # (output, labels)

class SoftDiceLoss(nn.Module):
    def __init__(self, weight=None, size_average=True):
        super(SoftDiceLoss, self).__init__()

    def forward(self, probs, targets):
        smooth = 1
        # num = targets.size(0)
        probs = F.sigmoid(probs)
        m1 = probs.view(-1)
        m2 = targets.view(-1)
        intersection = (m1 * m2)
        score = 2. * (intersection.sum() + smooth) / (m1.sum() + m2.sum() + smooth)
        score = 1 - score.sum()
        return score

def _criterion(logits, labels):
    return BinaryCrossEntropyLoss2d().forward(logits, labels) + \
        SoftDiceLoss().forward(logits, labels)

def NetEval(net,valdata_loader,crit):
    loss = 0.
    count = 0
    net.eval()
    for i,data in enumerate(valdata_loader,0):
        inputs, labels = data
        inputs, labels = to_var(inputs), to_var(labels)
        out = net(inputs)
        l = crit(out, labels)
        loss += l.data[0]
        count += 1
    return loss/count

# calculate Precision, Recall, F1-measure, IoU over the validation set
def Net_performace_val(net,valdata_loader):
    precision_list = []
    recall_list = []
    iou_list = []
    net.eval()
    print("len of valdata: ", len(valdata_loader))
    for i,data in enumerate(valdata_loader,0):

        inputs, labels = data
        out = NetPredict(net, inputs)   # out is numpy array 512x512
        labels = labels.numpy()
        labels = labels[0,0,:,:]        # labels is numpy array 512x512
        # remove the case where the mask is plain black
        if np.sum(labels) < 0.01*np.shape(labels)[0]*np.shape(labels)[1]: continue

        precision = average_precision_score(labels, out)
        recall = recall_score(labels, out, average='weighted')
        iou = IoU(out, labels)
        precision_list.append(precision)
        recall_list.append(recall)
        iou_list.append(iou)

    precision, recall, iou = np.mean(precision_list), np.mean(recall_list), np.mean(iou_list)
    F1_measure = 2.0*precision*recall/(precision + recall)

    return precision, recall, F1_measure, iou

# calculate IoU
def IoU(pred, target):
    # Ignore IoU for background class
    cls = 0.5
    pred_inds = pred > cls
    target_inds = target > cls

    intersection = (pred_inds[target_inds]).sum()  # Cast to long to prevent overflows
    union = pred_inds.sum() + target_inds.sum() - intersection
    if union == 0:
        ious = float('nan')  # If there is no ground truth, do not include in evaluation
    else:
        ious = 1.0*intersection / max(union, 1)
    return ious

#process the test data and save to separate .tif image
def NetTest(net,testdata_loader,path = "data/results/"):
    net.eval()
    for i, data in enumerate(testdata_loader, 0):
        if i >= 30: return 1        # for debug
        data = to_var(data)
        out = net(data)

        out = F.sigmoid(out)

        imgname = path + str(i) + ".tif"
        img = out.cpu()
        img = img[0,0,:,:]
        img = img.data.numpy()
        img_shape = img.shape
        img = img.reshape(-1)
        img[img < 0.5] = 0; img[img >= 0.5] = 1
        img = img.reshape(img_shape)
        img = np.uint8(img * 255)
        tiff.imsave(imgname, img)

# return input image size like 512x512, numpy array
def NetPredict(net, data):
    net.eval()
    data = to_var(data)
    out = net(data)

    out = F.sigmoid(out)

    img = out.cpu()
    img = img[0, 0, :, :]
    img = img.data.numpy()
    img_shape = img.shape
    img = img.reshape(-1)
    img[img < 0.5] = 0;
    img[img >= 0.5] = 1
    img = img.reshape(img_shape)
    return img
def write_2_log(content):
    path = "log_file.txt"
    output = open(path, "a")
    output.write("\n")
    output.write(content)
    output.close()

if __name__ == '__main__':
    '''subjects to change for each exp:
    + path to the dataset
    + opt function
    + leg description
    + N_epoch
    + saved_model
    '''
    start_begining = time.time()

    # path = "data/dataset"
    path = "/home/anhxtuan/HanLe/dataset/40aug_10ela_3inten_reflect"

    import os
    print("Does the folder exist?: ", os.path.isdir(path))
    print("Does the path exist?: ", os.path.exists(path))

    # imgs_train, imgs_mask_train = Utils.load_train_data(npy_path=path)
    # trainset = zip(imgs_train, imgs_mask_train)
    # trainloader = torch.utils.data.DataLoader(trainset, batch_size=1,
    #                                           shuffle=True, num_workers=2)

    imgs_val, imgs_mask_val = Utils.load_val_data(npy_path=path)
    valset = zip(imgs_val, imgs_mask_val)
    valloader = torch.utils.data.DataLoader(valset, batch_size=1,
                                              shuffle=False, num_workers=2)
    # net = Unet.UNet()                     # Unet 1
    # net = Unet_BatchNorm.UNet_BN()          # Unet 2 with batchNorm
    net = Unet_ResNet.UNet_ResNet()

    # f1 = open("Unet_BatchNorm.py", 'r')     # embede code into the model to be saved later
    f1 = open("Unet_ResNet.py", 'r')
    f2 = open("UnetTrain.py", 'r')
    f3 = open("Utils.py", 'r')
    model_notes = time.strftime("%c") + "\n" + f1.read() + "\n" + "==="*5 + f2.read() + "\n" + "==="*5 + f3.read()
    f1.close()
    f2.close()
    f3.close()

    # criterion = nn.BCELoss()
    criterion = BinaryCrossEntropyLoss2d()
    # criterion = SoftDiceLoss()

    if torch.cuda.is_available():
        # torch.set_default_tensor_type('torch.cuda.FloatTensor')
        # net.load_state_dict(torch.load("Unet2_model_6epoch_Leg14_dropout_0_2_rmSigmoid_40aug_10ela_3inten_reflect"))
        net.cuda()
        # criterion.cuda()

    opt = optim.SGD(net.parameters(), lr=1e-2, momentum=0.99)       # subject to change
    # opt = optim.RMSprop(net.parameters(), lr=1e-3, weight_decay=1e-3)
    # RMSprop[22](learning rate 0.001) with weight decay set to 0.001.
    # opt = optim.Adam(net.parameters(), lr=1e-3, weight_decay=1e-4)

    train_loss = []
    val_loss = []

    print("[epoch, #image] Loss")
    leg = "Leg18_ResNet_more_dropout_0_2_rmSigmoid_40aug_10ela_3inten_reflect"
    print("Processing: ", leg)
    model_name = ""

    N_epoch = 6
    model_saved = np.arange(2,N_epoch+1,2)
    val_loss_min = 100

    write_2_log("==="*30)
    write_2_log(time.strftime("%c"))       # time, date of exp
    write_2_log(leg)
    write_2_log(model_notes)
    write_2_log(time.strftime("%c"))  # time, date of exp
    write_2_log(leg)
    write_2_log("SGD(net.parameters(), lr=1e-2, momentum=0.99)")
    write_2_log("Number of epoch max: " + str(N_epoch))

    min_model_epoch = 0
    for epoch in range(N_epoch):
        running_loss = 0.0; count = 0
        net.train()

        N_files = 5
        for j in range(N_files):
            if N_files > 1:
                train_file = "/imgs_train_" + str(j + 1) + ".npy"
                mask_file = "/imgs_mask_train_" + str(j + 1) + ".npy"
            else:
                train_file = "/imgs_train.npy"
                mask_file = "/imgs_mask_train.npy"

            imgs_train, imgs_mask_train = Utils.load_train_data(npy_path=path, train_file=train_file, mask_file=mask_file)
            trainset = zip(imgs_train, imgs_mask_train)
            trainloader = torch.utils.data.DataLoader(trainset, batch_size=1,
                                                      shuffle=True, num_workers=2)
            for i, data in enumerate(trainloader, 0):
                inputs, labels = data
                temp = labels.numpy()
                temp = temp[0, 0, :, :]  # labels is numpy array 512x512
                # remove the case where the mask is plain black
                if np.sum(temp) < 0.01 * np.shape(temp)[0] * np.shape(temp)[1]: continue
                inputs, labels = to_var(inputs), to_var(labels)
                opt.zero_grad()
                out = net(inputs)
                loss = criterion(out, labels)
                loss.backward()
                opt.step()
                running_loss += loss.data[0]
                count += 1

        net.eval()
        val_loss_temp = NetEval(net, valloader, criterion)
        if epoch > 0 and val_loss_temp < val_loss_min:        # save the model which has the lowest val_loss, ignore first epoch
            val_loss_min = val_loss_temp
            torch.save(net.state_dict(), "ResNet_" + leg + "_min_val_loss")  # save model
            min_model_epoch = epoch + 1

        disp = 'Epoch %d: Train loss: %.6f, Val loss: %.6f' % (epoch + 1, running_loss/count, val_loss_temp)
        write_2_log(disp)
        print(disp)
        val_loss.append(val_loss_temp)
        train_loss.append(running_loss/count); running_loss = 0.0

        if (epoch + 1) in model_saved:        # save checkpoint
            model_name = "ResNet_" + str(epoch+1) + "epoch_" + leg
            torch.save(net.state_dict(), model_name)  # save model
            Analysis.analysis(model_file = model_name, valloader = valloader)

    write_2_log("Best model at epoch: " + str(min_model_epoch))
    write_2_log("Total training time: " + str((time.time() - start_begining) / 3600.0))

    val_loss_file = "data/results" + "/val_loss_" + str(N_epoch) + "epoch_" + leg + ".npy"
    train_loss_file = "data/results" + "/training_loss_" + str(N_epoch) + "epoch_" + leg + ".npy"

    np.save(val_loss_file, val_loss)
    np.save(train_loss_file, train_loss)
    print("total processing time in seconds: ", time.time() - start_begining)
    print("total processing time in mins: ", (time.time() - start_begining) / 60.0)
    print("total processing time in hours: ", (time.time() - start_begining) / 3600.0)

    # Analysis.analysis(model_file="ResNet_" + leg + "_min_val_loss", valloader=valloader)

    Analysis.PlotLoss(model_file = model_name, loss_train_path = train_loss_file, loss_val_path = val_loss_file, epoch_No = N_epoch)

    write_2_log(time.strftime("%c"))  # time, date of exp
===============import numpy as np
import torch.nn as nn
import torch
import cv2
from lcn import LecunLCN

LCN_enable = False

def input_filled_mirroring(x):      # fill missing data by mirroring the input image
    '''input size 636 --> output size 512'''
    w, h = x.shape
    e = 62  # extra width on 1 edge
    y = np.zeros((h + e * 2, w + e * 2))
    y[e:h + e, e:w + e] = x
    y[e:e + h, 0:e] = np.flip(y[e:e + h, e:2 * e], 1)  # flip vertically
    y[e:e + h, e + w:2 * e + w] = np.flip(y[e:e + h, w:e + w], 1)  # flip vertically
    y[0:e, 0:2 * e + w] = np.flip(y[e:2 * e, 0:2 * e + w], 0)  # flip horizontally
    y[e + h:2 * e + h, 0:2 * e + w] = np.flip(y[h:e + h, 0:2 * e + w], 0)  # flip horizontally
    return y

def nearest_cells_distance(pos, img):
    # searching in 8 directions to find 2 nearest distances to neighbor cells
    curr_value = img[pos]
    w = img.shape[0];h = img.shape[1]
    count_detect = 0  # detect 2 nearest neighbors. break the search if count_detect = 2
    x, y = pos

    # print("w,h: ", (w, h))
    d1 = 9999999;d2 = 9999999;d3 = 9999999;d4 = 9999999
    d5 = 9999999;d6 = 9999999;d7 = 9999999;d8 = 9999999
    for i in range(1, max(w, h)):
        # (x+1, y), (x+1, y+1), (x+1, y-1),
        # (x, y+1), (x, y-1)
        # (x-1, y), (x-1,y+1), (x-1,y-1),
        if x + i < w:
            if img[(x + i, y)] != curr_value and d1 == 9999999:
                d1 = i; count_detect += 1
            if y + i < h:
                if img[(x + i, y + i)] != curr_value and d2 == 9999999:
                    d2 = i; count_detect += 1
            elif y - i >= 0:
                if img[(x + i, y - i)] != curr_value and d3 == 9999999:
                    d3 = i; count_detect += 1
        if y + i < h:
            if img[(x, y + i)] != curr_value and d4 == 9999999:
                d4 = i; count_detect += 1
        if y - i >= 0:
            if img[(x, y - i)] != curr_value and d5 == 9999999:
                d5 = i; count_detect += 1
        if x - i >= 0:
            if img[(x - i, y)] != curr_value and d6 == 9999999:
                d6 = i; count_detect += 1
            if y + i < h:
                if img[(x - i, y + i)] != curr_value and d7 == 9999999:
                    d7 = i; count_detect += 1
            elif y - i >= 0:
                if img[(x - i, y - i)] != curr_value and d8 == 9999999:
                    d8 = i; count_detect += 1
        if count_detect >= 2: break

    d = [d1, d2, d3, d4, d5, d6, d7, d8]
    min_index = np.argmin(d)
    dist1 = d[min_index]
    d.remove(dist1)
    min_index = np.argmin(d)
    dist2 = d[min_index]
    return dist1, dist2

def create_weight_map(imgs_mask):
        print('-' * 30)
        print('Creating weights for masks ...')
        print('-' * 30)
        weight_map = np.ndarray(
            (len(imgs_mask), 1, np.shape(imgs_mask)[2], np.shape(imgs_mask)[3]), dtype=np.float32)
        w_0 = 10; sigma = 4
        imgs_w, imgs_h = np.shape(imgs_mask)[2], np.shape(imgs_mask)[3]
        total_pixels = imgs_w*imgs_h
        import time
        start = time.time()
        for i in range(len(imgs_mask)):
            if i%10 == 0: print("Done processing: %d images, time passed: %.2f mins" % (i, (time.time() - start)/60.0))
            temp = imgs_mask[i,0,:,:]
            w_border = 1 - np.sum(temp)/total_pixels        # w_c of pixel on the border (black)
            for m in range(imgs_w):
                for n in range(imgs_h):
                    # loop through all pixel of the mask
                    d1,d2 = nearest_cells_distance((m,n), temp)
                    w_c = w_border
                    if temp[m,n] == 0: w_c = 1 - w_border
                    weight_map[i,0,m,n] = w_c*5 + w_0*np.exp(-(d1 + d2)**2/(2*sigma**2))
                    # print("w_0*np.exp(): ", w_0*np.exp(-(d1 + d2)**2/(2*sigma**2)))
                    # print("w_border: ", w_border)

        np.save('data/dataset/weight_map_train.npy', weight_map)

        return weight_map

def load_train_data(npy_path = "data/dataset", train_file = "/imgs_train.npy", mask_file = "/imgs_mask_train.npy", hist_equal = False):

    print('-' * 30)
    print('load train images...')

    imgs_train = np.load(npy_path + train_file)
    imgs_mask_train = np.load(npy_path + mask_file)

    if hist_equal: imgs_train = hist_equalization(imgs_train)

    # weight_map_train = np.load(npy_path + "/weight_map_train.npy")
    # weight_map_train = weight_map_train.astype('float32')

    imgs_train = imgs_train.astype('float32')
    imgs_mask_train = imgs_mask_train.astype('float32')

    if LCN_enable:
        imgs_train = imgs_train.astype('float64')
        imgs_train = LecunLCN(imgs_train, image_shape=imgs_train.shape).output.eval()
        imgs_train = imgs_train.astype('float32')

    if not LCN_enable: imgs_train /= 255

    imgs_train -= imgs_train.mean(axis=0)
    imgs_mask_train /= 255
    imgs_mask_train[imgs_mask_train > 0.5] = 1
    imgs_mask_train[imgs_mask_train <= 0.5] = 0

    # weight_map_train = create_weight_map(imgs_mask_train)

    print("Done loading traing data")
    print('-' * 30)
    return imgs_train, imgs_mask_train

def load_val_data(npy_path = "data/dataset", hist_equal = True):

    print('-' * 30)
    print('load validation images...')

    imgs_train = np.load(npy_path + "/imgs_val.npy")
    imgs_mask_train = np.load(npy_path + "/imgs_mask_val.npy")

    if hist_equal: imgs_train = hist_equalization(imgs_train)

    imgs_train = imgs_train.astype('float32')
    imgs_mask_train = imgs_mask_train.astype('float32')

    if LCN_enable:
        imgs_train = imgs_train.astype('float64')
        imgs_train = LecunLCN(imgs_train, image_shape=imgs_train.shape).output.eval()
        imgs_train = imgs_train.astype('float32')

    if not LCN_enable: imgs_train /= 255
    imgs_train -= imgs_train.mean(axis=0)
    imgs_mask_train /= 255
    imgs_mask_train[imgs_mask_train > 0.5] = 1
    imgs_mask_train[imgs_mask_train <= 0.5] = 0
    print("Done loading validation data")
    print('-' * 30)
    return imgs_train, imgs_mask_train

def load_test_data(npy_path = "data/dataset", hist_equal = True):

    print('-' * 30)
    print('load test images...')

    imgs_test = np.load(npy_path + "/imgs_test.npy")

    if hist_equal: imgs_test = hist_equalization(imgs_test)

    imgs_test = imgs_test.astype('float32')

    if LCN_enable:
        imgs_test = imgs_test.astype('float64')
        imgs_test = LecunLCN(imgs_test, image_shape=imgs_test.shape).output.eval()
        imgs_test = imgs_test.astype('float32')

    if not LCN_enable: imgs_test /= 255

    imgs_test -= imgs_test.mean(axis=0)

    print("Done loading test data")
    print('-' * 30)
    return imgs_test

def load_val_5imgs(npy_path = "data/dataset"):
    print('-' * 30)
    print('load train images...')

    imgs_train = np.load(npy_path + "/imgs_val_5imgs.npy")
    imgs_mask_train = np.load(npy_path + "/imgs_mask_val_5imgs.npy")

    # imgs_train = hist_equalization(imgs_train)

    imgs_train = imgs_train.astype('float64')
    imgs_mask_train = imgs_mask_train.astype('float64')

    if LCN_enable: imgs_train = LecunLCN(imgs_train, image_shape=imgs_train.shape).output.eval()

    if not LCN_enable: imgs_train /= 255

    mean = imgs_train.mean(axis=0)
    imgs_train -= mean


    imgs_mask_train /= 255
    imgs_mask_train[imgs_mask_train > 0.5] = 1
    imgs_mask_train[imgs_mask_train <= 0.5] = 0

    # weight_map_train = self.create_weight_map(imgs_mask_train)

    print("Done loading traing data")
    print('-' * 30)
    return imgs_train, imgs_mask_train

def hist_equalization(inputs):      # inputs are uint8, 0-255, Nx1x636x636
    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))
    output = inputs.copy()
    for i in range(len(inputs)):
        img = inputs[i, 0, :, :]
        # res = cv2.equalizeHist(img)
        res = clahe.apply(img)
        output[i,0,:,:] = res
    return output

### BinaryCrossEntropyLoss2d().forward(logits, labels)
class BinaryCrossEntropyLoss2d(nn.Module):
    def __init__(self, weight=None, size_average=True):
        """
        Binary cross entropy loss 2D
        Args:
            weight:
            size_average:
        """
        super(BinaryCrossEntropyLoss2d, self).__init__()
        self.bce_loss = nn.BCELoss(weight, size_average)

    def forward(self, logits, targets):
        # probs = F.sigmoid(logits)
        probs = logits
        probs_flat = probs.view(-1)  # Flatten
        targets_flat = targets.view(-1)  # Flatten
        return self.bce_loss(probs_flat, targets_flat)      # (output, labels)

class BCE_with_Weights(nn.Module):
    def __init__(self, weights=None):
        """
        Binary cross entropy loss 2D
        Args:
            weights:
        """
        super(BCE_with_Weights, self).__init__()
        self.weights = weights

    def forward(self, output, target):
        if self.weights is not None:
            loss = self.weights * (target * torch.log(output) + (1 - target) * torch.log(1 - output))
        else:
            loss = target * torch.log(output) + (1 - target) * torch.log(1 - output)

        return torch.neg(torch.mean(loss))

class LRN(nn.Module):       # input x is Torch tensor
    def __init__(self, local_size=1, alpha=1.0, beta=0.75, ACROSS_CHANNELS=False):      #LRN(local_size=5, alpha=0.0001, beta=0.75),
        super(LRN, self).__init__()
        self.ACROSS_CHANNELS = ACROSS_CHANNELS
        if self.ACROSS_CHANNELS:
            self.average = nn.AvgPool3d(kernel_size=(local_size, 1, 1),
                                        stride=1, padding=(int((local_size - 1.0) / 2), 0, 0))
        else:
            self.average = nn.AvgPool2d(kernel_size=local_size,
                                        stride=1, padding=int((local_size - 1.0) / 2))
        self.alpha = alpha
        self.beta = beta

    def forward(self, x):
        if self.ACROSS_CHANNELS:
            div = x.pow(2).unsqueeze(1)
            div = self.average(div).squeeze(1)
            div = div.mul(self.alpha).add(1.0).pow(self.beta)
        else:
            div = x.pow(2)
            div = self.average(div)
            div = div.mul(self.alpha).add(1.0).pow(self.beta)
        x = x.div(div)
        return x


Sun Nov 19 22:45:17 2017
Leg18_ResNet_more_dropout_0_2_rmSigmoid_40aug_10ela_3inten_reflect
SGD(net.parameters(), lr=1e-2, momentum=0.99)
Number of epoch max: 6
Epoch 1: Train loss: 0.181587, Val loss: 0.372388
Epoch 2: Train loss: 0.135606, Val loss: 0.400348
ResNet_2epoch_Leg18_ResNet_more_dropout_0_2_rmSigmoid_40aug_10ela_3inten_reflect
Precision: 0.97192 
Recall: 0.92117 
F1_measure: 0.94587 
iou: 0.88854
Epoch 3: Train loss: 0.113840, Val loss: 0.318680
Epoch 4: Train loss: 0.100825, Val loss: 0.339867
ResNet_4epoch_Leg18_ResNet_more_dropout_0_2_rmSigmoid_40aug_10ela_3inten_reflect
Precision: 0.97302 
Recall: 0.90901 
F1_measure: 0.93993 
iou: 0.88110
Epoch 5: Train loss: 0.092592, Val loss: 0.342712
Epoch 6: Train loss: 0.086322, Val loss: 0.345297
ResNet_6epoch_Leg18_ResNet_more_dropout_0_2_rmSigmoid_40aug_10ela_3inten_reflect
Precision: 0.97250 
Recall: 0.91254 
F1_measure: 0.94157 
iou: 0.88272
Best model at epoch: 3
Total training time: 7.18157683611
Mon Nov 20 05:55:56 2017
==========================================================================================
Mon Nov 20 05:57:09 2017
Leg19_Unet_add_20elas_dropout_0_2_rmSigmoid_40aug_10ela_3inten_reflect
Mon Nov 20 05:57:06 2017
import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.autograd import Variable
import math


class ConvBnRelu(nn.Module):
    def __init__(self, in_channels, out_channels, kernel_size, padding, stride):
        super(ConvBnRelu, self).__init__()
        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=kernel_size, padding=padding, stride=stride)
        self.bn = nn.BatchNorm2d(out_channels)
        self.relu = nn.ReLU()

    def forward(self, x):
        x = self.conv(x)
        # x = self.bn(x)
        x = self.relu(x)
        return x


class StackEncoder(nn.Module):
    def __init__(self, in_channels, out_channels):
        super(StackEncoder, self).__init__()
        self.convr1 = ConvBnRelu(in_channels, out_channels, kernel_size=(3, 3), stride=1, padding=0)
        self.convr2 = ConvBnRelu(out_channels, out_channels, kernel_size=(3, 3), stride=1, padding=0)
        self.maxPool = nn.MaxPool2d(kernel_size=(2, 2), stride=2)

    def forward(self, x):
        x = self.convr1(x)
        x = self.convr2(x)
        x_trace = x             # save x to use in concat in the Decoder path
        out = self.maxPool(x)
        return out, x_trace


class StackDecoder(nn.Module):
    def __init__(self, in_channels, out_channels, upsample_size, padding, drop_out=False):
        super(StackDecoder, self).__init__()

        self.drop_out = drop_out
        self.dropout_layer = nn.Dropout2d(p=0.5)

        ''' this is old version
        self.upSample = nn.Upsample(size=upsample_size, scale_factor=(2, 2), mode="bilinear")
        self.convr1 = ConvBnRelu(in_channels, out_channels, kernel_size=(3, 3), stride=1, padding=padding)
        # Crop + concat step between these 2
        self.convr2 = ConvBnRelu(in_channels, out_channels, kernel_size=(3, 3), stride=1, padding=padding)
        '''
        self.upSample = nn.ConvTranspose2d(in_channels, out_channels, 2, stride=2)
        self.convr1 = ConvBnRelu(in_channels, out_channels, kernel_size=(3, 3), stride=1, padding=padding)
        self.convr2 = ConvBnRelu(out_channels, out_channels, kernel_size=(3, 3), stride=1, padding=padding)

    def _crop_concat(self, upsampled, bypass):
        """
         Crop y to the (h, w) of x and concat them.
         Used for the expansive path.
        Returns:
            The concatenated tensor
        """
        c = (bypass.size()[2] - upsampled.size()[2]) // 2
        bypass = F.pad(bypass, (-c, -c, -c, -c))

        return torch.cat((bypass, upsampled), 1)

    def forward(self, x, down_tensor):
        '''old version
        x = self.upSample(x)
        x = self.convr1(x)
        x = self._crop_concat(x, down_tensor)
        x = self.convr2(x)
        '''

        x = self.upSample(x)
        x = self._crop_concat(x, down_tensor)
        x = self.convr1(x)
        if self.drop_out: x = self.dropout_layer(x)
        x = self.convr2(x)
        if self.drop_out: x = self.dropout_layer(x)
        return x


class UNet_BN(nn.Module):
    def __init__(self):
        super(UNet_BN, self).__init__()
        # channels, height, width = in_shape

        # self.dropout = dropout

        self.model_code = ""        # variable to save model and main function when loaded

        self.down1 = StackEncoder(1, 64)
        self.down2 = StackEncoder(64, 128)
        self.down3 = StackEncoder(128, 256)
        self.down4 = StackEncoder(256, 512)

        self.center = nn.Sequential(
            # nn.Dropout2d(p=0.2),
            ConvBnRelu(512, 1024, kernel_size=(3, 3), stride=1, padding=0),
            nn.Dropout2d(p=0.2),
            ConvBnRelu(1024, 1024, kernel_size=(3, 3), stride=1, padding=0),
            nn.Dropout2d(p=0.2)
        )

        self.up1 = StackDecoder(in_channels=1024, out_channels=512, upsample_size=(64,64), padding = 1)
        self.up2 = StackDecoder(in_channels=512, out_channels=256, upsample_size=(128,128), padding = 1)
        self.up3 = StackDecoder(in_channels=256, out_channels=128, upsample_size=(256,256), padding = 1)
        self.up4 = StackDecoder(in_channels=128, out_channels=64, upsample_size=(512,512), padding = 1)

        # 1x1 convolution at the last layer
        # Different from the paper is the output size here
        self.output_seg_map = nn.Conv2d(64, 1, kernel_size=(1, 1), padding=0, stride=1)

        self._initialize_weights()

    def forward(self, x):
        x, x_trace1 = self.down1(x)
        x, x_trace2 = self.down2(x)
        x, x_trace3 = self.down3(x)
        x, x_trace4 = self.down4(x)
        x = self.center(x)
        x = self.up1(x, x_trace4)
        x = self.up2(x, x_trace3)
        x = self.up3(x, x_trace2)
        x = self.up4(x, x_trace1)

        x = self.output_seg_map(x)
        # x = F.sigmoid(x)
        # out = torch.squeeze(out, dim=1)
        return x


    def _initialize_weights(self):
        for m in self.modules():
            if isinstance(m, nn.Conv2d):
                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels
                m.weight.data.normal_(0, math.sqrt(2. / n))
                if m.bias is not None:
                    m.bias.data.zero_()
            elif isinstance(m, nn.BatchNorm2d):
                m.weight.data.fill_(1)
                m.bias.data.zero_()

# x = Variable(torch.randn(1,1,636,636))       # simulate input image
# net = UNet_BN()
# out = net(x)
# print("input: ", x)
# print("output: ", out)

===============from __future__ import print_function, division
import torch
from torch import optim
from torch.autograd import Variable
from torch.utils.data import DataLoader
import numpy as np
import torch.nn as nn
import torch.nn.functional as F
import Unet
import Unet_BatchNorm
import tifffile as tiff
import Utils
import time
from sklearn.metrics import average_precision_score, recall_score, f1_score
import Analysis
import Unet_ResNet

def to_var(x):
    if torch.cuda.is_available():
        return Variable(x.cuda())
    else:
        return Variable(x)

### BinaryCrossEntropyLoss2d().forward(logits, labels)
class BinaryCrossEntropyLoss2d(nn.Module):
    def __init__(self, weight=None, size_average=True):
        """
        Binary cross entropy loss 2D
        Args:
            weight:
            size_average:
        """
        super(BinaryCrossEntropyLoss2d, self).__init__()
        self.bce_loss = nn.BCELoss(weight, size_average)

    def forward(self, probs, targets):
        probs = F.sigmoid(probs)
        probs_flat = probs.view(-1)  # Flatten
        targets_flat = targets.view(-1)  # Flatten
        return self.bce_loss(probs_flat, targets_flat)      # (output, labels)

class SoftDiceLoss(nn.Module):
    def __init__(self, weight=None, size_average=True):
        super(SoftDiceLoss, self).__init__()

    def forward(self, probs, targets):
        smooth = 1
        # num = targets.size(0)
        probs = F.sigmoid(probs)
        m1 = probs.view(-1)
        m2 = targets.view(-1)
        intersection = (m1 * m2)
        score = 2. * (intersection.sum() + smooth) / (m1.sum() + m2.sum() + smooth)
        score = 1 - score.sum()
        return score

def _criterion(logits, labels):
    return BinaryCrossEntropyLoss2d().forward(logits, labels) + \
        SoftDiceLoss().forward(logits, labels)

def NetEval(net,valdata_loader,crit):
    loss = 0.
    count = 0
    net.eval()
    for i,data in enumerate(valdata_loader,0):
        inputs, labels = data
        inputs, labels = to_var(inputs), to_var(labels)
        out = net(inputs)
        l = crit(out, labels)
        loss += l.data[0]
        count += 1
    return loss/count

# calculate Precision, Recall, F1-measure, IoU over the validation set
def Net_performace_val(net,valdata_loader):
    precision_list = []
    recall_list = []
    iou_list = []
    net.eval()
    print("len of valdata: ", len(valdata_loader))
    for i,data in enumerate(valdata_loader,0):

        inputs, labels = data
        out = NetPredict(net, inputs)   # out is numpy array 512x512
        labels = labels.numpy()
        labels = labels[0,0,:,:]        # labels is numpy array 512x512
        # remove the case where the mask is plain black
        if np.sum(labels) < 0.01*np.shape(labels)[0]*np.shape(labels)[1]: continue

        precision = average_precision_score(labels, out)
        recall = recall_score(labels, out, average='weighted')
        iou = IoU(out, labels)
        precision_list.append(precision)
        recall_list.append(recall)
        iou_list.append(iou)

    precision, recall, iou = np.mean(precision_list), np.mean(recall_list), np.mean(iou_list)
    F1_measure = 2.0*precision*recall/(precision + recall)

    return precision, recall, F1_measure, iou

# calculate IoU
def IoU(pred, target):
    # Ignore IoU for background class
    cls = 0.5
    pred_inds = pred > cls
    target_inds = target > cls

    intersection = (pred_inds[target_inds]).sum()  # Cast to long to prevent overflows
    union = pred_inds.sum() + target_inds.sum() - intersection
    if union == 0:
        ious = float('nan')  # If there is no ground truth, do not include in evaluation
    else:
        ious = 1.0*intersection / max(union, 1)
    return ious

#process the test data and save to separate .tif image
def NetTest(net,testdata_loader,path = "data/results/"):
    net.eval()
    for i, data in enumerate(testdata_loader, 0):
        if i >= 30: return 1        # for debug
        data = to_var(data)
        out = net(data)

        out = F.sigmoid(out)

        imgname = path + str(i) + ".tif"
        img = out.cpu()
        img = img[0,0,:,:]
        img = img.data.numpy()
        img_shape = img.shape
        img = img.reshape(-1)
        img[img < 0.5] = 0; img[img >= 0.5] = 1
        img = img.reshape(img_shape)
        img = np.uint8(img * 255)
        tiff.imsave(imgname, img)

# return input image size like 512x512, numpy array
def NetPredict(net, data):
    net.eval()
    data = to_var(data)
    out = net(data)

    out = F.sigmoid(out)

    img = out.cpu()
    img = img[0, 0, :, :]
    img = img.data.numpy()
    img_shape = img.shape
    img = img.reshape(-1)
    img[img < 0.5] = 0;
    img[img >= 0.5] = 1
    img = img.reshape(img_shape)
    return img
def write_2_log(content):
    path = "log_file.txt"
    output = open(path, "a")
    output.write("\n")
    output.write(content)
    output.close()

if __name__ == '__main__':
    '''subjects to change for each exp:
    + path to the dataset
    + opt function
    + leg description
    + N_epoch
    + saved_model
    '''
    start_begining = time.time()

    # path = "data/dataset"
    path = "/home/anhxtuan/HanLe/dataset/20aug_10ela_3inten_reflect"

    import os
    print("Does the folder exist?: ", os.path.isdir(path))
    print("Does the path exist?: ", os.path.exists(path))

    # imgs_train, imgs_mask_train = Utils.load_train_data(npy_path=path)
    # trainset = zip(imgs_train, imgs_mask_train)
    # trainloader = torch.utils.data.DataLoader(trainset, batch_size=1,
    #                                           shuffle=True, num_workers=2)

    imgs_val, imgs_mask_val = Utils.load_val_data(npy_path=path)
    valset = zip(imgs_val, imgs_mask_val)
    valloader = torch.utils.data.DataLoader(valset, batch_size=1,
                                              shuffle=False, num_workers=2)
    # net = Unet.UNet()                     # Unet 1
    net = Unet_BatchNorm.UNet_BN()          # Unet 2 with batchNorm
    # net = Unet_ResNet.UNet_ResNet()

    f1 = open("Unet_BatchNorm.py", 'r')     # embede code into the model to be saved later
    # f1 = open("Unet_ResNet.py", 'r')
    f2 = open("UnetTrain.py", 'r')
    f3 = open("Utils.py", 'r')
    model_notes = time.strftime("%c") + "\n" + f1.read() + "\n" + "==="*5 + f2.read() + "\n" + "==="*5 + f3.read()
    f1.close()
    f2.close()
    f3.close()

    # criterion = nn.BCELoss()
    criterion = BinaryCrossEntropyLoss2d()
    # criterion = SoftDiceLoss()

    if torch.cuda.is_available():
        torch.set_default_tensor_type('torch.cuda.FloatTensor')
        net.load_state_dict(torch.load("Unet2_model_6epoch_Leg14_dropout_0_2_rmSigmoid_40aug_10ela_3inten_reflect"))
        net.cuda()
        # criterion.cuda()

    opt = optim.SGD(net.parameters(), lr=1e-2, momentum=0.99)       # subject to change
    # opt = optim.RMSprop(net.parameters(), lr=1e-3, weight_decay=1e-3)
    # RMSprop[22](learning rate 0.001) with weight decay set to 0.001.
    # opt = optim.Adam(net.parameters(), lr=1e-3, weight_decay=1e-4)

    train_loss = []
    val_loss = []

    print("[epoch, #image] Loss")
    leg = "Leg19_Unet_add_20elas_dropout_0_2_rmSigmoid_40aug_10ela_3inten_reflect"
    print("Processing: ", leg)
    model_name = ""

    N_epoch = 4
    model_saved = np.arange(2,N_epoch+1,2)
    val_loss_min = 100

    write_2_log("==="*30)
    write_2_log(time.strftime("%c"))       # time, date of exp
    write_2_log(leg)
    write_2_log(model_notes)
    write_2_log(time.strftime("%c"))  # time, date of exp
    write_2_log(leg)
    write_2_log("SGD(net.parameters(), lr=1e-2, momentum=0.99)")
    write_2_log("Number of epoch max: " + str(N_epoch))

    min_model_epoch = 0
    for epoch in range(N_epoch):
        running_loss = 0.0; count = 0
        net.train()

        N_files = 1
        for j in range(N_files):
            if N_files > 1:
                train_file = "/imgs_train_" + str(j + 1) + ".npy"
                mask_file = "/imgs_mask_train_" + str(j + 1) + ".npy"
            else:
                train_file = "/imgs_train.npy"
                mask_file = "/imgs_mask_train.npy"

            imgs_train, imgs_mask_train = Utils.load_train_data(npy_path=path, train_file=train_file, mask_file=mask_file)
            trainset = zip(imgs_train, imgs_mask_train)
            trainloader = torch.utils.data.DataLoader(trainset, batch_size=1,
                                                      shuffle=True, num_workers=2)
            for i, data in enumerate(trainloader, 0):
                inputs, labels = data
                temp = labels.numpy()
                temp = temp[0, 0, :, :]  # labels is numpy array 512x512
                # remove the case where the mask is plain black
                if np.sum(temp) < 0.01 * np.shape(temp)[0] * np.shape(temp)[1]: continue
                inputs, labels = to_var(inputs), to_var(labels)
                opt.zero_grad()
                out = net(inputs)
                loss = criterion(out, labels)
                loss.backward()
                opt.step()
                running_loss += loss.data[0]
                count += 1

        net.eval()
        val_loss_temp = NetEval(net, valloader, criterion)
        if epoch > 0 and val_loss_temp < val_loss_min:        # save the model which has the lowest val_loss, ignore first epoch
            val_loss_min = val_loss_temp
            torch.save(net.state_dict(), "Unet2_" + leg + "_min_val_loss")  # save model
            min_model_epoch = epoch + 1

        disp = 'Epoch %d: Train loss: %.6f, Val loss: %.6f' % (epoch + 1, running_loss/count, val_loss_temp)
        write_2_log(disp)
        print(disp)
        val_loss.append(val_loss_temp)
        train_loss.append(running_loss/count); running_loss = 0.0

        if (epoch + 1) in model_saved:        # save checkpoint
            model_name = "Unet2_" + str(epoch+1+6) + "epoch_" + leg
            torch.save(net.state_dict(), model_name)  # save model
            Analysis.analysis(model_file = model_name, valloader = valloader)

    write_2_log("Best model at epoch: " + str(min_model_epoch))
    write_2_log("Total training time: " + str((time.time() - start_begining) / 3600.0))

    val_loss_file = "data/results" + "/val_loss_" + str(N_epoch) + "epoch_" + leg + ".npy"
    train_loss_file = "data/results" + "/training_loss_" + str(N_epoch) + "epoch_" + leg + ".npy"

    np.save(val_loss_file, val_loss)
    np.save(train_loss_file, train_loss)
    print("total processing time in seconds: ", time.time() - start_begining)
    print("total processing time in mins: ", (time.time() - start_begining) / 60.0)
    print("total processing time in hours: ", (time.time() - start_begining) / 3600.0)

    # Analysis.analysis(model_file="ResNet_" + leg + "_min_val_loss", valloader=valloader)

    Analysis.PlotLoss(model_file = model_name, loss_train_path = train_loss_file, loss_val_path = val_loss_file, epoch_No = N_epoch)

    write_2_log(time.strftime("%c"))  # time, date of exp
===============import numpy as np
import torch.nn as nn
import torch
import cv2
from lcn import LecunLCN

LCN_enable = False

def input_filled_mirroring(x):      # fill missing data by mirroring the input image
    '''input size 636 --> output size 512'''
    w, h = x.shape
    e = 62  # extra width on 1 edge
    y = np.zeros((h + e * 2, w + e * 2))
    y[e:h + e, e:w + e] = x
    y[e:e + h, 0:e] = np.flip(y[e:e + h, e:2 * e], 1)  # flip vertically
    y[e:e + h, e + w:2 * e + w] = np.flip(y[e:e + h, w:e + w], 1)  # flip vertically
    y[0:e, 0:2 * e + w] = np.flip(y[e:2 * e, 0:2 * e + w], 0)  # flip horizontally
    y[e + h:2 * e + h, 0:2 * e + w] = np.flip(y[h:e + h, 0:2 * e + w], 0)  # flip horizontally
    return y

def nearest_cells_distance(pos, img):
    # searching in 8 directions to find 2 nearest distances to neighbor cells
    curr_value = img[pos]
    w = img.shape[0];h = img.shape[1]
    count_detect = 0  # detect 2 nearest neighbors. break the search if count_detect = 2
    x, y = pos

    # print("w,h: ", (w, h))
    d1 = 9999999;d2 = 9999999;d3 = 9999999;d4 = 9999999
    d5 = 9999999;d6 = 9999999;d7 = 9999999;d8 = 9999999
    for i in range(1, max(w, h)):
        # (x+1, y), (x+1, y+1), (x+1, y-1),
        # (x, y+1), (x, y-1)
        # (x-1, y), (x-1,y+1), (x-1,y-1),
        if x + i < w:
            if img[(x + i, y)] != curr_value and d1 == 9999999:
                d1 = i; count_detect += 1
            if y + i < h:
                if img[(x + i, y + i)] != curr_value and d2 == 9999999:
                    d2 = i; count_detect += 1
            elif y - i >= 0:
                if img[(x + i, y - i)] != curr_value and d3 == 9999999:
                    d3 = i; count_detect += 1
        if y + i < h:
            if img[(x, y + i)] != curr_value and d4 == 9999999:
                d4 = i; count_detect += 1
        if y - i >= 0:
            if img[(x, y - i)] != curr_value and d5 == 9999999:
                d5 = i; count_detect += 1
        if x - i >= 0:
            if img[(x - i, y)] != curr_value and d6 == 9999999:
                d6 = i; count_detect += 1
            if y + i < h:
                if img[(x - i, y + i)] != curr_value and d7 == 9999999:
                    d7 = i; count_detect += 1
            elif y - i >= 0:
                if img[(x - i, y - i)] != curr_value and d8 == 9999999:
                    d8 = i; count_detect += 1
        if count_detect >= 2: break

    d = [d1, d2, d3, d4, d5, d6, d7, d8]
    min_index = np.argmin(d)
    dist1 = d[min_index]
    d.remove(dist1)
    min_index = np.argmin(d)
    dist2 = d[min_index]
    return dist1, dist2

def create_weight_map(imgs_mask):
        print('-' * 30)
        print('Creating weights for masks ...')
        print('-' * 30)
        weight_map = np.ndarray(
            (len(imgs_mask), 1, np.shape(imgs_mask)[2], np.shape(imgs_mask)[3]), dtype=np.float32)
        w_0 = 10; sigma = 4
        imgs_w, imgs_h = np.shape(imgs_mask)[2], np.shape(imgs_mask)[3]
        total_pixels = imgs_w*imgs_h
        import time
        start = time.time()
        for i in range(len(imgs_mask)):
            if i%10 == 0: print("Done processing: %d images, time passed: %.2f mins" % (i, (time.time() - start)/60.0))
            temp = imgs_mask[i,0,:,:]
            w_border = 1 - np.sum(temp)/total_pixels        # w_c of pixel on the border (black)
            for m in range(imgs_w):
                for n in range(imgs_h):
                    # loop through all pixel of the mask
                    d1,d2 = nearest_cells_distance((m,n), temp)
                    w_c = w_border
                    if temp[m,n] == 0: w_c = 1 - w_border
                    weight_map[i,0,m,n] = w_c*5 + w_0*np.exp(-(d1 + d2)**2/(2*sigma**2))
                    # print("w_0*np.exp(): ", w_0*np.exp(-(d1 + d2)**2/(2*sigma**2)))
                    # print("w_border: ", w_border)

        np.save('data/dataset/weight_map_train.npy', weight_map)

        return weight_map

def load_train_data(npy_path = "data/dataset", train_file = "/imgs_train.npy", mask_file = "/imgs_mask_train.npy", hist_equal = False):

    print('-' * 30)
    print('load train images...')

    imgs_train = np.load(npy_path + train_file)
    imgs_mask_train = np.load(npy_path + mask_file)

    if hist_equal: imgs_train = hist_equalization(imgs_train)

    # weight_map_train = np.load(npy_path + "/weight_map_train.npy")
    # weight_map_train = weight_map_train.astype('float32')

    imgs_train = imgs_train.astype('float32')
    imgs_mask_train = imgs_mask_train.astype('float32')

    if LCN_enable:
        imgs_train = imgs_train.astype('float64')
        imgs_train = LecunLCN(imgs_train, image_shape=imgs_train.shape).output.eval()
        imgs_train = imgs_train.astype('float32')

    if not LCN_enable: imgs_train /= 255

    imgs_train -= imgs_train.mean(axis=0)
    imgs_mask_train /= 255
    imgs_mask_train[imgs_mask_train > 0.5] = 1
    imgs_mask_train[imgs_mask_train <= 0.5] = 0

    # weight_map_train = create_weight_map(imgs_mask_train)

    print("Done loading traing data")
    print('-' * 30)
    return imgs_train, imgs_mask_train

def load_val_data(npy_path = "data/dataset", hist_equal = True):

    print('-' * 30)
    print('load validation images...')

    imgs_train = np.load(npy_path + "/imgs_val.npy")
    imgs_mask_train = np.load(npy_path + "/imgs_mask_val.npy")

    if hist_equal: imgs_train = hist_equalization(imgs_train)

    imgs_train = imgs_train.astype('float32')
    imgs_mask_train = imgs_mask_train.astype('float32')

    if LCN_enable:
        imgs_train = imgs_train.astype('float64')
        imgs_train = LecunLCN(imgs_train, image_shape=imgs_train.shape).output.eval()
        imgs_train = imgs_train.astype('float32')

    if not LCN_enable: imgs_train /= 255
    imgs_train -= imgs_train.mean(axis=0)
    imgs_mask_train /= 255
    imgs_mask_train[imgs_mask_train > 0.5] = 1
    imgs_mask_train[imgs_mask_train <= 0.5] = 0
    print("Done loading validation data")
    print('-' * 30)
    return imgs_train, imgs_mask_train

def load_test_data(npy_path = "data/dataset", hist_equal = True):

    print('-' * 30)
    print('load test images...')

    imgs_test = np.load(npy_path + "/imgs_test.npy")

    if hist_equal: imgs_test = hist_equalization(imgs_test)

    imgs_test = imgs_test.astype('float32')

    if LCN_enable:
        imgs_test = imgs_test.astype('float64')
        imgs_test = LecunLCN(imgs_test, image_shape=imgs_test.shape).output.eval()
        imgs_test = imgs_test.astype('float32')

    if not LCN_enable: imgs_test /= 255

    imgs_test -= imgs_test.mean(axis=0)

    print("Done loading test data")
    print('-' * 30)
    return imgs_test

def load_val_5imgs(npy_path = "data/dataset"):
    print('-' * 30)
    print('load train images...')

    imgs_train = np.load(npy_path + "/imgs_val_5imgs.npy")
    imgs_mask_train = np.load(npy_path + "/imgs_mask_val_5imgs.npy")

    # imgs_train = hist_equalization(imgs_train)

    imgs_train = imgs_train.astype('float64')
    imgs_mask_train = imgs_mask_train.astype('float64')

    if LCN_enable: imgs_train = LecunLCN(imgs_train, image_shape=imgs_train.shape).output.eval()

    if not LCN_enable: imgs_train /= 255

    mean = imgs_train.mean(axis=0)
    imgs_train -= mean


    imgs_mask_train /= 255
    imgs_mask_train[imgs_mask_train > 0.5] = 1
    imgs_mask_train[imgs_mask_train <= 0.5] = 0

    # weight_map_train = self.create_weight_map(imgs_mask_train)

    print("Done loading traing data")
    print('-' * 30)
    return imgs_train, imgs_mask_train

def hist_equalization(inputs):      # inputs are uint8, 0-255, Nx1x636x636
    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))
    output = inputs.copy()
    for i in range(len(inputs)):
        img = inputs[i, 0, :, :]
        # res = cv2.equalizeHist(img)
        res = clahe.apply(img)
        output[i,0,:,:] = res
    return output

### BinaryCrossEntropyLoss2d().forward(logits, labels)
class BinaryCrossEntropyLoss2d(nn.Module):
    def __init__(self, weight=None, size_average=True):
        """
        Binary cross entropy loss 2D
        Args:
            weight:
            size_average:
        """
        super(BinaryCrossEntropyLoss2d, self).__init__()
        self.bce_loss = nn.BCELoss(weight, size_average)

    def forward(self, logits, targets):
        # probs = F.sigmoid(logits)
        probs = logits
        probs_flat = probs.view(-1)  # Flatten
        targets_flat = targets.view(-1)  # Flatten
        return self.bce_loss(probs_flat, targets_flat)      # (output, labels)

class BCE_with_Weights(nn.Module):
    def __init__(self, weights=None):
        """
        Binary cross entropy loss 2D
        Args:
            weights:
        """
        super(BCE_with_Weights, self).__init__()
        self.weights = weights

    def forward(self, output, target):
        if self.weights is not None:
            loss = self.weights * (target * torch.log(output) + (1 - target) * torch.log(1 - output))
        else:
            loss = target * torch.log(output) + (1 - target) * torch.log(1 - output)

        return torch.neg(torch.mean(loss))

class LRN(nn.Module):       # input x is Torch tensor
    def __init__(self, local_size=1, alpha=1.0, beta=0.75, ACROSS_CHANNELS=False):      #LRN(local_size=5, alpha=0.0001, beta=0.75),
        super(LRN, self).__init__()
        self.ACROSS_CHANNELS = ACROSS_CHANNELS
        if self.ACROSS_CHANNELS:
            self.average = nn.AvgPool3d(kernel_size=(local_size, 1, 1),
                                        stride=1, padding=(int((local_size - 1.0) / 2), 0, 0))
        else:
            self.average = nn.AvgPool2d(kernel_size=local_size,
                                        stride=1, padding=int((local_size - 1.0) / 2))
        self.alpha = alpha
        self.beta = beta

    def forward(self, x):
        if self.ACROSS_CHANNELS:
            div = x.pow(2).unsqueeze(1)
            div = self.average(div).squeeze(1)
            div = div.mul(self.alpha).add(1.0).pow(self.beta)
        else:
            div = x.pow(2)
            div = self.average(div)
            div = div.mul(self.alpha).add(1.0).pow(self.beta)
        x = x.div(div)
        return x


Mon Nov 20 05:57:09 2017
Leg19_Unet_add_20elas_dropout_0_2_rmSigmoid_40aug_10ela_3inten_reflect
SGD(net.parameters(), lr=1e-2, momentum=0.99)
Number of epoch max: 4
==========================================================================================
Mon Nov 20 06:13:21 2017
Leg19_Unet_add_20elas_dropout_0_2_rmSigmoid_40aug_10ela_3inten_reflect
Mon Nov 20 06:13:18 2017
import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.autograd import Variable
import math


class ConvBnRelu(nn.Module):
    def __init__(self, in_channels, out_channels, kernel_size, padding, stride):
        super(ConvBnRelu, self).__init__()
        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=kernel_size, padding=padding, stride=stride)
        self.bn = nn.BatchNorm2d(out_channels)
        self.relu = nn.ReLU()

    def forward(self, x):
        x = self.conv(x)
        # x = self.bn(x)
        x = self.relu(x)
        return x


class StackEncoder(nn.Module):
    def __init__(self, in_channels, out_channels):
        super(StackEncoder, self).__init__()
        self.convr1 = ConvBnRelu(in_channels, out_channels, kernel_size=(3, 3), stride=1, padding=0)
        self.convr2 = ConvBnRelu(out_channels, out_channels, kernel_size=(3, 3), stride=1, padding=0)
        self.maxPool = nn.MaxPool2d(kernel_size=(2, 2), stride=2)

    def forward(self, x):
        x = self.convr1(x)
        x = self.convr2(x)
        x_trace = x             # save x to use in concat in the Decoder path
        out = self.maxPool(x)
        return out, x_trace


class StackDecoder(nn.Module):
    def __init__(self, in_channels, out_channels, upsample_size, padding, drop_out=False):
        super(StackDecoder, self).__init__()

        self.drop_out = drop_out
        self.dropout_layer = nn.Dropout2d(p=0.5)

        ''' this is old version
        self.upSample = nn.Upsample(size=upsample_size, scale_factor=(2, 2), mode="bilinear")
        self.convr1 = ConvBnRelu(in_channels, out_channels, kernel_size=(3, 3), stride=1, padding=padding)
        # Crop + concat step between these 2
        self.convr2 = ConvBnRelu(in_channels, out_channels, kernel_size=(3, 3), stride=1, padding=padding)
        '''
        self.upSample = nn.ConvTranspose2d(in_channels, out_channels, 2, stride=2)
        self.convr1 = ConvBnRelu(in_channels, out_channels, kernel_size=(3, 3), stride=1, padding=padding)
        self.convr2 = ConvBnRelu(out_channels, out_channels, kernel_size=(3, 3), stride=1, padding=padding)

    def _crop_concat(self, upsampled, bypass):
        """
         Crop y to the (h, w) of x and concat them.
         Used for the expansive path.
        Returns:
            The concatenated tensor
        """
        c = (bypass.size()[2] - upsampled.size()[2]) // 2
        bypass = F.pad(bypass, (-c, -c, -c, -c))

        return torch.cat((bypass, upsampled), 1)

    def forward(self, x, down_tensor):
        '''old version
        x = self.upSample(x)
        x = self.convr1(x)
        x = self._crop_concat(x, down_tensor)
        x = self.convr2(x)
        '''

        x = self.upSample(x)
        x = self._crop_concat(x, down_tensor)
        x = self.convr1(x)
        if self.drop_out: x = self.dropout_layer(x)
        x = self.convr2(x)
        if self.drop_out: x = self.dropout_layer(x)
        return x


class UNet_BN(nn.Module):
    def __init__(self):
        super(UNet_BN, self).__init__()
        # channels, height, width = in_shape

        # self.dropout = dropout

        self.model_code = ""        # variable to save model and main function when loaded

        self.down1 = StackEncoder(1, 64)
        self.down2 = StackEncoder(64, 128)
        self.down3 = StackEncoder(128, 256)
        self.down4 = StackEncoder(256, 512)

        self.center = nn.Sequential(
            # nn.Dropout2d(p=0.2),
            ConvBnRelu(512, 1024, kernel_size=(3, 3), stride=1, padding=0),
            nn.Dropout2d(p=0.2),
            ConvBnRelu(1024, 1024, kernel_size=(3, 3), stride=1, padding=0),
            nn.Dropout2d(p=0.2)
        )

        self.up1 = StackDecoder(in_channels=1024, out_channels=512, upsample_size=(64,64), padding = 1)
        self.up2 = StackDecoder(in_channels=512, out_channels=256, upsample_size=(128,128), padding = 1)
        self.up3 = StackDecoder(in_channels=256, out_channels=128, upsample_size=(256,256), padding = 1)
        self.up4 = StackDecoder(in_channels=128, out_channels=64, upsample_size=(512,512), padding = 1)

        # 1x1 convolution at the last layer
        # Different from the paper is the output size here
        self.output_seg_map = nn.Conv2d(64, 1, kernel_size=(1, 1), padding=0, stride=1)

        self._initialize_weights()

    def forward(self, x):
        x, x_trace1 = self.down1(x)
        x, x_trace2 = self.down2(x)
        x, x_trace3 = self.down3(x)
        x, x_trace4 = self.down4(x)
        x = self.center(x)
        x = self.up1(x, x_trace4)
        x = self.up2(x, x_trace3)
        x = self.up3(x, x_trace2)
        x = self.up4(x, x_trace1)

        x = self.output_seg_map(x)
        # x = F.sigmoid(x)
        # out = torch.squeeze(out, dim=1)
        return x


    def _initialize_weights(self):
        for m in self.modules():
            if isinstance(m, nn.Conv2d):
                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels
                m.weight.data.normal_(0, math.sqrt(2. / n))
                if m.bias is not None:
                    m.bias.data.zero_()
            elif isinstance(m, nn.BatchNorm2d):
                m.weight.data.fill_(1)
                m.bias.data.zero_()

# x = Variable(torch.randn(1,1,636,636))       # simulate input image
# net = UNet_BN()
# out = net(x)
# print("input: ", x)
# print("output: ", out)

===============from __future__ import print_function, division
import torch
from torch import optim
from torch.autograd import Variable
from torch.utils.data import DataLoader
import numpy as np
import torch.nn as nn
import torch.nn.functional as F
import Unet
import Unet_BatchNorm
import tifffile as tiff
import Utils
import time
from sklearn.metrics import average_precision_score, recall_score, f1_score
import Analysis
import Unet_ResNet

def to_var(x):
    if torch.cuda.is_available():
        return Variable(x.cuda())
    else:
        return Variable(x)

### BinaryCrossEntropyLoss2d().forward(logits, labels)
class BinaryCrossEntropyLoss2d(nn.Module):
    def __init__(self, weight=None, size_average=True):
        """
        Binary cross entropy loss 2D
        Args:
            weight:
            size_average:
        """
        super(BinaryCrossEntropyLoss2d, self).__init__()
        self.bce_loss = nn.BCELoss(weight, size_average)

    def forward(self, probs, targets):
        probs = F.sigmoid(probs)
        probs_flat = probs.view(-1)  # Flatten
        targets_flat = targets.view(-1)  # Flatten
        return self.bce_loss(probs_flat, targets_flat)      # (output, labels)

class SoftDiceLoss(nn.Module):
    def __init__(self, weight=None, size_average=True):
        super(SoftDiceLoss, self).__init__()

    def forward(self, probs, targets):
        smooth = 1
        # num = targets.size(0)
        probs = F.sigmoid(probs)
        m1 = probs.view(-1)
        m2 = targets.view(-1)
        intersection = (m1 * m2)
        score = 2. * (intersection.sum() + smooth) / (m1.sum() + m2.sum() + smooth)
        score = 1 - score.sum()
        return score

def _criterion(logits, labels):
    return BinaryCrossEntropyLoss2d().forward(logits, labels) + \
        SoftDiceLoss().forward(logits, labels)

def NetEval(net,valdata_loader,crit):
    loss = 0.
    count = 0
    net.eval()
    for i,data in enumerate(valdata_loader,0):
        inputs, labels = data
        inputs, labels = to_var(inputs), to_var(labels)
        out = net(inputs)
        l = crit(out, labels)
        loss += l.data[0]
        count += 1
    return loss/count

# calculate Precision, Recall, F1-measure, IoU over the validation set
def Net_performace_val(net,valdata_loader):
    precision_list = []
    recall_list = []
    iou_list = []
    net.eval()
    print("len of valdata: ", len(valdata_loader))
    for i,data in enumerate(valdata_loader,0):

        inputs, labels = data
        out = NetPredict(net, inputs)   # out is numpy array 512x512
        labels = labels.numpy()
        labels = labels[0,0,:,:]        # labels is numpy array 512x512
        # remove the case where the mask is plain black
        if np.sum(labels) < 0.01*np.shape(labels)[0]*np.shape(labels)[1]: continue

        precision = average_precision_score(labels, out)
        recall = recall_score(labels, out, average='weighted')
        iou = IoU(out, labels)
        precision_list.append(precision)
        recall_list.append(recall)
        iou_list.append(iou)

    precision, recall, iou = np.mean(precision_list), np.mean(recall_list), np.mean(iou_list)
    F1_measure = 2.0*precision*recall/(precision + recall)

    return precision, recall, F1_measure, iou

# calculate IoU
def IoU(pred, target):
    # Ignore IoU for background class
    cls = 0.5
    pred_inds = pred > cls
    target_inds = target > cls

    intersection = (pred_inds[target_inds]).sum()  # Cast to long to prevent overflows
    union = pred_inds.sum() + target_inds.sum() - intersection
    if union == 0:
        ious = float('nan')  # If there is no ground truth, do not include in evaluation
    else:
        ious = 1.0*intersection / max(union, 1)
    return ious

#process the test data and save to separate .tif image
def NetTest(net,testdata_loader,path = "data/results/"):
    net.eval()
    for i, data in enumerate(testdata_loader, 0):
        if i >= 30: return 1        # for debug
        data = to_var(data)
        out = net(data)

        out = F.sigmoid(out)

        imgname = path + str(i) + ".tif"
        img = out.cpu()
        img = img[0,0,:,:]
        img = img.data.numpy()
        img_shape = img.shape
        img = img.reshape(-1)
        img[img < 0.5] = 0; img[img >= 0.5] = 1
        img = img.reshape(img_shape)
        img = np.uint8(img * 255)
        tiff.imsave(imgname, img)

# return input image size like 512x512, numpy array
def NetPredict(net, data):
    net.eval()
    data = to_var(data)
    out = net(data)

    out = F.sigmoid(out)

    img = out.cpu()
    img = img[0, 0, :, :]
    img = img.data.numpy()
    img_shape = img.shape
    img = img.reshape(-1)
    img[img < 0.5] = 0;
    img[img >= 0.5] = 1
    img = img.reshape(img_shape)
    return img
def write_2_log(content):
    path = "log_file.txt"
    output = open(path, "a")
    output.write("\n")
    output.write(content)
    output.close()

if __name__ == '__main__':
    '''subjects to change for each exp:
    + path to the dataset
    + opt function
    + leg description
    + N_epoch
    + saved_model
    '''
    start_begining = time.time()

    # path = "data/dataset"
    path = "/home/anhxtuan/HanLe/dataset/20aug_10ela_3inten_reflect"

    import os
    print("Does the folder exist?: ", os.path.isdir(path))
    print("Does the path exist?: ", os.path.exists(path))

    # imgs_train, imgs_mask_train = Utils.load_train_data(npy_path=path)
    # trainset = zip(imgs_train, imgs_mask_train)
    # trainloader = torch.utils.data.DataLoader(trainset, batch_size=1,
    #                                           shuffle=True, num_workers=2)

    imgs_val, imgs_mask_val = Utils.load_val_data(npy_path=path)
    valset = zip(imgs_val, imgs_mask_val)
    valloader = torch.utils.data.DataLoader(valset, batch_size=1,
                                              shuffle=False, num_workers=2)
    # net = Unet.UNet()                     # Unet 1
    net = Unet_BatchNorm.UNet_BN()          # Unet 2 with batchNorm
    # net = Unet_ResNet.UNet_ResNet()

    f1 = open("Unet_BatchNorm.py", 'r')     # embede code into the model to be saved later
    # f1 = open("Unet_ResNet.py", 'r')
    f2 = open("UnetTrain.py", 'r')
    f3 = open("Utils.py", 'r')
    model_notes = time.strftime("%c") + "\n" + f1.read() + "\n" + "==="*5 + f2.read() + "\n" + "==="*5 + f3.read()
    f1.close()
    f2.close()
    f3.close()

    # criterion = nn.BCELoss()
    criterion = BinaryCrossEntropyLoss2d()
    # criterion = SoftDiceLoss()

    if torch.cuda.is_available():
        torch.set_default_tensor_type('torch.cuda.FloatTensor')
        net.load_state_dict(torch.load("Unet2_model_6epoch_Leg14_dropout_0_2_rmSigmoid_40aug_10ela_3inten_reflect"))
        net.cuda()
        # criterion.cuda()

    opt = optim.SGD(net.parameters(), lr=1e-3, momentum=0.99)       # subject to change
    # opt = optim.RMSprop(net.parameters(), lr=1e-3, weight_decay=1e-3)
    # RMSprop[22](learning rate 0.001) with weight decay set to 0.001.
    # opt = optim.Adam(net.parameters(), lr=1e-3, weight_decay=1e-4)

    train_loss = []
    val_loss = []

    print("[epoch, #image] Loss")
    leg = "Leg19_Unet_add_20elas_dropout_0_2_rmSigmoid_40aug_10ela_3inten_reflect"
    print("Processing: ", leg)
    model_name = ""

    N_epoch = 3
    # model_saved = np.arange(2,N_epoch+1,2)
    model_saved = [1,2,3]
    val_loss_min = 100

    write_2_log("==="*30)
    write_2_log(time.strftime("%c"))       # time, date of exp
    write_2_log(leg)
    write_2_log(model_notes)
    write_2_log(time.strftime("%c"))  # time, date of exp
    write_2_log(leg)
    write_2_log("SGD(net.parameters(), lr=1e-3, momentum=0.99)")
    write_2_log("Number of epoch max: " + str(N_epoch))

    min_model_epoch = 0
    for epoch in range(N_epoch):
        running_loss = 0.0; count = 0
        net.train()

        N_files = 1
        for j in range(N_files):
            if N_files > 1:
                train_file = "/imgs_train_" + str(j + 1) + ".npy"
                mask_file = "/imgs_mask_train_" + str(j + 1) + ".npy"
            else:
                train_file = "/imgs_train.npy"
                mask_file = "/imgs_mask_train.npy"

            imgs_train, imgs_mask_train = Utils.load_train_data(npy_path=path, train_file=train_file, mask_file=mask_file)
            trainset = zip(imgs_train, imgs_mask_train)
            trainloader = torch.utils.data.DataLoader(trainset, batch_size=1,
                                                      shuffle=True, num_workers=2)
            for i, data in enumerate(trainloader, 0):
                inputs, labels = data
                temp = labels.numpy()
                temp = temp[0, 0, :, :]  # labels is numpy array 512x512
                # remove the case where the mask is plain black
                if np.sum(temp) < 0.01 * np.shape(temp)[0] * np.shape(temp)[1]: continue
                inputs, labels = to_var(inputs), to_var(labels)
                opt.zero_grad()
                out = net(inputs)
                loss = criterion(out, labels)
                loss.backward()
                opt.step()
                running_loss += loss.data[0]
                count += 1

        net.eval()
        val_loss_temp = NetEval(net, valloader, criterion)
        if epoch > 0 and val_loss_temp < val_loss_min:        # save the model which has the lowest val_loss, ignore first epoch
            val_loss_min = val_loss_temp
            torch.save(net.state_dict(), "Unet2_" + leg + "_min_val_loss")  # save model
            min_model_epoch = epoch + 1

        disp = 'Epoch %d: Train loss: %.6f, Val loss: %.6f' % (epoch + 1, running_loss/count, val_loss_temp)
        write_2_log(disp)
        print(disp)
        val_loss.append(val_loss_temp)
        train_loss.append(running_loss/count); running_loss = 0.0

        if (epoch + 1) in model_saved:        # save checkpoint
            model_name = "Unet2_" + str(epoch+1+6) + "epoch_" + leg
            torch.save(net.state_dict(), model_name)  # save model
            Analysis.analysis(model_file = model_name, valloader = valloader)

    write_2_log("Best model at epoch: " + str(min_model_epoch))
    write_2_log("Total training time: " + str((time.time() - start_begining) / 3600.0))

    val_loss_file = "data/results" + "/val_loss_" + str(N_epoch) + "epoch_" + leg + ".npy"
    train_loss_file = "data/results" + "/training_loss_" + str(N_epoch) + "epoch_" + leg + ".npy"

    np.save(val_loss_file, val_loss)
    np.save(train_loss_file, train_loss)
    print("total processing time in seconds: ", time.time() - start_begining)
    print("total processing time in mins: ", (time.time() - start_begining) / 60.0)
    print("total processing time in hours: ", (time.time() - start_begining) / 3600.0)

    # Analysis.analysis(model_file="ResNet_" + leg + "_min_val_loss", valloader=valloader)

    Analysis.PlotLoss(model_file = model_name, loss_train_path = train_loss_file, loss_val_path = val_loss_file, epoch_No = N_epoch)

    write_2_log(time.strftime("%c"))  # time, date of exp
===============import numpy as np
import torch.nn as nn
import torch
import cv2
from lcn import LecunLCN

LCN_enable = False

def input_filled_mirroring(x):      # fill missing data by mirroring the input image
    '''input size 636 --> output size 512'''
    w, h = x.shape
    e = 62  # extra width on 1 edge
    y = np.zeros((h + e * 2, w + e * 2))
    y[e:h + e, e:w + e] = x
    y[e:e + h, 0:e] = np.flip(y[e:e + h, e:2 * e], 1)  # flip vertically
    y[e:e + h, e + w:2 * e + w] = np.flip(y[e:e + h, w:e + w], 1)  # flip vertically
    y[0:e, 0:2 * e + w] = np.flip(y[e:2 * e, 0:2 * e + w], 0)  # flip horizontally
    y[e + h:2 * e + h, 0:2 * e + w] = np.flip(y[h:e + h, 0:2 * e + w], 0)  # flip horizontally
    return y

def nearest_cells_distance(pos, img):
    # searching in 8 directions to find 2 nearest distances to neighbor cells
    curr_value = img[pos]
    w = img.shape[0];h = img.shape[1]
    count_detect = 0  # detect 2 nearest neighbors. break the search if count_detect = 2
    x, y = pos

    # print("w,h: ", (w, h))
    d1 = 9999999;d2 = 9999999;d3 = 9999999;d4 = 9999999
    d5 = 9999999;d6 = 9999999;d7 = 9999999;d8 = 9999999
    for i in range(1, max(w, h)):
        # (x+1, y), (x+1, y+1), (x+1, y-1),
        # (x, y+1), (x, y-1)
        # (x-1, y), (x-1,y+1), (x-1,y-1),
        if x + i < w:
            if img[(x + i, y)] != curr_value and d1 == 9999999:
                d1 = i; count_detect += 1
            if y + i < h:
                if img[(x + i, y + i)] != curr_value and d2 == 9999999:
                    d2 = i; count_detect += 1
            elif y - i >= 0:
                if img[(x + i, y - i)] != curr_value and d3 == 9999999:
                    d3 = i; count_detect += 1
        if y + i < h:
            if img[(x, y + i)] != curr_value and d4 == 9999999:
                d4 = i; count_detect += 1
        if y - i >= 0:
            if img[(x, y - i)] != curr_value and d5 == 9999999:
                d5 = i; count_detect += 1
        if x - i >= 0:
            if img[(x - i, y)] != curr_value and d6 == 9999999:
                d6 = i; count_detect += 1
            if y + i < h:
                if img[(x - i, y + i)] != curr_value and d7 == 9999999:
                    d7 = i; count_detect += 1
            elif y - i >= 0:
                if img[(x - i, y - i)] != curr_value and d8 == 9999999:
                    d8 = i; count_detect += 1
        if count_detect >= 2: break

    d = [d1, d2, d3, d4, d5, d6, d7, d8]
    min_index = np.argmin(d)
    dist1 = d[min_index]
    d.remove(dist1)
    min_index = np.argmin(d)
    dist2 = d[min_index]
    return dist1, dist2

def create_weight_map(imgs_mask):
        print('-' * 30)
        print('Creating weights for masks ...')
        print('-' * 30)
        weight_map = np.ndarray(
            (len(imgs_mask), 1, np.shape(imgs_mask)[2], np.shape(imgs_mask)[3]), dtype=np.float32)
        w_0 = 10; sigma = 4
        imgs_w, imgs_h = np.shape(imgs_mask)[2], np.shape(imgs_mask)[3]
        total_pixels = imgs_w*imgs_h
        import time
        start = time.time()
        for i in range(len(imgs_mask)):
            if i%10 == 0: print("Done processing: %d images, time passed: %.2f mins" % (i, (time.time() - start)/60.0))
            temp = imgs_mask[i,0,:,:]
            w_border = 1 - np.sum(temp)/total_pixels        # w_c of pixel on the border (black)
            for m in range(imgs_w):
                for n in range(imgs_h):
                    # loop through all pixel of the mask
                    d1,d2 = nearest_cells_distance((m,n), temp)
                    w_c = w_border
                    if temp[m,n] == 0: w_c = 1 - w_border
                    weight_map[i,0,m,n] = w_c*5 + w_0*np.exp(-(d1 + d2)**2/(2*sigma**2))
                    # print("w_0*np.exp(): ", w_0*np.exp(-(d1 + d2)**2/(2*sigma**2)))
                    # print("w_border: ", w_border)

        np.save('data/dataset/weight_map_train.npy', weight_map)

        return weight_map

def load_train_data(npy_path = "data/dataset", train_file = "/imgs_train.npy", mask_file = "/imgs_mask_train.npy", hist_equal = False):

    print('-' * 30)
    print('load train images...')

    imgs_train = np.load(npy_path + train_file)
    imgs_mask_train = np.load(npy_path + mask_file)

    if hist_equal: imgs_train = hist_equalization(imgs_train)

    # weight_map_train = np.load(npy_path + "/weight_map_train.npy")
    # weight_map_train = weight_map_train.astype('float32')

    imgs_train = imgs_train.astype('float32')
    imgs_mask_train = imgs_mask_train.astype('float32')

    if LCN_enable:
        imgs_train = imgs_train.astype('float64')
        imgs_train = LecunLCN(imgs_train, image_shape=imgs_train.shape).output.eval()
        imgs_train = imgs_train.astype('float32')

    if not LCN_enable: imgs_train /= 255

    imgs_train -= imgs_train.mean(axis=0)
    imgs_mask_train /= 255
    imgs_mask_train[imgs_mask_train > 0.5] = 1
    imgs_mask_train[imgs_mask_train <= 0.5] = 0

    # weight_map_train = create_weight_map(imgs_mask_train)

    print("Done loading traing data")
    print('-' * 30)
    return imgs_train, imgs_mask_train

def load_val_data(npy_path = "data/dataset", hist_equal = True):

    print('-' * 30)
    print('load validation images...')

    imgs_train = np.load(npy_path + "/imgs_val.npy")
    imgs_mask_train = np.load(npy_path + "/imgs_mask_val.npy")

    if hist_equal: imgs_train = hist_equalization(imgs_train)

    imgs_train = imgs_train.astype('float32')
    imgs_mask_train = imgs_mask_train.astype('float32')

    if LCN_enable:
        imgs_train = imgs_train.astype('float64')
        imgs_train = LecunLCN(imgs_train, image_shape=imgs_train.shape).output.eval()
        imgs_train = imgs_train.astype('float32')

    if not LCN_enable: imgs_train /= 255
    imgs_train -= imgs_train.mean(axis=0)
    imgs_mask_train /= 255
    imgs_mask_train[imgs_mask_train > 0.5] = 1
    imgs_mask_train[imgs_mask_train <= 0.5] = 0
    print("Done loading validation data")
    print('-' * 30)
    return imgs_train, imgs_mask_train

def load_test_data(npy_path = "data/dataset", hist_equal = True):

    print('-' * 30)
    print('load test images...')

    imgs_test = np.load(npy_path + "/imgs_test.npy")

    if hist_equal: imgs_test = hist_equalization(imgs_test)

    imgs_test = imgs_test.astype('float32')

    if LCN_enable:
        imgs_test = imgs_test.astype('float64')
        imgs_test = LecunLCN(imgs_test, image_shape=imgs_test.shape).output.eval()
        imgs_test = imgs_test.astype('float32')

    if not LCN_enable: imgs_test /= 255

    imgs_test -= imgs_test.mean(axis=0)

    print("Done loading test data")
    print('-' * 30)
    return imgs_test

def load_val_5imgs(npy_path = "data/dataset"):
    print('-' * 30)
    print('load train images...')

    imgs_train = np.load(npy_path + "/imgs_val_5imgs.npy")
    imgs_mask_train = np.load(npy_path + "/imgs_mask_val_5imgs.npy")

    # imgs_train = hist_equalization(imgs_train)

    imgs_train = imgs_train.astype('float64')
    imgs_mask_train = imgs_mask_train.astype('float64')

    if LCN_enable: imgs_train = LecunLCN(imgs_train, image_shape=imgs_train.shape).output.eval()

    if not LCN_enable: imgs_train /= 255

    mean = imgs_train.mean(axis=0)
    imgs_train -= mean


    imgs_mask_train /= 255
    imgs_mask_train[imgs_mask_train > 0.5] = 1
    imgs_mask_train[imgs_mask_train <= 0.5] = 0

    # weight_map_train = self.create_weight_map(imgs_mask_train)

    print("Done loading traing data")
    print('-' * 30)
    return imgs_train, imgs_mask_train

def hist_equalization(inputs):      # inputs are uint8, 0-255, Nx1x636x636
    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))
    output = inputs.copy()
    for i in range(len(inputs)):
        img = inputs[i, 0, :, :]
        # res = cv2.equalizeHist(img)
        res = clahe.apply(img)
        output[i,0,:,:] = res
    return output

### BinaryCrossEntropyLoss2d().forward(logits, labels)
class BinaryCrossEntropyLoss2d(nn.Module):
    def __init__(self, weight=None, size_average=True):
        """
        Binary cross entropy loss 2D
        Args:
            weight:
            size_average:
        """
        super(BinaryCrossEntropyLoss2d, self).__init__()
        self.bce_loss = nn.BCELoss(weight, size_average)

    def forward(self, logits, targets):
        # probs = F.sigmoid(logits)
        probs = logits
        probs_flat = probs.view(-1)  # Flatten
        targets_flat = targets.view(-1)  # Flatten
        return self.bce_loss(probs_flat, targets_flat)      # (output, labels)

class BCE_with_Weights(nn.Module):
    def __init__(self, weights=None):
        """
        Binary cross entropy loss 2D
        Args:
            weights:
        """
        super(BCE_with_Weights, self).__init__()
        self.weights = weights

    def forward(self, output, target):
        if self.weights is not None:
            loss = self.weights * (target * torch.log(output) + (1 - target) * torch.log(1 - output))
        else:
            loss = target * torch.log(output) + (1 - target) * torch.log(1 - output)

        return torch.neg(torch.mean(loss))

class LRN(nn.Module):       # input x is Torch tensor
    def __init__(self, local_size=1, alpha=1.0, beta=0.75, ACROSS_CHANNELS=False):      #LRN(local_size=5, alpha=0.0001, beta=0.75),
        super(LRN, self).__init__()
        self.ACROSS_CHANNELS = ACROSS_CHANNELS
        if self.ACROSS_CHANNELS:
            self.average = nn.AvgPool3d(kernel_size=(local_size, 1, 1),
                                        stride=1, padding=(int((local_size - 1.0) / 2), 0, 0))
        else:
            self.average = nn.AvgPool2d(kernel_size=local_size,
                                        stride=1, padding=int((local_size - 1.0) / 2))
        self.alpha = alpha
        self.beta = beta

    def forward(self, x):
        if self.ACROSS_CHANNELS:
            div = x.pow(2).unsqueeze(1)
            div = self.average(div).squeeze(1)
            div = div.mul(self.alpha).add(1.0).pow(self.beta)
        else:
            div = x.pow(2)
            div = self.average(div)
            div = div.mul(self.alpha).add(1.0).pow(self.beta)
        x = x.div(div)
        return x


Mon Nov 20 06:13:21 2017
Leg19_Unet_add_20elas_dropout_0_2_rmSigmoid_40aug_10ela_3inten_reflect
SGD(net.parameters(), lr=1e-3, momentum=0.99)
Number of epoch max: 3
Epoch 1: Train loss: 0.074251, Val loss: 0.382641
Unet2_7epoch_Leg19_Unet_add_20elas_dropout_0_2_rmSigmoid_40aug_10ela_3inten_reflect
Precision: 0.97257 
Recall: 0.92251 
F1_measure: 0.94688 
iou: 0.89051
Epoch 2: Train loss: 0.071446, Val loss: 0.410971
Unet2_8epoch_Leg19_Unet_add_20elas_dropout_0_2_rmSigmoid_40aug_10ela_3inten_reflect
Precision: 0.97313 
Recall: 0.91958 
F1_measure: 0.94560 
iou: 0.88921
==========================================================================================
Mon Nov 20 07:14:48 2017
Leg20_Unet_add_20elas_dropout_0_2_rmSigmoid_40aug_10ela_3inten_reflect
Mon Nov 20 07:14:46 2017
import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.autograd import Variable
import math


class ConvBnRelu(nn.Module):
    def __init__(self, in_channels, out_channels, kernel_size, padding, stride):
        super(ConvBnRelu, self).__init__()
        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=kernel_size, padding=padding, stride=stride)
        self.bn = nn.BatchNorm2d(out_channels)
        self.relu = nn.ReLU()

    def forward(self, x):
        x = self.conv(x)
        # x = self.bn(x)
        x = self.relu(x)
        return x


class StackEncoder(nn.Module):
    def __init__(self, in_channels, out_channels):
        super(StackEncoder, self).__init__()
        self.convr1 = ConvBnRelu(in_channels, out_channels, kernel_size=(3, 3), stride=1, padding=0)
        self.convr2 = ConvBnRelu(out_channels, out_channels, kernel_size=(3, 3), stride=1, padding=0)
        self.maxPool = nn.MaxPool2d(kernel_size=(2, 2), stride=2)

    def forward(self, x):
        x = self.convr1(x)
        x = self.convr2(x)
        x_trace = x             # save x to use in concat in the Decoder path
        out = self.maxPool(x)
        return out, x_trace


class StackDecoder(nn.Module):
    def __init__(self, in_channels, out_channels, upsample_size, padding, drop_out=False):
        super(StackDecoder, self).__init__()

        self.drop_out = drop_out
        self.dropout_layer = nn.Dropout2d(p=0.5)

        ''' this is old version
        self.upSample = nn.Upsample(size=upsample_size, scale_factor=(2, 2), mode="bilinear")
        self.convr1 = ConvBnRelu(in_channels, out_channels, kernel_size=(3, 3), stride=1, padding=padding)
        # Crop + concat step between these 2
        self.convr2 = ConvBnRelu(in_channels, out_channels, kernel_size=(3, 3), stride=1, padding=padding)
        '''
        self.upSample = nn.ConvTranspose2d(in_channels, out_channels, 2, stride=2)
        self.convr1 = ConvBnRelu(in_channels, out_channels, kernel_size=(3, 3), stride=1, padding=padding)
        self.convr2 = ConvBnRelu(out_channels, out_channels, kernel_size=(3, 3), stride=1, padding=padding)

    def _crop_concat(self, upsampled, bypass):
        """
         Crop y to the (h, w) of x and concat them.
         Used for the expansive path.
        Returns:
            The concatenated tensor
        """
        c = (bypass.size()[2] - upsampled.size()[2]) // 2
        bypass = F.pad(bypass, (-c, -c, -c, -c))

        return torch.cat((bypass, upsampled), 1)

    def forward(self, x, down_tensor):
        '''old version
        x = self.upSample(x)
        x = self.convr1(x)
        x = self._crop_concat(x, down_tensor)
        x = self.convr2(x)
        '''

        x = self.upSample(x)
        x = self._crop_concat(x, down_tensor)
        x = self.convr1(x)
        if self.drop_out: x = self.dropout_layer(x)
        x = self.convr2(x)
        if self.drop_out: x = self.dropout_layer(x)
        return x


class UNet_BN(nn.Module):
    def __init__(self):
        super(UNet_BN, self).__init__()
        # channels, height, width = in_shape

        # self.dropout = dropout

        self.model_code = ""        # variable to save model and main function when loaded

        self.down1 = StackEncoder(1, 64)
        self.down2 = StackEncoder(64, 128)
        self.down3 = StackEncoder(128, 256)
        self.down4 = StackEncoder(256, 512)

        self.center = nn.Sequential(
            # nn.Dropout2d(p=0.2),
            ConvBnRelu(512, 1024, kernel_size=(3, 3), stride=1, padding=0),
            nn.Dropout2d(p=0.2),
            ConvBnRelu(1024, 1024, kernel_size=(3, 3), stride=1, padding=0),
            nn.Dropout2d(p=0.2)
        )

        self.up1 = StackDecoder(in_channels=1024, out_channels=512, upsample_size=(64,64), padding = 1)
        self.up2 = StackDecoder(in_channels=512, out_channels=256, upsample_size=(128,128), padding = 1)
        self.up3 = StackDecoder(in_channels=256, out_channels=128, upsample_size=(256,256), padding = 1)
        self.up4 = StackDecoder(in_channels=128, out_channels=64, upsample_size=(512,512), padding = 1)

        # 1x1 convolution at the last layer
        # Different from the paper is the output size here
        self.output_seg_map = nn.Conv2d(64, 1, kernel_size=(1, 1), padding=0, stride=1)

        self._initialize_weights()

    def forward(self, x):
        x, x_trace1 = self.down1(x)
        x, x_trace2 = self.down2(x)
        x, x_trace3 = self.down3(x)
        x, x_trace4 = self.down4(x)
        x = self.center(x)
        x = self.up1(x, x_trace4)
        x = self.up2(x, x_trace3)
        x = self.up3(x, x_trace2)
        x = self.up4(x, x_trace1)

        x = self.output_seg_map(x)
        # x = F.sigmoid(x)
        # out = torch.squeeze(out, dim=1)
        return x


    def _initialize_weights(self):
        for m in self.modules():
            if isinstance(m, nn.Conv2d):
                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels
                m.weight.data.normal_(0, math.sqrt(2. / n))
                if m.bias is not None:
                    m.bias.data.zero_()
            elif isinstance(m, nn.BatchNorm2d):
                m.weight.data.fill_(1)
                m.bias.data.zero_()

# x = Variable(torch.randn(1,1,636,636))       # simulate input image
# net = UNet_BN()
# out = net(x)
# print("input: ", x)
# print("output: ", out)

===============from __future__ import print_function, division
import torch
from torch import optim
from torch.autograd import Variable
from torch.utils.data import DataLoader
import numpy as np
import torch.nn as nn
import torch.nn.functional as F
import Unet
import Unet_BatchNorm
import tifffile as tiff
import Utils
import time
from sklearn.metrics import average_precision_score, recall_score, f1_score
import Analysis
import Unet_ResNet

def to_var(x):
    if torch.cuda.is_available():
        return Variable(x.cuda())
    else:
        return Variable(x)

### BinaryCrossEntropyLoss2d().forward(logits, labels)
class BinaryCrossEntropyLoss2d(nn.Module):
    def __init__(self, weight=None, size_average=True):
        """
        Binary cross entropy loss 2D
        Args:
            weight:
            size_average:
        """
        super(BinaryCrossEntropyLoss2d, self).__init__()
        self.bce_loss = nn.BCELoss(weight, size_average)

    def forward(self, probs, targets):
        probs = F.sigmoid(probs)
        probs_flat = probs.view(-1)  # Flatten
        targets_flat = targets.view(-1)  # Flatten
        return self.bce_loss(probs_flat, targets_flat)      # (output, labels)

class SoftDiceLoss(nn.Module):
    def __init__(self, weight=None, size_average=True):
        super(SoftDiceLoss, self).__init__()

    def forward(self, probs, targets):
        smooth = 1
        # num = targets.size(0)
        probs = F.sigmoid(probs)
        m1 = probs.view(-1)
        m2 = targets.view(-1)
        intersection = (m1 * m2)
        score = 2. * (intersection.sum() + smooth) / (m1.sum() + m2.sum() + smooth)
        score = 1 - score.sum()
        return score

def _criterion(logits, labels):
    return BinaryCrossEntropyLoss2d().forward(logits, labels) + \
        SoftDiceLoss().forward(logits, labels)

def NetEval(net,valdata_loader,crit):
    loss = 0.
    count = 0
    net.eval()
    for i,data in enumerate(valdata_loader,0):
        inputs, labels = data
        inputs, labels = to_var(inputs), to_var(labels)
        out = net(inputs)
        l = crit(out, labels)
        loss += l.data[0]
        count += 1
    return loss/count

# calculate Precision, Recall, F1-measure, IoU over the validation set
def Net_performace_val(net,valdata_loader):
    precision_list = []
    recall_list = []
    iou_list = []
    net.eval()
    print("len of valdata: ", len(valdata_loader))
    for i,data in enumerate(valdata_loader,0):

        inputs, labels = data
        out = NetPredict(net, inputs)   # out is numpy array 512x512
        labels = labels.numpy()
        labels = labels[0,0,:,:]        # labels is numpy array 512x512
        # remove the case where the mask is plain black
        if np.sum(labels) < 0.01*np.shape(labels)[0]*np.shape(labels)[1]: continue

        precision = average_precision_score(labels, out)
        recall = recall_score(labels, out, average='weighted')
        iou = IoU(out, labels)
        precision_list.append(precision)
        recall_list.append(recall)
        iou_list.append(iou)

    precision, recall, iou = np.mean(precision_list), np.mean(recall_list), np.mean(iou_list)
    F1_measure = 2.0*precision*recall/(precision + recall)

    return precision, recall, F1_measure, iou

# calculate IoU
def IoU(pred, target):
    # Ignore IoU for background class
    cls = 0.5
    pred_inds = pred > cls
    target_inds = target > cls

    intersection = (pred_inds[target_inds]).sum()  # Cast to long to prevent overflows
    union = pred_inds.sum() + target_inds.sum() - intersection
    if union == 0:
        ious = float('nan')  # If there is no ground truth, do not include in evaluation
    else:
        ious = 1.0*intersection / max(union, 1)
    return ious

#process the test data and save to separate .tif image
def NetTest(net,testdata_loader,path = "data/results/"):
    net.eval()
    for i, data in enumerate(testdata_loader, 0):
        if i >= 30: return 1        # for debug
        data = to_var(data)
        out = net(data)

        out = F.sigmoid(out)

        imgname = path + str(i) + ".tif"
        img = out.cpu()
        img = img[0,0,:,:]
        img = img.data.numpy()
        img_shape = img.shape
        img = img.reshape(-1)
        img[img < 0.5] = 0; img[img >= 0.5] = 1
        img = img.reshape(img_shape)
        img = np.uint8(img * 255)
        tiff.imsave(imgname, img)

# return input image size like 512x512, numpy array
def NetPredict(net, data):
    net.eval()
    data = to_var(data)
    out = net(data)

    out = F.sigmoid(out)

    img = out.cpu()
    img = img[0, 0, :, :]
    img = img.data.numpy()
    img_shape = img.shape
    img = img.reshape(-1)
    img[img < 0.5] = 0;
    img[img >= 0.5] = 1
    img = img.reshape(img_shape)
    return img
def write_2_log(content):
    path = "log_file.txt"
    output = open(path, "a")
    output.write("\n")
    output.write(content)
    output.close()

if __name__ == '__main__':
    '''subjects to change for each exp:
    + path to the dataset
    + opt function
    + leg description
    + N_epoch
    + saved_model
    '''
    start_begining = time.time()

    # path = "data/dataset"
    path = "/home/anhxtuan/HanLe/dataset/20aug_10ela_3inten_reflect"

    import os
    print("Does the folder exist?: ", os.path.isdir(path))
    print("Does the path exist?: ", os.path.exists(path))

    # imgs_train, imgs_mask_train = Utils.load_train_data(npy_path=path)
    # trainset = zip(imgs_train, imgs_mask_train)
    # trainloader = torch.utils.data.DataLoader(trainset, batch_size=1,
    #                                           shuffle=True, num_workers=2)

    imgs_val, imgs_mask_val = Utils.load_val_data(npy_path=path)
    valset = zip(imgs_val, imgs_mask_val)
    valloader = torch.utils.data.DataLoader(valset, batch_size=1,
                                              shuffle=False, num_workers=2)
    # net = Unet.UNet()                     # Unet 1
    net = Unet_BatchNorm.UNet_BN()          # Unet 2 with batchNorm
    # net = Unet_ResNet.UNet_ResNet()

    f1 = open("Unet_BatchNorm.py", 'r')     # embede code into the model to be saved later
    # f1 = open("Unet_ResNet.py", 'r')
    f2 = open("UnetTrain.py", 'r')
    f3 = open("Utils.py", 'r')
    model_notes = time.strftime("%c") + "\n" + f1.read() + "\n" + "==="*5 + f2.read() + "\n" + "==="*5 + f3.read()
    f1.close()
    f2.close()
    f3.close()

    # criterion = nn.BCELoss()
    criterion = BinaryCrossEntropyLoss2d()
    # criterion = SoftDiceLoss()

    if torch.cuda.is_available():
        torch.set_default_tensor_type('torch.cuda.FloatTensor')
        net.load_state_dict(torch.load("Unet2_model_6epoch_Leg14_dropout_0_2_rmSigmoid_40aug_10ela_3inten_reflect"))
        net.cuda()
        # criterion.cuda()

    opt = optim.SGD(net.parameters(), lr=1e-5, momentum=0.8)       # subject to change
    # opt = optim.RMSprop(net.parameters(), lr=1e-3, weight_decay=1e-3)
    # RMSprop[22](learning rate 0.001) with weight decay set to 0.001.
    # opt = optim.Adam(net.parameters(), lr=1e-3, weight_decay=1e-4)

    train_loss = []
    val_loss = []

    print("[epoch, #image] Loss")
    leg = "Leg20_Unet_add_20elas_dropout_0_2_rmSigmoid_40aug_10ela_3inten_reflect"
    print("Processing: ", leg)
    model_name = ""

    N_epoch = 2
    # model_saved = np.arange(2,N_epoch+1,2)
    model_saved = [1, 2]
    val_loss_min = 100

    write_2_log("==="*30)
    write_2_log(time.strftime("%c"))       # time, date of exp
    write_2_log(leg)
    write_2_log(model_notes)
    write_2_log(time.strftime("%c"))  # time, date of exp
    write_2_log(leg)
    write_2_log("SGD(net.parameters(), lr=1e-5, momentum=0.8)")
    write_2_log("Number of epoch max: " + str(N_epoch))

    min_model_epoch = 0
    for epoch in range(N_epoch):
        running_loss = 0.0; count = 0
        net.train()

        N_files = 1
        for j in range(N_files):
            if N_files > 1:
                train_file = "/imgs_train_" + str(j + 1) + ".npy"
                mask_file = "/imgs_mask_train_" + str(j + 1) + ".npy"
            else:
                train_file = "/imgs_train.npy"
                mask_file = "/imgs_mask_train.npy"

            imgs_train, imgs_mask_train = Utils.load_train_data(npy_path=path, train_file=train_file, mask_file=mask_file)
            trainset = zip(imgs_train, imgs_mask_train)
            trainloader = torch.utils.data.DataLoader(trainset, batch_size=1,
                                                      shuffle=True, num_workers=2)
            for i, data in enumerate(trainloader, 0):
                inputs, labels = data
                temp = labels.numpy()
                temp = temp[0, 0, :, :]  # labels is numpy array 512x512
                # remove the case where the mask is plain black
                if np.sum(temp) < 0.01 * np.shape(temp)[0] * np.shape(temp)[1]: continue
                inputs, labels = to_var(inputs), to_var(labels)
                opt.zero_grad()
                out = net(inputs)
                loss = criterion(out, labels)
                loss.backward()
                opt.step()
                running_loss += loss.data[0]
                count += 1

        net.eval()
        val_loss_temp = NetEval(net, valloader, criterion)
        if epoch > 0 and val_loss_temp < val_loss_min:        # save the model which has the lowest val_loss, ignore first epoch
            val_loss_min = val_loss_temp
            torch.save(net.state_dict(), "Unet2_" + leg + "_min_val_loss")  # save model
            min_model_epoch = epoch + 1

        disp = 'Epoch %d: Train loss: %.6f, Val loss: %.6f' % (epoch + 1, running_loss/count, val_loss_temp)
        write_2_log(disp)
        print(disp)
        val_loss.append(val_loss_temp)
        train_loss.append(running_loss/count); running_loss = 0.0

        if (epoch + 1) in model_saved:        # save checkpoint
            model_name = "Unet2_" + str(epoch+1+6) + "epoch_" + leg
            torch.save(net.state_dict(), model_name)  # save model
            Analysis.analysis(model_file = model_name, valloader = valloader)

    write_2_log("Best model at epoch: " + str(min_model_epoch))
    write_2_log("Total training time: " + str((time.time() - start_begining) / 3600.0))

    val_loss_file = "data/results" + "/val_loss_" + str(N_epoch) + "epoch_" + leg + ".npy"
    train_loss_file = "data/results" + "/training_loss_" + str(N_epoch) + "epoch_" + leg + ".npy"

    np.save(val_loss_file, val_loss)
    np.save(train_loss_file, train_loss)
    print("total processing time in seconds: ", time.time() - start_begining)
    print("total processing time in mins: ", (time.time() - start_begining) / 60.0)
    print("total processing time in hours: ", (time.time() - start_begining) / 3600.0)

    # Analysis.analysis(model_file="ResNet_" + leg + "_min_val_loss", valloader=valloader)

    Analysis.PlotLoss(model_file = model_name, loss_train_path = train_loss_file, loss_val_path = val_loss_file, epoch_No = N_epoch)

    write_2_log(time.strftime("%c"))  # time, date of exp
===============import numpy as np
import torch.nn as nn
import torch
import cv2
from lcn import LecunLCN

LCN_enable = False

def input_filled_mirroring(x):      # fill missing data by mirroring the input image
    '''input size 636 --> output size 512'''
    w, h = x.shape
    e = 62  # extra width on 1 edge
    y = np.zeros((h + e * 2, w + e * 2))
    y[e:h + e, e:w + e] = x
    y[e:e + h, 0:e] = np.flip(y[e:e + h, e:2 * e], 1)  # flip vertically
    y[e:e + h, e + w:2 * e + w] = np.flip(y[e:e + h, w:e + w], 1)  # flip vertically
    y[0:e, 0:2 * e + w] = np.flip(y[e:2 * e, 0:2 * e + w], 0)  # flip horizontally
    y[e + h:2 * e + h, 0:2 * e + w] = np.flip(y[h:e + h, 0:2 * e + w], 0)  # flip horizontally
    return y

def nearest_cells_distance(pos, img):
    # searching in 8 directions to find 2 nearest distances to neighbor cells
    curr_value = img[pos]
    w = img.shape[0];h = img.shape[1]
    count_detect = 0  # detect 2 nearest neighbors. break the search if count_detect = 2
    x, y = pos

    # print("w,h: ", (w, h))
    d1 = 9999999;d2 = 9999999;d3 = 9999999;d4 = 9999999
    d5 = 9999999;d6 = 9999999;d7 = 9999999;d8 = 9999999
    for i in range(1, max(w, h)):
        # (x+1, y), (x+1, y+1), (x+1, y-1),
        # (x, y+1), (x, y-1)
        # (x-1, y), (x-1,y+1), (x-1,y-1),
        if x + i < w:
            if img[(x + i, y)] != curr_value and d1 == 9999999:
                d1 = i; count_detect += 1
            if y + i < h:
                if img[(x + i, y + i)] != curr_value and d2 == 9999999:
                    d2 = i; count_detect += 1
            elif y - i >= 0:
                if img[(x + i, y - i)] != curr_value and d3 == 9999999:
                    d3 = i; count_detect += 1
        if y + i < h:
            if img[(x, y + i)] != curr_value and d4 == 9999999:
                d4 = i; count_detect += 1
        if y - i >= 0:
            if img[(x, y - i)] != curr_value and d5 == 9999999:
                d5 = i; count_detect += 1
        if x - i >= 0:
            if img[(x - i, y)] != curr_value and d6 == 9999999:
                d6 = i; count_detect += 1
            if y + i < h:
                if img[(x - i, y + i)] != curr_value and d7 == 9999999:
                    d7 = i; count_detect += 1
            elif y - i >= 0:
                if img[(x - i, y - i)] != curr_value and d8 == 9999999:
                    d8 = i; count_detect += 1
        if count_detect >= 2: break

    d = [d1, d2, d3, d4, d5, d6, d7, d8]
    min_index = np.argmin(d)
    dist1 = d[min_index]
    d.remove(dist1)
    min_index = np.argmin(d)
    dist2 = d[min_index]
    return dist1, dist2

def create_weight_map(imgs_mask):
        print('-' * 30)
        print('Creating weights for masks ...')
        print('-' * 30)
        weight_map = np.ndarray(
            (len(imgs_mask), 1, np.shape(imgs_mask)[2], np.shape(imgs_mask)[3]), dtype=np.float32)
        w_0 = 10; sigma = 4
        imgs_w, imgs_h = np.shape(imgs_mask)[2], np.shape(imgs_mask)[3]
        total_pixels = imgs_w*imgs_h
        import time
        start = time.time()
        for i in range(len(imgs_mask)):
            if i%10 == 0: print("Done processing: %d images, time passed: %.2f mins" % (i, (time.time() - start)/60.0))
            temp = imgs_mask[i,0,:,:]
            w_border = 1 - np.sum(temp)/total_pixels        # w_c of pixel on the border (black)
            for m in range(imgs_w):
                for n in range(imgs_h):
                    # loop through all pixel of the mask
                    d1,d2 = nearest_cells_distance((m,n), temp)
                    w_c = w_border
                    if temp[m,n] == 0: w_c = 1 - w_border
                    weight_map[i,0,m,n] = w_c*5 + w_0*np.exp(-(d1 + d2)**2/(2*sigma**2))
                    # print("w_0*np.exp(): ", w_0*np.exp(-(d1 + d2)**2/(2*sigma**2)))
                    # print("w_border: ", w_border)

        np.save('data/dataset/weight_map_train.npy', weight_map)

        return weight_map

def load_train_data(npy_path = "data/dataset", train_file = "/imgs_train.npy", mask_file = "/imgs_mask_train.npy", hist_equal = False):

    print('-' * 30)
    print('load train images...')

    imgs_train = np.load(npy_path + train_file)
    imgs_mask_train = np.load(npy_path + mask_file)

    if hist_equal: imgs_train = hist_equalization(imgs_train)

    # weight_map_train = np.load(npy_path + "/weight_map_train.npy")
    # weight_map_train = weight_map_train.astype('float32')

    imgs_train = imgs_train.astype('float32')
    imgs_mask_train = imgs_mask_train.astype('float32')

    if LCN_enable:
        imgs_train = imgs_train.astype('float64')
        imgs_train = LecunLCN(imgs_train, image_shape=imgs_train.shape).output.eval()
        imgs_train = imgs_train.astype('float32')

    if not LCN_enable: imgs_train /= 255

    imgs_train -= imgs_train.mean(axis=0)
    imgs_mask_train /= 255
    imgs_mask_train[imgs_mask_train > 0.5] = 1
    imgs_mask_train[imgs_mask_train <= 0.5] = 0

    # weight_map_train = create_weight_map(imgs_mask_train)

    print("Done loading traing data")
    print('-' * 30)
    return imgs_train, imgs_mask_train

def load_val_data(npy_path = "data/dataset", hist_equal = True):

    print('-' * 30)
    print('load validation images...')

    imgs_train = np.load(npy_path + "/imgs_val.npy")
    imgs_mask_train = np.load(npy_path + "/imgs_mask_val.npy")

    if hist_equal: imgs_train = hist_equalization(imgs_train)

    imgs_train = imgs_train.astype('float32')
    imgs_mask_train = imgs_mask_train.astype('float32')

    if LCN_enable:
        imgs_train = imgs_train.astype('float64')
        imgs_train = LecunLCN(imgs_train, image_shape=imgs_train.shape).output.eval()
        imgs_train = imgs_train.astype('float32')

    if not LCN_enable: imgs_train /= 255
    imgs_train -= imgs_train.mean(axis=0)
    imgs_mask_train /= 255
    imgs_mask_train[imgs_mask_train > 0.5] = 1
    imgs_mask_train[imgs_mask_train <= 0.5] = 0
    print("Done loading validation data")
    print('-' * 30)
    return imgs_train, imgs_mask_train

def load_test_data(npy_path = "data/dataset", hist_equal = True):

    print('-' * 30)
    print('load test images...')

    imgs_test = np.load(npy_path + "/imgs_test.npy")

    if hist_equal: imgs_test = hist_equalization(imgs_test)

    imgs_test = imgs_test.astype('float32')

    if LCN_enable:
        imgs_test = imgs_test.astype('float64')
        imgs_test = LecunLCN(imgs_test, image_shape=imgs_test.shape).output.eval()
        imgs_test = imgs_test.astype('float32')

    if not LCN_enable: imgs_test /= 255

    imgs_test -= imgs_test.mean(axis=0)

    print("Done loading test data")
    print('-' * 30)
    return imgs_test

def load_val_5imgs(npy_path = "data/dataset"):
    print('-' * 30)
    print('load train images...')

    imgs_train = np.load(npy_path + "/imgs_val_5imgs.npy")
    imgs_mask_train = np.load(npy_path + "/imgs_mask_val_5imgs.npy")

    # imgs_train = hist_equalization(imgs_train)

    imgs_train = imgs_train.astype('float64')
    imgs_mask_train = imgs_mask_train.astype('float64')

    if LCN_enable: imgs_train = LecunLCN(imgs_train, image_shape=imgs_train.shape).output.eval()

    if not LCN_enable: imgs_train /= 255

    mean = imgs_train.mean(axis=0)
    imgs_train -= mean


    imgs_mask_train /= 255
    imgs_mask_train[imgs_mask_train > 0.5] = 1
    imgs_mask_train[imgs_mask_train <= 0.5] = 0

    # weight_map_train = self.create_weight_map(imgs_mask_train)

    print("Done loading traing data")
    print('-' * 30)
    return imgs_train, imgs_mask_train

def hist_equalization(inputs):      # inputs are uint8, 0-255, Nx1x636x636
    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))
    output = inputs.copy()
    for i in range(len(inputs)):
        img = inputs[i, 0, :, :]
        # res = cv2.equalizeHist(img)
        res = clahe.apply(img)
        output[i,0,:,:] = res
    return output

### BinaryCrossEntropyLoss2d().forward(logits, labels)
class BinaryCrossEntropyLoss2d(nn.Module):
    def __init__(self, weight=None, size_average=True):
        """
        Binary cross entropy loss 2D
        Args:
            weight:
            size_average:
        """
        super(BinaryCrossEntropyLoss2d, self).__init__()
        self.bce_loss = nn.BCELoss(weight, size_average)

    def forward(self, logits, targets):
        # probs = F.sigmoid(logits)
        probs = logits
        probs_flat = probs.view(-1)  # Flatten
        targets_flat = targets.view(-1)  # Flatten
        return self.bce_loss(probs_flat, targets_flat)      # (output, labels)

class BCE_with_Weights(nn.Module):
    def __init__(self, weights=None):
        """
        Binary cross entropy loss 2D
        Args:
            weights:
        """
        super(BCE_with_Weights, self).__init__()
        self.weights = weights

    def forward(self, output, target):
        if self.weights is not None:
            loss = self.weights * (target * torch.log(output) + (1 - target) * torch.log(1 - output))
        else:
            loss = target * torch.log(output) + (1 - target) * torch.log(1 - output)

        return torch.neg(torch.mean(loss))

class LRN(nn.Module):       # input x is Torch tensor
    def __init__(self, local_size=1, alpha=1.0, beta=0.75, ACROSS_CHANNELS=False):      #LRN(local_size=5, alpha=0.0001, beta=0.75),
        super(LRN, self).__init__()
        self.ACROSS_CHANNELS = ACROSS_CHANNELS
        if self.ACROSS_CHANNELS:
            self.average = nn.AvgPool3d(kernel_size=(local_size, 1, 1),
                                        stride=1, padding=(int((local_size - 1.0) / 2), 0, 0))
        else:
            self.average = nn.AvgPool2d(kernel_size=local_size,
                                        stride=1, padding=int((local_size - 1.0) / 2))
        self.alpha = alpha
        self.beta = beta

    def forward(self, x):
        if self.ACROSS_CHANNELS:
            div = x.pow(2).unsqueeze(1)
            div = self.average(div).squeeze(1)
            div = div.mul(self.alpha).add(1.0).pow(self.beta)
        else:
            div = x.pow(2)
            div = self.average(div)
            div = div.mul(self.alpha).add(1.0).pow(self.beta)
        x = x.div(div)
        return x


Mon Nov 20 07:14:48 2017
Leg20_Unet_add_20elas_dropout_0_2_rmSigmoid_40aug_10ela_3inten_reflect
SGD(net.parameters(), lr=1e-5, momentum=0.8)
Number of epoch max: 2
Epoch 1: Train loss: 0.077721, Val loss: 0.425936
Unet2_7epoch_Leg20_Unet_add_20elas_dropout_0_2_rmSigmoid_40aug_10ela_3inten_reflect
Precision: 0.97290 
Recall: 0.92338 
F1_measure: 0.94749 
iou: 0.89170
Epoch 2: Train loss: 0.077274, Val loss: 0.416764
Unet2_8epoch_Leg20_Unet_add_20elas_dropout_0_2_rmSigmoid_40aug_10ela_3inten_reflect
Precision: 0.97291 
Recall: 0.92313 
F1_measure: 0.94737 
iou: 0.89154
Best model at epoch: 2
Total training time: 0.960674911671
Mon Nov 20 08:12:17 2017
==========================================================================================
Sun Nov 19 21:25:55 2017
Legxxxx_Unet_add_20elas_dropout_0_2_rmSigmoid_40aug_10ela_3inten_reflect
Sun Nov 19 21:25:55 2017
import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.autograd import Variable
import math


class ConvBnRelu(nn.Module):
    def __init__(self, in_channels, out_channels, kernel_size, padding, stride):
        super(ConvBnRelu, self).__init__()
        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=kernel_size, padding=padding, stride=stride)
        self.bn = nn.BatchNorm2d(out_channels)
        self.relu = nn.ReLU()

    def forward(self, x):
        x = self.conv(x)
        # x = self.bn(x)
        x = self.relu(x)
        return x


class StackEncoder(nn.Module):
    def __init__(self, in_channels, out_channels):
        super(StackEncoder, self).__init__()
        self.convr1 = ConvBnRelu(in_channels, out_channels, kernel_size=(3, 3), stride=1, padding=0)
        self.convr2 = ConvBnRelu(out_channels, out_channels, kernel_size=(3, 3), stride=1, padding=0)
        self.maxPool = nn.MaxPool2d(kernel_size=(2, 2), stride=2)

    def forward(self, x):
        x = self.convr1(x)
        x = self.convr2(x)
        x_trace = x             # save x to use in concat in the Decoder path
        out = self.maxPool(x)
        return out, x_trace


class StackDecoder(nn.Module):
    def __init__(self, in_channels, out_channels, upsample_size, padding, drop_out=False):
        super(StackDecoder, self).__init__()

        self.drop_out = drop_out
        self.dropout_layer = nn.Dropout2d(p=0.5)

        ''' this is old version
        self.upSample = nn.Upsample(size=upsample_size, scale_factor=(2, 2), mode="bilinear")
        self.convr1 = ConvBnRelu(in_channels, out_channels, kernel_size=(3, 3), stride=1, padding=padding)
        # Crop + concat step between these 2
        self.convr2 = ConvBnRelu(in_channels, out_channels, kernel_size=(3, 3), stride=1, padding=padding)
        '''
        self.upSample = nn.ConvTranspose2d(in_channels, out_channels, 2, stride=2)
        self.convr1 = ConvBnRelu(in_channels, out_channels, kernel_size=(3, 3), stride=1, padding=padding)
        self.convr2 = ConvBnRelu(out_channels, out_channels, kernel_size=(3, 3), stride=1, padding=padding)

    def _crop_concat(self, upsampled, bypass):
        """
         Crop y to the (h, w) of x and concat them.
         Used for the expansive path.
        Returns:
            The concatenated tensor
        """
        c = (bypass.size()[2] - upsampled.size()[2]) // 2
        bypass = F.pad(bypass, (-c, -c, -c, -c))

        return torch.cat((bypass, upsampled), 1)

    def forward(self, x, down_tensor):
        '''old version
        x = self.upSample(x)
        x = self.convr1(x)
        x = self._crop_concat(x, down_tensor)
        x = self.convr2(x)
        '''

        x = self.upSample(x)
        x = self._crop_concat(x, down_tensor)
        x = self.convr1(x)
        if self.drop_out: x = self.dropout_layer(x)
        x = self.convr2(x)
        if self.drop_out: x = self.dropout_layer(x)
        return x


class UNet_BN(nn.Module):
    def __init__(self):
        super(UNet_BN, self).__init__()
        # channels, height, width = in_shape

        # self.dropout = dropout

        self.model_code = ""        # variable to save model and main function when loaded

        self.down1 = StackEncoder(1, 64)
        self.down2 = StackEncoder(64, 128)
        self.down3 = StackEncoder(128, 256)
        self.down4 = StackEncoder(256, 512)

        self.center = nn.Sequential(
            # nn.Dropout2d(p=0.2),
            ConvBnRelu(512, 1024, kernel_size=(3, 3), stride=1, padding=0),
            nn.Dropout2d(p=0.2),
            ConvBnRelu(1024, 1024, kernel_size=(3, 3), stride=1, padding=0),
            nn.Dropout2d(p=0.2)
        )

        self.up1 = StackDecoder(in_channels=1024, out_channels=512, upsample_size=(64,64), padding = 1)
        self.up2 = StackDecoder(in_channels=512, out_channels=256, upsample_size=(128,128), padding = 1)
        self.up3 = StackDecoder(in_channels=256, out_channels=128, upsample_size=(256,256), padding = 1)
        self.up4 = StackDecoder(in_channels=128, out_channels=64, upsample_size=(512,512), padding = 1)

        # 1x1 convolution at the last layer
        # Different from the paper is the output size here
        self.output_seg_map = nn.Conv2d(64, 1, kernel_size=(1, 1), padding=0, stride=1)

        self._initialize_weights()

    def forward(self, x):
        x, x_trace1 = self.down1(x)
        x, x_trace2 = self.down2(x)
        x, x_trace3 = self.down3(x)
        x, x_trace4 = self.down4(x)
        x = self.center(x)
        x = self.up1(x, x_trace4)
        x = self.up2(x, x_trace3)
        x = self.up3(x, x_trace2)
        x = self.up4(x, x_trace1)

        x = self.output_seg_map(x)
        # x = F.sigmoid(x)
        # out = torch.squeeze(out, dim=1)
        return x


    def _initialize_weights(self):
        for m in self.modules():
            if isinstance(m, nn.Conv2d):
                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels
                m.weight.data.normal_(0, math.sqrt(2. / n))
                if m.bias is not None:
                    m.bias.data.zero_()
            elif isinstance(m, nn.BatchNorm2d):
                m.weight.data.fill_(1)
                m.bias.data.zero_()

# x = Variable(torch.randn(1,1,636,636))       # simulate input image
# net = UNet_BN()
# out = net(x)
# print("input: ", x)
# print("output: ", out)

===============from __future__ import print_function, division
import torch
from torch import optim
from torch.autograd import Variable
from torch.utils.data import DataLoader
import numpy as np
import torch.nn as nn
import torch.nn.functional as F
import Unet
import Unet_BatchNorm
import tifffile as tiff
import Utils
import time
from sklearn.metrics import average_precision_score, recall_score, f1_score
import Analysis
import Unet_ResNet

def to_var(x):
    if torch.cuda.is_available():
        return Variable(x.cuda())
    else:
        return Variable(x)

### BinaryCrossEntropyLoss2d().forward(logits, labels)
class BinaryCrossEntropyLoss2d(nn.Module):
    def __init__(self, weight=None, size_average=True):
        """
        Binary cross entropy loss 2D
        Args:
            weight:
            size_average:
        """
        super(BinaryCrossEntropyLoss2d, self).__init__()
        self.bce_loss = nn.BCELoss(weight, size_average)

    def forward(self, probs, targets):
        probs = F.sigmoid(probs)
        probs_flat = probs.view(-1)  # Flatten
        targets_flat = targets.view(-1)  # Flatten
        return self.bce_loss(probs_flat, targets_flat)      # (output, labels)

class SoftDiceLoss(nn.Module):
    def __init__(self, weight=None, size_average=True):
        super(SoftDiceLoss, self).__init__()

    def forward(self, probs, targets):
        smooth = 1
        # num = targets.size(0)
        probs = F.sigmoid(probs)
        m1 = probs.view(-1)
        m2 = targets.view(-1)
        intersection = (m1 * m2)
        score = 2. * (intersection.sum() + smooth) / (m1.sum() + m2.sum() + smooth)
        score = 1 - score.sum()
        return score

def _criterion(logits, labels):
    return BinaryCrossEntropyLoss2d().forward(logits, labels) + \
        SoftDiceLoss().forward(logits, labels)

def NetEval(net,valdata_loader,crit):
    loss = 0.
    count = 0
    net.eval()
    for i,data in enumerate(valdata_loader,0):
        inputs, labels = data
        inputs, labels = to_var(inputs), to_var(labels)
        out = net(inputs)
        l = crit(out, labels)
        loss += l.data[0]
        count += 1
    return loss/count

# calculate Precision, Recall, F1-measure, IoU over the validation set
def Net_performace_val(net,valdata_loader):
    precision_list = []
    recall_list = []
    iou_list = []
    net.eval()
    print("len of valdata: ", len(valdata_loader))
    for i,data in enumerate(valdata_loader,0):

        inputs, labels = data
        out = NetPredict(net, inputs)   # out is numpy array 512x512
        labels = labels.numpy()
        labels = labels[0,0,:,:]        # labels is numpy array 512x512
        # remove the case where the mask is plain black
        if np.sum(labels) < 0.01*np.shape(labels)[0]*np.shape(labels)[1]: continue

        precision = average_precision_score(labels, out)
        recall = recall_score(labels, out, average='weighted')
        iou = IoU(out, labels)
        precision_list.append(precision)
        recall_list.append(recall)
        iou_list.append(iou)

    precision, recall, iou = np.mean(precision_list), np.mean(recall_list), np.mean(iou_list)
    F1_measure = 2.0*precision*recall/(precision + recall)

    return precision, recall, F1_measure, iou

# calculate IoU
def IoU(pred, target):
    # Ignore IoU for background class
    cls = 0.5
    pred_inds = pred > cls
    target_inds = target > cls

    intersection = (pred_inds[target_inds]).sum()  # Cast to long to prevent overflows
    union = pred_inds.sum() + target_inds.sum() - intersection
    if union == 0:
        ious = float('nan')  # If there is no ground truth, do not include in evaluation
    else:
        ious = 1.0*intersection / max(union, 1)
    return ious

#process the test data and save to separate .tif image
def NetTest(net,testdata_loader,path = "data/results/"):
    net.eval()
    for i, data in enumerate(testdata_loader, 0):
        if i >= 30: return 1        # for debug
        data = to_var(data)
        out = net(data)

        out = F.sigmoid(out)

        imgname = path + str(i) + ".tif"
        img = out.cpu()
        img = img[0,0,:,:]
        img = img.data.numpy()
        img_shape = img.shape
        img = img.reshape(-1)
        img[img < 0.5] = 0; img[img >= 0.5] = 1
        img = img.reshape(img_shape)
        img = np.uint8(img * 255)
        tiff.imsave(imgname, img)

# return input image size like 512x512, numpy array
def NetPredict(net, data):
    net.eval()
    data = to_var(data)
    out = net(data)

    out = F.sigmoid(out)

    img = out.cpu()
    img = img[0, 0, :, :]
    img = img.data.numpy()
    img_shape = img.shape
    img = img.reshape(-1)
    img[img < 0.5] = 0;
    img[img >= 0.5] = 1
    img = img.reshape(img_shape)
    return img
def write_2_log(content):
    path = "log_file.txt"
    output = open(path, "a")
    output.write("\n")
    output.write(content)
    output.close()

if __name__ == '__main__':
    '''subjects to change for each exp:
    + path to the dataset
    + opt function
    + leg description
    + N_epoch
    + saved_model
    '''
    start_begining = time.time()

    path = "data/dataset"
    # path = "/home/anhxtuan/HanLe/dataset/20aug_10ela_3inten_reflect"

    import os
    print("Does the folder exist?: ", os.path.isdir(path))
    print("Does the path exist?: ", os.path.exists(path))

    # imgs_train, imgs_mask_train = Utils.load_train_data(npy_path=path)
    # trainset = zip(imgs_train, imgs_mask_train)
    # trainloader = torch.utils.data.DataLoader(trainset, batch_size=1,
    #                                           shuffle=True, num_workers=2)

    imgs_val, imgs_mask_val = Utils.load_val_data(npy_path=path)
    valset = zip(imgs_val, imgs_mask_val)
    valloader = torch.utils.data.DataLoader(valset, batch_size=1,
                                              shuffle=False, num_workers=2)
    # net = Unet.UNet()                     # Unet 1
    net = Unet_BatchNorm.UNet_BN()          # Unet 2 with batchNorm
    # net = Unet_ResNet.UNet_ResNet()

    f1 = open("Unet_BatchNorm.py", 'r')     # embede code into the model to be saved later
    # f1 = open("Unet_ResNet.py", 'r')
    f2 = open("UnetTrain.py", 'r')
    f3 = open("Utils.py", 'r')
    model_notes = time.strftime("%c") + "\n" + f1.read() + "\n" + "==="*5 + f2.read() + "\n" + "==="*5 + f3.read()
    f1.close()
    f2.close()
    f3.close()

    # criterion = nn.BCELoss()
    criterion = BinaryCrossEntropyLoss2d()
    # criterion = SoftDiceLoss()

    if torch.cuda.is_available():
        torch.set_default_tensor_type('torch.cuda.FloatTensor')
        net.load_state_dict(torch.load("Unet2_model_6epoch_Leg14_dropout_0_2_rmSigmoid_40aug_10ela_3inten_reflect"))
        net.cuda()
        # criterion.cuda()

    opt = optim.SGD(net.parameters(), lr=1e-5, momentum=0.8)       # subject to change
    # opt = optim.RMSprop(net.parameters(), lr=1e-3, weight_decay=1e-3)
    # RMSprop[22](learning rate 0.001) with weight decay set to 0.001.
    # opt = optim.Adam(net.parameters(), lr=1e-3, weight_decay=1e-4)

    train_loss = []
    val_loss = []

    print("[epoch, #image] Loss")
    leg = "Legxxxx_Unet_add_20elas_dropout_0_2_rmSigmoid_40aug_10ela_3inten_reflect"
    print("Processing: ", leg)
    model_name = ""

    N_epoch = 2
    # model_saved = np.arange(2,N_epoch+1,2)
    model_saved = [1, 2]
    val_loss_min = 100

    write_2_log("==="*30)
    write_2_log(time.strftime("%c"))       # time, date of exp
    write_2_log(leg)
    write_2_log(model_notes)
    write_2_log(time.strftime("%c"))  # time, date of exp
    write_2_log(leg)
    write_2_log("SGD(net.parameters(), lr=1e-5, momentum=0.8)")
    write_2_log("Number of epoch max: " + str(N_epoch))

    min_model_epoch = 0
    for epoch in range(N_epoch):
        running_loss = 0.0; count = 0
        net.train()

        N_files = 1
        for j in range(N_files):
            if N_files > 1:
                train_file = "/imgs_train_" + str(j + 1) + ".npy"
                mask_file = "/imgs_mask_train_" + str(j + 1) + ".npy"
            else:
                train_file = "/imgs_train.npy"
                mask_file = "/imgs_mask_train.npy"

            imgs_train, imgs_mask_train = Utils.load_train_data(npy_path=path, train_file=train_file, mask_file=mask_file)
            trainset = zip(imgs_train, imgs_mask_train)
            trainloader = torch.utils.data.DataLoader(trainset, batch_size=1,
                                                      shuffle=True, num_workers=2)
            for i, data in enumerate(trainloader, 0):
                inputs, labels = data
                temp = labels.numpy()
                temp = temp[0, 0, :, :]  # labels is numpy array 512x512
                # remove the case where the mask is plain black
                if np.sum(temp) < 0.01 * np.shape(temp)[0] * np.shape(temp)[1]: continue
                inputs, labels = to_var(inputs), to_var(labels)
                opt.zero_grad()
                out = net(inputs)
                loss = criterion(out, labels)
                loss.backward()
                opt.step()
                running_loss += loss.data[0]
                count += 1

        net.eval()
        val_loss_temp = NetEval(net, valloader, criterion)
        if epoch > 0 and val_loss_temp < val_loss_min:        # save the model which has the lowest val_loss, ignore first epoch
            val_loss_min = val_loss_temp
            torch.save(net.state_dict(), "Unet2_" + leg + "_min_val_loss")  # save model
            min_model_epoch = epoch + 1

        disp = 'Epoch %d: Train loss: %.6f, Val loss: %.6f' % (epoch + 1, running_loss/count, val_loss_temp)
        write_2_log(disp)
        print(disp)
        val_loss.append(val_loss_temp)
        train_loss.append(running_loss/count); running_loss = 0.0

        if (epoch + 1) in model_saved:        # save checkpoint
            model_name = "Unet2_" + str(epoch+1+6) + "epoch_" + leg
            torch.save(net.state_dict(), model_name)  # save model
            Analysis.analysis(model_file = model_name, valloader = valloader)

    write_2_log("Best model at epoch: " + str(min_model_epoch))
    write_2_log("Total training time: " + str((time.time() - start_begining) / 3600.0))

    val_loss_file = "data/results" + "/val_loss_" + str(N_epoch) + "epoch_" + leg + ".npy"
    train_loss_file = "data/results" + "/training_loss_" + str(N_epoch) + "epoch_" + leg + ".npy"

    np.save(val_loss_file, val_loss)
    np.save(train_loss_file, train_loss)
    print("total processing time in seconds: ", time.time() - start_begining)
    print("total processing time in mins: ", (time.time() - start_begining) / 60.0)
    print("total processing time in hours: ", (time.time() - start_begining) / 3600.0)

    # Analysis.analysis(model_file="ResNet_" + leg + "_min_val_loss", valloader=valloader)

    Analysis.PlotLoss(model_file = model_name, loss_train_path = train_loss_file, loss_val_path = val_loss_file, epoch_No = N_epoch)

    write_2_log(time.strftime("%c"))  # time, date of exp
===============import numpy as np
import torch.nn as nn
import torch
import cv2
from lcn import LecunLCN

LCN_enable = False

def input_filled_mirroring(x):      # fill missing data by mirroring the input image
    '''input size 636 --> output size 512'''
    w, h = x.shape
    e = 62  # extra width on 1 edge
    y = np.zeros((h + e * 2, w + e * 2))
    y[e:h + e, e:w + e] = x
    y[e:e + h, 0:e] = np.flip(y[e:e + h, e:2 * e], 1)  # flip vertically
    y[e:e + h, e + w:2 * e + w] = np.flip(y[e:e + h, w:e + w], 1)  # flip vertically
    y[0:e, 0:2 * e + w] = np.flip(y[e:2 * e, 0:2 * e + w], 0)  # flip horizontally
    y[e + h:2 * e + h, 0:2 * e + w] = np.flip(y[h:e + h, 0:2 * e + w], 0)  # flip horizontally
    return y

def nearest_cells_distance(pos, img):
    # searching in 8 directions to find 2 nearest distances to neighbor cells
    curr_value = img[pos]
    w = img.shape[0];h = img.shape[1]
    count_detect = 0  # detect 2 nearest neighbors. break the search if count_detect = 2
    x, y = pos

    # print("w,h: ", (w, h))
    d1 = 9999999;d2 = 9999999;d3 = 9999999;d4 = 9999999
    d5 = 9999999;d6 = 9999999;d7 = 9999999;d8 = 9999999
    for i in range(1, max(w, h)):
        # (x+1, y), (x+1, y+1), (x+1, y-1),
        # (x, y+1), (x, y-1)
        # (x-1, y), (x-1,y+1), (x-1,y-1),
        if x + i < w:
            if img[(x + i, y)] != curr_value and d1 == 9999999:
                d1 = i; count_detect += 1
            if y + i < h:
                if img[(x + i, y + i)] != curr_value and d2 == 9999999:
                    d2 = i; count_detect += 1
            elif y - i >= 0:
                if img[(x + i, y - i)] != curr_value and d3 == 9999999:
                    d3 = i; count_detect += 1
        if y + i < h:
            if img[(x, y + i)] != curr_value and d4 == 9999999:
                d4 = i; count_detect += 1
        if y - i >= 0:
            if img[(x, y - i)] != curr_value and d5 == 9999999:
                d5 = i; count_detect += 1
        if x - i >= 0:
            if img[(x - i, y)] != curr_value and d6 == 9999999:
                d6 = i; count_detect += 1
            if y + i < h:
                if img[(x - i, y + i)] != curr_value and d7 == 9999999:
                    d7 = i; count_detect += 1
            elif y - i >= 0:
                if img[(x - i, y - i)] != curr_value and d8 == 9999999:
                    d8 = i; count_detect += 1
        if count_detect >= 2: break

    d = [d1, d2, d3, d4, d5, d6, d7, d8]
    min_index = np.argmin(d)
    dist1 = d[min_index]
    d.remove(dist1)
    min_index = np.argmin(d)
    dist2 = d[min_index]
    return dist1, dist2

def create_weight_map(imgs_mask):
        print('-' * 30)
        print('Creating weights for masks ...')
        print('-' * 30)
        weight_map = np.ndarray(
            (len(imgs_mask), 1, np.shape(imgs_mask)[2], np.shape(imgs_mask)[3]), dtype=np.float32)
        w_0 = 10; sigma = 4
        imgs_w, imgs_h = np.shape(imgs_mask)[2], np.shape(imgs_mask)[3]
        total_pixels = imgs_w*imgs_h
        import time
        start = time.time()
        for i in range(len(imgs_mask)):
            if i%10 == 0: print("Done processing: %d images, time passed: %.2f mins" % (i, (time.time() - start)/60.0))
            temp = imgs_mask[i,0,:,:]
            w_border = 1 - np.sum(temp)/total_pixels        # w_c of pixel on the border (black)
            for m in range(imgs_w):
                for n in range(imgs_h):
                    # loop through all pixel of the mask
                    d1,d2 = nearest_cells_distance((m,n), temp)
                    w_c = w_border
                    if temp[m,n] == 0: w_c = 1 - w_border
                    weight_map[i,0,m,n] = w_c*5 + w_0*np.exp(-(d1 + d2)**2/(2*sigma**2))
                    # print("w_0*np.exp(): ", w_0*np.exp(-(d1 + d2)**2/(2*sigma**2)))
                    # print("w_border: ", w_border)

        np.save('data/dataset/weight_map_train.npy', weight_map)

        return weight_map

def load_train_data(npy_path = "data/dataset", train_file = "/imgs_train.npy", mask_file = "/imgs_mask_train.npy", hist_equal = False):

    print('-' * 30)
    print('load train images...')

    imgs_train = np.load(npy_path + train_file)
    imgs_mask_train = np.load(npy_path + mask_file)

    if hist_equal: imgs_train = hist_equalization(imgs_train)

    # weight_map_train = np.load(npy_path + "/weight_map_train.npy")
    # weight_map_train = weight_map_train.astype('float32')

    imgs_train = imgs_train.astype('float32')
    imgs_mask_train = imgs_mask_train.astype('float32')

    if LCN_enable:
        imgs_train = imgs_train.astype('float64')
        imgs_train = LecunLCN(imgs_train, image_shape=imgs_train.shape).output.eval()
        imgs_train = imgs_train.astype('float32')

    if not LCN_enable: imgs_train /= 255

    imgs_train -= imgs_train.mean(axis=0)
    imgs_mask_train /= 255
    imgs_mask_train[imgs_mask_train > 0.5] = 1
    imgs_mask_train[imgs_mask_train <= 0.5] = 0

    # weight_map_train = create_weight_map(imgs_mask_train)

    print("Done loading traing data")
    print('-' * 30)
    return imgs_train, imgs_mask_train

def load_val_data(npy_path = "data/dataset", hist_equal = True):

    print('-' * 30)
    print('load validation images...')

    imgs_train = np.load(npy_path + "/imgs_val.npy")
    imgs_mask_train = np.load(npy_path + "/imgs_mask_val.npy")

    if hist_equal: imgs_train = hist_equalization(imgs_train)

    imgs_train = imgs_train.astype('float32')
    imgs_mask_train = imgs_mask_train.astype('float32')

    if LCN_enable:
        imgs_train = imgs_train.astype('float64')
        imgs_train = LecunLCN(imgs_train, image_shape=imgs_train.shape).output.eval()
        imgs_train = imgs_train.astype('float32')

    if not LCN_enable: imgs_train /= 255
    imgs_train -= imgs_train.mean(axis=0)
    imgs_mask_train /= 255
    imgs_mask_train[imgs_mask_train > 0.5] = 1
    imgs_mask_train[imgs_mask_train <= 0.5] = 0
    print("Done loading validation data")
    print('-' * 30)
    return imgs_train, imgs_mask_train

def load_test_data(npy_path = "data/dataset", hist_equal = True):

    print('-' * 30)
    print('load test images...')

    imgs_test = np.load(npy_path + "/imgs_test.npy")

    if hist_equal: imgs_test = hist_equalization(imgs_test)

    imgs_test = imgs_test.astype('float32')

    if LCN_enable:
        imgs_test = imgs_test.astype('float64')
        imgs_test = LecunLCN(imgs_test, image_shape=imgs_test.shape).output.eval()
        imgs_test = imgs_test.astype('float32')

    if not LCN_enable: imgs_test /= 255

    imgs_test -= imgs_test.mean(axis=0)

    print("Done loading test data")
    print('-' * 30)
    return imgs_test

def load_val_5imgs(npy_path = "data/dataset"):
    print('-' * 30)
    print('load train images...')

    imgs_train = np.load(npy_path + "/imgs_val_5imgs.npy")
    imgs_mask_train = np.load(npy_path + "/imgs_mask_val_5imgs.npy")

    # imgs_train = hist_equalization(imgs_train)

    imgs_train = imgs_train.astype('float64')
    imgs_mask_train = imgs_mask_train.astype('float64')

    if LCN_enable: imgs_train = LecunLCN(imgs_train, image_shape=imgs_train.shape).output.eval()

    if not LCN_enable: imgs_train /= 255

    mean = imgs_train.mean(axis=0)
    imgs_train -= mean


    imgs_mask_train /= 255
    imgs_mask_train[imgs_mask_train > 0.5] = 1
    imgs_mask_train[imgs_mask_train <= 0.5] = 0

    # weight_map_train = self.create_weight_map(imgs_mask_train)

    print("Done loading traing data")
    print('-' * 30)
    return imgs_train, imgs_mask_train

def hist_equalization(inputs):      # inputs are uint8, 0-255, Nx1x636x636
    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))
    output = inputs.copy()
    for i in range(len(inputs)):
        img = inputs[i, 0, :, :]
        # res = cv2.equalizeHist(img)
        res = clahe.apply(img)
        output[i,0,:,:] = res
    return output

### BinaryCrossEntropyLoss2d().forward(logits, labels)
class BinaryCrossEntropyLoss2d(nn.Module):
    def __init__(self, weight=None, size_average=True):
        """
        Binary cross entropy loss 2D
        Args:
            weight:
            size_average:
        """
        super(BinaryCrossEntropyLoss2d, self).__init__()
        self.bce_loss = nn.BCELoss(weight, size_average)

    def forward(self, logits, targets):
        # probs = F.sigmoid(logits)
        probs = logits
        probs_flat = probs.view(-1)  # Flatten
        targets_flat = targets.view(-1)  # Flatten
        return self.bce_loss(probs_flat, targets_flat)      # (output, labels)

class BCE_with_Weights(nn.Module):
    def __init__(self, weights=None):
        """
        Binary cross entropy loss 2D
        Args:
            weights:
        """
        super(BCE_with_Weights, self).__init__()
        self.weights = weights

    def forward(self, output, target):
        if self.weights is not None:
            loss = self.weights * (target * torch.log(output) + (1 - target) * torch.log(1 - output))
        else:
            loss = target * torch.log(output) + (1 - target) * torch.log(1 - output)

        return torch.neg(torch.mean(loss))

class LRN(nn.Module):       # input x is Torch tensor
    def __init__(self, local_size=1, alpha=1.0, beta=0.75, ACROSS_CHANNELS=False):      #LRN(local_size=5, alpha=0.0001, beta=0.75),
        super(LRN, self).__init__()
        self.ACROSS_CHANNELS = ACROSS_CHANNELS
        if self.ACROSS_CHANNELS:
            self.average = nn.AvgPool3d(kernel_size=(local_size, 1, 1),
                                        stride=1, padding=(int((local_size - 1.0) / 2), 0, 0))
        else:
            self.average = nn.AvgPool2d(kernel_size=local_size,
                                        stride=1, padding=int((local_size - 1.0) / 2))
        self.alpha = alpha
        self.beta = beta

    def forward(self, x):
        if self.ACROSS_CHANNELS:
            div = x.pow(2).unsqueeze(1)
            div = self.average(div).squeeze(1)
            div = div.mul(self.alpha).add(1.0).pow(self.beta)
        else:
            div = x.pow(2)
            div = self.average(div)
            div = div.mul(self.alpha).add(1.0).pow(self.beta)
        x = x.div(div)
        return x


Sun Nov 19 21:25:55 2017
Legxxxx_Unet_add_20elas_dropout_0_2_rmSigmoid_40aug_10ela_3inten_reflect
SGD(net.parameters(), lr=1e-5, momentum=0.8)
Number of epoch max: 2
==========================================================================================
Sun Nov 19 21:26:22 2017
Legxxxx_Unet_add_20elas_dropout_0_2_rmSigmoid_40aug_10ela_3inten_reflect
Sun Nov 19 21:26:22 2017
import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.autograd import Variable
import math


class ConvBnRelu(nn.Module):
    def __init__(self, in_channels, out_channels, kernel_size, padding, stride):
        super(ConvBnRelu, self).__init__()
        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=kernel_size, padding=padding, stride=stride)
        self.bn = nn.BatchNorm2d(out_channels)
        self.relu = nn.ReLU()

    def forward(self, x):
        x = self.conv(x)
        # x = self.bn(x)
        x = self.relu(x)
        return x


class StackEncoder(nn.Module):
    def __init__(self, in_channels, out_channels):
        super(StackEncoder, self).__init__()
        self.convr1 = ConvBnRelu(in_channels, out_channels, kernel_size=(3, 3), stride=1, padding=0)
        self.convr2 = ConvBnRelu(out_channels, out_channels, kernel_size=(3, 3), stride=1, padding=0)
        self.maxPool = nn.MaxPool2d(kernel_size=(2, 2), stride=2)

    def forward(self, x):
        x = self.convr1(x)
        x = self.convr2(x)
        x_trace = x             # save x to use in concat in the Decoder path
        out = self.maxPool(x)
        return out, x_trace


class StackDecoder(nn.Module):
    def __init__(self, in_channels, out_channels, upsample_size, padding, drop_out=False):
        super(StackDecoder, self).__init__()

        self.drop_out = drop_out
        self.dropout_layer = nn.Dropout2d(p=0.5)

        ''' this is old version
        self.upSample = nn.Upsample(size=upsample_size, scale_factor=(2, 2), mode="bilinear")
        self.convr1 = ConvBnRelu(in_channels, out_channels, kernel_size=(3, 3), stride=1, padding=padding)
        # Crop + concat step between these 2
        self.convr2 = ConvBnRelu(in_channels, out_channels, kernel_size=(3, 3), stride=1, padding=padding)
        '''
        self.upSample = nn.ConvTranspose2d(in_channels, out_channels, 2, stride=2)
        self.convr1 = ConvBnRelu(in_channels, out_channels, kernel_size=(3, 3), stride=1, padding=padding)
        self.convr2 = ConvBnRelu(out_channels, out_channels, kernel_size=(3, 3), stride=1, padding=padding)

    def _crop_concat(self, upsampled, bypass):
        """
         Crop y to the (h, w) of x and concat them.
         Used for the expansive path.
        Returns:
            The concatenated tensor
        """
        c = (bypass.size()[2] - upsampled.size()[2]) // 2
        bypass = F.pad(bypass, (-c, -c, -c, -c))

        return torch.cat((bypass, upsampled), 1)

    def forward(self, x, down_tensor):
        '''old version
        x = self.upSample(x)
        x = self.convr1(x)
        x = self._crop_concat(x, down_tensor)
        x = self.convr2(x)
        '''

        x = self.upSample(x)
        x = self._crop_concat(x, down_tensor)
        x = self.convr1(x)
        if self.drop_out: x = self.dropout_layer(x)
        x = self.convr2(x)
        if self.drop_out: x = self.dropout_layer(x)
        return x


class UNet_BN(nn.Module):
    def __init__(self):
        super(UNet_BN, self).__init__()
        # channels, height, width = in_shape

        # self.dropout = dropout

        self.model_code = ""        # variable to save model and main function when loaded

        self.down1 = StackEncoder(1, 64)
        self.down2 = StackEncoder(64, 128)
        self.down3 = StackEncoder(128, 256)
        self.down4 = StackEncoder(256, 512)

        self.center = nn.Sequential(
            # nn.Dropout2d(p=0.2),
            ConvBnRelu(512, 1024, kernel_size=(3, 3), stride=1, padding=0),
            nn.Dropout2d(p=0.2),
            ConvBnRelu(1024, 1024, kernel_size=(3, 3), stride=1, padding=0),
            nn.Dropout2d(p=0.2)
        )

        self.up1 = StackDecoder(in_channels=1024, out_channels=512, upsample_size=(64,64), padding = 1)
        self.up2 = StackDecoder(in_channels=512, out_channels=256, upsample_size=(128,128), padding = 1)
        self.up3 = StackDecoder(in_channels=256, out_channels=128, upsample_size=(256,256), padding = 1)
        self.up4 = StackDecoder(in_channels=128, out_channels=64, upsample_size=(512,512), padding = 1)

        # 1x1 convolution at the last layer
        # Different from the paper is the output size here
        self.output_seg_map = nn.Conv2d(64, 1, kernel_size=(1, 1), padding=0, stride=1)

        self._initialize_weights()

    def forward(self, x):
        x, x_trace1 = self.down1(x)
        x, x_trace2 = self.down2(x)
        x, x_trace3 = self.down3(x)
        x, x_trace4 = self.down4(x)
        x = self.center(x)
        x = self.up1(x, x_trace4)
        x = self.up2(x, x_trace3)
        x = self.up3(x, x_trace2)
        x = self.up4(x, x_trace1)

        x = self.output_seg_map(x)
        # x = F.sigmoid(x)
        # out = torch.squeeze(out, dim=1)
        return x


    def _initialize_weights(self):
        for m in self.modules():
            if isinstance(m, nn.Conv2d):
                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels
                m.weight.data.normal_(0, math.sqrt(2. / n))
                if m.bias is not None:
                    m.bias.data.zero_()
            elif isinstance(m, nn.BatchNorm2d):
                m.weight.data.fill_(1)
                m.bias.data.zero_()

# x = Variable(torch.randn(1,1,636,636))       # simulate input image
# net = UNet_BN()
# out = net(x)
# print("input: ", x)
# print("output: ", out)

===============from __future__ import print_function, division
import torch
from torch import optim
from torch.autograd import Variable
from torch.utils.data import DataLoader
import numpy as np
import torch.nn as nn
import torch.nn.functional as F
import Unet
import Unet_BatchNorm
import tifffile as tiff
import Utils
import time
from sklearn.metrics import average_precision_score, recall_score, f1_score
import Analysis
import Unet_ResNet

def to_var(x):
    if torch.cuda.is_available():
        return Variable(x.cuda())
    else:
        return Variable(x)

### BinaryCrossEntropyLoss2d().forward(logits, labels)
class BinaryCrossEntropyLoss2d(nn.Module):
    def __init__(self, weight=None, size_average=True):
        """
        Binary cross entropy loss 2D
        Args:
            weight:
            size_average:
        """
        super(BinaryCrossEntropyLoss2d, self).__init__()
        self.bce_loss = nn.BCELoss(weight, size_average)

    def forward(self, probs, targets):
        probs = F.sigmoid(probs)
        probs_flat = probs.view(-1)  # Flatten
        targets_flat = targets.view(-1)  # Flatten
        return self.bce_loss(probs_flat, targets_flat)      # (output, labels)

class SoftDiceLoss(nn.Module):
    def __init__(self, weight=None, size_average=True):
        super(SoftDiceLoss, self).__init__()

    def forward(self, probs, targets):
        smooth = 1
        # num = targets.size(0)
        probs = F.sigmoid(probs)
        m1 = probs.view(-1)
        m2 = targets.view(-1)
        intersection = (m1 * m2)
        score = 2. * (intersection.sum() + smooth) / (m1.sum() + m2.sum() + smooth)
        score = 1 - score.sum()
        return score

def _criterion(logits, labels):
    return BinaryCrossEntropyLoss2d().forward(logits, labels) + \
        SoftDiceLoss().forward(logits, labels)

def NetEval(net,valdata_loader,crit):
    loss = 0.
    count = 0
    net.eval()
    for i,data in enumerate(valdata_loader,0):
        inputs, labels = data
        inputs, labels = to_var(inputs), to_var(labels)
        out = net(inputs)
        l = crit(out, labels)
        loss += l.data[0]
        count += 1
    return loss/count

# calculate Precision, Recall, F1-measure, IoU over the validation set
def Net_performace_val(net,valdata_loader):
    precision_list = []
    recall_list = []
    iou_list = []
    net.eval()
    print("len of valdata: ", len(valdata_loader))
    for i,data in enumerate(valdata_loader,0):

        inputs, labels = data
        out = NetPredict(net, inputs)   # out is numpy array 512x512
        labels = labels.numpy()
        labels = labels[0,0,:,:]        # labels is numpy array 512x512
        # remove the case where the mask is plain black
        if np.sum(labels) < 0.01*np.shape(labels)[0]*np.shape(labels)[1]: continue

        precision = average_precision_score(labels, out)
        recall = recall_score(labels, out, average='weighted')
        iou = IoU(out, labels)
        precision_list.append(precision)
        recall_list.append(recall)
        iou_list.append(iou)

    precision, recall, iou = np.mean(precision_list), np.mean(recall_list), np.mean(iou_list)
    F1_measure = 2.0*precision*recall/(precision + recall)

    return precision, recall, F1_measure, iou

# calculate IoU
def IoU(pred, target):
    # Ignore IoU for background class
    cls = 0.5
    pred_inds = pred > cls
    target_inds = target > cls

    intersection = (pred_inds[target_inds]).sum()  # Cast to long to prevent overflows
    union = pred_inds.sum() + target_inds.sum() - intersection
    if union == 0:
        ious = float('nan')  # If there is no ground truth, do not include in evaluation
    else:
        ious = 1.0*intersection / max(union, 1)
    return ious

#process the test data and save to separate .tif image
def NetTest(net,testdata_loader,path = "data/results/"):
    net.eval()
    for i, data in enumerate(testdata_loader, 0):
        if i >= 30: return 1        # for debug
        data = to_var(data)
        out = net(data)

        out = F.sigmoid(out)

        imgname = path + str(i) + ".tif"
        img = out.cpu()
        img = img[0,0,:,:]
        img = img.data.numpy()
        img_shape = img.shape
        img = img.reshape(-1)
        img[img < 0.5] = 0; img[img >= 0.5] = 1
        img = img.reshape(img_shape)
        img = np.uint8(img * 255)
        tiff.imsave(imgname, img)

# return input image size like 512x512, numpy array
def NetPredict(net, data):
    net.eval()
    data = to_var(data)
    out = net(data)

    out = F.sigmoid(out)

    img = out.cpu()
    img = img[0, 0, :, :]
    img = img.data.numpy()
    img_shape = img.shape
    img = img.reshape(-1)
    img[img < 0.5] = 0;
    img[img >= 0.5] = 1
    img = img.reshape(img_shape)
    return img
def write_2_log(content):
    path = "log_file.txt"
    output = open(path, "a")
    output.write("\n")
    output.write(content)
    output.close()

if __name__ == '__main__':
    '''subjects to change for each exp:
    + path to the dataset
    + opt function
    + leg description
    + N_epoch
    + saved_model
    '''
    start_begining = time.time()

    path = "data/dataset"
    # path = "/home/anhxtuan/HanLe/dataset/20aug_10ela_3inten_reflect"

    import os
    print("Does the folder exist?: ", os.path.isdir(path))
    print("Does the path exist?: ", os.path.exists(path))

    # imgs_train, imgs_mask_train = Utils.load_train_data(npy_path=path)
    # trainset = zip(imgs_train, imgs_mask_train)
    # trainloader = torch.utils.data.DataLoader(trainset, batch_size=1,
    #                                           shuffle=True, num_workers=2)

    imgs_val, imgs_mask_val = Utils.load_val_data(npy_path=path)
    valset = zip(imgs_val, imgs_mask_val)
    valloader = torch.utils.data.DataLoader(valset, batch_size=1,
                                              shuffle=False, num_workers=2)
    # net = Unet.UNet()                     # Unet 1
    net = Unet_BatchNorm.UNet_BN()          # Unet 2 with batchNorm
    # net = Unet_ResNet.UNet_ResNet()

    f1 = open("Unet_BatchNorm.py", 'r')     # embede code into the model to be saved later
    # f1 = open("Unet_ResNet.py", 'r')
    f2 = open("UnetTrain.py", 'r')
    f3 = open("Utils.py", 'r')
    model_notes = time.strftime("%c") + "\n" + f1.read() + "\n" + "==="*5 + f2.read() + "\n" + "==="*5 + f3.read()
    f1.close()
    f2.close()
    f3.close()

    # criterion = nn.BCELoss()
    criterion = BinaryCrossEntropyLoss2d()
    # criterion = SoftDiceLoss()

    if torch.cuda.is_available():
        torch.set_default_tensor_type('torch.cuda.FloatTensor')
        net.load_state_dict(torch.load("Unet2_model_6epoch_Leg14_dropout_0_2_rmSigmoid_40aug_10ela_3inten_reflect"))
        net.cuda()
        # criterion.cuda()

    opt = optim.SGD(net.parameters(), lr=1e-5, momentum=0.8)       # subject to change
    # opt = optim.RMSprop(net.parameters(), lr=1e-3, weight_decay=1e-3)
    # RMSprop[22](learning rate 0.001) with weight decay set to 0.001.
    # opt = optim.Adam(net.parameters(), lr=1e-3, weight_decay=1e-4)

    train_loss = []
    val_loss = []

    print("[epoch, #image] Loss")
    leg = "Legxxxx_Unet_add_20elas_dropout_0_2_rmSigmoid_40aug_10ela_3inten_reflect"
    print("Processing: ", leg)
    model_name = ""

    N_epoch = 2
    # model_saved = np.arange(2,N_epoch+1,2)
    model_saved = [1, 2]
    val_loss_min = 100

    write_2_log("==="*30)
    write_2_log(time.strftime("%c"))       # time, date of exp
    write_2_log(leg)
    write_2_log(model_notes)
    write_2_log(time.strftime("%c"))  # time, date of exp
    write_2_log(leg)
    write_2_log("SGD(net.parameters(), lr=1e-5, momentum=0.8)")
    write_2_log("Number of epoch max: " + str(N_epoch))

    min_model_epoch = 0
    for epoch in range(N_epoch):
        running_loss = 0.0; count = 0
        net.train()

        N_files = 1
        for j in range(N_files):
            if N_files > 1:
                train_file = "/imgs_train_" + str(j + 1) + ".npy"
                mask_file = "/imgs_mask_train_" + str(j + 1) + ".npy"
            else:
                train_file = "/imgs_train.npy"
                mask_file = "/imgs_mask_train.npy"

            imgs_train, imgs_mask_train = Utils.load_train_data(npy_path=path, train_file=train_file, mask_file=mask_file)
            trainset = zip(imgs_train, imgs_mask_train)
            trainloader = torch.utils.data.DataLoader(trainset, batch_size=1,
                                                      shuffle=True, num_workers=2)
            for i, data in enumerate(trainloader, 0):
                inputs, labels = data
                temp = labels.numpy()
                temp = temp[0, 0, :, :]  # labels is numpy array 512x512
                # remove the case where the mask is plain black
                if np.sum(temp) < 0.01 * np.shape(temp)[0] * np.shape(temp)[1]: continue
                inputs, labels = to_var(inputs), to_var(labels)
                opt.zero_grad()
                out = net(inputs)
                loss = criterion(out, labels)
                loss.backward()
                opt.step()
                running_loss += loss.data[0]
                count += 1

        net.eval()
        val_loss_temp = NetEval(net, valloader, criterion)
        if epoch > 0 and val_loss_temp < val_loss_min:        # save the model which has the lowest val_loss, ignore first epoch
            val_loss_min = val_loss_temp
            torch.save(net.state_dict(), "Unet2_" + leg + "_min_val_loss")  # save model
            min_model_epoch = epoch + 1

        disp = 'Epoch %d: Train loss: %.6f, Val loss: %.6f' % (epoch + 1, running_loss/count, val_loss_temp)
        write_2_log(disp)
        print(disp)
        val_loss.append(val_loss_temp)
        train_loss.append(running_loss/count); running_loss = 0.0

        if (epoch + 1) in model_saved:        # save checkpoint
            model_name = "Unet2_" + str(epoch+1+6) + "epoch_" + leg
            torch.save(net.state_dict(), model_name)  # save model
            Analysis.analysis(model_file = model_name, valloader = valloader)

    write_2_log("Best model at epoch: " + str(min_model_epoch))
    write_2_log("Total training time: " + str((time.time() - start_begining) / 3600.0))

    val_loss_file = "data/results" + "/val_loss_" + str(N_epoch) + "epoch_" + leg + ".npy"
    train_loss_file = "data/results" + "/training_loss_" + str(N_epoch) + "epoch_" + leg + ".npy"

    np.save(val_loss_file, val_loss)
    np.save(train_loss_file, train_loss)
    print("total processing time in seconds: ", time.time() - start_begining)
    print("total processing time in mins: ", (time.time() - start_begining) / 60.0)
    print("total processing time in hours: ", (time.time() - start_begining) / 3600.0)

    # Analysis.analysis(model_file="ResNet_" + leg + "_min_val_loss", valloader=valloader)

    Analysis.PlotLoss(model_file = model_name, loss_train_path = train_loss_file, loss_val_path = val_loss_file, epoch_No = N_epoch)

    write_2_log(time.strftime("%c"))  # time, date of exp
===============import numpy as np
import torch.nn as nn
import torch
import cv2
from lcn import LecunLCN

LCN_enable = False

def input_filled_mirroring(x):      # fill missing data by mirroring the input image
    '''input size 636 --> output size 512'''
    w, h = x.shape
    e = 62  # extra width on 1 edge
    y = np.zeros((h + e * 2, w + e * 2))
    y[e:h + e, e:w + e] = x
    y[e:e + h, 0:e] = np.flip(y[e:e + h, e:2 * e], 1)  # flip vertically
    y[e:e + h, e + w:2 * e + w] = np.flip(y[e:e + h, w:e + w], 1)  # flip vertically
    y[0:e, 0:2 * e + w] = np.flip(y[e:2 * e, 0:2 * e + w], 0)  # flip horizontally
    y[e + h:2 * e + h, 0:2 * e + w] = np.flip(y[h:e + h, 0:2 * e + w], 0)  # flip horizontally
    return y

def nearest_cells_distance(pos, img):
    # searching in 8 directions to find 2 nearest distances to neighbor cells
    curr_value = img[pos]
    w = img.shape[0];h = img.shape[1]
    count_detect = 0  # detect 2 nearest neighbors. break the search if count_detect = 2
    x, y = pos

    # print("w,h: ", (w, h))
    d1 = 9999999;d2 = 9999999;d3 = 9999999;d4 = 9999999
    d5 = 9999999;d6 = 9999999;d7 = 9999999;d8 = 9999999
    for i in range(1, max(w, h)):
        # (x+1, y), (x+1, y+1), (x+1, y-1),
        # (x, y+1), (x, y-1)
        # (x-1, y), (x-1,y+1), (x-1,y-1),
        if x + i < w:
            if img[(x + i, y)] != curr_value and d1 == 9999999:
                d1 = i; count_detect += 1
            if y + i < h:
                if img[(x + i, y + i)] != curr_value and d2 == 9999999:
                    d2 = i; count_detect += 1
            elif y - i >= 0:
                if img[(x + i, y - i)] != curr_value and d3 == 9999999:
                    d3 = i; count_detect += 1
        if y + i < h:
            if img[(x, y + i)] != curr_value and d4 == 9999999:
                d4 = i; count_detect += 1
        if y - i >= 0:
            if img[(x, y - i)] != curr_value and d5 == 9999999:
                d5 = i; count_detect += 1
        if x - i >= 0:
            if img[(x - i, y)] != curr_value and d6 == 9999999:
                d6 = i; count_detect += 1
            if y + i < h:
                if img[(x - i, y + i)] != curr_value and d7 == 9999999:
                    d7 = i; count_detect += 1
            elif y - i >= 0:
                if img[(x - i, y - i)] != curr_value and d8 == 9999999:
                    d8 = i; count_detect += 1
        if count_detect >= 2: break

    d = [d1, d2, d3, d4, d5, d6, d7, d8]
    min_index = np.argmin(d)
    dist1 = d[min_index]
    d.remove(dist1)
    min_index = np.argmin(d)
    dist2 = d[min_index]
    return dist1, dist2

def create_weight_map(imgs_mask):
        print('-' * 30)
        print('Creating weights for masks ...')
        print('-' * 30)
        weight_map = np.ndarray(
            (len(imgs_mask), 1, np.shape(imgs_mask)[2], np.shape(imgs_mask)[3]), dtype=np.float32)
        w_0 = 10; sigma = 4
        imgs_w, imgs_h = np.shape(imgs_mask)[2], np.shape(imgs_mask)[3]
        total_pixels = imgs_w*imgs_h
        import time
        start = time.time()
        for i in range(len(imgs_mask)):
            if i%10 == 0: print("Done processing: %d images, time passed: %.2f mins" % (i, (time.time() - start)/60.0))
            temp = imgs_mask[i,0,:,:]
            w_border = 1 - np.sum(temp)/total_pixels        # w_c of pixel on the border (black)
            for m in range(imgs_w):
                for n in range(imgs_h):
                    # loop through all pixel of the mask
                    d1,d2 = nearest_cells_distance((m,n), temp)
                    w_c = w_border
                    if temp[m,n] == 0: w_c = 1 - w_border
                    weight_map[i,0,m,n] = w_c*5 + w_0*np.exp(-(d1 + d2)**2/(2*sigma**2))
                    # print("w_0*np.exp(): ", w_0*np.exp(-(d1 + d2)**2/(2*sigma**2)))
                    # print("w_border: ", w_border)

        np.save('data/dataset/weight_map_train.npy', weight_map)

        return weight_map

def load_train_data(npy_path = "data/dataset", train_file = "/imgs_train.npy", mask_file = "/imgs_mask_train.npy", hist_equal = False):

    print('-' * 30)
    print('load train images...')

    imgs_train = np.load(npy_path + train_file)
    imgs_mask_train = np.load(npy_path + mask_file)

    if hist_equal: imgs_train = hist_equalization(imgs_train)

    # weight_map_train = np.load(npy_path + "/weight_map_train.npy")
    # weight_map_train = weight_map_train.astype('float32')

    imgs_train = imgs_train.astype('float32')
    imgs_mask_train = imgs_mask_train.astype('float32')

    if LCN_enable:
        imgs_train = imgs_train.astype('float64')
        imgs_train = LecunLCN(imgs_train, image_shape=imgs_train.shape).output.eval()
        imgs_train = imgs_train.astype('float32')

    if not LCN_enable: imgs_train /= 255

    imgs_train -= imgs_train.mean(axis=0)
    imgs_mask_train /= 255
    imgs_mask_train[imgs_mask_train > 0.5] = 1
    imgs_mask_train[imgs_mask_train <= 0.5] = 0

    # weight_map_train = create_weight_map(imgs_mask_train)

    print("Done loading traing data")
    print('-' * 30)
    return imgs_train, imgs_mask_train

def load_val_data(npy_path = "data/dataset", hist_equal = True):

    print('-' * 30)
    print('load validation images...')

    imgs_train = np.load(npy_path + "/imgs_val.npy")
    imgs_mask_train = np.load(npy_path + "/imgs_mask_val.npy")

    if hist_equal: imgs_train = hist_equalization(imgs_train)

    imgs_train = imgs_train.astype('float32')
    imgs_mask_train = imgs_mask_train.astype('float32')

    if LCN_enable:
        imgs_train = imgs_train.astype('float64')
        imgs_train = LecunLCN(imgs_train, image_shape=imgs_train.shape).output.eval()
        imgs_train = imgs_train.astype('float32')

    if not LCN_enable: imgs_train /= 255
    imgs_train -= imgs_train.mean(axis=0)
    imgs_mask_train /= 255
    imgs_mask_train[imgs_mask_train > 0.5] = 1
    imgs_mask_train[imgs_mask_train <= 0.5] = 0
    print("Done loading validation data")
    print('-' * 30)
    return imgs_train, imgs_mask_train

def load_test_data(npy_path = "data/dataset", hist_equal = True):

    print('-' * 30)
    print('load test images...')

    imgs_test = np.load(npy_path + "/imgs_test.npy")

    if hist_equal: imgs_test = hist_equalization(imgs_test)

    imgs_test = imgs_test.astype('float32')

    if LCN_enable:
        imgs_test = imgs_test.astype('float64')
        imgs_test = LecunLCN(imgs_test, image_shape=imgs_test.shape).output.eval()
        imgs_test = imgs_test.astype('float32')

    if not LCN_enable: imgs_test /= 255

    imgs_test -= imgs_test.mean(axis=0)

    print("Done loading test data")
    print('-' * 30)
    return imgs_test

def load_val_5imgs(npy_path = "data/dataset"):
    print('-' * 30)
    print('load train images...')

    imgs_train = np.load(npy_path + "/imgs_val_5imgs.npy")
    imgs_mask_train = np.load(npy_path + "/imgs_mask_val_5imgs.npy")

    # imgs_train = hist_equalization(imgs_train)

    imgs_train = imgs_train.astype('float64')
    imgs_mask_train = imgs_mask_train.astype('float64')

    if LCN_enable: imgs_train = LecunLCN(imgs_train, image_shape=imgs_train.shape).output.eval()

    if not LCN_enable: imgs_train /= 255

    mean = imgs_train.mean(axis=0)
    imgs_train -= mean


    imgs_mask_train /= 255
    imgs_mask_train[imgs_mask_train > 0.5] = 1
    imgs_mask_train[imgs_mask_train <= 0.5] = 0

    # weight_map_train = self.create_weight_map(imgs_mask_train)

    print("Done loading traing data")
    print('-' * 30)
    return imgs_train, imgs_mask_train

def hist_equalization(inputs):      # inputs are uint8, 0-255, Nx1x636x636
    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))
    output = inputs.copy()
    for i in range(len(inputs)):
        img = inputs[i, 0, :, :]
        # res = cv2.equalizeHist(img)
        res = clahe.apply(img)
        output[i,0,:,:] = res
    return output

### BinaryCrossEntropyLoss2d().forward(logits, labels)
class BinaryCrossEntropyLoss2d(nn.Module):
    def __init__(self, weight=None, size_average=True):
        """
        Binary cross entropy loss 2D
        Args:
            weight:
            size_average:
        """
        super(BinaryCrossEntropyLoss2d, self).__init__()
        self.bce_loss = nn.BCELoss(weight, size_average)

    def forward(self, logits, targets):
        # probs = F.sigmoid(logits)
        probs = logits
        probs_flat = probs.view(-1)  # Flatten
        targets_flat = targets.view(-1)  # Flatten
        return self.bce_loss(probs_flat, targets_flat)      # (output, labels)

class BCE_with_Weights(nn.Module):
    def __init__(self, weights=None):
        """
        Binary cross entropy loss 2D
        Args:
            weights:
        """
        super(BCE_with_Weights, self).__init__()
        self.weights = weights

    def forward(self, output, target):
        if self.weights is not None:
            loss = self.weights * (target * torch.log(output) + (1 - target) * torch.log(1 - output))
        else:
            loss = target * torch.log(output) + (1 - target) * torch.log(1 - output)

        return torch.neg(torch.mean(loss))

class LRN(nn.Module):       # input x is Torch tensor
    def __init__(self, local_size=1, alpha=1.0, beta=0.75, ACROSS_CHANNELS=False):      #LRN(local_size=5, alpha=0.0001, beta=0.75),
        super(LRN, self).__init__()
        self.ACROSS_CHANNELS = ACROSS_CHANNELS
        if self.ACROSS_CHANNELS:
            self.average = nn.AvgPool3d(kernel_size=(local_size, 1, 1),
                                        stride=1, padding=(int((local_size - 1.0) / 2), 0, 0))
        else:
            self.average = nn.AvgPool2d(kernel_size=local_size,
                                        stride=1, padding=int((local_size - 1.0) / 2))
        self.alpha = alpha
        self.beta = beta

    def forward(self, x):
        if self.ACROSS_CHANNELS:
            div = x.pow(2).unsqueeze(1)
            div = self.average(div).squeeze(1)
            div = div.mul(self.alpha).add(1.0).pow(self.beta)
        else:
            div = x.pow(2)
            div = self.average(div)
            div = div.mul(self.alpha).add(1.0).pow(self.beta)
        x = x.div(div)
        return x


Sun Nov 19 21:26:22 2017
Legxxxx_Unet_add_20elas_dropout_0_2_rmSigmoid_40aug_10ela_3inten_reflect
SGD(net.parameters(), lr=1e-5, momentum=0.8)
Number of epoch max: 2
==========================================================================================
Sun Nov 19 21:26:44 2017
Legxxxx_Unet_add_20elas_dropout_0_2_rmSigmoid_40aug_10ela_3inten_reflect
Sun Nov 19 21:26:44 2017
import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.autograd import Variable
import math


class ConvBnRelu(nn.Module):
    def __init__(self, in_channels, out_channels, kernel_size, padding, stride):
        super(ConvBnRelu, self).__init__()
        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=kernel_size, padding=padding, stride=stride)
        self.bn = nn.BatchNorm2d(out_channels)
        self.relu = nn.ReLU()

    def forward(self, x):
        x = self.conv(x)
        # x = self.bn(x)
        x = self.relu(x)
        return x


class StackEncoder(nn.Module):
    def __init__(self, in_channels, out_channels):
        super(StackEncoder, self).__init__()
        self.convr1 = ConvBnRelu(in_channels, out_channels, kernel_size=(3, 3), stride=1, padding=0)
        self.convr2 = ConvBnRelu(out_channels, out_channels, kernel_size=(3, 3), stride=1, padding=0)
        self.maxPool = nn.MaxPool2d(kernel_size=(2, 2), stride=2)

    def forward(self, x):
        x = self.convr1(x)
        x = self.convr2(x)
        x_trace = x             # save x to use in concat in the Decoder path
        out = self.maxPool(x)
        return out, x_trace


class StackDecoder(nn.Module):
    def __init__(self, in_channels, out_channels, upsample_size, padding, drop_out=False):
        super(StackDecoder, self).__init__()

        self.drop_out = drop_out
        self.dropout_layer = nn.Dropout2d(p=0.5)

        ''' this is old version
        self.upSample = nn.Upsample(size=upsample_size, scale_factor=(2, 2), mode="bilinear")
        self.convr1 = ConvBnRelu(in_channels, out_channels, kernel_size=(3, 3), stride=1, padding=padding)
        # Crop + concat step between these 2
        self.convr2 = ConvBnRelu(in_channels, out_channels, kernel_size=(3, 3), stride=1, padding=padding)
        '''
        self.upSample = nn.ConvTranspose2d(in_channels, out_channels, 2, stride=2)
        self.convr1 = ConvBnRelu(in_channels, out_channels, kernel_size=(3, 3), stride=1, padding=padding)
        self.convr2 = ConvBnRelu(out_channels, out_channels, kernel_size=(3, 3), stride=1, padding=padding)

    def _crop_concat(self, upsampled, bypass):
        """
         Crop y to the (h, w) of x and concat them.
         Used for the expansive path.
        Returns:
            The concatenated tensor
        """
        c = (bypass.size()[2] - upsampled.size()[2]) // 2
        bypass = F.pad(bypass, (-c, -c, -c, -c))

        return torch.cat((bypass, upsampled), 1)

    def forward(self, x, down_tensor):
        '''old version
        x = self.upSample(x)
        x = self.convr1(x)
        x = self._crop_concat(x, down_tensor)
        x = self.convr2(x)
        '''

        x = self.upSample(x)
        x = self._crop_concat(x, down_tensor)
        x = self.convr1(x)
        if self.drop_out: x = self.dropout_layer(x)
        x = self.convr2(x)
        if self.drop_out: x = self.dropout_layer(x)
        return x


class UNet_BN(nn.Module):
    def __init__(self):
        super(UNet_BN, self).__init__()
        # channels, height, width = in_shape

        # self.dropout = dropout

        self.model_code = ""        # variable to save model and main function when loaded

        self.down1 = StackEncoder(1, 64)
        self.down2 = StackEncoder(64, 128)
        self.down3 = StackEncoder(128, 256)
        self.down4 = StackEncoder(256, 512)

        self.center = nn.Sequential(
            # nn.Dropout2d(p=0.2),
            ConvBnRelu(512, 1024, kernel_size=(3, 3), stride=1, padding=0),
            nn.Dropout2d(p=0.2),
            ConvBnRelu(1024, 1024, kernel_size=(3, 3), stride=1, padding=0),
            nn.Dropout2d(p=0.2)
        )

        self.up1 = StackDecoder(in_channels=1024, out_channels=512, upsample_size=(64,64), padding = 1)
        self.up2 = StackDecoder(in_channels=512, out_channels=256, upsample_size=(128,128), padding = 1)
        self.up3 = StackDecoder(in_channels=256, out_channels=128, upsample_size=(256,256), padding = 1)
        self.up4 = StackDecoder(in_channels=128, out_channels=64, upsample_size=(512,512), padding = 1)

        # 1x1 convolution at the last layer
        # Different from the paper is the output size here
        self.output_seg_map = nn.Conv2d(64, 1, kernel_size=(1, 1), padding=0, stride=1)

        self._initialize_weights()

    def forward(self, x):
        x, x_trace1 = self.down1(x)
        x, x_trace2 = self.down2(x)
        x, x_trace3 = self.down3(x)
        x, x_trace4 = self.down4(x)
        x = self.center(x)
        x = self.up1(x, x_trace4)
        x = self.up2(x, x_trace3)
        x = self.up3(x, x_trace2)
        x = self.up4(x, x_trace1)

        x = self.output_seg_map(x)
        # x = F.sigmoid(x)
        # out = torch.squeeze(out, dim=1)
        return x


    def _initialize_weights(self):
        for m in self.modules():
            if isinstance(m, nn.Conv2d):
                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels
                m.weight.data.normal_(0, math.sqrt(2. / n))
                if m.bias is not None:
                    m.bias.data.zero_()
            elif isinstance(m, nn.BatchNorm2d):
                m.weight.data.fill_(1)
                m.bias.data.zero_()

# x = Variable(torch.randn(1,1,636,636))       # simulate input image
# net = UNet_BN()
# out = net(x)
# print("input: ", x)
# print("output: ", out)

===============from __future__ import print_function, division
import torch
from torch import optim
from torch.autograd import Variable
from torch.utils.data import DataLoader
import numpy as np
import torch.nn as nn
import torch.nn.functional as F
import Unet
import Unet_BatchNorm
import tifffile as tiff
import Utils
import time
from sklearn.metrics import average_precision_score, recall_score, f1_score
import Analysis
import Unet_ResNet

def to_var(x):
    if torch.cuda.is_available():
        return Variable(x.cuda())
    else:
        return Variable(x)

### BinaryCrossEntropyLoss2d().forward(logits, labels)
class BinaryCrossEntropyLoss2d(nn.Module):
    def __init__(self, weight=None, size_average=True):
        """
        Binary cross entropy loss 2D
        Args:
            weight:
            size_average:
        """
        super(BinaryCrossEntropyLoss2d, self).__init__()
        self.bce_loss = nn.BCELoss(weight, size_average)

    def forward(self, probs, targets):
        probs = F.sigmoid(probs)
        probs_flat = probs.view(-1)  # Flatten
        targets_flat = targets.view(-1)  # Flatten
        return self.bce_loss(probs_flat, targets_flat)      # (output, labels)

class SoftDiceLoss(nn.Module):
    def __init__(self, weight=None, size_average=True):
        super(SoftDiceLoss, self).__init__()

    def forward(self, probs, targets):
        smooth = 1
        # num = targets.size(0)
        probs = F.sigmoid(probs)
        m1 = probs.view(-1)
        m2 = targets.view(-1)
        intersection = (m1 * m2)
        score = 2. * (intersection.sum() + smooth) / (m1.sum() + m2.sum() + smooth)
        score = 1 - score.sum()
        return score

def _criterion(logits, labels):
    return BinaryCrossEntropyLoss2d().forward(logits, labels) + \
        SoftDiceLoss().forward(logits, labels)

def NetEval(net,valdata_loader,crit):
    loss = 0.
    count = 0
    net.eval()
    for i,data in enumerate(valdata_loader,0):
        inputs, labels = data
        inputs, labels = to_var(inputs), to_var(labels)
        out = net(inputs)
        l = crit(out, labels)
        loss += l.data[0]
        count += 1
    return loss/count

# calculate Precision, Recall, F1-measure, IoU over the validation set
def Net_performace_val(net,valdata_loader):
    precision_list = []
    recall_list = []
    iou_list = []
    net.eval()
    print("len of valdata: ", len(valdata_loader))
    for i,data in enumerate(valdata_loader,0):

        inputs, labels = data
        out = NetPredict(net, inputs)   # out is numpy array 512x512
        labels = labels.numpy()
        labels = labels[0,0,:,:]        # labels is numpy array 512x512
        # remove the case where the mask is plain black
        if np.sum(labels) < 0.01*np.shape(labels)[0]*np.shape(labels)[1]: continue

        precision = average_precision_score(labels, out)
        recall = recall_score(labels, out, average='weighted')
        iou = IoU(out, labels)
        precision_list.append(precision)
        recall_list.append(recall)
        iou_list.append(iou)

    precision, recall, iou = np.mean(precision_list), np.mean(recall_list), np.mean(iou_list)
    F1_measure = 2.0*precision*recall/(precision + recall)

    return precision, recall, F1_measure, iou

# calculate IoU
def IoU(pred, target):
    # Ignore IoU for background class
    cls = 0.5
    pred_inds = pred > cls
    target_inds = target > cls

    intersection = (pred_inds[target_inds]).sum()  # Cast to long to prevent overflows
    union = pred_inds.sum() + target_inds.sum() - intersection
    if union == 0:
        ious = float('nan')  # If there is no ground truth, do not include in evaluation
    else:
        ious = 1.0*intersection / max(union, 1)
    return ious

#process the test data and save to separate .tif image
def NetTest(net,testdata_loader,path = "data/results/"):
    net.eval()
    for i, data in enumerate(testdata_loader, 0):
        if i >= 30: return 1        # for debug
        data = to_var(data)
        out = net(data)

        out = F.sigmoid(out)

        imgname = path + str(i) + ".tif"
        img = out.cpu()
        img = img[0,0,:,:]
        img = img.data.numpy()
        img_shape = img.shape
        img = img.reshape(-1)
        img[img < 0.5] = 0; img[img >= 0.5] = 1
        img = img.reshape(img_shape)
        img = np.uint8(img * 255)
        tiff.imsave(imgname, img)

# return input image size like 512x512, numpy array
def NetPredict(net, data):
    net.eval()
    data = to_var(data)
    out = net(data)

    out = F.sigmoid(out)

    img = out.cpu()
    img = img[0, 0, :, :]
    img = img.data.numpy()
    img_shape = img.shape
    img = img.reshape(-1)
    img[img < 0.5] = 0;
    img[img >= 0.5] = 1
    img = img.reshape(img_shape)
    return img
def write_2_log(content):
    path = "log_file.txt"
    output = open(path, "a")
    output.write("\n")
    output.write(content)
    output.close()

if __name__ == '__main__':
    '''subjects to change for each exp:
    + path to the dataset
    + opt function
    + leg description
    + N_epoch
    + saved_model
    '''
    start_begining = time.time()

    path = "data/dataset"
    # path = "/home/anhxtuan/HanLe/dataset/20aug_10ela_3inten_reflect"

    import os
    print("Does the folder exist?: ", os.path.isdir(path))
    print("Does the path exist?: ", os.path.exists(path))

    # imgs_train, imgs_mask_train = Utils.load_train_data(npy_path=path)
    # trainset = zip(imgs_train, imgs_mask_train)
    # trainloader = torch.utils.data.DataLoader(trainset, batch_size=1,
    #                                           shuffle=True, num_workers=2)

    imgs_val, imgs_mask_val = Utils.load_val_data(npy_path=path)
    valset = zip(imgs_val, imgs_mask_val)
    valloader = torch.utils.data.DataLoader(valset, batch_size=1,
                                              shuffle=False, num_workers=2)
    # net = Unet.UNet()                     # Unet 1
    net = Unet_BatchNorm.UNet_BN()          # Unet 2 with batchNorm
    # net = Unet_ResNet.UNet_ResNet()

    f1 = open("Unet_BatchNorm.py", 'r')     # embede code into the model to be saved later
    # f1 = open("Unet_ResNet.py", 'r')
    f2 = open("UnetTrain.py", 'r')
    f3 = open("Utils.py", 'r')
    model_notes = time.strftime("%c") + "\n" + f1.read() + "\n" + "==="*5 + f2.read() + "\n" + "==="*5 + f3.read()
    f1.close()
    f2.close()
    f3.close()

    # criterion = nn.BCELoss()
    criterion = BinaryCrossEntropyLoss2d()
    # criterion = SoftDiceLoss()

    if torch.cuda.is_available():
        torch.set_default_tensor_type('torch.cuda.FloatTensor')
        net.load_state_dict(torch.load("Unet2_model_6epoch_Leg14_dropout_0_2_rmSigmoid_40aug_10ela_3inten_reflect"))
        net.cuda()
        # criterion.cuda()

    opt = optim.SGD(net.parameters(), lr=1e-5, momentum=0.8)       # subject to change
    # opt = optim.RMSprop(net.parameters(), lr=1e-3, weight_decay=1e-3)
    # RMSprop[22](learning rate 0.001) with weight decay set to 0.001.
    # opt = optim.Adam(net.parameters(), lr=1e-3, weight_decay=1e-4)

    train_loss = []
    val_loss = []

    print("[epoch, #image] Loss")
    leg = "Legxxxx_Unet_add_20elas_dropout_0_2_rmSigmoid_40aug_10ela_3inten_reflect"
    print("Processing: ", leg)
    model_name = ""

    N_epoch = 2
    # model_saved = np.arange(2,N_epoch+1,2)
    model_saved = [1, 2]
    val_loss_min = 100

    write_2_log("==="*30)
    write_2_log(time.strftime("%c"))       # time, date of exp
    write_2_log(leg)
    write_2_log(model_notes)
    write_2_log(time.strftime("%c"))  # time, date of exp
    write_2_log(leg)
    write_2_log("SGD(net.parameters(), lr=1e-5, momentum=0.8)")
    write_2_log("Number of epoch max: " + str(N_epoch))

    min_model_epoch = 0
    for epoch in range(N_epoch):
        running_loss = 0.0; count = 0
        net.train()

        N_files = 1
        for j in range(N_files):
            if N_files > 1:
                train_file = "/imgs_train_" + str(j + 1) + ".npy"
                mask_file = "/imgs_mask_train_" + str(j + 1) + ".npy"
            else:
                train_file = "/imgs_train.npy"
                mask_file = "/imgs_mask_train.npy"

            imgs_train, imgs_mask_train = Utils.load_train_data(npy_path=path, train_file=train_file, mask_file=mask_file)
            trainset = zip(imgs_train, imgs_mask_train)
            trainloader = torch.utils.data.DataLoader(trainset, batch_size=1,
                                                      shuffle=True, num_workers=2)
            for i, data in enumerate(trainloader, 0):
                inputs, labels = data
                temp = labels.numpy()
                temp = temp[0, 0, :, :]  # labels is numpy array 512x512
                # remove the case where the mask is plain black
                if np.sum(temp) < 0.01 * np.shape(temp)[0] * np.shape(temp)[1]: continue
                inputs, labels = to_var(inputs), to_var(labels)
                opt.zero_grad()
                out = net(inputs)
                loss = criterion(out, labels)
                loss.backward()
                opt.step()
                running_loss += loss.data[0]
                count += 1

        net.eval()
        val_loss_temp = NetEval(net, valloader, criterion)
        if epoch > 0 and val_loss_temp < val_loss_min:        # save the model which has the lowest val_loss, ignore first epoch
            val_loss_min = val_loss_temp
            torch.save(net.state_dict(), "Unet2_" + leg + "_min_val_loss")  # save model
            min_model_epoch = epoch + 1

        disp = 'Epoch %d: Train loss: %.6f, Val loss: %.6f' % (epoch + 1, running_loss/count, val_loss_temp)
        write_2_log(disp)
        print(disp)
        val_loss.append(val_loss_temp)
        train_loss.append(running_loss/count); running_loss = 0.0

        if (epoch + 1) in model_saved:        # save checkpoint
            model_name = "Unet2_" + str(epoch+1+6) + "epoch_" + leg
            torch.save(net.state_dict(), model_name)  # save model
            Analysis.analysis(model_file = model_name, valloader = valloader)

    write_2_log("Best model at epoch: " + str(min_model_epoch))
    write_2_log("Total training time: " + str((time.time() - start_begining) / 3600.0))

    val_loss_file = "data/results" + "/val_loss_" + str(N_epoch) + "epoch_" + leg + ".npy"
    train_loss_file = "data/results" + "/training_loss_" + str(N_epoch) + "epoch_" + leg + ".npy"

    np.save(val_loss_file, val_loss)
    np.save(train_loss_file, train_loss)
    print("total processing time in seconds: ", time.time() - start_begining)
    print("total processing time in mins: ", (time.time() - start_begining) / 60.0)
    print("total processing time in hours: ", (time.time() - start_begining) / 3600.0)

    # Analysis.analysis(model_file="ResNet_" + leg + "_min_val_loss", valloader=valloader)

    Analysis.PlotLoss(model_file = model_name, loss_train_path = train_loss_file, loss_val_path = val_loss_file, epoch_No = N_epoch)

    write_2_log(time.strftime("%c"))  # time, date of exp
===============import numpy as np
import torch.nn as nn
import torch
import cv2
from lcn import LecunLCN

LCN_enable = False

def input_filled_mirroring(x):      # fill missing data by mirroring the input image
    '''input size 636 --> output size 512'''
    w, h = x.shape
    e = 62  # extra width on 1 edge
    y = np.zeros((h + e * 2, w + e * 2))
    y[e:h + e, e:w + e] = x
    y[e:e + h, 0:e] = np.flip(y[e:e + h, e:2 * e], 1)  # flip vertically
    y[e:e + h, e + w:2 * e + w] = np.flip(y[e:e + h, w:e + w], 1)  # flip vertically
    y[0:e, 0:2 * e + w] = np.flip(y[e:2 * e, 0:2 * e + w], 0)  # flip horizontally
    y[e + h:2 * e + h, 0:2 * e + w] = np.flip(y[h:e + h, 0:2 * e + w], 0)  # flip horizontally
    return y

def nearest_cells_distance(pos, img):
    # searching in 8 directions to find 2 nearest distances to neighbor cells
    curr_value = img[pos]
    w = img.shape[0];h = img.shape[1]
    count_detect = 0  # detect 2 nearest neighbors. break the search if count_detect = 2
    x, y = pos

    # print("w,h: ", (w, h))
    d1 = 9999999;d2 = 9999999;d3 = 9999999;d4 = 9999999
    d5 = 9999999;d6 = 9999999;d7 = 9999999;d8 = 9999999
    for i in range(1, max(w, h)):
        # (x+1, y), (x+1, y+1), (x+1, y-1),
        # (x, y+1), (x, y-1)
        # (x-1, y), (x-1,y+1), (x-1,y-1),
        if x + i < w:
            if img[(x + i, y)] != curr_value and d1 == 9999999:
                d1 = i; count_detect += 1
            if y + i < h:
                if img[(x + i, y + i)] != curr_value and d2 == 9999999:
                    d2 = i; count_detect += 1
            elif y - i >= 0:
                if img[(x + i, y - i)] != curr_value and d3 == 9999999:
                    d3 = i; count_detect += 1
        if y + i < h:
            if img[(x, y + i)] != curr_value and d4 == 9999999:
                d4 = i; count_detect += 1
        if y - i >= 0:
            if img[(x, y - i)] != curr_value and d5 == 9999999:
                d5 = i; count_detect += 1
        if x - i >= 0:
            if img[(x - i, y)] != curr_value and d6 == 9999999:
                d6 = i; count_detect += 1
            if y + i < h:
                if img[(x - i, y + i)] != curr_value and d7 == 9999999:
                    d7 = i; count_detect += 1
            elif y - i >= 0:
                if img[(x - i, y - i)] != curr_value and d8 == 9999999:
                    d8 = i; count_detect += 1
        if count_detect >= 2: break

    d = [d1, d2, d3, d4, d5, d6, d7, d8]
    min_index = np.argmin(d)
    dist1 = d[min_index]
    d.remove(dist1)
    min_index = np.argmin(d)
    dist2 = d[min_index]
    return dist1, dist2

def create_weight_map(imgs_mask):
        print('-' * 30)
        print('Creating weights for masks ...')
        print('-' * 30)
        weight_map = np.ndarray(
            (len(imgs_mask), 1, np.shape(imgs_mask)[2], np.shape(imgs_mask)[3]), dtype=np.float32)
        w_0 = 10; sigma = 4
        imgs_w, imgs_h = np.shape(imgs_mask)[2], np.shape(imgs_mask)[3]
        total_pixels = imgs_w*imgs_h
        import time
        start = time.time()
        for i in range(len(imgs_mask)):
            if i%10 == 0: print("Done processing: %d images, time passed: %.2f mins" % (i, (time.time() - start)/60.0))
            temp = imgs_mask[i,0,:,:]
            w_border = 1 - np.sum(temp)/total_pixels        # w_c of pixel on the border (black)
            for m in range(imgs_w):
                for n in range(imgs_h):
                    # loop through all pixel of the mask
                    d1,d2 = nearest_cells_distance((m,n), temp)
                    w_c = w_border
                    if temp[m,n] == 0: w_c = 1 - w_border
                    weight_map[i,0,m,n] = w_c*5 + w_0*np.exp(-(d1 + d2)**2/(2*sigma**2))
                    # print("w_0*np.exp(): ", w_0*np.exp(-(d1 + d2)**2/(2*sigma**2)))
                    # print("w_border: ", w_border)

        np.save('data/dataset/weight_map_train.npy', weight_map)

        return weight_map

def load_train_data(npy_path = "data/dataset", train_file = "/imgs_train.npy", mask_file = "/imgs_mask_train.npy", hist_equal = False):

    print('-' * 30)
    print('load train images...')

    imgs_train = np.load(npy_path + train_file)
    imgs_mask_train = np.load(npy_path + mask_file)

    if hist_equal: imgs_train = hist_equalization(imgs_train)

    # weight_map_train = np.load(npy_path + "/weight_map_train.npy")
    # weight_map_train = weight_map_train.astype('float32')

    imgs_train = imgs_train.astype('float32')
    imgs_mask_train = imgs_mask_train.astype('float32')

    if LCN_enable:
        imgs_train = imgs_train.astype('float64')
        imgs_train = LecunLCN(imgs_train, image_shape=imgs_train.shape).output.eval()
        imgs_train = imgs_train.astype('float32')

    if not LCN_enable: imgs_train /= 255

    imgs_train -= imgs_train.mean(axis=0)
    imgs_mask_train /= 255
    imgs_mask_train[imgs_mask_train > 0.5] = 1
    imgs_mask_train[imgs_mask_train <= 0.5] = 0

    # weight_map_train = create_weight_map(imgs_mask_train)

    print("Done loading traing data")
    print('-' * 30)
    return imgs_train, imgs_mask_train

def load_val_data(npy_path = "data/dataset", hist_equal = True):

    print('-' * 30)
    print('load validation images...')

    imgs_train = np.load(npy_path + "/imgs_val.npy")
    imgs_mask_train = np.load(npy_path + "/imgs_mask_val.npy")

    if hist_equal: imgs_train = hist_equalization(imgs_train)

    imgs_train = imgs_train.astype('float32')
    imgs_mask_train = imgs_mask_train.astype('float32')

    if LCN_enable:
        imgs_train = imgs_train.astype('float64')
        imgs_train = LecunLCN(imgs_train, image_shape=imgs_train.shape).output.eval()
        imgs_train = imgs_train.astype('float32')

    if not LCN_enable: imgs_train /= 255
    imgs_train -= imgs_train.mean(axis=0)
    imgs_mask_train /= 255
    imgs_mask_train[imgs_mask_train > 0.5] = 1
    imgs_mask_train[imgs_mask_train <= 0.5] = 0
    print("Done loading validation data")
    print('-' * 30)
    return imgs_train, imgs_mask_train

def load_test_data(npy_path = "data/dataset", hist_equal = True):

    print('-' * 30)
    print('load test images...')

    imgs_test = np.load(npy_path + "/imgs_test.npy")

    if hist_equal: imgs_test = hist_equalization(imgs_test)

    imgs_test = imgs_test.astype('float32')

    if LCN_enable:
        imgs_test = imgs_test.astype('float64')
        imgs_test = LecunLCN(imgs_test, image_shape=imgs_test.shape).output.eval()
        imgs_test = imgs_test.astype('float32')

    if not LCN_enable: imgs_test /= 255

    imgs_test -= imgs_test.mean(axis=0)

    print("Done loading test data")
    print('-' * 30)
    return imgs_test

def load_val_5imgs(npy_path = "data/dataset"):
    print('-' * 30)
    print('load train images...')

    imgs_train = np.load(npy_path + "/imgs_val_5imgs.npy")
    imgs_mask_train = np.load(npy_path + "/imgs_mask_val_5imgs.npy")

    # imgs_train = hist_equalization(imgs_train)

    imgs_train = imgs_train.astype('float64')
    imgs_mask_train = imgs_mask_train.astype('float64')

    if LCN_enable: imgs_train = LecunLCN(imgs_train, image_shape=imgs_train.shape).output.eval()

    if not LCN_enable: imgs_train /= 255

    mean = imgs_train.mean(axis=0)
    imgs_train -= mean


    imgs_mask_train /= 255
    imgs_mask_train[imgs_mask_train > 0.5] = 1
    imgs_mask_train[imgs_mask_train <= 0.5] = 0

    # weight_map_train = self.create_weight_map(imgs_mask_train)

    print("Done loading traing data")
    print('-' * 30)
    return imgs_train, imgs_mask_train

def hist_equalization(inputs):      # inputs are uint8, 0-255, Nx1x636x636
    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))
    output = inputs.copy()
    for i in range(len(inputs)):
        img = inputs[i, 0, :, :]
        # res = cv2.equalizeHist(img)
        res = clahe.apply(img)
        output[i,0,:,:] = res
    return output

### BinaryCrossEntropyLoss2d().forward(logits, labels)
class BinaryCrossEntropyLoss2d(nn.Module):
    def __init__(self, weight=None, size_average=True):
        """
        Binary cross entropy loss 2D
        Args:
            weight:
            size_average:
        """
        super(BinaryCrossEntropyLoss2d, self).__init__()
        self.bce_loss = nn.BCELoss(weight, size_average)

    def forward(self, logits, targets):
        # probs = F.sigmoid(logits)
        probs = logits
        probs_flat = probs.view(-1)  # Flatten
        targets_flat = targets.view(-1)  # Flatten
        return self.bce_loss(probs_flat, targets_flat)      # (output, labels)

class BCE_with_Weights(nn.Module):
    def __init__(self, weights=None):
        """
        Binary cross entropy loss 2D
        Args:
            weights:
        """
        super(BCE_with_Weights, self).__init__()
        self.weights = weights

    def forward(self, output, target):
        if self.weights is not None:
            loss = self.weights * (target * torch.log(output) + (1 - target) * torch.log(1 - output))
        else:
            loss = target * torch.log(output) + (1 - target) * torch.log(1 - output)

        return torch.neg(torch.mean(loss))

class LRN(nn.Module):       # input x is Torch tensor
    def __init__(self, local_size=1, alpha=1.0, beta=0.75, ACROSS_CHANNELS=False):      #LRN(local_size=5, alpha=0.0001, beta=0.75),
        super(LRN, self).__init__()
        self.ACROSS_CHANNELS = ACROSS_CHANNELS
        if self.ACROSS_CHANNELS:
            self.average = nn.AvgPool3d(kernel_size=(local_size, 1, 1),
                                        stride=1, padding=(int((local_size - 1.0) / 2), 0, 0))
        else:
            self.average = nn.AvgPool2d(kernel_size=local_size,
                                        stride=1, padding=int((local_size - 1.0) / 2))
        self.alpha = alpha
        self.beta = beta

    def forward(self, x):
        if self.ACROSS_CHANNELS:
            div = x.pow(2).unsqueeze(1)
            div = self.average(div).squeeze(1)
            div = div.mul(self.alpha).add(1.0).pow(self.beta)
        else:
            div = x.pow(2)
            div = self.average(div)
            div = div.mul(self.alpha).add(1.0).pow(self.beta)
        x = x.div(div)
        return x


Sun Nov 19 21:26:44 2017
Legxxxx_Unet_add_20elas_dropout_0_2_rmSigmoid_40aug_10ela_3inten_reflect
SGD(net.parameters(), lr=1e-5, momentum=0.8)
Number of epoch max: 2
==========================================================================================
Fri Nov 24 13:05:52 2017
Leg21_finetuneLeg12_dropout_0_2_rmSigmoid_20aug_10ela_3inten_reflect
Fri Nov 24 13:05:42 2017
import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.autograd import Variable
import math


class ConvBnRelu(nn.Module):
    def __init__(self, in_channels, out_channels, kernel_size, padding, stride):
        super(ConvBnRelu, self).__init__()
        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=kernel_size, padding=padding, stride=stride)
        self.bn = nn.BatchNorm2d(out_channels)
        self.relu = nn.ReLU()

    def forward(self, x):
        x = self.conv(x)
        # x = self.bn(x)
        x = self.relu(x)
        return x


class StackEncoder(nn.Module):
    def __init__(self, in_channels, out_channels):
        super(StackEncoder, self).__init__()
        self.convr1 = ConvBnRelu(in_channels, out_channels, kernel_size=(3, 3), stride=1, padding=0)
        self.convr2 = ConvBnRelu(out_channels, out_channels, kernel_size=(3, 3), stride=1, padding=0)
        self.maxPool = nn.MaxPool2d(kernel_size=(2, 2), stride=2)

    def forward(self, x):
        x = self.convr1(x)
        x = self.convr2(x)
        x_trace = x             # save x to use in concat in the Decoder path
        out = self.maxPool(x)
        return out, x_trace


class StackDecoder(nn.Module):
    def __init__(self, in_channels, out_channels, upsample_size, padding, drop_out=False):
        super(StackDecoder, self).__init__()

        self.drop_out = drop_out
        self.dropout_layer = nn.Dropout2d(p=0.5)

        ''' this is old version
        self.upSample = nn.Upsample(size=upsample_size, scale_factor=(2, 2), mode="bilinear")
        self.convr1 = ConvBnRelu(in_channels, out_channels, kernel_size=(3, 3), stride=1, padding=padding)
        # Crop + concat step between these 2
        self.convr2 = ConvBnRelu(in_channels, out_channels, kernel_size=(3, 3), stride=1, padding=padding)
        '''
        self.upSample = nn.ConvTranspose2d(in_channels, out_channels, 2, stride=2)
        self.convr1 = ConvBnRelu(in_channels, out_channels, kernel_size=(3, 3), stride=1, padding=padding)
        self.convr2 = ConvBnRelu(out_channels, out_channels, kernel_size=(3, 3), stride=1, padding=padding)

    def _crop_concat(self, upsampled, bypass):
        """
         Crop y to the (h, w) of x and concat them.
         Used for the expansive path.
        Returns:
            The concatenated tensor
        """
        c = (bypass.size()[2] - upsampled.size()[2]) // 2
        bypass = F.pad(bypass, (-c, -c, -c, -c))

        return torch.cat((bypass, upsampled), 1)

    def forward(self, x, down_tensor):
        '''old version
        x = self.upSample(x)
        x = self.convr1(x)
        x = self._crop_concat(x, down_tensor)
        x = self.convr2(x)
        '''

        x = self.upSample(x)
        x = self._crop_concat(x, down_tensor)
        x = self.convr1(x)
        if self.drop_out: x = self.dropout_layer(x)
        x = self.convr2(x)
        if self.drop_out: x = self.dropout_layer(x)
        return x


class UNet_BN(nn.Module):
    def __init__(self):
        super(UNet_BN, self).__init__()
        # channels, height, width = in_shape

        # self.dropout = dropout

        self.model_code = ""        # variable to save model and main function when loaded

        self.down1 = StackEncoder(1, 64)
        self.down2 = StackEncoder(64, 128)
        self.down3 = StackEncoder(128, 256)
        self.down4 = StackEncoder(256, 512)

        self.center = nn.Sequential(
            # nn.Dropout2d(p=0.2),
            ConvBnRelu(512, 1024, kernel_size=(3, 3), stride=1, padding=0),
            nn.Dropout2d(p=0.2),
            ConvBnRelu(1024, 1024, kernel_size=(3, 3), stride=1, padding=0),
            nn.Dropout2d(p=0.2)
        )

        self.up1 = StackDecoder(in_channels=1024, out_channels=512, upsample_size=(64,64), padding = 1)
        self.up2 = StackDecoder(in_channels=512, out_channels=256, upsample_size=(128,128), padding = 1)
        self.up3 = StackDecoder(in_channels=256, out_channels=128, upsample_size=(256,256), padding = 1)
        self.up4 = StackDecoder(in_channels=128, out_channels=64, upsample_size=(512,512), padding = 1)

        # 1x1 convolution at the last layer
        # Different from the paper is the output size here
        self.output_seg_map = nn.Conv2d(64, 1, kernel_size=(1, 1), padding=0, stride=1)

        self._initialize_weights()

    def forward(self, x):
        x, x_trace1 = self.down1(x)
        x, x_trace2 = self.down2(x)
        x, x_trace3 = self.down3(x)
        x, x_trace4 = self.down4(x)
        x = self.center(x)
        x = self.up1(x, x_trace4)
        x = self.up2(x, x_trace3)
        x = self.up3(x, x_trace2)
        x = self.up4(x, x_trace1)

        x = self.output_seg_map(x)
        # x = F.sigmoid(x)
        # out = torch.squeeze(out, dim=1)
        return x


    def _initialize_weights(self):
        for m in self.modules():
            if isinstance(m, nn.Conv2d):
                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels
                m.weight.data.normal_(0, math.sqrt(2. / n))
                if m.bias is not None:
                    m.bias.data.zero_()
            elif isinstance(m, nn.BatchNorm2d):
                m.weight.data.fill_(1)
                m.bias.data.zero_()

# x = Variable(torch.randn(1,1,636,636))       # simulate input image
# net = UNet_BN()
# out = net(x)
# print("input: ", x)
# print("output: ", out)
===============from __future__ import print_function, division
import torch
from torch import optim
from torch.autograd import Variable
from torch.utils.data import DataLoader
import numpy as np
import torch.nn as nn
import torch.nn.functional as F
import Unet_BatchNorm
import tifffile as tiff
import Utils
import time
from sklearn.metrics import average_precision_score, recall_score, f1_score
import Analysis

def to_var(x):
    if torch.cuda.is_available():
        return Variable(x.cuda())
    else:
        return Variable(x)

### BinaryCrossEntropyLoss2d().forward(logits, labels)
class BinaryCrossEntropyLoss2d(nn.Module):
    def __init__(self, weight=None, size_average=True):
        """
        Binary cross entropy loss 2D
        Args:
            weight:
            size_average:
        """
        super(BinaryCrossEntropyLoss2d, self).__init__()
        self.bce_loss = nn.BCELoss(weight, size_average)

    def forward(self, probs, targets):
        probs = F.sigmoid(probs)
        probs_flat = probs.view(-1)  # Flatten
        targets_flat = targets.view(-1)  # Flatten
        return self.bce_loss(probs_flat, targets_flat)      # (output, labels)

class SoftDiceLoss(nn.Module):
    def __init__(self, weight=None, size_average=True):
        super(SoftDiceLoss, self).__init__()

    def forward(self, probs, targets):
        smooth = 1
        num = targets.size(0)
        probs = F.sigmoid(probs)
        m1 = probs.view(num, -1)
        m2 = targets.view(num, -1)
        intersection = (m1 * m2)
        score = 2. * (intersection.sum(1) + smooth) / (m1.sum(1) + m2.sum(1) + smooth)
        score = 1 - score.sum() / num
        return score

def _criterion(logits, labels):
    return BinaryCrossEntropyLoss2d().forward(logits, labels) + \
        SoftDiceLoss().forward(logits, labels)

def NetEval(net,valdata_loader,crit):
    loss = 0.
    count = 0
    net.eval()
    for i,data in enumerate(valdata_loader,0):
        inputs, labels = data
        inputs, labels = to_var(inputs), to_var(labels)
        out = net(inputs)
        l = crit(out, labels)
        loss += l.data[0]
        count += 1
    return loss/count

# calculate Precision, Recall, F1-measure, IoU over the validation set
def Net_performace_val(net,valdata_loader):
    precision_list = []
    recall_list = []
    iou_list = []
    net.eval()
    print("len of valdata: ", len(valdata_loader))
    for i,data in enumerate(valdata_loader,0):

        inputs, labels = data
        out = NetPredict(net, inputs)   # out is numpy array 512x512
        labels = labels.numpy()
        labels = labels[0,0,:,:]        # labels is numpy array 512x512
        # remove the case where the mask is plain black
        if np.sum(labels) < 0.01*np.shape(labels)[0]*np.shape(labels)[1]: continue

        precision = average_precision_score(labels, out)
        recall = recall_score(labels, out, average='weighted')
        iou = IoU(out, labels)
        precision_list.append(precision)
        recall_list.append(recall)
        iou_list.append(iou)

    precision, recall, iou = np.mean(precision_list), np.mean(recall_list), np.mean(iou_list)
    F1_measure = 2.0*precision*recall/(precision + recall)

    return precision, recall, F1_measure, iou

# calculate IoU
def IoU(pred, target):
    # Ignore IoU for background class
    cls = 0.5
    pred_inds = pred > cls
    target_inds = target > cls

    intersection = (pred_inds[target_inds]).sum()  # Cast to long to prevent overflows
    union = pred_inds.sum() + target_inds.sum() - intersection
    if union == 0:
        ious = float('nan')  # If there is no ground truth, do not include in evaluation
    else:
        ious = 1.0*intersection / max(union, 1)
    return ious

#process the test data and save to separate .tif image
def NetTest(net,testdata_loader,path = "data/results/"):
    net.eval()
    for i, data in enumerate(testdata_loader, 0):
        if i >= 30: return 1        # for debug
        data = to_var(data)
        out = net(data)

        out = F.sigmoid(out)

        imgname = path + str(i) + ".tif"
        img = out.cpu()
        img = img[0,0,:,:]
        img = img.data.numpy()
        img_shape = img.shape
        img = img.reshape(-1)
        img[img < 0.5] = 0; img[img >= 0.5] = 1
        img = img.reshape(img_shape)
        img = np.uint8(img * 255)
        tiff.imsave(imgname, img)

# return input image size like 512x512, numpy array
def NetPredict(net, data):
    net.eval()
    data = to_var(data)
    out = net(data)

    out = F.sigmoid(out)

    img = out.cpu()
    img = img[0, 0, :, :]
    img = img.data.numpy()
    img_shape = img.shape
    img = img.reshape(-1)
    img[img < 0.5] = 0;
    img[img >= 0.5] = 1
    img = img.reshape(img_shape)
    return img
def write_2_log(content):
    path = "log_file.txt"
    output = open(path, "a")
    output.write("\n")
    output.write(content)
    output.close()

if __name__ == '__main__':
    '''subjects to change for each exp:
    + path to the dataset
    + opt function
    + leg description
    + N_epoch
    + saved_model
    '''
    start_begining = time.time()

    # path = "data/dataset"
    path = "/home/anhxtuan/HanLe/dataset/20aug_10ela_3inten_reflect"

    import os
    print("Does the folder exist?: ", os.path.isdir(path))
    print("Does the path exist?: ", os.path.exists(path))

    imgs_train, imgs_mask_train = Utils.load_train_data(npy_path=path)
    imgs_val, imgs_mask_val = Utils.load_val_data(npy_path=path)
    batch_size = 1
    trainset = zip(imgs_train, imgs_mask_train)
    trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,
                                              shuffle=True, num_workers=2)
    valset = zip(imgs_val, imgs_mask_val)
    valloader = torch.utils.data.DataLoader(valset, batch_size=batch_size,
                                              shuffle=False, num_workers=2)
    # net = Unet.UNet()                     # Unet 1
    net = Unet_BatchNorm.UNet_BN()          # Unet 2 with batchNorm

    f1 = open("Unet_BatchNorm.py", 'r')     # embede code into the model to be saved later
    f2 = open("UnetTrain.py", 'r')
    f3 = open("Utils.py", 'r')
    model_notes = time.strftime("%c") + "\n" + f1.read() + "\n" + "==="*5 + f2.read() + "\n" + "==="*5 + f3.read()
    f1.close()
    f2.close()
    f3.close()

    criterion = BinaryCrossEntropyLoss2d()
    # criterion = SoftDiceLoss()
    # criterion = nn.BCELoss()

    if torch.cuda.is_available():
        torch.set_default_tensor_type('torch.cuda.FloatTensor')
        net.load_state_dict(torch.load("Unet2_model_12epoch_Leg12_dropout_0_2_rmSigmoid_20aug_10ela_3inten_reflect"))
        net.cuda()
        # criterion.cuda()

    opt = optim.SGD(net.parameters(), lr=1e-5, momentum=0.8)       # subject to change
    # opt = optim.RMSprop(net.parameters(), lr=2e-4)
    # RMSprop[22](learning rate 0.001) with weight decay set to 0.001.
    # opt = optim.Adam(net.parameters(), lr=1e-3, weight_decay=1e-4)

    train_loss = []
    val_loss = []

    print("[epoch, #image] Loss")
    leg = "Leg21_finetuneLeg12_dropout_0_2_rmSigmoid_20aug_10ela_3inten_reflect"
    print("Processing: ", leg)
    model_name = ""

    N_epoch = 10
    model_saved = np.arange(2,N_epoch+1,2)
    val_loss_min = 100

    write_2_log("==="*30)
    write_2_log(time.strftime("%c"))       # time, date of exp
    write_2_log(leg)
    write_2_log(model_notes)
    write_2_log(time.strftime("%c"))  # time, date of exp
    write_2_log(leg)
    write_2_log("optim.SGD(net.parameters(), lr=1e-5, momentum=0.8)")
    write_2_log("Number of epoch max: " + str(N_epoch))


    min_model_epoch = 0
    for epoch in range(N_epoch):
        running_loss = 0.0; count = 0
        net.train()
        for i, data in enumerate(trainloader, 0):
            inputs, labels = data
            temp = labels.numpy()
            temp = temp[0, 0, :, :]  # labels is numpy array 512x512
            # remove the case where the mask is plain black
            if np.sum(temp) < 0.01 * np.shape(temp)[0] * np.shape(temp)[1]: continue
            inputs, labels = to_var(inputs), to_var(labels)
            opt.zero_grad()
            out = net(inputs)
            loss = criterion(out, labels)
            loss.backward()
            opt.step()
            running_loss += loss.data[0]
            count += 1

        net.eval()
        val_loss_temp = NetEval(net, valloader, criterion)
        if epoch > 0 and val_loss_temp < val_loss_min:        # save the model which has the lowest val_loss, ignore first epoch
            val_loss_min = val_loss_temp
            torch.save(net.state_dict(), "Unet2_model_" + leg + "_min_val_loss")  # save model
            min_model_epoch = epoch + 1

        disp = 'Epoch %d: Train loss: %.6f, Val loss: %.6f' % (epoch + 1, running_loss/count, val_loss_temp)
        write_2_log(disp)
        print(disp)
        val_loss.append(val_loss_temp)
        train_loss.append(running_loss/count); running_loss = 0.0

        if (epoch + 1) in model_saved:        # save checkpoint
            model_name = "Unet2_model_" + str(epoch+1) + "epoch_" + leg
            torch.save(net.state_dict(), model_name)  # save model
            Analysis.analysis(model_file = model_name, valloader = valloader)

    write_2_log("Best model at epoch: " + str(min_model_epoch))
    write_2_log("Total training time: " + str((time.time() - start_begining) / 3600.0))

    val_loss_file = "data/results" + "/val_loss_" + str(N_epoch) + "epoch_" + leg + ".npy"
    train_loss_file = "data/results" + "/training_loss_" + str(N_epoch) + "epoch_" + leg + ".npy"

    np.save(val_loss_file, val_loss)
    np.save(train_loss_file, train_loss)
    print("total processing time in seconds: ", time.time() - start_begining)
    print("total processing time in mins: ", (time.time() - start_begining) / 60.0)
    print("total processing time in hours: ", (time.time() - start_begining) / 3600.0)

    # Analysis.analysis(model_file="Unet2_model_" + leg + "_min_val_loss", valloader=valloader)

    Analysis.PlotLoss(model_file = model_name, loss_train_path = train_loss_file, loss_val_path = val_loss_file, epoch_No = N_epoch)

    write_2_log(time.strftime("%c"))  # time, date of exp
===============
import numpy as np
import torch.nn as nn
import torch
import cv2
from lcn import LecunLCN

LCN_enable = False

def input_filled_mirroring(x, e = 62):      # fill missing data by mirroring the input image
    '''input size 636 --> output size 512'''
    w, h = x.shape
    #e = 62  # extra width on 1 edge
    y = np.zeros((h + e * 2, w + e * 2))
    y[e:h + e, e:w + e] = x
    y[e:e + h, 0:e] = np.flip(y[e:e + h, e:2 * e], 1)  # flip vertically
    y[e:e + h, e + w:2 * e + w] = np.flip(y[e:e + h, w:e + w], 1)  # flip vertically
    y[0:e, 0:2 * e + w] = np.flip(y[e:2 * e, 0:2 * e + w], 0)  # flip horizontally
    y[e + h:2 * e + h, 0:2 * e + w] = np.flip(y[h:e + h, 0:2 * e + w], 0)  # flip horizontally
    return y

def nearest_cells_distance(pos, img):
    # searching in 8 directions to find 2 nearest distances to neighbor cells
    curr_value = img[pos]
    w = img.shape[0];h = img.shape[1]
    count_detect = 0  # detect 2 nearest neighbors. break the search if count_detect = 2
    x, y = pos

    # print("w,h: ", (w, h))
    d1 = 9999999;d2 = 9999999;d3 = 9999999;d4 = 9999999
    d5 = 9999999;d6 = 9999999;d7 = 9999999;d8 = 9999999
    for i in range(1, max(w, h)):
        # (x+1, y), (x+1, y+1), (x+1, y-1),
        # (x, y+1), (x, y-1)
        # (x-1, y), (x-1,y+1), (x-1,y-1),
        if x + i < w:
            if img[(x + i, y)] != curr_value and d1 == 9999999:
                d1 = i; count_detect += 1
            if y + i < h:
                if img[(x + i, y + i)] != curr_value and d2 == 9999999:
                    d2 = i; count_detect += 1
            elif y - i >= 0:
                if img[(x + i, y - i)] != curr_value and d3 == 9999999:
                    d3 = i; count_detect += 1
        if y + i < h:
            if img[(x, y + i)] != curr_value and d4 == 9999999:
                d4 = i; count_detect += 1
        if y - i >= 0:
            if img[(x, y - i)] != curr_value and d5 == 9999999:
                d5 = i; count_detect += 1
        if x - i >= 0:
            if img[(x - i, y)] != curr_value and d6 == 9999999:
                d6 = i; count_detect += 1
            if y + i < h:
                if img[(x - i, y + i)] != curr_value and d7 == 9999999:
                    d7 = i; count_detect += 1
            elif y - i >= 0:
                if img[(x - i, y - i)] != curr_value and d8 == 9999999:
                    d8 = i; count_detect += 1
        if count_detect >= 2: break

    d = [d1, d2, d3, d4, d5, d6, d7, d8]
    min_index = np.argmin(d)
    dist1 = d[min_index]
    d.remove(dist1)
    min_index = np.argmin(d)
    dist2 = d[min_index]
    return dist1, dist2

def create_weight_map(imgs_mask):
        print('-' * 30)
        print('Creating weights for masks ...')
        print('-' * 30)
        weight_map = np.ndarray(
            (len(imgs_mask), 1, np.shape(imgs_mask)[2], np.shape(imgs_mask)[3]), dtype=np.float32)
        w_0 = 10; sigma = 4
        imgs_w, imgs_h = np.shape(imgs_mask)[2], np.shape(imgs_mask)[3]
        total_pixels = imgs_w*imgs_h
        import time
        start = time.time()
        for i in range(len(imgs_mask)):
            if i%10 == 0: print("Done processing: %d images, time passed: %.2f mins" % (i, (time.time() - start)/60.0))
            temp = imgs_mask[i,0,:,:]
            w_border = 1 - np.sum(temp)/total_pixels        # w_c of pixel on the border (black)
            for m in range(imgs_w):
                for n in range(imgs_h):
                    # loop through all pixel of the mask
                    d1,d2 = nearest_cells_distance((m,n), temp)
                    w_c = w_border
                    if temp[m,n] == 0: w_c = 1 - w_border
                    weight_map[i,0,m,n] = w_c*5 + w_0*np.exp(-(d1 + d2)**2/(2*sigma**2))
                    # print("w_0*np.exp(): ", w_0*np.exp(-(d1 + d2)**2/(2*sigma**2)))
                    # print("w_border: ", w_border)

        np.save('data/dataset/weight_map_train.npy', weight_map)

        return weight_map

def load_train_data(npy_path = "data/dataset", hist_equal = False):

    print('-' * 30)
    print('load train images...')

    imgs_train = np.load(npy_path + "/imgs_train.npy")
    imgs_mask_train = np.load(npy_path + "/imgs_mask_train.npy")

    if hist_equal: imgs_train = hist_equalization(imgs_train)

    # weight_map_train = np.load(npy_path + "/weight_map_train.npy")
    # weight_map_train = weight_map_train.astype('float32')

    imgs_train = imgs_train.astype('float32')
    imgs_mask_train = imgs_mask_train.astype('float32')

    if LCN_enable:
        imgs_train = imgs_train.astype('float64')
        imgs_train = LecunLCN(imgs_train, image_shape=imgs_train.shape).output.eval()
        imgs_train = imgs_train.astype('float32')

    if not LCN_enable: imgs_train /= 255

    imgs_train -= imgs_train.mean(axis=0)
    imgs_mask_train /= 255
    imgs_mask_train[imgs_mask_train > 0.5] = 1
    imgs_mask_train[imgs_mask_train <= 0.5] = 0

    # weight_map_train = create_weight_map(imgs_mask_train)

    print("Done loading traing data")
    print('-' * 30)
    return imgs_train, imgs_mask_train

def load_val_data(npy_path = "data/dataset", hist_equal = True):

    print('-' * 30)
    print('load validation images...')

    imgs_train = np.load(npy_path + "/imgs_val.npy")
    imgs_mask_train = np.load(npy_path + "/imgs_mask_val.npy")

    if hist_equal: imgs_train = hist_equalization(imgs_train)

    imgs_train = imgs_train.astype('float32')
    imgs_mask_train = imgs_mask_train.astype('float32')

    if LCN_enable:
        imgs_train = imgs_train.astype('float64')
        imgs_train = LecunLCN(imgs_train, image_shape=imgs_train.shape).output.eval()
        imgs_train = imgs_train.astype('float32')

    if not LCN_enable: imgs_train /= 255
    imgs_train -= imgs_train.mean(axis=0)
    imgs_mask_train /= 255
    imgs_mask_train[imgs_mask_train > 0.5] = 1
    imgs_mask_train[imgs_mask_train <= 0.5] = 0
    print("Done loading validation data")
    print('-' * 30)
    return imgs_train, imgs_mask_train

def load_test_data(npy_path = "data/dataset", hist_equal = True):

    print('-' * 30)
    print('load test images...')

    imgs_test = np.load(npy_path + "/imgs_test.npy")

    if hist_equal: imgs_test = hist_equalization(imgs_test)

    imgs_test = imgs_test.astype('float32')

    if LCN_enable:
        imgs_test = imgs_test.astype('float64')
        imgs_test = LecunLCN(imgs_test, image_shape=imgs_test.shape).output.eval()
        imgs_test = imgs_test.astype('float32')

    if not LCN_enable: imgs_test /= 255

    imgs_test -= imgs_test.mean(axis=0)

    print("Done loading test data")
    print('-' * 30)
    return imgs_test

def load_val_5imgs(npy_path = "data/dataset"):
    print('-' * 30)
    print('load train images...')

    imgs_train = np.load(npy_path + "/imgs_val_5imgs.npy")
    imgs_mask_train = np.load(npy_path + "/imgs_mask_val_5imgs.npy")

    # imgs_train = hist_equalization(imgs_train)

    imgs_train = imgs_train.astype('float64')
    imgs_mask_train = imgs_mask_train.astype('float64')

    if LCN_enable: imgs_train = LecunLCN(imgs_train, image_shape=imgs_train.shape).output.eval()

    if not LCN_enable: imgs_train /= 255

    mean = imgs_train.mean(axis=0)
    imgs_train -= mean


    imgs_mask_train /= 255
    imgs_mask_train[imgs_mask_train > 0.5] = 1
    imgs_mask_train[imgs_mask_train <= 0.5] = 0

    # weight_map_train = self.create_weight_map(imgs_mask_train)

    print("Done loading traing data")
    print('-' * 30)
    return imgs_train, imgs_mask_train

def hist_equalization(inputs):      # inputs are uint8, 0-255, Nx1x636x636
    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))
    output = inputs.copy()
    for i in range(len(inputs)):
        img = inputs[i, 0, :, :]
        # res = cv2.equalizeHist(img)
        res = clahe.apply(img)
        output[i,0,:,:] = res
    return output

### BinaryCrossEntropyLoss2d().forward(logits, labels)
class BinaryCrossEntropyLoss2d(nn.Module):
    def __init__(self, weight=None, size_average=True):
        """
        Binary cross entropy loss 2D
        Args:
            weight:
            size_average:
        """
        super(BinaryCrossEntropyLoss2d, self).__init__()
        self.bce_loss = nn.BCELoss(weight, size_average)

    def forward(self, logits, targets):
        # probs = F.sigmoid(logits)
        probs = logits
        probs_flat = probs.view(-1)  # Flatten
        targets_flat = targets.view(-1)  # Flatten
        return self.bce_loss(probs_flat, targets_flat)      # (output, labels)

class BCE_with_Weights(nn.Module):
    def __init__(self, weights=None):
        """
        Binary cross entropy loss 2D
        Args:
            weights:
        """
        super(BCE_with_Weights, self).__init__()
        self.weights = weights

    def forward(self, output, target):
        if self.weights is not None:
            loss = self.weights * (target * torch.log(output) + (1 - target) * torch.log(1 - output))
        else:
            loss = target * torch.log(output) + (1 - target) * torch.log(1 - output)

        return torch.neg(torch.mean(loss))

class LRN(nn.Module):       # input x is Torch tensor
    def __init__(self, local_size=1, alpha=1.0, beta=0.75, ACROSS_CHANNELS=False):      #LRN(local_size=5, alpha=0.0001, beta=0.75),
        super(LRN, self).__init__()
        self.ACROSS_CHANNELS = ACROSS_CHANNELS
        if self.ACROSS_CHANNELS:
            self.average = nn.AvgPool3d(kernel_size=(local_size, 1, 1),
                                        stride=1, padding=(int((local_size - 1.0) / 2), 0, 0))
        else:
            self.average = nn.AvgPool2d(kernel_size=local_size,
                                        stride=1, padding=int((local_size - 1.0) / 2))
        self.alpha = alpha
        self.beta = beta

    def forward(self, x):
        if self.ACROSS_CHANNELS:
            div = x.pow(2).unsqueeze(1)
            div = self.average(div).squeeze(1)
            div = div.mul(self.alpha).add(1.0).pow(self.beta)
        else:
            div = x.pow(2)
            div = self.average(div)
            div = div.mul(self.alpha).add(1.0).pow(self.beta)
        x = x.div(div)
        return x
Fri Nov 24 13:05:52 2017
Leg21_finetuneLeg12_dropout_0_2_rmSigmoid_20aug_10ela_3inten_reflect
optim.SGD(net.parameters(), lr=1e-5, momentum=0.8)
Number of epoch max: 10
Epoch 1: Train loss: 0.058938, Val loss: 0.544014
Epoch 2: Train loss: 0.058484, Val loss: 0.544800
Unet2_model_2epoch_Leg21_finetuneLeg12_dropout_0_2_rmSigmoid_20aug_10ela_3inten_reflect
Precision: 0.97094 
Recall: 0.91686 
F1_measure: 0.94312 
iou: 0.88355
Epoch 3: Train loss: 0.058306, Val loss: 0.546628
Epoch 4: Train loss: 0.058191, Val loss: 0.548513
Unet2_model_4epoch_Leg21_finetuneLeg12_dropout_0_2_rmSigmoid_20aug_10ela_3inten_reflect
Precision: 0.97096 
Recall: 0.91643 
F1_measure: 0.94290 
iou: 0.88325
Epoch 5: Train loss: 0.058102, Val loss: 0.550111
Epoch 6: Train loss: 0.058035, Val loss: 0.551537
Unet2_model_6epoch_Leg21_finetuneLeg12_dropout_0_2_rmSigmoid_20aug_10ela_3inten_reflect
Precision: 0.97098 
Recall: 0.91605 
F1_measure: 0.94271 
iou: 0.88299
Epoch 7: Train loss: 0.057974, Val loss: 0.552806
Epoch 8: Train loss: 0.057920, Val loss: 0.553913
Unet2_model_8epoch_Leg21_finetuneLeg12_dropout_0_2_rmSigmoid_20aug_10ela_3inten_reflect
Precision: 0.97099 
Recall: 0.91577 
F1_measure: 0.94257 
iou: 0.88280
Epoch 9: Train loss: 0.057874, Val loss: 0.554891
Epoch 10: Train loss: 0.057829, Val loss: 0.555799
Unet2_model_10epoch_Leg21_finetuneLeg12_dropout_0_2_rmSigmoid_20aug_10ela_3inten_reflect
Precision: 0.97100 
Recall: 0.91554 
F1_measure: 0.94246 
iou: 0.88265
Best model at epoch: 2
Total training time: 4.19842439969
Fri Nov 24 17:17:09 2017
==========================================================================================
Fri Nov 24 23:57:43 2017
Leg22_CROP_dropout_0_2_rmSigmoid_20aug_10ela_3inten_reflect
Fri Nov 24 23:57:39 2017
import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.autograd import Variable
import math


class ConvBnRelu(nn.Module):
    def __init__(self, in_channels, out_channels, kernel_size, padding, stride):
        super(ConvBnRelu, self).__init__()
        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=kernel_size, padding=padding, stride=stride)
        self.bn = nn.BatchNorm2d(out_channels)
        self.relu = nn.ReLU()

    def forward(self, x):
        x = self.conv(x)
        # x = self.bn(x)
        x = self.relu(x)
        return x


class StackEncoder(nn.Module):
    def __init__(self, in_channels, out_channels):
        super(StackEncoder, self).__init__()
        self.convr1 = ConvBnRelu(in_channels, out_channels, kernel_size=(3, 3), stride=1, padding=0)
        self.convr2 = ConvBnRelu(out_channels, out_channels, kernel_size=(3, 3), stride=1, padding=0)
        self.maxPool = nn.MaxPool2d(kernel_size=(2, 2), stride=2)

    def forward(self, x):
        x = self.convr1(x)
        x = self.convr2(x)
        x_trace = x             # save x to use in concat in the Decoder path
        out = self.maxPool(x)
        return out, x_trace


class StackDecoder(nn.Module):
    def __init__(self, in_channels, out_channels, padding = 0, drop_out=False):
        super(StackDecoder, self).__init__()

        self.drop_out = drop_out
        self.dropout_layer = nn.Dropout2d(p=0.5)

        ''' this is old version
        self.upSample = nn.Upsample(size=upsample_size, scale_factor=(2, 2), mode="bilinear")
        self.convr1 = ConvBnRelu(in_channels, out_channels, kernel_size=(3, 3), stride=1, padding=padding)
        # Crop + concat step between these 2
        self.convr2 = ConvBnRelu(in_channels, out_channels, kernel_size=(3, 3), stride=1, padding=padding)
        '''
        self.upSample = nn.ConvTranspose2d(in_channels, out_channels, 2, stride=2)
        self.convr1 = ConvBnRelu(in_channels, out_channels, kernel_size=(3, 3), stride=1, padding=padding)
        self.convr2 = ConvBnRelu(out_channels, out_channels, kernel_size=(3, 3), stride=1, padding=padding)

    def _crop_concat(self, upsampled, bypass):
        """
         Crop y to the (h, w) of x and concat them.
         Used for the expansive path.
        Returns:
            The concatenated tensor
        """
        c = (bypass.size()[2] - upsampled.size()[2]) // 2
        bypass = F.pad(bypass, (-c, -c, -c, -c))

        return torch.cat((bypass, upsampled), 1)

    def forward(self, x, down_tensor):
        '''old version
        x = self.upSample(x)
        x = self.convr1(x)
        x = self._crop_concat(x, down_tensor)
        x = self.convr2(x)
        '''

        x = self.upSample(x)
        x = self._crop_concat(x, down_tensor)
        x = self.convr1(x)
        if self.drop_out: x = self.dropout_layer(x)
        x = self.convr2(x)
        if self.drop_out: x = self.dropout_layer(x)
        return x


class UNET_CROP(nn.Module):
    def __init__(self):
        super(UNET_CROP, self).__init__()
        # channels, height, width = in_shape

        # self.dropout = dropout

        self.model_code = ""        # variable to save model and main function when loaded

        self.down1 = StackEncoder(1, 64)
        self.down2 = StackEncoder(64, 128)
        self.down3 = StackEncoder(128, 256)
        self.down4 = StackEncoder(256, 512)

        self.center = nn.Sequential(
            # nn.Dropout2d(p=0.2),
            ConvBnRelu(512, 1024, kernel_size=(3, 3), stride=1, padding=0),
            nn.Dropout2d(p=0.2),
            ConvBnRelu(1024, 1024, kernel_size=(3, 3), stride=1, padding=0),
            nn.Dropout2d(p=0.2)
        )

        self.up1 = StackDecoder(in_channels=1024, out_channels=512)
        self.up2 = StackDecoder(in_channels=512, out_channels=256)
        self.up3 = StackDecoder(in_channels=256, out_channels=128)
        self.up4 = StackDecoder(in_channels=128, out_channels=64)

        # 1x1 convolution at the last layer
        # Different from the paper is the output size here
        self.output_seg_map = nn.Conv2d(64, 1, kernel_size=(1, 1), padding=0, stride=1)

        self._initialize_weights()

    def forward(self, x):
        x, x_trace1 = self.down1(x)
        x, x_trace2 = self.down2(x)
        x, x_trace3 = self.down3(x)
        x, x_trace4 = self.down4(x)
        x = self.center(x)
        x = self.up1(x, x_trace4)
        x = self.up2(x, x_trace3)
        x = self.up3(x, x_trace2)
        x = self.up4(x, x_trace1)

        x = self.output_seg_map(x)
        # x = F.sigmoid(x)
        # out = torch.squeeze(out, dim=1)
        return x


    def _initialize_weights(self):
        for m in self.modules():
            if isinstance(m, nn.Conv2d):
                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels
                m.weight.data.normal_(0, math.sqrt(2. / n))
                if m.bias is not None:
                    m.bias.data.zero_()
            elif isinstance(m, nn.BatchNorm2d):
                m.weight.data.fill_(1)
                m.bias.data.zero_()

# x = Variable(torch.randn(1,1,700, 700))       # simulate input image
# net = UNET_CROP()
# out = net(x)
# print("input: ", x)
# print("output: ", out)
===============from __future__ import print_function, division
import torch
from torch import optim
from torch.autograd import Variable
from torch.utils.data import DataLoader
import numpy as np
import torch.nn as nn
import torch.nn.functional as F
import Unet_crop
import tifffile as tiff
import Utils
import time
from sklearn.metrics import average_precision_score, recall_score, f1_score
import Analysis_crop
import cv2

def to_var(x):
    if torch.cuda.is_available():
        return Variable(x.cuda())
    else:
        return Variable(x)

### BinaryCrossEntropyLoss2d().forward(logits, labels)
class BinaryCrossEntropyLoss2d(nn.Module):
    def __init__(self, weight=None, size_average=True):
        """
        Binary cross entropy loss 2D
        Args:
            weight:
            size_average:
        """
        super(BinaryCrossEntropyLoss2d, self).__init__()
        self.bce_loss = nn.BCELoss(weight, size_average)

    def forward(self, probs, targets):
        probs = F.sigmoid(probs)
        probs_flat = probs.view(-1)  # Flatten
        targets_flat = targets.view(-1)  # Flatten
        return self.bce_loss(probs_flat, targets_flat)      # (output, labels)

def NetEval(net,valdata_loader,crit):
    loss = 0.
    count = 0
    net.eval()
    crop_input, crop_label,_ = crop_info()
    for i,data in enumerate(valdata_loader,0):
        inputs, labels = data
        inputs = inputs.numpy()
        labels = labels.numpy()
        for j in len(crop_input):  # training on the crop images and corresponding labels
            ci = crop_input[j]  # crop index for inputs
            cl = crop_label[j]  # crop index for lables
            temp = labels.numpy()
            temp = temp[0, 0, :, :]  # labels is numpy array 512x512
            if np.sum(temp) < 0.01 * np.shape(temp)[0] * np.shape(temp)[1]: break
            x = inputs[:, :, ci[0]:ci[0] + 572, ci[1]:ci[1] + 572]
            y = labels[:, :, cl[0]: cl[0] + 388, cl[1]:cl[1] + 388]
            x = torch.from_numpy(x)
            y = torch.from_numpy(y)
            x, y = to_var(x), to_var(y)
            inputs, labels = to_var(x), to_var(y)
            out = net(x)
            l = crit(out, labels)
            loss += l.data[0]
            count += 1
    return loss/count

#process the test data and save to separate .tif image
def NetTest(net,testdata_loader,path = "data/results/"):
    net.eval()
    crop_input, crop_label, average_mask = crop_info()
    for i, data in enumerate(testdata_loader, 0):
        if i >= 30: return 1        # for debug
        data = to_var(data)
        img_shape = 512
        img = np.zeros((img_shape, img_shape))
        for j in len(crop_input):  # training on the crop images and corresponding labels
            ci = crop_input[j]  # crop index for inputs

            x = data.numpy()[:, :, ci[0]:ci[0] + 572, ci[1]:ci[1] + 572]

            x = torch.from_numpy(x)

            x = to_var(x)
            out = F.sigmoid(net(x))
            out = out.cpu()
            out = out[0,0,:,:]
            img += out.data.numpy()

        img = img/average_mask
        img = img.reshape(-1)
        img[img < 0.5] = 0; img[img >= 0.5] = 1
        img = img.reshape(img_shape)
        img = np.uint8(img * 255)
        imgname = path + str(i) + ".tif"
        tiff.imsave(imgname, img)

# return input image size like 512x512, numpy array
def NetPredict(net, input_image):
    net.eval()
    _, crop_label, average_mask = crop_info()

    # input_image is grayscale input image of 512x512
    data = Utils.input_filled_mirroring(input_image, e = 94)
    imgdatas = np.ndarray((1, 1, data.shape[0], data.shape[1]), dtype=np.uint8)
    imgdatas[0] = np.expand_dims(data, 0)
    data = Utils.hist_equalization(imgdatas)
    data = data.astype('float32')
    data /= 255
    data -= data.mean(axis=0)

    img_shape = input_image.shape
    img = np.zeros((img_shape, img_shape))
    for j in len(crop_input):  # training on the crop images and corresponding labels
        ci = crop_input[j]  # crop index for inputs
        x = data.numpy()[:, :, ci[0]:ci[0] + 572, ci[1]:ci[1] + 572]
        x = torch.from_numpy(x)
        x = to_var(x)
        out = F.sigmoid(net(x))
        out = out.cpu()
        out = out[0, 0, :, :]
        img += out.data.numpy()

    img = img / average_mask
    img = img.reshape(-1)
    img[img < 0.5] = 0
    img[img >= 0.5] = 1
    img = img.reshape(img_shape)
    img = np.uint8(img * 255)
    return img


def write_2_log(content):
    path = "log_file.txt"
    output = open(path, "a")
    output.write("\n")
    output.write(content)
    output.close()

def crop_info():
    crop_input = [[0, 0], [128, 0], [0, 128], [128, 128]]
    crop_label = [[0, 0], [124, 0], [0, 124], [124, 124]]
    average_mask = np.ones((512, 512))
    average_mask[124:388, 0:124] = 2
    average_mask[0:124, 124:388] = 2
    average_mask[124:388, 388:512] = 2
    average_mask[388:512, 124:388] = 2
    average_mask[124:388, 124:388] = 4
    return crop_input, crop_label, average_mask

if __name__ == '__main__':
    '''subjects to change for each exp:
    + path to the dataset
    + opt function
    + leg description
    + N_epoch
    + saved_model
    '''
    start_begining = time.time()

    # path = "data/dataset"
    path = "/home/anhxtuan/HanLe/dataset/20aug_10ela_3inten_reflect"
    path = "/home/anhxtuan/HanLe/dataset/20aug_10ela_3inten_reflect_700"

    import os
    print("Does the folder exist?: ", os.path.isdir(path))
    print("Does the path exist?: ", os.path.exists(path))

    imgs_train, imgs_mask_train = Utils.load_train_data(npy_path=path)
    imgs_val, imgs_mask_val = Utils.load_val_data(npy_path=path)
    batch_size = 1
    trainset = zip(imgs_train, imgs_mask_train)
    trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,
                                              shuffle=True, num_workers=2)
    valset = zip(imgs_val, imgs_mask_val)
    valloader = torch.utils.data.DataLoader(valset, batch_size=batch_size,
                                              shuffle=False, num_workers=2)
    # net = Unet.UNet()                     # Unet 1
    # net = Unet_BatchNorm.UNet_BN()          # Unet 2 with batchNorm
    net = Unet_crop.UNET_CROP()

    f1 = open("Unet_crop.py", 'r')     # embede code into the model to be saved later
    f2 = open("UnetTrain_crop.py", 'r')
    f3 = open("Utils.py", 'r')
    model_notes = time.strftime("%c") + "\n" + f1.read() + "\n" + "==="*5 + f2.read() + "\n" + "==="*5 + f3.read()
    f1.close()
    f2.close()
    f3.close()

    criterion = BinaryCrossEntropyLoss2d()
    # criterion = SoftDiceLoss()
    # criterion = nn.BCELoss()

    if torch.cuda.is_available():
        # torch.set_default_tensor_type('torch.cuda.FloatTensor')
        # net.load_state_dict(torch.load("Unet2_model_12epoch_Leg12_droput_0_2_rmSigmoid_20aug_10ela_3inten_reflect"))
        net.cuda()
        # criterion.cuda()

    opt = optim.SGD(net.parameters(), lr=1e-2, momentum=0.99)       # subject to change
    # opt = optim.RMSprop(net.parameters(), lr=2e-4)
    # RMSprop[22](learning rate 0.001) with weight decay set to 0.001.
    # opt = optim.Adam(net.parameters(), lr=1e-3, weight_decay=1e-4)

    train_loss = []
    val_loss = []

    print("[epoch, #image] Loss")
    leg = "Leg22_CROP_dropout_0_2_rmSigmoid_20aug_10ela_3inten_reflect"
    print("Processing: ", leg)
    model_name = ""

    N_epoch = 6
    model_saved = np.arange(1,N_epoch+1,2)
    val_loss_min = 100

    write_2_log("==="*30)
    write_2_log(time.strftime("%c"))       # time, date of exp
    write_2_log(leg)
    write_2_log(model_notes)
    write_2_log(time.strftime("%c"))  # time, date of exp
    write_2_log(leg)
    write_2_log("optim.SGD(net.parameters(), lr=1e-2, momentum=0.99)")
    write_2_log("Number of epoch max: " + str(N_epoch))

    crop_input, crop_label,_ = crop_info()
    min_model_epoch = 0
    for epoch in range(N_epoch):
        running_loss = 0.0; count = 0
        net.train()
        for i, data in enumerate(trainloader, 0):
            if i > 1000: break

            inputs, labels = data
            temp = labels.numpy()
            for j in len(crop_input):       # training on the crop images and corresponding labels
                ci = crop_input[j]          # crop index for inputs
                cl = crop_label[j]          # crop index for lables
                temp = labels.numpy()
                temp = temp[0, 0, :, :]  # labels is numpy array 512x512
                if np.sum(temp) < 0.01 * np.shape(temp)[0] * np.shape(temp)[1]: break
                x = inputs.numpy()[:, :, ci[0]:ci[0] + 572, ci[1]:ci[1] + 572]
                y = labels.numpy()[:, :, cl[0]: cl[0] + 388, cl[1]:cl[1] + 388]
                x = torch.from_numpy(x)
                y = torch.from_numpy(y)
                x, y = to_var(x), to_var(y)
                opt.zero_grad()
                out = net(x)
                loss = criterion(out, y)
                loss.backward()
                opt.step()
                running_loss += loss.data[0]
                count += 1

        net.eval()
        val_loss_temp = NetEval(net, valloader, criterion)
        if epoch > 0 and val_loss_temp < val_loss_min:        # save the model which has the lowest val_loss, ignore first epoch
            val_loss_min = val_loss_temp
            torch.save(net.state_dict(), "Unet2_model_" + leg + "_min_val_loss")  # save model
            min_model_epoch = epoch + 1

        disp = 'Epoch %d: Train loss: %.6f, Val loss: %.6f' % (epoch + 1, running_loss/count, val_loss_temp)
        write_2_log(disp)
        print(disp)
        val_loss.append(val_loss_temp)
        train_loss.append(running_loss/count); running_loss = 0.0

        if (epoch + 1) in model_saved:        # save checkpoint
            model_name = "Unet2_model_" + str(epoch+1) + "epoch_" + leg
            torch.save(net.state_dict(), model_name)  # save model
            Analysis_crop.analysis(model_file = model_name, valloader = valloader)

    write_2_log("Best model at epoch: " + str(min_model_epoch))
    write_2_log("Total training time: " + str((time.time() - start_begining) / 3600.0))

    val_loss_file = "data/results" + "/val_loss_" + str(N_epoch) + "epoch_" + leg + ".npy"
    train_loss_file = "data/results" + "/training_loss_" + str(N_epoch) + "epoch_" + leg + ".npy"

    np.save(val_loss_file, val_loss)
    np.save(train_loss_file, train_loss)
    print("total processing time in seconds: ", time.time() - start_begining)
    print("total processing time in mins: ", (time.time() - start_begining) / 60.0)
    print("total processing time in hours: ", (time.time() - start_begining) / 3600.0)

    # Analysis.analysis(model_file="Unet2_model_" + leg + "_min_val_loss", valloader=valloader)

    Analysis_crop.PlotLoss(model_file = model_name, loss_train_path = train_loss_file, loss_val_path = val_loss_file, epoch_No = N_epoch)

    write_2_log(time.strftime("%c"))  # time, date of exp
===============
import numpy as np
import torch.nn as nn
import torch
import cv2
from lcn import LecunLCN

LCN_enable = False

def input_filled_mirroring(x, e = 62):      # fill missing data by mirroring the input image
    '''input size 636 --> output size 512'''
    w, h = x.shape
    #e = 62  # extra width on 1 edge
    y = np.zeros((h + e * 2, w + e * 2))
    y[e:h + e, e:w + e] = x
    y[e:e + h, 0:e] = np.flip(y[e:e + h, e:2 * e], 1)  # flip vertically
    y[e:e + h, e + w:2 * e + w] = np.flip(y[e:e + h, w:e + w], 1)  # flip vertically
    y[0:e, 0:2 * e + w] = np.flip(y[e:2 * e, 0:2 * e + w], 0)  # flip horizontally
    y[e + h:2 * e + h, 0:2 * e + w] = np.flip(y[h:e + h, 0:2 * e + w], 0)  # flip horizontally
    return y

def nearest_cells_distance(pos, img):
    # searching in 8 directions to find 2 nearest distances to neighbor cells
    curr_value = img[pos]
    w = img.shape[0];h = img.shape[1]
    count_detect = 0  # detect 2 nearest neighbors. break the search if count_detect = 2
    x, y = pos

    # print("w,h: ", (w, h))
    d1 = 9999999;d2 = 9999999;d3 = 9999999;d4 = 9999999
    d5 = 9999999;d6 = 9999999;d7 = 9999999;d8 = 9999999
    for i in range(1, max(w, h)):
        # (x+1, y), (x+1, y+1), (x+1, y-1),
        # (x, y+1), (x, y-1)
        # (x-1, y), (x-1,y+1), (x-1,y-1),
        if x + i < w:
            if img[(x + i, y)] != curr_value and d1 == 9999999:
                d1 = i; count_detect += 1
            if y + i < h:
                if img[(x + i, y + i)] != curr_value and d2 == 9999999:
                    d2 = i; count_detect += 1
            elif y - i >= 0:
                if img[(x + i, y - i)] != curr_value and d3 == 9999999:
                    d3 = i; count_detect += 1
        if y + i < h:
            if img[(x, y + i)] != curr_value and d4 == 9999999:
                d4 = i; count_detect += 1
        if y - i >= 0:
            if img[(x, y - i)] != curr_value and d5 == 9999999:
                d5 = i; count_detect += 1
        if x - i >= 0:
            if img[(x - i, y)] != curr_value and d6 == 9999999:
                d6 = i; count_detect += 1
            if y + i < h:
                if img[(x - i, y + i)] != curr_value and d7 == 9999999:
                    d7 = i; count_detect += 1
            elif y - i >= 0:
                if img[(x - i, y - i)] != curr_value and d8 == 9999999:
                    d8 = i; count_detect += 1
        if count_detect >= 2: break

    d = [d1, d2, d3, d4, d5, d6, d7, d8]
    min_index = np.argmin(d)
    dist1 = d[min_index]
    d.remove(dist1)
    min_index = np.argmin(d)
    dist2 = d[min_index]
    return dist1, dist2

def create_weight_map(imgs_mask):
        print('-' * 30)
        print('Creating weights for masks ...')
        print('-' * 30)
        weight_map = np.ndarray(
            (len(imgs_mask), 1, np.shape(imgs_mask)[2], np.shape(imgs_mask)[3]), dtype=np.float32)
        w_0 = 10; sigma = 4
        imgs_w, imgs_h = np.shape(imgs_mask)[2], np.shape(imgs_mask)[3]
        total_pixels = imgs_w*imgs_h
        import time
        start = time.time()
        for i in range(len(imgs_mask)):
            if i%10 == 0: print("Done processing: %d images, time passed: %.2f mins" % (i, (time.time() - start)/60.0))
            temp = imgs_mask[i,0,:,:]
            w_border = 1 - np.sum(temp)/total_pixels        # w_c of pixel on the border (black)
            for m in range(imgs_w):
                for n in range(imgs_h):
                    # loop through all pixel of the mask
                    d1,d2 = nearest_cells_distance((m,n), temp)
                    w_c = w_border
                    if temp[m,n] == 0: w_c = 1 - w_border
                    weight_map[i,0,m,n] = w_c*5 + w_0*np.exp(-(d1 + d2)**2/(2*sigma**2))
                    # print("w_0*np.exp(): ", w_0*np.exp(-(d1 + d2)**2/(2*sigma**2)))
                    # print("w_border: ", w_border)

        np.save('data/dataset/weight_map_train.npy', weight_map)

        return weight_map

def load_train_data(npy_path = "data/dataset", hist_equal = False):

    print('-' * 30)
    print('load train images...')

    imgs_train = np.load(npy_path + "/imgs_train.npy")
    imgs_mask_train = np.load(npy_path + "/imgs_mask_train.npy")

    if hist_equal: imgs_train = hist_equalization(imgs_train)

    # weight_map_train = np.load(npy_path + "/weight_map_train.npy")
    # weight_map_train = weight_map_train.astype('float32')

    imgs_train = imgs_train.astype('float32')
    imgs_mask_train = imgs_mask_train.astype('float32')

    if LCN_enable:
        imgs_train = imgs_train.astype('float64')
        imgs_train = LecunLCN(imgs_train, image_shape=imgs_train.shape).output.eval()
        imgs_train = imgs_train.astype('float32')

    if not LCN_enable: imgs_train /= 255

    imgs_train -= imgs_train.mean(axis=0)
    imgs_mask_train /= 255
    imgs_mask_train[imgs_mask_train > 0.5] = 1
    imgs_mask_train[imgs_mask_train <= 0.5] = 0

    # weight_map_train = create_weight_map(imgs_mask_train)

    print("Done loading traing data")
    print('-' * 30)
    return imgs_train, imgs_mask_train

def load_val_data(npy_path = "data/dataset", hist_equal = True):

    print('-' * 30)
    print('load validation images...')

    imgs_train = np.load(npy_path + "/imgs_val.npy")
    imgs_mask_train = np.load(npy_path + "/imgs_mask_val.npy")

    if hist_equal: imgs_train = hist_equalization(imgs_train)

    imgs_train = imgs_train.astype('float32')
    imgs_mask_train = imgs_mask_train.astype('float32')

    if LCN_enable:
        imgs_train = imgs_train.astype('float64')
        imgs_train = LecunLCN(imgs_train, image_shape=imgs_train.shape).output.eval()
        imgs_train = imgs_train.astype('float32')

    if not LCN_enable: imgs_train /= 255
    imgs_train -= imgs_train.mean(axis=0)
    imgs_mask_train /= 255
    imgs_mask_train[imgs_mask_train > 0.5] = 1
    imgs_mask_train[imgs_mask_train <= 0.5] = 0
    print("Done loading validation data")
    print('-' * 30)
    return imgs_train, imgs_mask_train

def load_test_data(npy_path = "data/dataset", hist_equal = True):

    print('-' * 30)
    print('load test images...')

    imgs_test = np.load(npy_path + "/imgs_test.npy")

    if hist_equal: imgs_test = hist_equalization(imgs_test)

    imgs_test = imgs_test.astype('float32')

    if LCN_enable:
        imgs_test = imgs_test.astype('float64')
        imgs_test = LecunLCN(imgs_test, image_shape=imgs_test.shape).output.eval()
        imgs_test = imgs_test.astype('float32')

    if not LCN_enable: imgs_test /= 255

    imgs_test -= imgs_test.mean(axis=0)

    print("Done loading test data")
    print('-' * 30)
    return imgs_test

def load_val_5imgs(npy_path = "data/dataset"):
    print('-' * 30)
    print('load train images...')

    imgs_train = np.load(npy_path + "/imgs_val_5imgs.npy")
    imgs_mask_train = np.load(npy_path + "/imgs_mask_val_5imgs.npy")

    # imgs_train = hist_equalization(imgs_train)

    imgs_train = imgs_train.astype('float64')
    imgs_mask_train = imgs_mask_train.astype('float64')

    if LCN_enable: imgs_train = LecunLCN(imgs_train, image_shape=imgs_train.shape).output.eval()

    if not LCN_enable: imgs_train /= 255

    mean = imgs_train.mean(axis=0)
    imgs_train -= mean


    imgs_mask_train /= 255
    imgs_mask_train[imgs_mask_train > 0.5] = 1
    imgs_mask_train[imgs_mask_train <= 0.5] = 0

    # weight_map_train = self.create_weight_map(imgs_mask_train)

    print("Done loading traing data")
    print('-' * 30)
    return imgs_train, imgs_mask_train

def hist_equalization(inputs):      # inputs are uint8, 0-255, Nx1x636x636
    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))
    output = inputs.copy()
    for i in range(len(inputs)):
        img = inputs[i, 0, :, :]
        # res = cv2.equalizeHist(img)
        res = clahe.apply(img)
        output[i,0,:,:] = res
    return output

### BinaryCrossEntropyLoss2d().forward(logits, labels)
class BinaryCrossEntropyLoss2d(nn.Module):
    def __init__(self, weight=None, size_average=True):
        """
        Binary cross entropy loss 2D
        Args:
            weight:
            size_average:
        """
        super(BinaryCrossEntropyLoss2d, self).__init__()
        self.bce_loss = nn.BCELoss(weight, size_average)

    def forward(self, logits, targets):
        # probs = F.sigmoid(logits)
        probs = logits
        probs_flat = probs.view(-1)  # Flatten
        targets_flat = targets.view(-1)  # Flatten
        return self.bce_loss(probs_flat, targets_flat)      # (output, labels)

class BCE_with_Weights(nn.Module):
    def __init__(self, weights=None):
        """
        Binary cross entropy loss 2D
        Args:
            weights:
        """
        super(BCE_with_Weights, self).__init__()
        self.weights = weights

    def forward(self, output, target):
        if self.weights is not None:
            loss = self.weights * (target * torch.log(output) + (1 - target) * torch.log(1 - output))
        else:
            loss = target * torch.log(output) + (1 - target) * torch.log(1 - output)

        return torch.neg(torch.mean(loss))

class LRN(nn.Module):       # input x is Torch tensor
    def __init__(self, local_size=1, alpha=1.0, beta=0.75, ACROSS_CHANNELS=False):      #LRN(local_size=5, alpha=0.0001, beta=0.75),
        super(LRN, self).__init__()
        self.ACROSS_CHANNELS = ACROSS_CHANNELS
        if self.ACROSS_CHANNELS:
            self.average = nn.AvgPool3d(kernel_size=(local_size, 1, 1),
                                        stride=1, padding=(int((local_size - 1.0) / 2), 0, 0))
        else:
            self.average = nn.AvgPool2d(kernel_size=local_size,
                                        stride=1, padding=int((local_size - 1.0) / 2))
        self.alpha = alpha
        self.beta = beta

    def forward(self, x):
        if self.ACROSS_CHANNELS:
            div = x.pow(2).unsqueeze(1)
            div = self.average(div).squeeze(1)
            div = div.mul(self.alpha).add(1.0).pow(self.beta)
        else:
            div = x.pow(2)
            div = self.average(div)
            div = div.mul(self.alpha).add(1.0).pow(self.beta)
        x = x.div(div)
        return x
Fri Nov 24 23:57:43 2017
Leg22_CROP_dropout_0_2_rmSigmoid_20aug_10ela_3inten_reflect
optim.SGD(net.parameters(), lr=1e-2, momentum=0.99)
Number of epoch max: 6
==========================================================================================
Sat Nov 25 00:01:10 2017
Leg22_CROP_dropout_0_2_rmSigmoid_20aug_10ela_3inten_reflect
Sat Nov 25 00:01:08 2017
import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.autograd import Variable
import math


class ConvBnRelu(nn.Module):
    def __init__(self, in_channels, out_channels, kernel_size, padding, stride):
        super(ConvBnRelu, self).__init__()
        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=kernel_size, padding=padding, stride=stride)
        self.bn = nn.BatchNorm2d(out_channels)
        self.relu = nn.ReLU()

    def forward(self, x):
        x = self.conv(x)
        # x = self.bn(x)
        x = self.relu(x)
        return x


class StackEncoder(nn.Module):
    def __init__(self, in_channels, out_channels):
        super(StackEncoder, self).__init__()
        self.convr1 = ConvBnRelu(in_channels, out_channels, kernel_size=(3, 3), stride=1, padding=0)
        self.convr2 = ConvBnRelu(out_channels, out_channels, kernel_size=(3, 3), stride=1, padding=0)
        self.maxPool = nn.MaxPool2d(kernel_size=(2, 2), stride=2)

    def forward(self, x):
        x = self.convr1(x)
        x = self.convr2(x)
        x_trace = x             # save x to use in concat in the Decoder path
        out = self.maxPool(x)
        return out, x_trace


class StackDecoder(nn.Module):
    def __init__(self, in_channels, out_channels, padding = 0, drop_out=False):
        super(StackDecoder, self).__init__()

        self.drop_out = drop_out
        self.dropout_layer = nn.Dropout2d(p=0.5)

        ''' this is old version
        self.upSample = nn.Upsample(size=upsample_size, scale_factor=(2, 2), mode="bilinear")
        self.convr1 = ConvBnRelu(in_channels, out_channels, kernel_size=(3, 3), stride=1, padding=padding)
        # Crop + concat step between these 2
        self.convr2 = ConvBnRelu(in_channels, out_channels, kernel_size=(3, 3), stride=1, padding=padding)
        '''
        self.upSample = nn.ConvTranspose2d(in_channels, out_channels, 2, stride=2)
        self.convr1 = ConvBnRelu(in_channels, out_channels, kernel_size=(3, 3), stride=1, padding=padding)
        self.convr2 = ConvBnRelu(out_channels, out_channels, kernel_size=(3, 3), stride=1, padding=padding)

    def _crop_concat(self, upsampled, bypass):
        """
         Crop y to the (h, w) of x and concat them.
         Used for the expansive path.
        Returns:
            The concatenated tensor
        """
        c = (bypass.size()[2] - upsampled.size()[2]) // 2
        bypass = F.pad(bypass, (-c, -c, -c, -c))

        return torch.cat((bypass, upsampled), 1)

    def forward(self, x, down_tensor):
        '''old version
        x = self.upSample(x)
        x = self.convr1(x)
        x = self._crop_concat(x, down_tensor)
        x = self.convr2(x)
        '''

        x = self.upSample(x)
        x = self._crop_concat(x, down_tensor)
        x = self.convr1(x)
        if self.drop_out: x = self.dropout_layer(x)
        x = self.convr2(x)
        if self.drop_out: x = self.dropout_layer(x)
        return x


class UNET_CROP(nn.Module):
    def __init__(self):
        super(UNET_CROP, self).__init__()
        # channels, height, width = in_shape

        # self.dropout = dropout

        self.model_code = ""        # variable to save model and main function when loaded

        self.down1 = StackEncoder(1, 64)
        self.down2 = StackEncoder(64, 128)
        self.down3 = StackEncoder(128, 256)
        self.down4 = StackEncoder(256, 512)

        self.center = nn.Sequential(
            # nn.Dropout2d(p=0.2),
            ConvBnRelu(512, 1024, kernel_size=(3, 3), stride=1, padding=0),
            nn.Dropout2d(p=0.2),
            ConvBnRelu(1024, 1024, kernel_size=(3, 3), stride=1, padding=0),
            nn.Dropout2d(p=0.2)
        )

        self.up1 = StackDecoder(in_channels=1024, out_channels=512)
        self.up2 = StackDecoder(in_channels=512, out_channels=256)
        self.up3 = StackDecoder(in_channels=256, out_channels=128)
        self.up4 = StackDecoder(in_channels=128, out_channels=64)

        # 1x1 convolution at the last layer
        # Different from the paper is the output size here
        self.output_seg_map = nn.Conv2d(64, 1, kernel_size=(1, 1), padding=0, stride=1)

        self._initialize_weights()

    def forward(self, x):
        x, x_trace1 = self.down1(x)
        x, x_trace2 = self.down2(x)
        x, x_trace3 = self.down3(x)
        x, x_trace4 = self.down4(x)
        x = self.center(x)
        x = self.up1(x, x_trace4)
        x = self.up2(x, x_trace3)
        x = self.up3(x, x_trace2)
        x = self.up4(x, x_trace1)

        x = self.output_seg_map(x)
        # x = F.sigmoid(x)
        # out = torch.squeeze(out, dim=1)
        return x


    def _initialize_weights(self):
        for m in self.modules():
            if isinstance(m, nn.Conv2d):
                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels
                m.weight.data.normal_(0, math.sqrt(2. / n))
                if m.bias is not None:
                    m.bias.data.zero_()
            elif isinstance(m, nn.BatchNorm2d):
                m.weight.data.fill_(1)
                m.bias.data.zero_()

# x = Variable(torch.randn(1,1,700, 700))       # simulate input image
# net = UNET_CROP()
# out = net(x)
# print("input: ", x)
# print("output: ", out)
===============from __future__ import print_function, division
import torch
from torch import optim
from torch.autograd import Variable
from torch.utils.data import DataLoader
import numpy as np
import torch.nn as nn
import torch.nn.functional as F
import Unet_crop
import tifffile as tiff
import Utils
import time
from sklearn.metrics import average_precision_score, recall_score, f1_score
import Analysis_crop
import cv2

def to_var(x):
    if torch.cuda.is_available():
        return Variable(x.cuda())
    else:
        return Variable(x)

### BinaryCrossEntropyLoss2d().forward(logits, labels)
class BinaryCrossEntropyLoss2d(nn.Module):
    def __init__(self, weight=None, size_average=True):
        """
        Binary cross entropy loss 2D
        Args:
            weight:
            size_average:
        """
        super(BinaryCrossEntropyLoss2d, self).__init__()
        self.bce_loss = nn.BCELoss(weight, size_average)

    def forward(self, probs, targets):
        probs = F.sigmoid(probs)
        probs_flat = probs.view(-1)  # Flatten
        targets_flat = targets.view(-1)  # Flatten
        return self.bce_loss(probs_flat, targets_flat)      # (output, labels)

def NetEval(net,valdata_loader,crit):
    loss = 0.
    count = 0
    net.eval()
    crop_input, crop_label,_ = crop_info()
    for i,data in enumerate(valdata_loader,0):
        inputs, labels = data
        inputs = inputs.numpy()
        labels = labels.numpy()
        for j in range(len(crop_input)):  # training on the crop images and corresponding labels
            ci = crop_input[j]  # crop index for inputs
            cl = crop_label[j]  # crop index for lables
            temp = labels.numpy()
            temp = temp[0, 0, :, :]  # labels is numpy array 512x512
            if np.sum(temp) < 0.01 * np.shape(temp)[0] * np.shape(temp)[1]: break
            x = inputs[:, :, ci[0]:ci[0] + 572, ci[1]:ci[1] + 572]
            y = labels[:, :, cl[0]: cl[0] + 388, cl[1]:cl[1] + 388]
            x = torch.from_numpy(x)
            y = torch.from_numpy(y)
            x, y = to_var(x), to_var(y)
            inputs, labels = to_var(x), to_var(y)
            out = net(x)
            l = crit(out, labels)
            loss += l.data[0]
            count += 1
    return loss/count

#process the test data and save to separate .tif image
def NetTest(net,testdata_loader,path = "data/results/"):
    net.eval()
    crop_input, crop_label, average_mask = crop_info()
    for i, data in enumerate(testdata_loader, 0):
        if i >= 30: return 1        # for debug
        data = to_var(data)
        img_shape = 512
        img = np.zeros((img_shape, img_shape))
        for j in range(len(crop_input)):  # training on the crop images and corresponding labels
            ci = crop_input[j]  # crop index for inputs

            x = data.numpy()[:, :, ci[0]:ci[0] + 572, ci[1]:ci[1] + 572]

            x = torch.from_numpy(x)

            x = to_var(x)
            out = F.sigmoid(net(x))
            out = out.cpu()
            out = out[0,0,:,:]
            img += out.data.numpy()

        img = img/average_mask
        img = img.reshape(-1)
        img[img < 0.5] = 0; img[img >= 0.5] = 1
        img = img.reshape(img_shape)
        img = np.uint8(img * 255)
        imgname = path + str(i) + ".tif"
        tiff.imsave(imgname, img)

# return input image size like 512x512, numpy array
def NetPredict(net, input_image):
    net.eval()
    _, crop_label, average_mask = crop_info()

    # input_image is grayscale input image of 512x512
    data = Utils.input_filled_mirroring(input_image, e = 94)
    imgdatas = np.ndarray((1, 1, data.shape[0], data.shape[1]), dtype=np.uint8)
    imgdatas[0] = np.expand_dims(data, 0)
    data = Utils.hist_equalization(imgdatas)
    data = data.astype('float32')
    data /= 255
    data -= data.mean(axis=0)

    img_shape = input_image.shape
    img = np.zeros((img_shape, img_shape))
    for j in range(len(crop_input)):  # training on the crop images and corresponding labels
        ci = crop_input[j]  # crop index for inputs
        x = data.numpy()[:, :, ci[0]:ci[0] + 572, ci[1]:ci[1] + 572]
        x = torch.from_numpy(x)
        x = to_var(x)
        out = F.sigmoid(net(x))
        out = out.cpu()
        out = out[0, 0, :, :]
        img += out.data.numpy()

    img = img / average_mask
    img = img.reshape(-1)
    img[img < 0.5] = 0
    img[img >= 0.5] = 1
    img = img.reshape(img_shape)
    img = np.uint8(img * 255)
    return img


def write_2_log(content):
    path = "log_file.txt"
    output = open(path, "a")
    output.write("\n")
    output.write(content)
    output.close()

def crop_info():
    crop_input = [[0, 0], [128, 0], [0, 128], [128, 128]]
    crop_label = [[0, 0], [124, 0], [0, 124], [124, 124]]
    average_mask = np.ones((512, 512))
    average_mask[124:388, 0:124] = 2
    average_mask[0:124, 124:388] = 2
    average_mask[124:388, 388:512] = 2
    average_mask[388:512, 124:388] = 2
    average_mask[124:388, 124:388] = 4
    return crop_input, crop_label, average_mask

if __name__ == '__main__':
    '''subjects to change for each exp:
    + path to the dataset
    + opt function
    + leg description
    + N_epoch
    + saved_model
    '''
    start_begining = time.time()

    # path = "data/dataset"
    path = "/home/anhxtuan/HanLe/dataset/20aug_10ela_3inten_reflect"
    path = "/home/anhxtuan/HanLe/dataset/20aug_10ela_3inten_reflect_700"

    import os
    print("Does the folder exist?: ", os.path.isdir(path))
    print("Does the path exist?: ", os.path.exists(path))

    imgs_train, imgs_mask_train = Utils.load_train_data(npy_path=path)
    imgs_val, imgs_mask_val = Utils.load_val_data(npy_path=path)
    batch_size = 1
    trainset = zip(imgs_train, imgs_mask_train)
    trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,
                                              shuffle=True, num_workers=2)
    valset = zip(imgs_val, imgs_mask_val)
    valloader = torch.utils.data.DataLoader(valset, batch_size=batch_size,
                                              shuffle=False, num_workers=2)
    # net = Unet.UNet()                     # Unet 1
    # net = Unet_BatchNorm.UNet_BN()          # Unet 2 with batchNorm
    net = Unet_crop.UNET_CROP()

    f1 = open("Unet_crop.py", 'r')     # embede code into the model to be saved later
    f2 = open("UnetTrain_crop.py", 'r')
    f3 = open("Utils.py", 'r')
    model_notes = time.strftime("%c") + "\n" + f1.read() + "\n" + "==="*5 + f2.read() + "\n" + "==="*5 + f3.read()
    f1.close()
    f2.close()
    f3.close()

    criterion = BinaryCrossEntropyLoss2d()
    # criterion = SoftDiceLoss()
    # criterion = nn.BCELoss()

    if torch.cuda.is_available():
        # torch.set_default_tensor_type('torch.cuda.FloatTensor')
        # net.load_state_dict(torch.load("Unet2_model_12epoch_Leg12_droput_0_2_rmSigmoid_20aug_10ela_3inten_reflect"))
        net.cuda()
        # criterion.cuda()

    opt = optim.SGD(net.parameters(), lr=1e-2, momentum=0.99)       # subject to change
    # opt = optim.RMSprop(net.parameters(), lr=2e-4)
    # RMSprop[22](learning rate 0.001) with weight decay set to 0.001.
    # opt = optim.Adam(net.parameters(), lr=1e-3, weight_decay=1e-4)

    train_loss = []
    val_loss = []

    print("[epoch, #image] Loss")
    leg = "Leg22_CROP_dropout_0_2_rmSigmoid_20aug_10ela_3inten_reflect"
    print("Processing: ", leg)
    model_name = ""

    N_epoch = 6
    model_saved = np.arange(1,N_epoch+1,2)
    val_loss_min = 100

    write_2_log("==="*30)
    write_2_log(time.strftime("%c"))       # time, date of exp
    write_2_log(leg)
    write_2_log(model_notes)
    write_2_log(time.strftime("%c"))  # time, date of exp
    write_2_log(leg)
    write_2_log("optim.SGD(net.parameters(), lr=1e-2, momentum=0.99)")
    write_2_log("Number of epoch max: " + str(N_epoch))

    crop_input, crop_label,_ = crop_info()
    min_model_epoch = 0
    for epoch in range(N_epoch):
        running_loss = 0.0; count = 0
        net.train()
        for i, data in enumerate(trainloader, 0):
            if i > 1000: break

            inputs, labels = data
            temp = labels.numpy()
            for j in range(len(crop_input)):       # training on the crop images and corresponding labels
                ci = crop_input[j]          # crop index for inputs
                cl = crop_label[j]          # crop index for lables
                temp = labels.numpy()
                temp = temp[0, 0, :, :]  # labels is numpy array 512x512
                if np.sum(temp) < 0.01 * np.shape(temp)[0] * np.shape(temp)[1]: break
                x = inputs.numpy()[:, :, ci[0]:ci[0] + 572, ci[1]:ci[1] + 572]
                y = labels.numpy()[:, :, cl[0]: cl[0] + 388, cl[1]:cl[1] + 388]
                x = torch.from_numpy(x)
                y = torch.from_numpy(y)
                x, y = to_var(x), to_var(y)
                opt.zero_grad()
                out = net(x)
                loss = criterion(out, y)
                loss.backward()
                opt.step()
                running_loss += loss.data[0]
                count += 1

        net.eval()
        val_loss_temp = NetEval(net, valloader, criterion)
        if epoch > 0 and val_loss_temp < val_loss_min:        # save the model which has the lowest val_loss, ignore first epoch
            val_loss_min = val_loss_temp
            torch.save(net.state_dict(), "Unet2_model_" + leg + "_min_val_loss")  # save model
            min_model_epoch = epoch + 1

        disp = 'Epoch %d: Train loss: %.6f, Val loss: %.6f' % (epoch + 1, running_loss/count, val_loss_temp)
        write_2_log(disp)
        print(disp)
        val_loss.append(val_loss_temp)
        train_loss.append(running_loss/count); running_loss = 0.0

        if (epoch + 1) in model_saved:        # save checkpoint
            model_name = "Unet2_model_" + str(epoch+1) + "epoch_" + leg
            torch.save(net.state_dict(), model_name)  # save model
            Analysis_crop.analysis(model_file = model_name, valloader = valloader)

    write_2_log("Best model at epoch: " + str(min_model_epoch))
    write_2_log("Total training time: " + str((time.time() - start_begining) / 3600.0))

    val_loss_file = "data/results" + "/val_loss_" + str(N_epoch) + "epoch_" + leg + ".npy"
    train_loss_file = "data/results" + "/training_loss_" + str(N_epoch) + "epoch_" + leg + ".npy"

    np.save(val_loss_file, val_loss)
    np.save(train_loss_file, train_loss)
    print("total processing time in seconds: ", time.time() - start_begining)
    print("total processing time in mins: ", (time.time() - start_begining) / 60.0)
    print("total processing time in hours: ", (time.time() - start_begining) / 3600.0)

    # Analysis.analysis(model_file="Unet2_model_" + leg + "_min_val_loss", valloader=valloader)

    Analysis_crop.PlotLoss(model_file = model_name, loss_train_path = train_loss_file, loss_val_path = val_loss_file, epoch_No = N_epoch)

    write_2_log(time.strftime("%c"))  # time, date of exp
===============
import numpy as np
import torch.nn as nn
import torch
import cv2
from lcn import LecunLCN

LCN_enable = False

def input_filled_mirroring(x, e = 62):      # fill missing data by mirroring the input image
    '''input size 636 --> output size 512'''
    w, h = x.shape
    #e = 62  # extra width on 1 edge
    y = np.zeros((h + e * 2, w + e * 2))
    y[e:h + e, e:w + e] = x
    y[e:e + h, 0:e] = np.flip(y[e:e + h, e:2 * e], 1)  # flip vertically
    y[e:e + h, e + w:2 * e + w] = np.flip(y[e:e + h, w:e + w], 1)  # flip vertically
    y[0:e, 0:2 * e + w] = np.flip(y[e:2 * e, 0:2 * e + w], 0)  # flip horizontally
    y[e + h:2 * e + h, 0:2 * e + w] = np.flip(y[h:e + h, 0:2 * e + w], 0)  # flip horizontally
    return y

def nearest_cells_distance(pos, img):
    # searching in 8 directions to find 2 nearest distances to neighbor cells
    curr_value = img[pos]
    w = img.shape[0];h = img.shape[1]
    count_detect = 0  # detect 2 nearest neighbors. break the search if count_detect = 2
    x, y = pos

    # print("w,h: ", (w, h))
    d1 = 9999999;d2 = 9999999;d3 = 9999999;d4 = 9999999
    d5 = 9999999;d6 = 9999999;d7 = 9999999;d8 = 9999999
    for i in range(1, max(w, h)):
        # (x+1, y), (x+1, y+1), (x+1, y-1),
        # (x, y+1), (x, y-1)
        # (x-1, y), (x-1,y+1), (x-1,y-1),
        if x + i < w:
            if img[(x + i, y)] != curr_value and d1 == 9999999:
                d1 = i; count_detect += 1
            if y + i < h:
                if img[(x + i, y + i)] != curr_value and d2 == 9999999:
                    d2 = i; count_detect += 1
            elif y - i >= 0:
                if img[(x + i, y - i)] != curr_value and d3 == 9999999:
                    d3 = i; count_detect += 1
        if y + i < h:
            if img[(x, y + i)] != curr_value and d4 == 9999999:
                d4 = i; count_detect += 1
        if y - i >= 0:
            if img[(x, y - i)] != curr_value and d5 == 9999999:
                d5 = i; count_detect += 1
        if x - i >= 0:
            if img[(x - i, y)] != curr_value and d6 == 9999999:
                d6 = i; count_detect += 1
            if y + i < h:
                if img[(x - i, y + i)] != curr_value and d7 == 9999999:
                    d7 = i; count_detect += 1
            elif y - i >= 0:
                if img[(x - i, y - i)] != curr_value and d8 == 9999999:
                    d8 = i; count_detect += 1
        if count_detect >= 2: break

    d = [d1, d2, d3, d4, d5, d6, d7, d8]
    min_index = np.argmin(d)
    dist1 = d[min_index]
    d.remove(dist1)
    min_index = np.argmin(d)
    dist2 = d[min_index]
    return dist1, dist2

def create_weight_map(imgs_mask):
        print('-' * 30)
        print('Creating weights for masks ...')
        print('-' * 30)
        weight_map = np.ndarray(
            (len(imgs_mask), 1, np.shape(imgs_mask)[2], np.shape(imgs_mask)[3]), dtype=np.float32)
        w_0 = 10; sigma = 4
        imgs_w, imgs_h = np.shape(imgs_mask)[2], np.shape(imgs_mask)[3]
        total_pixels = imgs_w*imgs_h
        import time
        start = time.time()
        for i in range(len(imgs_mask)):
            if i%10 == 0: print("Done processing: %d images, time passed: %.2f mins" % (i, (time.time() - start)/60.0))
            temp = imgs_mask[i,0,:,:]
            w_border = 1 - np.sum(temp)/total_pixels        # w_c of pixel on the border (black)
            for m in range(imgs_w):
                for n in range(imgs_h):
                    # loop through all pixel of the mask
                    d1,d2 = nearest_cells_distance((m,n), temp)
                    w_c = w_border
                    if temp[m,n] == 0: w_c = 1 - w_border
                    weight_map[i,0,m,n] = w_c*5 + w_0*np.exp(-(d1 + d2)**2/(2*sigma**2))
                    # print("w_0*np.exp(): ", w_0*np.exp(-(d1 + d2)**2/(2*sigma**2)))
                    # print("w_border: ", w_border)

        np.save('data/dataset/weight_map_train.npy', weight_map)

        return weight_map

def load_train_data(npy_path = "data/dataset", hist_equal = False):

    print('-' * 30)
    print('load train images...')

    imgs_train = np.load(npy_path + "/imgs_train.npy")
    imgs_mask_train = np.load(npy_path + "/imgs_mask_train.npy")

    if hist_equal: imgs_train = hist_equalization(imgs_train)

    # weight_map_train = np.load(npy_path + "/weight_map_train.npy")
    # weight_map_train = weight_map_train.astype('float32')

    imgs_train = imgs_train.astype('float32')
    imgs_mask_train = imgs_mask_train.astype('float32')

    if LCN_enable:
        imgs_train = imgs_train.astype('float64')
        imgs_train = LecunLCN(imgs_train, image_shape=imgs_train.shape).output.eval()
        imgs_train = imgs_train.astype('float32')

    if not LCN_enable: imgs_train /= 255

    imgs_train -= imgs_train.mean(axis=0)
    imgs_mask_train /= 255
    imgs_mask_train[imgs_mask_train > 0.5] = 1
    imgs_mask_train[imgs_mask_train <= 0.5] = 0

    # weight_map_train = create_weight_map(imgs_mask_train)

    print("Done loading traing data")
    print('-' * 30)
    return imgs_train, imgs_mask_train

def load_val_data(npy_path = "data/dataset", hist_equal = True):

    print('-' * 30)
    print('load validation images...')

    imgs_train = np.load(npy_path + "/imgs_val.npy")
    imgs_mask_train = np.load(npy_path + "/imgs_mask_val.npy")

    if hist_equal: imgs_train = hist_equalization(imgs_train)

    imgs_train = imgs_train.astype('float32')
    imgs_mask_train = imgs_mask_train.astype('float32')

    if LCN_enable:
        imgs_train = imgs_train.astype('float64')
        imgs_train = LecunLCN(imgs_train, image_shape=imgs_train.shape).output.eval()
        imgs_train = imgs_train.astype('float32')

    if not LCN_enable: imgs_train /= 255
    imgs_train -= imgs_train.mean(axis=0)
    imgs_mask_train /= 255
    imgs_mask_train[imgs_mask_train > 0.5] = 1
    imgs_mask_train[imgs_mask_train <= 0.5] = 0
    print("Done loading validation data")
    print('-' * 30)
    return imgs_train, imgs_mask_train

def load_test_data(npy_path = "data/dataset", hist_equal = True):

    print('-' * 30)
    print('load test images...')

    imgs_test = np.load(npy_path + "/imgs_test.npy")

    if hist_equal: imgs_test = hist_equalization(imgs_test)

    imgs_test = imgs_test.astype('float32')

    if LCN_enable:
        imgs_test = imgs_test.astype('float64')
        imgs_test = LecunLCN(imgs_test, image_shape=imgs_test.shape).output.eval()
        imgs_test = imgs_test.astype('float32')

    if not LCN_enable: imgs_test /= 255

    imgs_test -= imgs_test.mean(axis=0)

    print("Done loading test data")
    print('-' * 30)
    return imgs_test

def load_val_5imgs(npy_path = "data/dataset"):
    print('-' * 30)
    print('load train images...')

    imgs_train = np.load(npy_path + "/imgs_val_5imgs.npy")
    imgs_mask_train = np.load(npy_path + "/imgs_mask_val_5imgs.npy")

    # imgs_train = hist_equalization(imgs_train)

    imgs_train = imgs_train.astype('float64')
    imgs_mask_train = imgs_mask_train.astype('float64')

    if LCN_enable: imgs_train = LecunLCN(imgs_train, image_shape=imgs_train.shape).output.eval()

    if not LCN_enable: imgs_train /= 255

    mean = imgs_train.mean(axis=0)
    imgs_train -= mean


    imgs_mask_train /= 255
    imgs_mask_train[imgs_mask_train > 0.5] = 1
    imgs_mask_train[imgs_mask_train <= 0.5] = 0

    # weight_map_train = self.create_weight_map(imgs_mask_train)

    print("Done loading traing data")
    print('-' * 30)
    return imgs_train, imgs_mask_train

def hist_equalization(inputs):      # inputs are uint8, 0-255, Nx1x636x636
    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))
    output = inputs.copy()
    for i in range(len(inputs)):
        img = inputs[i, 0, :, :]
        # res = cv2.equalizeHist(img)
        res = clahe.apply(img)
        output[i,0,:,:] = res
    return output

### BinaryCrossEntropyLoss2d().forward(logits, labels)
class BinaryCrossEntropyLoss2d(nn.Module):
    def __init__(self, weight=None, size_average=True):
        """
        Binary cross entropy loss 2D
        Args:
            weight:
            size_average:
        """
        super(BinaryCrossEntropyLoss2d, self).__init__()
        self.bce_loss = nn.BCELoss(weight, size_average)

    def forward(self, logits, targets):
        # probs = F.sigmoid(logits)
        probs = logits
        probs_flat = probs.view(-1)  # Flatten
        targets_flat = targets.view(-1)  # Flatten
        return self.bce_loss(probs_flat, targets_flat)      # (output, labels)

class BCE_with_Weights(nn.Module):
    def __init__(self, weights=None):
        """
        Binary cross entropy loss 2D
        Args:
            weights:
        """
        super(BCE_with_Weights, self).__init__()
        self.weights = weights

    def forward(self, output, target):
        if self.weights is not None:
            loss = self.weights * (target * torch.log(output) + (1 - target) * torch.log(1 - output))
        else:
            loss = target * torch.log(output) + (1 - target) * torch.log(1 - output)

        return torch.neg(torch.mean(loss))

class LRN(nn.Module):       # input x is Torch tensor
    def __init__(self, local_size=1, alpha=1.0, beta=0.75, ACROSS_CHANNELS=False):      #LRN(local_size=5, alpha=0.0001, beta=0.75),
        super(LRN, self).__init__()
        self.ACROSS_CHANNELS = ACROSS_CHANNELS
        if self.ACROSS_CHANNELS:
            self.average = nn.AvgPool3d(kernel_size=(local_size, 1, 1),
                                        stride=1, padding=(int((local_size - 1.0) / 2), 0, 0))
        else:
            self.average = nn.AvgPool2d(kernel_size=local_size,
                                        stride=1, padding=int((local_size - 1.0) / 2))
        self.alpha = alpha
        self.beta = beta

    def forward(self, x):
        if self.ACROSS_CHANNELS:
            div = x.pow(2).unsqueeze(1)
            div = self.average(div).squeeze(1)
            div = div.mul(self.alpha).add(1.0).pow(self.beta)
        else:
            div = x.pow(2)
            div = self.average(div)
            div = div.mul(self.alpha).add(1.0).pow(self.beta)
        x = x.div(div)
        return x
Sat Nov 25 00:01:10 2017
Leg22_CROP_dropout_0_2_rmSigmoid_20aug_10ela_3inten_reflect
optim.SGD(net.parameters(), lr=1e-2, momentum=0.99)
Number of epoch max: 6
==========================================================================================
Sat Nov 25 00:18:11 2017
Leg22_CROP_dropout_0_2_rmSigmoid_20aug_10ela_3inten_reflect
Sat Nov 25 00:18:09 2017
import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.autograd import Variable
import math


class ConvBnRelu(nn.Module):
    def __init__(self, in_channels, out_channels, kernel_size, padding, stride):
        super(ConvBnRelu, self).__init__()
        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=kernel_size, padding=padding, stride=stride)
        self.bn = nn.BatchNorm2d(out_channels)
        self.relu = nn.ReLU()

    def forward(self, x):
        x = self.conv(x)
        # x = self.bn(x)
        x = self.relu(x)
        return x


class StackEncoder(nn.Module):
    def __init__(self, in_channels, out_channels):
        super(StackEncoder, self).__init__()
        self.convr1 = ConvBnRelu(in_channels, out_channels, kernel_size=(3, 3), stride=1, padding=0)
        self.convr2 = ConvBnRelu(out_channels, out_channels, kernel_size=(3, 3), stride=1, padding=0)
        self.maxPool = nn.MaxPool2d(kernel_size=(2, 2), stride=2)

    def forward(self, x):
        x = self.convr1(x)
        x = self.convr2(x)
        x_trace = x             # save x to use in concat in the Decoder path
        out = self.maxPool(x)
        return out, x_trace


class StackDecoder(nn.Module):
    def __init__(self, in_channels, out_channels, padding = 0, drop_out=False):
        super(StackDecoder, self).__init__()

        self.drop_out = drop_out
        self.dropout_layer = nn.Dropout2d(p=0.5)

        ''' this is old version
        self.upSample = nn.Upsample(size=upsample_size, scale_factor=(2, 2), mode="bilinear")
        self.convr1 = ConvBnRelu(in_channels, out_channels, kernel_size=(3, 3), stride=1, padding=padding)
        # Crop + concat step between these 2
        self.convr2 = ConvBnRelu(in_channels, out_channels, kernel_size=(3, 3), stride=1, padding=padding)
        '''
        self.upSample = nn.ConvTranspose2d(in_channels, out_channels, 2, stride=2)
        self.convr1 = ConvBnRelu(in_channels, out_channels, kernel_size=(3, 3), stride=1, padding=padding)
        self.convr2 = ConvBnRelu(out_channels, out_channels, kernel_size=(3, 3), stride=1, padding=padding)

    def _crop_concat(self, upsampled, bypass):
        """
         Crop y to the (h, w) of x and concat them.
         Used for the expansive path.
        Returns:
            The concatenated tensor
        """
        c = (bypass.size()[2] - upsampled.size()[2]) // 2
        bypass = F.pad(bypass, (-c, -c, -c, -c))

        return torch.cat((bypass, upsampled), 1)

    def forward(self, x, down_tensor):
        '''old version
        x = self.upSample(x)
        x = self.convr1(x)
        x = self._crop_concat(x, down_tensor)
        x = self.convr2(x)
        '''

        x = self.upSample(x)
        x = self._crop_concat(x, down_tensor)
        x = self.convr1(x)
        if self.drop_out: x = self.dropout_layer(x)
        x = self.convr2(x)
        if self.drop_out: x = self.dropout_layer(x)
        return x


class UNET_CROP(nn.Module):
    def __init__(self):
        super(UNET_CROP, self).__init__()
        # channels, height, width = in_shape

        # self.dropout = dropout

        self.model_code = ""        # variable to save model and main function when loaded

        self.down1 = StackEncoder(1, 64)
        self.down2 = StackEncoder(64, 128)
        self.down3 = StackEncoder(128, 256)
        self.down4 = StackEncoder(256, 512)

        self.center = nn.Sequential(
            # nn.Dropout2d(p=0.2),
            ConvBnRelu(512, 1024, kernel_size=(3, 3), stride=1, padding=0),
            nn.Dropout2d(p=0.2),
            ConvBnRelu(1024, 1024, kernel_size=(3, 3), stride=1, padding=0),
            nn.Dropout2d(p=0.2)
        )

        self.up1 = StackDecoder(in_channels=1024, out_channels=512)
        self.up2 = StackDecoder(in_channels=512, out_channels=256)
        self.up3 = StackDecoder(in_channels=256, out_channels=128)
        self.up4 = StackDecoder(in_channels=128, out_channels=64)

        # 1x1 convolution at the last layer
        # Different from the paper is the output size here
        self.output_seg_map = nn.Conv2d(64, 1, kernel_size=(1, 1), padding=0, stride=1)

        self._initialize_weights()

    def forward(self, x):
        x, x_trace1 = self.down1(x)
        x, x_trace2 = self.down2(x)
        x, x_trace3 = self.down3(x)
        x, x_trace4 = self.down4(x)
        x = self.center(x)
        x = self.up1(x, x_trace4)
        x = self.up2(x, x_trace3)
        x = self.up3(x, x_trace2)
        x = self.up4(x, x_trace1)

        x = self.output_seg_map(x)
        # x = F.sigmoid(x)
        # out = torch.squeeze(out, dim=1)
        return x


    def _initialize_weights(self):
        for m in self.modules():
            if isinstance(m, nn.Conv2d):
                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels
                m.weight.data.normal_(0, math.sqrt(2. / n))
                if m.bias is not None:
                    m.bias.data.zero_()
            elif isinstance(m, nn.BatchNorm2d):
                m.weight.data.fill_(1)
                m.bias.data.zero_()

# x = Variable(torch.randn(1,1,700, 700))       # simulate input image
# net = UNET_CROP()
# out = net(x)
# print("input: ", x)
# print("output: ", out)
===============from __future__ import print_function, division
import torch
from torch import optim
from torch.autograd import Variable
from torch.utils.data import DataLoader
import numpy as np
import torch.nn as nn
import torch.nn.functional as F
import Unet_crop
import tifffile as tiff
import Utils
import time
from sklearn.metrics import average_precision_score, recall_score, f1_score
import Analysis_crop
import cv2

def to_var(x):
    if torch.cuda.is_available():
        return Variable(x.cuda())
    else:
        return Variable(x)

### BinaryCrossEntropyLoss2d().forward(logits, labels)
class BinaryCrossEntropyLoss2d(nn.Module):
    def __init__(self, weight=None, size_average=True):
        """
        Binary cross entropy loss 2D
        Args:
            weight:
            size_average:
        """
        super(BinaryCrossEntropyLoss2d, self).__init__()
        self.bce_loss = nn.BCELoss(weight, size_average)

    def forward(self, probs, targets):
        probs = F.sigmoid(probs)
        probs_flat = probs.view(-1)  # Flatten
        targets_flat = targets.view(-1)  # Flatten
        return self.bce_loss(probs_flat, targets_flat)      # (output, labels)

def NetEval(net,valdata_loader,crit):
    loss = 0.
    count = 0
    net.eval()
    crop_input, crop_label,_ = crop_info()
    for i,data in enumerate(valdata_loader,0):
        inputs, labels = data
        inputs = inputs.numpy()
        labels = labels.numpy()
        for j in range(len(crop_input)):  # training on the crop images and corresponding labels
            ci = crop_input[j]  # crop index for inputs
            cl = crop_label[j]  # crop index for lables
            temp = labels[0, 0, :, :]  # labels is numpy array 512x512
            if np.sum(temp) < 0.01 * np.shape(temp)[0] * np.shape(temp)[1]: break
            x = inputs[:, :, ci[0]:ci[0] + 572, ci[1]:ci[1] + 572]
            y = labels[:, :, cl[0]: cl[0] + 388, cl[1]:cl[1] + 388]
            x = torch.from_numpy(x)
            y = torch.from_numpy(y)
            x, y = to_var(x), to_var(y)
            inputs, labels = to_var(x), to_var(y)
            out = net(x)
            l = crit(out, labels)
            loss += l.data[0]
            count += 1
    return loss/count

#process the test data and save to separate .tif image
def NetTest(net,testdata_loader,path = "data/results/"):
    net.eval()
    crop_input, crop_label, average_mask = crop_info()
    for i, data in enumerate(testdata_loader, 0):
        if i >= 30: return 1        # for debug
        data = to_var(data)
        img_shape = 512
        img = np.zeros((img_shape, img_shape))
        for j in range(len(crop_input)):  # training on the crop images and corresponding labels
            ci = crop_input[j]  # crop index for inputs

            x = data.numpy()[:, :, ci[0]:ci[0] + 572, ci[1]:ci[1] + 572]

            x = torch.from_numpy(x)

            x = to_var(x)
            out = F.sigmoid(net(x))
            out = out.cpu()
            out = out[0,0,:,:]
            img += out.data.numpy()

        img = img/average_mask
        img = img.reshape(-1)
        img[img < 0.5] = 0; img[img >= 0.5] = 1
        img = img.reshape(img_shape)
        img = np.uint8(img * 255)
        imgname = path + str(i) + ".tif"
        tiff.imsave(imgname, img)

# return input image size like 512x512, numpy array
def NetPredict(net, input_image):
    net.eval()
    _, crop_label, average_mask = crop_info()

    # input_image is grayscale input image of 512x512
    data = Utils.input_filled_mirroring(input_image, e = 94)
    imgdatas = np.ndarray((1, 1, data.shape[0], data.shape[1]), dtype=np.uint8)
    imgdatas[0] = np.expand_dims(data, 0)
    data = Utils.hist_equalization(imgdatas)
    data = data.astype('float32')
    data /= 255
    data -= data.mean(axis=0)

    img_shape = input_image.shape
    img = np.zeros((img_shape, img_shape))
    for j in range(len(crop_input)):  # training on the crop images and corresponding labels
        ci = crop_input[j]  # crop index for inputs
        x = data.numpy()[:, :, ci[0]:ci[0] + 572, ci[1]:ci[1] + 572]
        x = torch.from_numpy(x)
        x = to_var(x)
        out = F.sigmoid(net(x))
        out = out.cpu()
        out = out[0, 0, :, :]
        img += out.data.numpy()

    img = img / average_mask
    img = img.reshape(-1)
    img[img < 0.5] = 0
    img[img >= 0.5] = 1
    img = img.reshape(img_shape)
    img = np.uint8(img * 255)
    return img


def write_2_log(content):
    path = "log_file.txt"
    output = open(path, "a")
    output.write("\n")
    output.write(content)
    output.close()

def crop_info():
    crop_input = [[0, 0], [128, 0], [0, 128], [128, 128]]
    crop_label = [[0, 0], [124, 0], [0, 124], [124, 124]]
    average_mask = np.ones((512, 512))
    average_mask[124:388, 0:124] = 2
    average_mask[0:124, 124:388] = 2
    average_mask[124:388, 388:512] = 2
    average_mask[388:512, 124:388] = 2
    average_mask[124:388, 124:388] = 4
    return crop_input, crop_label, average_mask

if __name__ == '__main__':
    '''subjects to change for each exp:
    + path to the dataset
    + opt function
    + leg description
    + N_epoch
    + saved_model
    '''
    start_begining = time.time()

    # path = "data/dataset"
    path = "/home/anhxtuan/HanLe/dataset/20aug_10ela_3inten_reflect"
    path = "/home/anhxtuan/HanLe/dataset/20aug_10ela_3inten_reflect_700"

    import os
    print("Does the folder exist?: ", os.path.isdir(path))
    print("Does the path exist?: ", os.path.exists(path))

    imgs_train, imgs_mask_train = Utils.load_train_data(npy_path=path)
    imgs_val, imgs_mask_val = Utils.load_val_data(npy_path=path)
    batch_size = 1
    trainset = zip(imgs_train, imgs_mask_train)
    trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,
                                              shuffle=True, num_workers=2)
    valset = zip(imgs_val, imgs_mask_val)
    valloader = torch.utils.data.DataLoader(valset, batch_size=batch_size,
                                              shuffle=False, num_workers=2)
    # net = Unet.UNet()                     # Unet 1
    # net = Unet_BatchNorm.UNet_BN()          # Unet 2 with batchNorm
    net = Unet_crop.UNET_CROP()

    f1 = open("Unet_crop.py", 'r')     # embede code into the model to be saved later
    f2 = open("UnetTrain_crop.py", 'r')
    f3 = open("Utils.py", 'r')
    model_notes = time.strftime("%c") + "\n" + f1.read() + "\n" + "==="*5 + f2.read() + "\n" + "==="*5 + f3.read()
    f1.close()
    f2.close()
    f3.close()

    criterion = BinaryCrossEntropyLoss2d()
    # criterion = SoftDiceLoss()
    # criterion = nn.BCELoss()

    if torch.cuda.is_available():
        # torch.set_default_tensor_type('torch.cuda.FloatTensor')
        # net.load_state_dict(torch.load("Unet2_model_12epoch_Leg12_droput_0_2_rmSigmoid_20aug_10ela_3inten_reflect"))
        net.cuda()
        # criterion.cuda()

    opt = optim.SGD(net.parameters(), lr=1e-2, momentum=0.99)       # subject to change
    # opt = optim.RMSprop(net.parameters(), lr=2e-4)
    # RMSprop[22](learning rate 0.001) with weight decay set to 0.001.
    # opt = optim.Adam(net.parameters(), lr=1e-3, weight_decay=1e-4)

    train_loss = []
    val_loss = []

    print("[epoch, #image] Loss")
    leg = "Leg22_CROP_dropout_0_2_rmSigmoid_20aug_10ela_3inten_reflect"
    print("Processing: ", leg)
    model_name = ""

    N_epoch = 6
    model_saved = np.arange(1,N_epoch+1,2)
    val_loss_min = 100

    write_2_log("==="*30)
    write_2_log(time.strftime("%c"))       # time, date of exp
    write_2_log(leg)
    write_2_log(model_notes)
    write_2_log(time.strftime("%c"))  # time, date of exp
    write_2_log(leg)
    write_2_log("optim.SGD(net.parameters(), lr=1e-2, momentum=0.99)")
    write_2_log("Number of epoch max: " + str(N_epoch))

    crop_input, crop_label,_ = crop_info()
    min_model_epoch = 0
    for epoch in range(N_epoch):
        running_loss = 0.0; count = 0
        net.train()
        for i, data in enumerate(trainloader, 0):
            if i > 1000: break

            inputs, labels = data
            temp = labels.numpy()
            for j in range(len(crop_input)):       # training on the crop images and corresponding labels
                ci = crop_input[j]          # crop index for inputs
                cl = crop_label[j]          # crop index for lables
                temp = labels[0, 0, :, :]  # labels is numpy array 512x512
                if np.sum(temp) < 0.01 * np.shape(temp)[0] * np.shape(temp)[1]: break
                x = inputs.numpy()[:, :, ci[0]:ci[0] + 572, ci[1]:ci[1] + 572]
                y = labels.numpy()[:, :, cl[0]: cl[0] + 388, cl[1]:cl[1] + 388]
                x = torch.from_numpy(x)
                y = torch.from_numpy(y)
                x, y = to_var(x), to_var(y)
                opt.zero_grad()
                out = net(x)
                loss = criterion(out, y)
                loss.backward()
                opt.step()
                running_loss += loss.data[0]
                count += 1

        net.eval()
        val_loss_temp = NetEval(net, valloader, criterion)
        if epoch > 0 and val_loss_temp < val_loss_min:        # save the model which has the lowest val_loss, ignore first epoch
            val_loss_min = val_loss_temp
            torch.save(net.state_dict(), "Unet2_model_" + leg + "_min_val_loss")  # save model
            min_model_epoch = epoch + 1

        disp = 'Epoch %d: Train loss: %.6f, Val loss: %.6f' % (epoch + 1, running_loss/count, val_loss_temp)
        write_2_log(disp)
        print(disp)
        val_loss.append(val_loss_temp)
        train_loss.append(running_loss/count); running_loss = 0.0

        if (epoch + 1) in model_saved:        # save checkpoint
            model_name = "Unet2_model_" + str(epoch+1) + "epoch_" + leg
            torch.save(net.state_dict(), model_name)  # save model
            Analysis_crop.analysis(model_file = model_name, valloader = valloader)

    write_2_log("Best model at epoch: " + str(min_model_epoch))
    write_2_log("Total training time: " + str((time.time() - start_begining) / 3600.0))

    val_loss_file = "data/results" + "/val_loss_" + str(N_epoch) + "epoch_" + leg + ".npy"
    train_loss_file = "data/results" + "/training_loss_" + str(N_epoch) + "epoch_" + leg + ".npy"

    np.save(val_loss_file, val_loss)
    np.save(train_loss_file, train_loss)
    print("total processing time in seconds: ", time.time() - start_begining)
    print("total processing time in mins: ", (time.time() - start_begining) / 60.0)
    print("total processing time in hours: ", (time.time() - start_begining) / 3600.0)

    # Analysis.analysis(model_file="Unet2_model_" + leg + "_min_val_loss", valloader=valloader)

    Analysis_crop.PlotLoss(model_file = model_name, loss_train_path = train_loss_file, loss_val_path = val_loss_file, epoch_No = N_epoch)

    write_2_log(time.strftime("%c"))  # time, date of exp
===============
import numpy as np
import torch.nn as nn
import torch
import cv2
from lcn import LecunLCN

LCN_enable = False

def input_filled_mirroring(x, e = 62):      # fill missing data by mirroring the input image
    '''input size 636 --> output size 512'''
    w, h = x.shape
    #e = 62  # extra width on 1 edge
    y = np.zeros((h + e * 2, w + e * 2))
    y[e:h + e, e:w + e] = x
    y[e:e + h, 0:e] = np.flip(y[e:e + h, e:2 * e], 1)  # flip vertically
    y[e:e + h, e + w:2 * e + w] = np.flip(y[e:e + h, w:e + w], 1)  # flip vertically
    y[0:e, 0:2 * e + w] = np.flip(y[e:2 * e, 0:2 * e + w], 0)  # flip horizontally
    y[e + h:2 * e + h, 0:2 * e + w] = np.flip(y[h:e + h, 0:2 * e + w], 0)  # flip horizontally
    return y

def nearest_cells_distance(pos, img):
    # searching in 8 directions to find 2 nearest distances to neighbor cells
    curr_value = img[pos]
    w = img.shape[0];h = img.shape[1]
    count_detect = 0  # detect 2 nearest neighbors. break the search if count_detect = 2
    x, y = pos

    # print("w,h: ", (w, h))
    d1 = 9999999;d2 = 9999999;d3 = 9999999;d4 = 9999999
    d5 = 9999999;d6 = 9999999;d7 = 9999999;d8 = 9999999
    for i in range(1, max(w, h)):
        # (x+1, y), (x+1, y+1), (x+1, y-1),
        # (x, y+1), (x, y-1)
        # (x-1, y), (x-1,y+1), (x-1,y-1),
        if x + i < w:
            if img[(x + i, y)] != curr_value and d1 == 9999999:
                d1 = i; count_detect += 1
            if y + i < h:
                if img[(x + i, y + i)] != curr_value and d2 == 9999999:
                    d2 = i; count_detect += 1
            elif y - i >= 0:
                if img[(x + i, y - i)] != curr_value and d3 == 9999999:
                    d3 = i; count_detect += 1
        if y + i < h:
            if img[(x, y + i)] != curr_value and d4 == 9999999:
                d4 = i; count_detect += 1
        if y - i >= 0:
            if img[(x, y - i)] != curr_value and d5 == 9999999:
                d5 = i; count_detect += 1
        if x - i >= 0:
            if img[(x - i, y)] != curr_value and d6 == 9999999:
                d6 = i; count_detect += 1
            if y + i < h:
                if img[(x - i, y + i)] != curr_value and d7 == 9999999:
                    d7 = i; count_detect += 1
            elif y - i >= 0:
                if img[(x - i, y - i)] != curr_value and d8 == 9999999:
                    d8 = i; count_detect += 1
        if count_detect >= 2: break

    d = [d1, d2, d3, d4, d5, d6, d7, d8]
    min_index = np.argmin(d)
    dist1 = d[min_index]
    d.remove(dist1)
    min_index = np.argmin(d)
    dist2 = d[min_index]
    return dist1, dist2

def create_weight_map(imgs_mask):
        print('-' * 30)
        print('Creating weights for masks ...')
        print('-' * 30)
        weight_map = np.ndarray(
            (len(imgs_mask), 1, np.shape(imgs_mask)[2], np.shape(imgs_mask)[3]), dtype=np.float32)
        w_0 = 10; sigma = 4
        imgs_w, imgs_h = np.shape(imgs_mask)[2], np.shape(imgs_mask)[3]
        total_pixels = imgs_w*imgs_h
        import time
        start = time.time()
        for i in range(len(imgs_mask)):
            if i%10 == 0: print("Done processing: %d images, time passed: %.2f mins" % (i, (time.time() - start)/60.0))
            temp = imgs_mask[i,0,:,:]
            w_border = 1 - np.sum(temp)/total_pixels        # w_c of pixel on the border (black)
            for m in range(imgs_w):
                for n in range(imgs_h):
                    # loop through all pixel of the mask
                    d1,d2 = nearest_cells_distance((m,n), temp)
                    w_c = w_border
                    if temp[m,n] == 0: w_c = 1 - w_border
                    weight_map[i,0,m,n] = w_c*5 + w_0*np.exp(-(d1 + d2)**2/(2*sigma**2))
                    # print("w_0*np.exp(): ", w_0*np.exp(-(d1 + d2)**2/(2*sigma**2)))
                    # print("w_border: ", w_border)

        np.save('data/dataset/weight_map_train.npy', weight_map)

        return weight_map

def load_train_data(npy_path = "data/dataset", hist_equal = False):

    print('-' * 30)
    print('load train images...')

    imgs_train = np.load(npy_path + "/imgs_train.npy")
    imgs_mask_train = np.load(npy_path + "/imgs_mask_train.npy")

    if hist_equal: imgs_train = hist_equalization(imgs_train)

    # weight_map_train = np.load(npy_path + "/weight_map_train.npy")
    # weight_map_train = weight_map_train.astype('float32')

    imgs_train = imgs_train.astype('float32')
    imgs_mask_train = imgs_mask_train.astype('float32')

    if LCN_enable:
        imgs_train = imgs_train.astype('float64')
        imgs_train = LecunLCN(imgs_train, image_shape=imgs_train.shape).output.eval()
        imgs_train = imgs_train.astype('float32')

    if not LCN_enable: imgs_train /= 255

    imgs_train -= imgs_train.mean(axis=0)
    imgs_mask_train /= 255
    imgs_mask_train[imgs_mask_train > 0.5] = 1
    imgs_mask_train[imgs_mask_train <= 0.5] = 0

    # weight_map_train = create_weight_map(imgs_mask_train)

    print("Done loading traing data")
    print('-' * 30)
    return imgs_train, imgs_mask_train

def load_val_data(npy_path = "data/dataset", hist_equal = True):

    print('-' * 30)
    print('load validation images...')

    imgs_train = np.load(npy_path + "/imgs_val.npy")
    imgs_mask_train = np.load(npy_path + "/imgs_mask_val.npy")

    if hist_equal: imgs_train = hist_equalization(imgs_train)

    imgs_train = imgs_train.astype('float32')
    imgs_mask_train = imgs_mask_train.astype('float32')

    if LCN_enable:
        imgs_train = imgs_train.astype('float64')
        imgs_train = LecunLCN(imgs_train, image_shape=imgs_train.shape).output.eval()
        imgs_train = imgs_train.astype('float32')

    if not LCN_enable: imgs_train /= 255
    imgs_train -= imgs_train.mean(axis=0)
    imgs_mask_train /= 255
    imgs_mask_train[imgs_mask_train > 0.5] = 1
    imgs_mask_train[imgs_mask_train <= 0.5] = 0
    print("Done loading validation data")
    print('-' * 30)
    return imgs_train, imgs_mask_train

def load_test_data(npy_path = "data/dataset", hist_equal = True):

    print('-' * 30)
    print('load test images...')

    imgs_test = np.load(npy_path + "/imgs_test.npy")

    if hist_equal: imgs_test = hist_equalization(imgs_test)

    imgs_test = imgs_test.astype('float32')

    if LCN_enable:
        imgs_test = imgs_test.astype('float64')
        imgs_test = LecunLCN(imgs_test, image_shape=imgs_test.shape).output.eval()
        imgs_test = imgs_test.astype('float32')

    if not LCN_enable: imgs_test /= 255

    imgs_test -= imgs_test.mean(axis=0)

    print("Done loading test data")
    print('-' * 30)
    return imgs_test

def load_val_5imgs(npy_path = "data/dataset"):
    print('-' * 30)
    print('load train images...')

    imgs_train = np.load(npy_path + "/imgs_val_5imgs.npy")
    imgs_mask_train = np.load(npy_path + "/imgs_mask_val_5imgs.npy")

    # imgs_train = hist_equalization(imgs_train)

    imgs_train = imgs_train.astype('float64')
    imgs_mask_train = imgs_mask_train.astype('float64')

    if LCN_enable: imgs_train = LecunLCN(imgs_train, image_shape=imgs_train.shape).output.eval()

    if not LCN_enable: imgs_train /= 255

    mean = imgs_train.mean(axis=0)
    imgs_train -= mean


    imgs_mask_train /= 255
    imgs_mask_train[imgs_mask_train > 0.5] = 1
    imgs_mask_train[imgs_mask_train <= 0.5] = 0

    # weight_map_train = self.create_weight_map(imgs_mask_train)

    print("Done loading traing data")
    print('-' * 30)
    return imgs_train, imgs_mask_train

def hist_equalization(inputs):      # inputs are uint8, 0-255, Nx1x636x636
    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))
    output = inputs.copy()
    for i in range(len(inputs)):
        img = inputs[i, 0, :, :]
        # res = cv2.equalizeHist(img)
        res = clahe.apply(img)
        output[i,0,:,:] = res
    return output

### BinaryCrossEntropyLoss2d().forward(logits, labels)
class BinaryCrossEntropyLoss2d(nn.Module):
    def __init__(self, weight=None, size_average=True):
        """
        Binary cross entropy loss 2D
        Args:
            weight:
            size_average:
        """
        super(BinaryCrossEntropyLoss2d, self).__init__()
        self.bce_loss = nn.BCELoss(weight, size_average)

    def forward(self, logits, targets):
        # probs = F.sigmoid(logits)
        probs = logits
        probs_flat = probs.view(-1)  # Flatten
        targets_flat = targets.view(-1)  # Flatten
        return self.bce_loss(probs_flat, targets_flat)      # (output, labels)

class BCE_with_Weights(nn.Module):
    def __init__(self, weights=None):
        """
        Binary cross entropy loss 2D
        Args:
            weights:
        """
        super(BCE_with_Weights, self).__init__()
        self.weights = weights

    def forward(self, output, target):
        if self.weights is not None:
            loss = self.weights * (target * torch.log(output) + (1 - target) * torch.log(1 - output))
        else:
            loss = target * torch.log(output) + (1 - target) * torch.log(1 - output)

        return torch.neg(torch.mean(loss))

class LRN(nn.Module):       # input x is Torch tensor
    def __init__(self, local_size=1, alpha=1.0, beta=0.75, ACROSS_CHANNELS=False):      #LRN(local_size=5, alpha=0.0001, beta=0.75),
        super(LRN, self).__init__()
        self.ACROSS_CHANNELS = ACROSS_CHANNELS
        if self.ACROSS_CHANNELS:
            self.average = nn.AvgPool3d(kernel_size=(local_size, 1, 1),
                                        stride=1, padding=(int((local_size - 1.0) / 2), 0, 0))
        else:
            self.average = nn.AvgPool2d(kernel_size=local_size,
                                        stride=1, padding=int((local_size - 1.0) / 2))
        self.alpha = alpha
        self.beta = beta

    def forward(self, x):
        if self.ACROSS_CHANNELS:
            div = x.pow(2).unsqueeze(1)
            div = self.average(div).squeeze(1)
            div = div.mul(self.alpha).add(1.0).pow(self.beta)
        else:
            div = x.pow(2)
            div = self.average(div)
            div = div.mul(self.alpha).add(1.0).pow(self.beta)
        x = x.div(div)
        return x
Sat Nov 25 00:18:11 2017
Leg22_CROP_dropout_0_2_rmSigmoid_20aug_10ela_3inten_reflect
optim.SGD(net.parameters(), lr=1e-2, momentum=0.99)
Number of epoch max: 6
==========================================================================================
Sat Nov 25 00:29:22 2017
Leg22_CROP_dropout_0_2_rmSigmoid_20aug_10ela_3inten_reflect
Sat Nov 25 00:29:19 2017
import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.autograd import Variable
import math


class ConvBnRelu(nn.Module):
    def __init__(self, in_channels, out_channels, kernel_size, padding, stride):
        super(ConvBnRelu, self).__init__()
        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=kernel_size, padding=padding, stride=stride)
        self.bn = nn.BatchNorm2d(out_channels)
        self.relu = nn.ReLU()

    def forward(self, x):
        x = self.conv(x)
        # x = self.bn(x)
        x = self.relu(x)
        return x


class StackEncoder(nn.Module):
    def __init__(self, in_channels, out_channels):
        super(StackEncoder, self).__init__()
        self.convr1 = ConvBnRelu(in_channels, out_channels, kernel_size=(3, 3), stride=1, padding=0)
        self.convr2 = ConvBnRelu(out_channels, out_channels, kernel_size=(3, 3), stride=1, padding=0)
        self.maxPool = nn.MaxPool2d(kernel_size=(2, 2), stride=2)

    def forward(self, x):
        x = self.convr1(x)
        x = self.convr2(x)
        x_trace = x             # save x to use in concat in the Decoder path
        out = self.maxPool(x)
        return out, x_trace


class StackDecoder(nn.Module):
    def __init__(self, in_channels, out_channels, padding = 0, drop_out=False):
        super(StackDecoder, self).__init__()

        self.drop_out = drop_out
        self.dropout_layer = nn.Dropout2d(p=0.5)

        ''' this is old version
        self.upSample = nn.Upsample(size=upsample_size, scale_factor=(2, 2), mode="bilinear")
        self.convr1 = ConvBnRelu(in_channels, out_channels, kernel_size=(3, 3), stride=1, padding=padding)
        # Crop + concat step between these 2
        self.convr2 = ConvBnRelu(in_channels, out_channels, kernel_size=(3, 3), stride=1, padding=padding)
        '''
        self.upSample = nn.ConvTranspose2d(in_channels, out_channels, 2, stride=2)
        self.convr1 = ConvBnRelu(in_channels, out_channels, kernel_size=(3, 3), stride=1, padding=padding)
        self.convr2 = ConvBnRelu(out_channels, out_channels, kernel_size=(3, 3), stride=1, padding=padding)

    def _crop_concat(self, upsampled, bypass):
        """
         Crop y to the (h, w) of x and concat them.
         Used for the expansive path.
        Returns:
            The concatenated tensor
        """
        c = (bypass.size()[2] - upsampled.size()[2]) // 2
        bypass = F.pad(bypass, (-c, -c, -c, -c))

        return torch.cat((bypass, upsampled), 1)

    def forward(self, x, down_tensor):
        '''old version
        x = self.upSample(x)
        x = self.convr1(x)
        x = self._crop_concat(x, down_tensor)
        x = self.convr2(x)
        '''

        x = self.upSample(x)
        x = self._crop_concat(x, down_tensor)
        x = self.convr1(x)
        if self.drop_out: x = self.dropout_layer(x)
        x = self.convr2(x)
        if self.drop_out: x = self.dropout_layer(x)
        return x


class UNET_CROP(nn.Module):
    def __init__(self):
        super(UNET_CROP, self).__init__()
        # channels, height, width = in_shape

        # self.dropout = dropout

        self.model_code = ""        # variable to save model and main function when loaded

        self.down1 = StackEncoder(1, 64)
        self.down2 = StackEncoder(64, 128)
        self.down3 = StackEncoder(128, 256)
        self.down4 = StackEncoder(256, 512)

        self.center = nn.Sequential(
            # nn.Dropout2d(p=0.2),
            ConvBnRelu(512, 1024, kernel_size=(3, 3), stride=1, padding=0),
            nn.Dropout2d(p=0.2),
            ConvBnRelu(1024, 1024, kernel_size=(3, 3), stride=1, padding=0),
            nn.Dropout2d(p=0.2)
        )

        self.up1 = StackDecoder(in_channels=1024, out_channels=512)
        self.up2 = StackDecoder(in_channels=512, out_channels=256)
        self.up3 = StackDecoder(in_channels=256, out_channels=128)
        self.up4 = StackDecoder(in_channels=128, out_channels=64)

        # 1x1 convolution at the last layer
        # Different from the paper is the output size here
        self.output_seg_map = nn.Conv2d(64, 1, kernel_size=(1, 1), padding=0, stride=1)

        self._initialize_weights()

    def forward(self, x):
        x, x_trace1 = self.down1(x)
        x, x_trace2 = self.down2(x)
        x, x_trace3 = self.down3(x)
        x, x_trace4 = self.down4(x)
        x = self.center(x)
        x = self.up1(x, x_trace4)
        x = self.up2(x, x_trace3)
        x = self.up3(x, x_trace2)
        x = self.up4(x, x_trace1)

        x = self.output_seg_map(x)
        # x = F.sigmoid(x)
        # out = torch.squeeze(out, dim=1)
        return x


    def _initialize_weights(self):
        for m in self.modules():
            if isinstance(m, nn.Conv2d):
                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels
                m.weight.data.normal_(0, math.sqrt(2. / n))
                if m.bias is not None:
                    m.bias.data.zero_()
            elif isinstance(m, nn.BatchNorm2d):
                m.weight.data.fill_(1)
                m.bias.data.zero_()

# x = Variable(torch.randn(1,1,700, 700))       # simulate input image
# net = UNET_CROP()
# out = net(x)
# print("input: ", x)
# print("output: ", out)
===============from __future__ import print_function, division
import torch
from torch import optim
from torch.autograd import Variable
from torch.utils.data import DataLoader
import numpy as np
import torch.nn as nn
import torch.nn.functional as F
import Unet_crop
import tifffile as tiff
import Utils
import time
from sklearn.metrics import average_precision_score, recall_score, f1_score
import Analysis_crop
import cv2

def to_var(x):
    if torch.cuda.is_available():
        return Variable(x.cuda())
    else:
        return Variable(x)

### BinaryCrossEntropyLoss2d().forward(logits, labels)
class BinaryCrossEntropyLoss2d(nn.Module):
    def __init__(self, weight=None, size_average=True):
        """
        Binary cross entropy loss 2D
        Args:
            weight:
            size_average:
        """
        super(BinaryCrossEntropyLoss2d, self).__init__()
        self.bce_loss = nn.BCELoss(weight, size_average)

    def forward(self, probs, targets):
        probs = F.sigmoid(probs)
        probs_flat = probs.view(-1)  # Flatten
        targets_flat = targets.view(-1)  # Flatten
        return self.bce_loss(probs_flat, targets_flat)      # (output, labels)

def NetEval(net,valdata_loader,crit):
    loss = 0.
    count = 0
    net.eval()
    crop_input, crop_label,_ = crop_info()
    for i,data in enumerate(valdata_loader,0):
        inputs, labels = data
        inputs = inputs.numpy()
        labels = labels.numpy()
        for j in range(len(crop_input)):  # training on the crop images and corresponding labels
            ci = crop_input[j]  # crop index for inputs
            cl = crop_label[j]  # crop index for lables
            temp = labels[0, 0, :, :]  # labels is numpy array 512x512
            if np.sum(temp) < 0.01 * np.shape(temp)[0] * np.shape(temp)[1]: break
            x = inputs[:, :, ci[0]:ci[0] + 572, ci[1]:ci[1] + 572]
            y = labels[:, :, cl[0]: cl[0] + 388, cl[1]:cl[1] + 388]
            x = torch.from_numpy(x)
            y = torch.from_numpy(y)
            x, y = to_var(x), to_var(y)
            inputs, labels = to_var(x), to_var(y)
            out = net(x)
            l = crit(out, labels)
            loss += l.data[0]
            count += 1
    return loss/count

#process the test data and save to separate .tif image
def NetTest(net,testdata_loader,path = "data/results/"):
    net.eval()
    crop_input, crop_label, average_mask = crop_info()
    for i, data in enumerate(testdata_loader, 0):
        if i >= 30: return 1        # for debug
        data = to_var(data)
        img_shape = 512
        img = np.zeros((img_shape, img_shape))
        for j in range(len(crop_input)):  # training on the crop images and corresponding labels
            ci = crop_input[j]  # crop index for inputs

            x = data.numpy()[:, :, ci[0]:ci[0] + 572, ci[1]:ci[1] + 572]

            x = torch.from_numpy(x)

            x = to_var(x)
            out = F.sigmoid(net(x))
            out = out.cpu()
            out = out[0,0,:,:]
            img += out.data.numpy()

        img = img/average_mask
        img = img.reshape(-1)
        img[img < 0.5] = 0; img[img >= 0.5] = 1
        img = img.reshape(img_shape)
        img = np.uint8(img * 255)
        imgname = path + str(i) + ".tif"
        tiff.imsave(imgname, img)

# return input image size like 512x512, numpy array
def NetPredict(net, input_image):
    net.eval()
    _, crop_label, average_mask = crop_info()

    # input_image is grayscale input image of 512x512
    data = Utils.input_filled_mirroring(input_image, e = 94)
    imgdatas = np.ndarray((1, 1, data.shape[0], data.shape[1]), dtype=np.uint8)
    imgdatas[0] = np.expand_dims(data, 0)
    data = Utils.hist_equalization(imgdatas)
    data = data.astype('float32')
    data /= 255
    data -= data.mean(axis=0)

    img_shape = input_image.shape
    img = np.zeros((img_shape, img_shape))
    for j in range(len(crop_input)):  # training on the crop images and corresponding labels
        ci = crop_input[j]  # crop index for inputs
        x = data.numpy()[:, :, ci[0]:ci[0] + 572, ci[1]:ci[1] + 572]
        x = torch.from_numpy(x)
        x = to_var(x)
        out = F.sigmoid(net(x))
        out = out.cpu()
        out = out[0, 0, :, :]
        img += out.data.numpy()

    img = img / average_mask
    img = img.reshape(-1)
    img[img < 0.5] = 0
    img[img >= 0.5] = 1
    img = img.reshape(img_shape)
    img = np.uint8(img * 255)
    return img


def write_2_log(content):
    path = "log_file.txt"
    output = open(path, "a")
    output.write("\n")
    output.write(content)
    output.close()

def crop_info():
    crop_input = [[0, 0], [128, 0], [0, 128], [128, 128]]
    crop_label = [[0, 0], [124, 0], [0, 124], [124, 124]]
    average_mask = np.ones((512, 512))
    average_mask[124:388, 0:124] = 2
    average_mask[0:124, 124:388] = 2
    average_mask[124:388, 388:512] = 2
    average_mask[388:512, 124:388] = 2
    average_mask[124:388, 124:388] = 4
    return crop_input, crop_label, average_mask

if __name__ == '__main__':
    '''subjects to change for each exp:
    + path to the dataset
    + opt function
    + leg description
    + N_epoch
    + saved_model
    '''
    start_begining = time.time()

    # path = "data/dataset"
    path = "/home/anhxtuan/HanLe/dataset/20aug_10ela_3inten_reflect"
    path = "/home/anhxtuan/HanLe/dataset/20aug_10ela_3inten_reflect_700"

    import os
    print("Does the folder exist?: ", os.path.isdir(path))
    print("Does the path exist?: ", os.path.exists(path))

    imgs_train, imgs_mask_train = Utils.load_train_data(npy_path=path)
    imgs_val, imgs_mask_val = Utils.load_val_data(npy_path=path)
    batch_size = 1
    trainset = zip(imgs_train, imgs_mask_train)
    trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,
                                              shuffle=True, num_workers=2)
    valset = zip(imgs_val, imgs_mask_val)
    valloader = torch.utils.data.DataLoader(valset, batch_size=batch_size,
                                              shuffle=False, num_workers=2)
    # net = Unet.UNet()                     # Unet 1
    # net = Unet_BatchNorm.UNet_BN()          # Unet 2 with batchNorm
    net = Unet_crop.UNET_CROP()

    f1 = open("Unet_crop.py", 'r')     # embede code into the model to be saved later
    f2 = open("UnetTrain_crop.py", 'r')
    f3 = open("Utils.py", 'r')
    model_notes = time.strftime("%c") + "\n" + f1.read() + "\n" + "==="*5 + f2.read() + "\n" + "==="*5 + f3.read()
    f1.close()
    f2.close()
    f3.close()

    criterion = BinaryCrossEntropyLoss2d()
    # criterion = SoftDiceLoss()
    # criterion = nn.BCELoss()

    if torch.cuda.is_available():
        # torch.set_default_tensor_type('torch.cuda.FloatTensor')
        # net.load_state_dict(torch.load("Unet2_model_12epoch_Leg12_droput_0_2_rmSigmoid_20aug_10ela_3inten_reflect"))
        net.cuda()
        # criterion.cuda()

    opt = optim.SGD(net.parameters(), lr=1e-2, momentum=0.99)       # subject to change
    # opt = optim.RMSprop(net.parameters(), lr=2e-4)
    # RMSprop[22](learning rate 0.001) with weight decay set to 0.001.
    # opt = optim.Adam(net.parameters(), lr=1e-3, weight_decay=1e-4)

    train_loss = []
    val_loss = []

    print("[epoch, #image] Loss")
    leg = "Leg22_CROP_dropout_0_2_rmSigmoid_20aug_10ela_3inten_reflect"
    print("Processing: ", leg)
    model_name = ""

    N_epoch = 6
    model_saved = np.arange(1,N_epoch+1,2)
    val_loss_min = 100

    write_2_log("==="*30)
    write_2_log(time.strftime("%c"))       # time, date of exp
    write_2_log(leg)
    write_2_log(model_notes)
    write_2_log(time.strftime("%c"))  # time, date of exp
    write_2_log(leg)
    write_2_log("optim.SGD(net.parameters(), lr=1e-2, momentum=0.99)")
    write_2_log("Number of epoch max: " + str(N_epoch))

    crop_input, crop_label,_ = crop_info()
    min_model_epoch = 0
    for epoch in range(N_epoch):
        running_loss = 0.0; count = 0
        net.train()
        for i, data in enumerate(trainloader, 0):
            if i > 1000: break

            inputs, labels = data
            temp = labels.numpy()
            for j in range(len(crop_input)):       # training on the crop images and corresponding labels
                ci = crop_input[j]          # crop index for inputs
                cl = crop_label[j]          # crop index for lables
                temp = temp[0, 0, :, :]  # labels is numpy array 512x512
                if np.sum(temp) < 0.01 * np.shape(temp)[0] * np.shape(temp)[1]: break
                x = inputs.numpy()[:, :, ci[0]:ci[0] + 572, ci[1]:ci[1] + 572]
                y = labels.numpy()[:, :, cl[0]: cl[0] + 388, cl[1]:cl[1] + 388]
                x = torch.from_numpy(x)
                y = torch.from_numpy(y)
                x, y = to_var(x), to_var(y)
                opt.zero_grad()
                out = net(x)
                loss = criterion(out, y)
                loss.backward()
                opt.step()
                running_loss += loss.data[0]
                count += 1

        net.eval()
        val_loss_temp = NetEval(net, valloader, criterion)
        if epoch > 0 and val_loss_temp < val_loss_min:        # save the model which has the lowest val_loss, ignore first epoch
            val_loss_min = val_loss_temp
            torch.save(net.state_dict(), "Unet2_model_" + leg + "_min_val_loss")  # save model
            min_model_epoch = epoch + 1

        disp = 'Epoch %d: Train loss: %.6f, Val loss: %.6f' % (epoch + 1, running_loss/count, val_loss_temp)
        write_2_log(disp)
        print(disp)
        val_loss.append(val_loss_temp)
        train_loss.append(running_loss/count); running_loss = 0.0

        if (epoch + 1) in model_saved:        # save checkpoint
            model_name = "Unet2_model_" + str(epoch+1) + "epoch_" + leg
            torch.save(net.state_dict(), model_name)  # save model
            Analysis_crop.analysis(model_file = model_name, valloader = valloader)

    write_2_log("Best model at epoch: " + str(min_model_epoch))
    write_2_log("Total training time: " + str((time.time() - start_begining) / 3600.0))

    val_loss_file = "data/results" + "/val_loss_" + str(N_epoch) + "epoch_" + leg + ".npy"
    train_loss_file = "data/results" + "/training_loss_" + str(N_epoch) + "epoch_" + leg + ".npy"

    np.save(val_loss_file, val_loss)
    np.save(train_loss_file, train_loss)
    print("total processing time in seconds: ", time.time() - start_begining)
    print("total processing time in mins: ", (time.time() - start_begining) / 60.0)
    print("total processing time in hours: ", (time.time() - start_begining) / 3600.0)

    # Analysis.analysis(model_file="Unet2_model_" + leg + "_min_val_loss", valloader=valloader)

    Analysis_crop.PlotLoss(model_file = model_name, loss_train_path = train_loss_file, loss_val_path = val_loss_file, epoch_No = N_epoch)

    write_2_log(time.strftime("%c"))  # time, date of exp
===============
import numpy as np
import torch.nn as nn
import torch
import cv2
from lcn import LecunLCN

LCN_enable = False

def input_filled_mirroring(x, e = 62):      # fill missing data by mirroring the input image
    '''input size 636 --> output size 512'''
    w, h = x.shape
    #e = 62  # extra width on 1 edge
    y = np.zeros((h + e * 2, w + e * 2))
    y[e:h + e, e:w + e] = x
    y[e:e + h, 0:e] = np.flip(y[e:e + h, e:2 * e], 1)  # flip vertically
    y[e:e + h, e + w:2 * e + w] = np.flip(y[e:e + h, w:e + w], 1)  # flip vertically
    y[0:e, 0:2 * e + w] = np.flip(y[e:2 * e, 0:2 * e + w], 0)  # flip horizontally
    y[e + h:2 * e + h, 0:2 * e + w] = np.flip(y[h:e + h, 0:2 * e + w], 0)  # flip horizontally
    return y

def nearest_cells_distance(pos, img):
    # searching in 8 directions to find 2 nearest distances to neighbor cells
    curr_value = img[pos]
    w = img.shape[0];h = img.shape[1]
    count_detect = 0  # detect 2 nearest neighbors. break the search if count_detect = 2
    x, y = pos

    # print("w,h: ", (w, h))
    d1 = 9999999;d2 = 9999999;d3 = 9999999;d4 = 9999999
    d5 = 9999999;d6 = 9999999;d7 = 9999999;d8 = 9999999
    for i in range(1, max(w, h)):
        # (x+1, y), (x+1, y+1), (x+1, y-1),
        # (x, y+1), (x, y-1)
        # (x-1, y), (x-1,y+1), (x-1,y-1),
        if x + i < w:
            if img[(x + i, y)] != curr_value and d1 == 9999999:
                d1 = i; count_detect += 1
            if y + i < h:
                if img[(x + i, y + i)] != curr_value and d2 == 9999999:
                    d2 = i; count_detect += 1
            elif y - i >= 0:
                if img[(x + i, y - i)] != curr_value and d3 == 9999999:
                    d3 = i; count_detect += 1
        if y + i < h:
            if img[(x, y + i)] != curr_value and d4 == 9999999:
                d4 = i; count_detect += 1
        if y - i >= 0:
            if img[(x, y - i)] != curr_value and d5 == 9999999:
                d5 = i; count_detect += 1
        if x - i >= 0:
            if img[(x - i, y)] != curr_value and d6 == 9999999:
                d6 = i; count_detect += 1
            if y + i < h:
                if img[(x - i, y + i)] != curr_value and d7 == 9999999:
                    d7 = i; count_detect += 1
            elif y - i >= 0:
                if img[(x - i, y - i)] != curr_value and d8 == 9999999:
                    d8 = i; count_detect += 1
        if count_detect >= 2: break

    d = [d1, d2, d3, d4, d5, d6, d7, d8]
    min_index = np.argmin(d)
    dist1 = d[min_index]
    d.remove(dist1)
    min_index = np.argmin(d)
    dist2 = d[min_index]
    return dist1, dist2

def create_weight_map(imgs_mask):
        print('-' * 30)
        print('Creating weights for masks ...')
        print('-' * 30)
        weight_map = np.ndarray(
            (len(imgs_mask), 1, np.shape(imgs_mask)[2], np.shape(imgs_mask)[3]), dtype=np.float32)
        w_0 = 10; sigma = 4
        imgs_w, imgs_h = np.shape(imgs_mask)[2], np.shape(imgs_mask)[3]
        total_pixels = imgs_w*imgs_h
        import time
        start = time.time()
        for i in range(len(imgs_mask)):
            if i%10 == 0: print("Done processing: %d images, time passed: %.2f mins" % (i, (time.time() - start)/60.0))
            temp = imgs_mask[i,0,:,:]
            w_border = 1 - np.sum(temp)/total_pixels        # w_c of pixel on the border (black)
            for m in range(imgs_w):
                for n in range(imgs_h):
                    # loop through all pixel of the mask
                    d1,d2 = nearest_cells_distance((m,n), temp)
                    w_c = w_border
                    if temp[m,n] == 0: w_c = 1 - w_border
                    weight_map[i,0,m,n] = w_c*5 + w_0*np.exp(-(d1 + d2)**2/(2*sigma**2))
                    # print("w_0*np.exp(): ", w_0*np.exp(-(d1 + d2)**2/(2*sigma**2)))
                    # print("w_border: ", w_border)

        np.save('data/dataset/weight_map_train.npy', weight_map)

        return weight_map

def load_train_data(npy_path = "data/dataset", hist_equal = False):

    print('-' * 30)
    print('load train images...')

    imgs_train = np.load(npy_path + "/imgs_train.npy")
    imgs_mask_train = np.load(npy_path + "/imgs_mask_train.npy")

    if hist_equal: imgs_train = hist_equalization(imgs_train)

    # weight_map_train = np.load(npy_path + "/weight_map_train.npy")
    # weight_map_train = weight_map_train.astype('float32')

    imgs_train = imgs_train.astype('float32')
    imgs_mask_train = imgs_mask_train.astype('float32')

    if LCN_enable:
        imgs_train = imgs_train.astype('float64')
        imgs_train = LecunLCN(imgs_train, image_shape=imgs_train.shape).output.eval()
        imgs_train = imgs_train.astype('float32')

    if not LCN_enable: imgs_train /= 255

    imgs_train -= imgs_train.mean(axis=0)
    imgs_mask_train /= 255
    imgs_mask_train[imgs_mask_train > 0.5] = 1
    imgs_mask_train[imgs_mask_train <= 0.5] = 0

    # weight_map_train = create_weight_map(imgs_mask_train)

    print("Done loading traing data")
    print('-' * 30)
    return imgs_train, imgs_mask_train

def load_val_data(npy_path = "data/dataset", hist_equal = True):

    print('-' * 30)
    print('load validation images...')

    imgs_train = np.load(npy_path + "/imgs_val.npy")
    imgs_mask_train = np.load(npy_path + "/imgs_mask_val.npy")

    if hist_equal: imgs_train = hist_equalization(imgs_train)

    imgs_train = imgs_train.astype('float32')
    imgs_mask_train = imgs_mask_train.astype('float32')

    if LCN_enable:
        imgs_train = imgs_train.astype('float64')
        imgs_train = LecunLCN(imgs_train, image_shape=imgs_train.shape).output.eval()
        imgs_train = imgs_train.astype('float32')

    if not LCN_enable: imgs_train /= 255
    imgs_train -= imgs_train.mean(axis=0)
    imgs_mask_train /= 255
    imgs_mask_train[imgs_mask_train > 0.5] = 1
    imgs_mask_train[imgs_mask_train <= 0.5] = 0
    print("Done loading validation data")
    print('-' * 30)
    return imgs_train, imgs_mask_train

def load_test_data(npy_path = "data/dataset", hist_equal = True):

    print('-' * 30)
    print('load test images...')

    imgs_test = np.load(npy_path + "/imgs_test.npy")

    if hist_equal: imgs_test = hist_equalization(imgs_test)

    imgs_test = imgs_test.astype('float32')

    if LCN_enable:
        imgs_test = imgs_test.astype('float64')
        imgs_test = LecunLCN(imgs_test, image_shape=imgs_test.shape).output.eval()
        imgs_test = imgs_test.astype('float32')

    if not LCN_enable: imgs_test /= 255

    imgs_test -= imgs_test.mean(axis=0)

    print("Done loading test data")
    print('-' * 30)
    return imgs_test

def load_val_5imgs(npy_path = "data/dataset"):
    print('-' * 30)
    print('load train images...')

    imgs_train = np.load(npy_path + "/imgs_val_5imgs.npy")
    imgs_mask_train = np.load(npy_path + "/imgs_mask_val_5imgs.npy")

    # imgs_train = hist_equalization(imgs_train)

    imgs_train = imgs_train.astype('float64')
    imgs_mask_train = imgs_mask_train.astype('float64')

    if LCN_enable: imgs_train = LecunLCN(imgs_train, image_shape=imgs_train.shape).output.eval()

    if not LCN_enable: imgs_train /= 255

    mean = imgs_train.mean(axis=0)
    imgs_train -= mean


    imgs_mask_train /= 255
    imgs_mask_train[imgs_mask_train > 0.5] = 1
    imgs_mask_train[imgs_mask_train <= 0.5] = 0

    # weight_map_train = self.create_weight_map(imgs_mask_train)

    print("Done loading traing data")
    print('-' * 30)
    return imgs_train, imgs_mask_train

def hist_equalization(inputs):      # inputs are uint8, 0-255, Nx1x636x636
    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))
    output = inputs.copy()
    for i in range(len(inputs)):
        img = inputs[i, 0, :, :]
        # res = cv2.equalizeHist(img)
        res = clahe.apply(img)
        output[i,0,:,:] = res
    return output

### BinaryCrossEntropyLoss2d().forward(logits, labels)
class BinaryCrossEntropyLoss2d(nn.Module):
    def __init__(self, weight=None, size_average=True):
        """
        Binary cross entropy loss 2D
        Args:
            weight:
            size_average:
        """
        super(BinaryCrossEntropyLoss2d, self).__init__()
        self.bce_loss = nn.BCELoss(weight, size_average)

    def forward(self, logits, targets):
        # probs = F.sigmoid(logits)
        probs = logits
        probs_flat = probs.view(-1)  # Flatten
        targets_flat = targets.view(-1)  # Flatten
        return self.bce_loss(probs_flat, targets_flat)      # (output, labels)

class BCE_with_Weights(nn.Module):
    def __init__(self, weights=None):
        """
        Binary cross entropy loss 2D
        Args:
            weights:
        """
        super(BCE_with_Weights, self).__init__()
        self.weights = weights

    def forward(self, output, target):
        if self.weights is not None:
            loss = self.weights * (target * torch.log(output) + (1 - target) * torch.log(1 - output))
        else:
            loss = target * torch.log(output) + (1 - target) * torch.log(1 - output)

        return torch.neg(torch.mean(loss))

class LRN(nn.Module):       # input x is Torch tensor
    def __init__(self, local_size=1, alpha=1.0, beta=0.75, ACROSS_CHANNELS=False):      #LRN(local_size=5, alpha=0.0001, beta=0.75),
        super(LRN, self).__init__()
        self.ACROSS_CHANNELS = ACROSS_CHANNELS
        if self.ACROSS_CHANNELS:
            self.average = nn.AvgPool3d(kernel_size=(local_size, 1, 1),
                                        stride=1, padding=(int((local_size - 1.0) / 2), 0, 0))
        else:
            self.average = nn.AvgPool2d(kernel_size=local_size,
                                        stride=1, padding=int((local_size - 1.0) / 2))
        self.alpha = alpha
        self.beta = beta

    def forward(self, x):
        if self.ACROSS_CHANNELS:
            div = x.pow(2).unsqueeze(1)
            div = self.average(div).squeeze(1)
            div = div.mul(self.alpha).add(1.0).pow(self.beta)
        else:
            div = x.pow(2)
            div = self.average(div)
            div = div.mul(self.alpha).add(1.0).pow(self.beta)
        x = x.div(div)
        return x
Sat Nov 25 00:29:22 2017
Leg22_CROP_dropout_0_2_rmSigmoid_20aug_10ela_3inten_reflect
optim.SGD(net.parameters(), lr=1e-2, momentum=0.99)
Number of epoch max: 6
==========================================================================================
Sat Nov 25 00:39:48 2017
Leg22_CROP_dropout_0_2_rmSigmoid_20aug_10ela_3inten_reflect
Sat Nov 25 00:39:46 2017
import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.autograd import Variable
import math


class ConvBnRelu(nn.Module):
    def __init__(self, in_channels, out_channels, kernel_size, padding, stride):
        super(ConvBnRelu, self).__init__()
        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=kernel_size, padding=padding, stride=stride)
        self.bn = nn.BatchNorm2d(out_channels)
        self.relu = nn.ReLU()

    def forward(self, x):
        x = self.conv(x)
        # x = self.bn(x)
        x = self.relu(x)
        return x


class StackEncoder(nn.Module):
    def __init__(self, in_channels, out_channels):
        super(StackEncoder, self).__init__()
        self.convr1 = ConvBnRelu(in_channels, out_channels, kernel_size=(3, 3), stride=1, padding=0)
        self.convr2 = ConvBnRelu(out_channels, out_channels, kernel_size=(3, 3), stride=1, padding=0)
        self.maxPool = nn.MaxPool2d(kernel_size=(2, 2), stride=2)

    def forward(self, x):
        x = self.convr1(x)
        x = self.convr2(x)
        x_trace = x             # save x to use in concat in the Decoder path
        out = self.maxPool(x)
        return out, x_trace


class StackDecoder(nn.Module):
    def __init__(self, in_channels, out_channels, padding = 0, drop_out=False):
        super(StackDecoder, self).__init__()

        self.drop_out = drop_out
        self.dropout_layer = nn.Dropout2d(p=0.5)

        ''' this is old version
        self.upSample = nn.Upsample(size=upsample_size, scale_factor=(2, 2), mode="bilinear")
        self.convr1 = ConvBnRelu(in_channels, out_channels, kernel_size=(3, 3), stride=1, padding=padding)
        # Crop + concat step between these 2
        self.convr2 = ConvBnRelu(in_channels, out_channels, kernel_size=(3, 3), stride=1, padding=padding)
        '''
        self.upSample = nn.ConvTranspose2d(in_channels, out_channels, 2, stride=2)
        self.convr1 = ConvBnRelu(in_channels, out_channels, kernel_size=(3, 3), stride=1, padding=padding)
        self.convr2 = ConvBnRelu(out_channels, out_channels, kernel_size=(3, 3), stride=1, padding=padding)

    def _crop_concat(self, upsampled, bypass):
        """
         Crop y to the (h, w) of x and concat them.
         Used for the expansive path.
        Returns:
            The concatenated tensor
        """
        c = (bypass.size()[2] - upsampled.size()[2]) // 2
        bypass = F.pad(bypass, (-c, -c, -c, -c))

        return torch.cat((bypass, upsampled), 1)

    def forward(self, x, down_tensor):
        '''old version
        x = self.upSample(x)
        x = self.convr1(x)
        x = self._crop_concat(x, down_tensor)
        x = self.convr2(x)
        '''

        x = self.upSample(x)
        x = self._crop_concat(x, down_tensor)
        x = self.convr1(x)
        if self.drop_out: x = self.dropout_layer(x)
        x = self.convr2(x)
        if self.drop_out: x = self.dropout_layer(x)
        return x


class UNET_CROP(nn.Module):
    def __init__(self):
        super(UNET_CROP, self).__init__()
        # channels, height, width = in_shape

        # self.dropout = dropout

        self.model_code = ""        # variable to save model and main function when loaded

        self.down1 = StackEncoder(1, 64)
        self.down2 = StackEncoder(64, 128)
        self.down3 = StackEncoder(128, 256)
        self.down4 = StackEncoder(256, 512)

        self.center = nn.Sequential(
            # nn.Dropout2d(p=0.2),
            ConvBnRelu(512, 1024, kernel_size=(3, 3), stride=1, padding=0),
            nn.Dropout2d(p=0.2),
            ConvBnRelu(1024, 1024, kernel_size=(3, 3), stride=1, padding=0),
            nn.Dropout2d(p=0.2)
        )

        self.up1 = StackDecoder(in_channels=1024, out_channels=512)
        self.up2 = StackDecoder(in_channels=512, out_channels=256)
        self.up3 = StackDecoder(in_channels=256, out_channels=128)
        self.up4 = StackDecoder(in_channels=128, out_channels=64)

        # 1x1 convolution at the last layer
        # Different from the paper is the output size here
        self.output_seg_map = nn.Conv2d(64, 1, kernel_size=(1, 1), padding=0, stride=1)

        self._initialize_weights()

    def forward(self, x):
        x, x_trace1 = self.down1(x)
        x, x_trace2 = self.down2(x)
        x, x_trace3 = self.down3(x)
        x, x_trace4 = self.down4(x)
        x = self.center(x)
        x = self.up1(x, x_trace4)
        x = self.up2(x, x_trace3)
        x = self.up3(x, x_trace2)
        x = self.up4(x, x_trace1)

        x = self.output_seg_map(x)
        # x = F.sigmoid(x)
        # out = torch.squeeze(out, dim=1)
        return x


    def _initialize_weights(self):
        for m in self.modules():
            if isinstance(m, nn.Conv2d):
                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels
                m.weight.data.normal_(0, math.sqrt(2. / n))
                if m.bias is not None:
                    m.bias.data.zero_()
            elif isinstance(m, nn.BatchNorm2d):
                m.weight.data.fill_(1)
                m.bias.data.zero_()

# x = Variable(torch.randn(1,1,700, 700))       # simulate input image
# net = UNET_CROP()
# out = net(x)
# print("input: ", x)
# print("output: ", out)
===============from __future__ import print_function, division
import torch
from torch import optim
from torch.autograd import Variable
from torch.utils.data import DataLoader
import numpy as np
import torch.nn as nn
import torch.nn.functional as F
import Unet_crop
import tifffile as tiff
import Utils
import time
from sklearn.metrics import average_precision_score, recall_score, f1_score
import Analysis_crop
import cv2

def to_var(x):
    if torch.cuda.is_available():
        return Variable(x.cuda())
    else:
        return Variable(x)

### BinaryCrossEntropyLoss2d().forward(logits, labels)
class BinaryCrossEntropyLoss2d(nn.Module):
    def __init__(self, weight=None, size_average=True):
        """
        Binary cross entropy loss 2D
        Args:
            weight:
            size_average:
        """
        super(BinaryCrossEntropyLoss2d, self).__init__()
        self.bce_loss = nn.BCELoss(weight, size_average)

    def forward(self, probs, targets):
        probs = F.sigmoid(probs)
        probs_flat = probs.view(-1)  # Flatten
        targets_flat = targets.view(-1)  # Flatten
        return self.bce_loss(probs_flat, targets_flat)      # (output, labels)

def NetEval(net,valdata_loader,crit):
    loss = 0.
    count = 0
    net.eval()
    crop_input, crop_label,_ = crop_info()
    for i,data in enumerate(valdata_loader,0):
        inputs, labels = data
        inputs = inputs.numpy()
        labels = labels.numpy()
        for j in range(len(crop_input)):  # training on the crop images and corresponding labels
            ci = crop_input[j]  # crop index for inputs
            cl = crop_label[j]  # crop index for lables
            # temp = labels[0, 0, :, :]  # labels is numpy array 512x512
            # if np.sum(temp) < 0.01 * np.shape(temp)[0] * np.shape(temp)[1]: break
            x = inputs[:, :, ci[0]:ci[0] + 572, ci[1]:ci[1] + 572]
            y = labels[:, :, cl[0]: cl[0] + 388, cl[1]:cl[1] + 388]
            x = torch.from_numpy(x)
            y = torch.from_numpy(y)
            x, y = to_var(x), to_var(y)
            inputs, labels = to_var(x), to_var(y)
            out = net(x)
            l = crit(out, labels)
            loss += l.data[0]
            count += 1
    return loss/count

#process the test data and save to separate .tif image
def NetTest(net,testdata_loader,path = "data/results/"):
    net.eval()
    crop_input, crop_label, average_mask = crop_info()
    for i, data in enumerate(testdata_loader, 0):
        if i >= 30: return 1        # for debug
        data = to_var(data)
        img_shape = 512
        img = np.zeros((img_shape, img_shape))
        for j in range(len(crop_input)):  # training on the crop images and corresponding labels
            ci = crop_input[j]  # crop index for inputs

            x = data.numpy()[:, :, ci[0]:ci[0] + 572, ci[1]:ci[1] + 572]

            x = torch.from_numpy(x)

            x = to_var(x)
            out = F.sigmoid(net(x))
            out = out.cpu()
            out = out[0,0,:,:]
            img += out.data.numpy()

        img = img/average_mask
        img = img.reshape(-1)
        img[img < 0.5] = 0; img[img >= 0.5] = 1
        img = img.reshape(img_shape)
        img = np.uint8(img * 255)
        imgname = path + str(i) + ".tif"
        tiff.imsave(imgname, img)

# return input image size like 512x512, numpy array
def NetPredict(net, input_image):
    net.eval()
    _, crop_label, average_mask = crop_info()

    # input_image is grayscale input image of 512x512
    data = Utils.input_filled_mirroring(input_image, e = 94)
    imgdatas = np.ndarray((1, 1, data.shape[0], data.shape[1]), dtype=np.uint8)
    imgdatas[0] = np.expand_dims(data, 0)
    data = Utils.hist_equalization(imgdatas)
    data = data.astype('float32')
    data /= 255
    data -= data.mean(axis=0)

    img_shape = input_image.shape
    img = np.zeros((img_shape, img_shape))
    for j in range(len(crop_input)):  # training on the crop images and corresponding labels
        ci = crop_input[j]  # crop index for inputs
        x = data.numpy()[:, :, ci[0]:ci[0] + 572, ci[1]:ci[1] + 572]
        x = torch.from_numpy(x)
        x = to_var(x)
        out = F.sigmoid(net(x))
        out = out.cpu()
        out = out[0, 0, :, :]
        img += out.data.numpy()

    img = img / average_mask
    img = img.reshape(-1)
    img[img < 0.5] = 0
    img[img >= 0.5] = 1
    img = img.reshape(img_shape)
    img = np.uint8(img * 255)
    return img


def write_2_log(content):
    path = "log_file.txt"
    output = open(path, "a")
    output.write("\n")
    output.write(content)
    output.close()

def crop_info():
    crop_input = [[0, 0], [128, 0], [0, 128], [128, 128]]
    crop_label = [[0, 0], [124, 0], [0, 124], [124, 124]]
    average_mask = np.ones((512, 512))
    average_mask[124:388, 0:124] = 2
    average_mask[0:124, 124:388] = 2
    average_mask[124:388, 388:512] = 2
    average_mask[388:512, 124:388] = 2
    average_mask[124:388, 124:388] = 4
    return crop_input, crop_label, average_mask

if __name__ == '__main__':
    '''subjects to change for each exp:
    + path to the dataset
    + opt function
    + leg description
    + N_epoch
    + saved_model
    '''
    start_begining = time.time()

    # path = "data/dataset"
    path = "/home/anhxtuan/HanLe/dataset/20aug_10ela_3inten_reflect"
    path = "/home/anhxtuan/HanLe/dataset/20aug_10ela_3inten_reflect_700"

    import os
    print("Does the folder exist?: ", os.path.isdir(path))
    print("Does the path exist?: ", os.path.exists(path))

    imgs_train, imgs_mask_train = Utils.load_train_data(npy_path=path)
    imgs_val, imgs_mask_val = Utils.load_val_data(npy_path=path)
    batch_size = 1
    trainset = zip(imgs_train, imgs_mask_train)
    trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,
                                              shuffle=True, num_workers=2)
    valset = zip(imgs_val, imgs_mask_val)
    valloader = torch.utils.data.DataLoader(valset, batch_size=batch_size,
                                              shuffle=False, num_workers=2)
    # net = Unet.UNet()                     # Unet 1
    # net = Unet_BatchNorm.UNet_BN()          # Unet 2 with batchNorm
    net = Unet_crop.UNET_CROP()

    f1 = open("Unet_crop.py", 'r')     # embede code into the model to be saved later
    f2 = open("UnetTrain_crop.py", 'r')
    f3 = open("Utils.py", 'r')
    model_notes = time.strftime("%c") + "\n" + f1.read() + "\n" + "==="*5 + f2.read() + "\n" + "==="*5 + f3.read()
    f1.close()
    f2.close()
    f3.close()

    criterion = BinaryCrossEntropyLoss2d()
    # criterion = SoftDiceLoss()
    # criterion = nn.BCELoss()

    if torch.cuda.is_available():
        # torch.set_default_tensor_type('torch.cuda.FloatTensor')
        # net.load_state_dict(torch.load("Unet2_model_12epoch_Leg12_droput_0_2_rmSigmoid_20aug_10ela_3inten_reflect"))
        net.cuda()
        # criterion.cuda()

    opt = optim.SGD(net.parameters(), lr=1e-2, momentum=0.99)       # subject to change
    # opt = optim.RMSprop(net.parameters(), lr=2e-4)
    # RMSprop[22](learning rate 0.001) with weight decay set to 0.001.
    # opt = optim.Adam(net.parameters(), lr=1e-3, weight_decay=1e-4)

    train_loss = []
    val_loss = []

    print("[epoch, #image] Loss")
    leg = "Leg22_CROP_dropout_0_2_rmSigmoid_20aug_10ela_3inten_reflect"
    print("Processing: ", leg)
    model_name = ""

    N_epoch = 6
    model_saved = np.arange(1,N_epoch+1,2)
    val_loss_min = 100

    write_2_log("==="*30)
    write_2_log(time.strftime("%c"))       # time, date of exp
    write_2_log(leg)
    write_2_log(model_notes)
    write_2_log(time.strftime("%c"))  # time, date of exp
    write_2_log(leg)
    write_2_log("optim.SGD(net.parameters(), lr=1e-2, momentum=0.99)")
    write_2_log("Number of epoch max: " + str(N_epoch))

    crop_input, crop_label,_ = crop_info()
    min_model_epoch = 0
    for epoch in range(N_epoch):
        running_loss = 0.0; count = 0
        net.train()
        for i, data in enumerate(trainloader, 0):
            if i > 1000: break

            inputs, labels = data
            temp = labels.numpy()
            for j in range(len(crop_input)):       # training on the crop images and corresponding labels
                ci = crop_input[j]          # crop index for inputs
                cl = crop_label[j]          # crop index for lables
                # temp = temp[0, 0, :, :]  # labels is numpy array 512x512
                # if np.sum(temp) < 0.01 * np.shape(temp)[0] * np.shape(temp)[1]: break
                x = inputs.numpy()[:, :, ci[0]:ci[0] + 572, ci[1]:ci[1] + 572]
                y = labels.numpy()[:, :, cl[0]: cl[0] + 388, cl[1]:cl[1] + 388]
                x = torch.from_numpy(x)
                y = torch.from_numpy(y)
                x, y = to_var(x), to_var(y)
                opt.zero_grad()
                out = net(x)
                loss = criterion(out, y)
                loss.backward()
                opt.step()
                running_loss += loss.data[0]
                count += 1

        net.eval()
        val_loss_temp = NetEval(net, valloader, criterion)
        if epoch > 0 and val_loss_temp < val_loss_min:        # save the model which has the lowest val_loss, ignore first epoch
            val_loss_min = val_loss_temp
            torch.save(net.state_dict(), "Unet2_model_" + leg + "_min_val_loss")  # save model
            min_model_epoch = epoch + 1

        disp = 'Epoch %d: Train loss: %.6f, Val loss: %.6f' % (epoch + 1, running_loss/count, val_loss_temp)
        write_2_log(disp)
        print(disp)
        val_loss.append(val_loss_temp)
        train_loss.append(running_loss/count); running_loss = 0.0

        if (epoch + 1) in model_saved:        # save checkpoint
            model_name = "Unet2_model_" + str(epoch+1) + "epoch_" + leg
            torch.save(net.state_dict(), model_name)  # save model
            Analysis_crop.analysis(model_file = model_name, valloader = valloader)

    write_2_log("Best model at epoch: " + str(min_model_epoch))
    write_2_log("Total training time: " + str((time.time() - start_begining) / 3600.0))

    val_loss_file = "data/results" + "/val_loss_" + str(N_epoch) + "epoch_" + leg + ".npy"
    train_loss_file = "data/results" + "/training_loss_" + str(N_epoch) + "epoch_" + leg + ".npy"

    np.save(val_loss_file, val_loss)
    np.save(train_loss_file, train_loss)
    print("total processing time in seconds: ", time.time() - start_begining)
    print("total processing time in mins: ", (time.time() - start_begining) / 60.0)
    print("total processing time in hours: ", (time.time() - start_begining) / 3600.0)

    # Analysis.analysis(model_file="Unet2_model_" + leg + "_min_val_loss", valloader=valloader)

    Analysis_crop.PlotLoss(model_file = model_name, loss_train_path = train_loss_file, loss_val_path = val_loss_file, epoch_No = N_epoch)

    write_2_log(time.strftime("%c"))  # time, date of exp
===============
import numpy as np
import torch.nn as nn
import torch
import cv2
from lcn import LecunLCN

LCN_enable = False

def input_filled_mirroring(x, e = 62):      # fill missing data by mirroring the input image
    '''input size 636 --> output size 512'''
    w, h = x.shape
    #e = 62  # extra width on 1 edge
    y = np.zeros((h + e * 2, w + e * 2))
    y[e:h + e, e:w + e] = x
    y[e:e + h, 0:e] = np.flip(y[e:e + h, e:2 * e], 1)  # flip vertically
    y[e:e + h, e + w:2 * e + w] = np.flip(y[e:e + h, w:e + w], 1)  # flip vertically
    y[0:e, 0:2 * e + w] = np.flip(y[e:2 * e, 0:2 * e + w], 0)  # flip horizontally
    y[e + h:2 * e + h, 0:2 * e + w] = np.flip(y[h:e + h, 0:2 * e + w], 0)  # flip horizontally
    return y

def nearest_cells_distance(pos, img):
    # searching in 8 directions to find 2 nearest distances to neighbor cells
    curr_value = img[pos]
    w = img.shape[0];h = img.shape[1]
    count_detect = 0  # detect 2 nearest neighbors. break the search if count_detect = 2
    x, y = pos

    # print("w,h: ", (w, h))
    d1 = 9999999;d2 = 9999999;d3 = 9999999;d4 = 9999999
    d5 = 9999999;d6 = 9999999;d7 = 9999999;d8 = 9999999
    for i in range(1, max(w, h)):
        # (x+1, y), (x+1, y+1), (x+1, y-1),
        # (x, y+1), (x, y-1)
        # (x-1, y), (x-1,y+1), (x-1,y-1),
        if x + i < w:
            if img[(x + i, y)] != curr_value and d1 == 9999999:
                d1 = i; count_detect += 1
            if y + i < h:
                if img[(x + i, y + i)] != curr_value and d2 == 9999999:
                    d2 = i; count_detect += 1
            elif y - i >= 0:
                if img[(x + i, y - i)] != curr_value and d3 == 9999999:
                    d3 = i; count_detect += 1
        if y + i < h:
            if img[(x, y + i)] != curr_value and d4 == 9999999:
                d4 = i; count_detect += 1
        if y - i >= 0:
            if img[(x, y - i)] != curr_value and d5 == 9999999:
                d5 = i; count_detect += 1
        if x - i >= 0:
            if img[(x - i, y)] != curr_value and d6 == 9999999:
                d6 = i; count_detect += 1
            if y + i < h:
                if img[(x - i, y + i)] != curr_value and d7 == 9999999:
                    d7 = i; count_detect += 1
            elif y - i >= 0:
                if img[(x - i, y - i)] != curr_value and d8 == 9999999:
                    d8 = i; count_detect += 1
        if count_detect >= 2: break

    d = [d1, d2, d3, d4, d5, d6, d7, d8]
    min_index = np.argmin(d)
    dist1 = d[min_index]
    d.remove(dist1)
    min_index = np.argmin(d)
    dist2 = d[min_index]
    return dist1, dist2

def create_weight_map(imgs_mask):
        print('-' * 30)
        print('Creating weights for masks ...')
        print('-' * 30)
        weight_map = np.ndarray(
            (len(imgs_mask), 1, np.shape(imgs_mask)[2], np.shape(imgs_mask)[3]), dtype=np.float32)
        w_0 = 10; sigma = 4
        imgs_w, imgs_h = np.shape(imgs_mask)[2], np.shape(imgs_mask)[3]
        total_pixels = imgs_w*imgs_h
        import time
        start = time.time()
        for i in range(len(imgs_mask)):
            if i%10 == 0: print("Done processing: %d images, time passed: %.2f mins" % (i, (time.time() - start)/60.0))
            temp = imgs_mask[i,0,:,:]
            w_border = 1 - np.sum(temp)/total_pixels        # w_c of pixel on the border (black)
            for m in range(imgs_w):
                for n in range(imgs_h):
                    # loop through all pixel of the mask
                    d1,d2 = nearest_cells_distance((m,n), temp)
                    w_c = w_border
                    if temp[m,n] == 0: w_c = 1 - w_border
                    weight_map[i,0,m,n] = w_c*5 + w_0*np.exp(-(d1 + d2)**2/(2*sigma**2))
                    # print("w_0*np.exp(): ", w_0*np.exp(-(d1 + d2)**2/(2*sigma**2)))
                    # print("w_border: ", w_border)

        np.save('data/dataset/weight_map_train.npy', weight_map)

        return weight_map

def load_train_data(npy_path = "data/dataset", hist_equal = False):

    print('-' * 30)
    print('load train images...')

    imgs_train = np.load(npy_path + "/imgs_train.npy")
    imgs_mask_train = np.load(npy_path + "/imgs_mask_train.npy")

    if hist_equal: imgs_train = hist_equalization(imgs_train)

    # weight_map_train = np.load(npy_path + "/weight_map_train.npy")
    # weight_map_train = weight_map_train.astype('float32')

    imgs_train = imgs_train.astype('float32')
    imgs_mask_train = imgs_mask_train.astype('float32')

    if LCN_enable:
        imgs_train = imgs_train.astype('float64')
        imgs_train = LecunLCN(imgs_train, image_shape=imgs_train.shape).output.eval()
        imgs_train = imgs_train.astype('float32')

    if not LCN_enable: imgs_train /= 255

    imgs_train -= imgs_train.mean(axis=0)
    imgs_mask_train /= 255
    imgs_mask_train[imgs_mask_train > 0.5] = 1
    imgs_mask_train[imgs_mask_train <= 0.5] = 0

    # weight_map_train = create_weight_map(imgs_mask_train)

    print("Done loading traing data")
    print('-' * 30)
    return imgs_train, imgs_mask_train

def load_val_data(npy_path = "data/dataset", hist_equal = True):

    print('-' * 30)
    print('load validation images...')

    imgs_train = np.load(npy_path + "/imgs_val.npy")
    imgs_mask_train = np.load(npy_path + "/imgs_mask_val.npy")

    if hist_equal: imgs_train = hist_equalization(imgs_train)

    imgs_train = imgs_train.astype('float32')
    imgs_mask_train = imgs_mask_train.astype('float32')

    if LCN_enable:
        imgs_train = imgs_train.astype('float64')
        imgs_train = LecunLCN(imgs_train, image_shape=imgs_train.shape).output.eval()
        imgs_train = imgs_train.astype('float32')

    if not LCN_enable: imgs_train /= 255
    imgs_train -= imgs_train.mean(axis=0)
    imgs_mask_train /= 255
    imgs_mask_train[imgs_mask_train > 0.5] = 1
    imgs_mask_train[imgs_mask_train <= 0.5] = 0
    print("Done loading validation data")
    print('-' * 30)
    return imgs_train, imgs_mask_train

def load_test_data(npy_path = "data/dataset", hist_equal = True):

    print('-' * 30)
    print('load test images...')

    imgs_test = np.load(npy_path + "/imgs_test.npy")

    if hist_equal: imgs_test = hist_equalization(imgs_test)

    imgs_test = imgs_test.astype('float32')

    if LCN_enable:
        imgs_test = imgs_test.astype('float64')
        imgs_test = LecunLCN(imgs_test, image_shape=imgs_test.shape).output.eval()
        imgs_test = imgs_test.astype('float32')

    if not LCN_enable: imgs_test /= 255

    imgs_test -= imgs_test.mean(axis=0)

    print("Done loading test data")
    print('-' * 30)
    return imgs_test

def load_val_5imgs(npy_path = "data/dataset"):
    print('-' * 30)
    print('load train images...')

    imgs_train = np.load(npy_path + "/imgs_val_5imgs.npy")
    imgs_mask_train = np.load(npy_path + "/imgs_mask_val_5imgs.npy")

    # imgs_train = hist_equalization(imgs_train)

    imgs_train = imgs_train.astype('float64')
    imgs_mask_train = imgs_mask_train.astype('float64')

    if LCN_enable: imgs_train = LecunLCN(imgs_train, image_shape=imgs_train.shape).output.eval()

    if not LCN_enable: imgs_train /= 255

    mean = imgs_train.mean(axis=0)
    imgs_train -= mean


    imgs_mask_train /= 255
    imgs_mask_train[imgs_mask_train > 0.5] = 1
    imgs_mask_train[imgs_mask_train <= 0.5] = 0

    # weight_map_train = self.create_weight_map(imgs_mask_train)

    print("Done loading traing data")
    print('-' * 30)
    return imgs_train, imgs_mask_train

def hist_equalization(inputs):      # inputs are uint8, 0-255, Nx1x636x636
    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))
    output = inputs.copy()
    for i in range(len(inputs)):
        img = inputs[i, 0, :, :]
        # res = cv2.equalizeHist(img)
        res = clahe.apply(img)
        output[i,0,:,:] = res
    return output

### BinaryCrossEntropyLoss2d().forward(logits, labels)
class BinaryCrossEntropyLoss2d(nn.Module):
    def __init__(self, weight=None, size_average=True):
        """
        Binary cross entropy loss 2D
        Args:
            weight:
            size_average:
        """
        super(BinaryCrossEntropyLoss2d, self).__init__()
        self.bce_loss = nn.BCELoss(weight, size_average)

    def forward(self, logits, targets):
        # probs = F.sigmoid(logits)
        probs = logits
        probs_flat = probs.view(-1)  # Flatten
        targets_flat = targets.view(-1)  # Flatten
        return self.bce_loss(probs_flat, targets_flat)      # (output, labels)

class BCE_with_Weights(nn.Module):
    def __init__(self, weights=None):
        """
        Binary cross entropy loss 2D
        Args:
            weights:
        """
        super(BCE_with_Weights, self).__init__()
        self.weights = weights

    def forward(self, output, target):
        if self.weights is not None:
            loss = self.weights * (target * torch.log(output) + (1 - target) * torch.log(1 - output))
        else:
            loss = target * torch.log(output) + (1 - target) * torch.log(1 - output)

        return torch.neg(torch.mean(loss))

class LRN(nn.Module):       # input x is Torch tensor
    def __init__(self, local_size=1, alpha=1.0, beta=0.75, ACROSS_CHANNELS=False):      #LRN(local_size=5, alpha=0.0001, beta=0.75),
        super(LRN, self).__init__()
        self.ACROSS_CHANNELS = ACROSS_CHANNELS
        if self.ACROSS_CHANNELS:
            self.average = nn.AvgPool3d(kernel_size=(local_size, 1, 1),
                                        stride=1, padding=(int((local_size - 1.0) / 2), 0, 0))
        else:
            self.average = nn.AvgPool2d(kernel_size=local_size,
                                        stride=1, padding=int((local_size - 1.0) / 2))
        self.alpha = alpha
        self.beta = beta

    def forward(self, x):
        if self.ACROSS_CHANNELS:
            div = x.pow(2).unsqueeze(1)
            div = self.average(div).squeeze(1)
            div = div.mul(self.alpha).add(1.0).pow(self.beta)
        else:
            div = x.pow(2)
            div = self.average(div)
            div = div.mul(self.alpha).add(1.0).pow(self.beta)
        x = x.div(div)
        return x
Sat Nov 25 00:39:48 2017
Leg22_CROP_dropout_0_2_rmSigmoid_20aug_10ela_3inten_reflect
optim.SGD(net.parameters(), lr=1e-2, momentum=0.99)
Number of epoch max: 6
==========================================================================================
Sat Nov 25 01:03:07 2017
Leg22_CROP_dropout_0_2_rmSigmoid_20aug_10ela_3inten_reflect
Sat Nov 25 01:03:05 2017
import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.autograd import Variable
import math


class ConvBnRelu(nn.Module):
    def __init__(self, in_channels, out_channels, kernel_size, padding, stride):
        super(ConvBnRelu, self).__init__()
        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=kernel_size, padding=padding, stride=stride)
        self.bn = nn.BatchNorm2d(out_channels)
        self.relu = nn.ReLU()

    def forward(self, x):
        x = self.conv(x)
        # x = self.bn(x)
        x = self.relu(x)
        return x


class StackEncoder(nn.Module):
    def __init__(self, in_channels, out_channels):
        super(StackEncoder, self).__init__()
        self.convr1 = ConvBnRelu(in_channels, out_channels, kernel_size=(3, 3), stride=1, padding=0)
        self.convr2 = ConvBnRelu(out_channels, out_channels, kernel_size=(3, 3), stride=1, padding=0)
        self.maxPool = nn.MaxPool2d(kernel_size=(2, 2), stride=2)

    def forward(self, x):
        x = self.convr1(x)
        x = self.convr2(x)
        x_trace = x             # save x to use in concat in the Decoder path
        out = self.maxPool(x)
        return out, x_trace


class StackDecoder(nn.Module):
    def __init__(self, in_channels, out_channels, padding = 0, drop_out=False):
        super(StackDecoder, self).__init__()

        self.drop_out = drop_out
        self.dropout_layer = nn.Dropout2d(p=0.5)

        ''' this is old version
        self.upSample = nn.Upsample(size=upsample_size, scale_factor=(2, 2), mode="bilinear")
        self.convr1 = ConvBnRelu(in_channels, out_channels, kernel_size=(3, 3), stride=1, padding=padding)
        # Crop + concat step between these 2
        self.convr2 = ConvBnRelu(in_channels, out_channels, kernel_size=(3, 3), stride=1, padding=padding)
        '''
        self.upSample = nn.ConvTranspose2d(in_channels, out_channels, 2, stride=2)
        self.convr1 = ConvBnRelu(in_channels, out_channels, kernel_size=(3, 3), stride=1, padding=padding)
        self.convr2 = ConvBnRelu(out_channels, out_channels, kernel_size=(3, 3), stride=1, padding=padding)

    def _crop_concat(self, upsampled, bypass):
        """
         Crop y to the (h, w) of x and concat them.
         Used for the expansive path.
        Returns:
            The concatenated tensor
        """
        c = (bypass.size()[2] - upsampled.size()[2]) // 2
        bypass = F.pad(bypass, (-c, -c, -c, -c))

        return torch.cat((bypass, upsampled), 1)

    def forward(self, x, down_tensor):
        '''old version
        x = self.upSample(x)
        x = self.convr1(x)
        x = self._crop_concat(x, down_tensor)
        x = self.convr2(x)
        '''

        x = self.upSample(x)
        x = self._crop_concat(x, down_tensor)
        x = self.convr1(x)
        if self.drop_out: x = self.dropout_layer(x)
        x = self.convr2(x)
        if self.drop_out: x = self.dropout_layer(x)
        return x


class UNET_CROP(nn.Module):
    def __init__(self):
        super(UNET_CROP, self).__init__()
        # channels, height, width = in_shape

        # self.dropout = dropout

        self.model_code = ""        # variable to save model and main function when loaded

        self.down1 = StackEncoder(1, 64)
        self.down2 = StackEncoder(64, 128)
        self.down3 = StackEncoder(128, 256)
        self.down4 = StackEncoder(256, 512)

        self.center = nn.Sequential(
            # nn.Dropout2d(p=0.2),
            ConvBnRelu(512, 1024, kernel_size=(3, 3), stride=1, padding=0),
            nn.Dropout2d(p=0.2),
            ConvBnRelu(1024, 1024, kernel_size=(3, 3), stride=1, padding=0),
            nn.Dropout2d(p=0.2)
        )

        self.up1 = StackDecoder(in_channels=1024, out_channels=512)
        self.up2 = StackDecoder(in_channels=512, out_channels=256)
        self.up3 = StackDecoder(in_channels=256, out_channels=128)
        self.up4 = StackDecoder(in_channels=128, out_channels=64)

        # 1x1 convolution at the last layer
        # Different from the paper is the output size here
        self.output_seg_map = nn.Conv2d(64, 1, kernel_size=(1, 1), padding=0, stride=1)

        self._initialize_weights()

    def forward(self, x):
        x, x_trace1 = self.down1(x)
        x, x_trace2 = self.down2(x)
        x, x_trace3 = self.down3(x)
        x, x_trace4 = self.down4(x)
        x = self.center(x)
        x = self.up1(x, x_trace4)
        x = self.up2(x, x_trace3)
        x = self.up3(x, x_trace2)
        x = self.up4(x, x_trace1)

        x = self.output_seg_map(x)
        # x = F.sigmoid(x)
        # out = torch.squeeze(out, dim=1)
        return x


    def _initialize_weights(self):
        for m in self.modules():
            if isinstance(m, nn.Conv2d):
                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels
                m.weight.data.normal_(0, math.sqrt(2. / n))
                if m.bias is not None:
                    m.bias.data.zero_()
            elif isinstance(m, nn.BatchNorm2d):
                m.weight.data.fill_(1)
                m.bias.data.zero_()

# x = Variable(torch.randn(1,1,700, 700))       # simulate input image
# net = UNET_CROP()
# out = net(x)
# print("input: ", x)
# print("output: ", out)
===============from __future__ import print_function, division
import torch
from torch import optim
from torch.autograd import Variable
from torch.utils.data import DataLoader
import numpy as np
import torch.nn as nn
import torch.nn.functional as F
import Unet_crop
import tifffile as tiff
import Utils
import time
from sklearn.metrics import average_precision_score, recall_score, f1_score
import Analysis_crop
import cv2

def to_var(x):
    if torch.cuda.is_available():
        return Variable(x.cuda())
    else:
        return Variable(x)

### BinaryCrossEntropyLoss2d().forward(logits, labels)
class BinaryCrossEntropyLoss2d(nn.Module):
    def __init__(self, weight=None, size_average=True):
        """
        Binary cross entropy loss 2D
        Args:
            weight:
            size_average:
        """
        super(BinaryCrossEntropyLoss2d, self).__init__()
        self.bce_loss = nn.BCELoss(weight, size_average)

    def forward(self, probs, targets):
        probs = F.sigmoid(probs)
        probs_flat = probs.view(-1)  # Flatten
        targets_flat = targets.view(-1)  # Flatten
        return self.bce_loss(probs_flat, targets_flat)      # (output, labels)

def NetEval(net,valdata_loader,crit):
    loss = 0.
    count = 0
    net.eval()
    crop_input, crop_label,_ = crop_info()
    for i,data in enumerate(valdata_loader,0):
        if i > 100: break
        inputs, labels = data
        # inputs = inputs.numpy()
        # labels = labels.numpy()
        for j in range(len(crop_input)):  # training on the crop images and corresponding labels
            ci = crop_input[j]  # crop index for inputs
            cl = crop_label[j]  # crop index for lables
            # temp = labels[0, 0, :, :]  # labels is numpy array 512x512
            # if np.sum(temp) < 0.01 * np.shape(temp)[0] * np.shape(temp)[1]: break
            x = inputs.numpy()[:, :, ci[0]:ci[0] + 572, ci[1]:ci[1] + 572]
            y = labels.numpy()[:, :, cl[0]: cl[0] + 388, cl[1]:cl[1] + 388]
            x = torch.from_numpy(x)
            y = torch.from_numpy(y)
            x, y = to_var(x), to_var(y)
            out = net(x)
            l = crit(out, labels)
            loss += l.data[0]
            count += 1
    return loss/count

#process the test data and save to separate .tif image
def NetTest(net,testdata_loader,path = "data/results/"):
    net.eval()
    crop_input, crop_label, average_mask = crop_info()
    for i, data in enumerate(testdata_loader, 0):
        if i >= 30: return 1        # for debug
        # data = to_var(data)
        img_shape = 512
        img = np.zeros((img_shape, img_shape))
        for j in range(len(crop_input)):  # training on the crop images and corresponding labels
            ci = crop_input[j]  # crop index for inputs
            x = data.numpy()[:, :, ci[0]:ci[0] + 572, ci[1]:ci[1] + 572]
            x = torch.from_numpy(x)
            x = to_var(x)
            out = F.sigmoid(net(x))
            out = out.cpu()
            out = out[0,0,:,:]
            img += out.data.numpy()

        img = img/average_mask
        img = img.reshape(-1)
        img[img < 0.5] = 0; img[img >= 0.5] = 1
        img = img.reshape(img_shape)
        img = np.uint8(img * 255)
        imgname = path + str(i) + ".tif"
        tiff.imsave(imgname, img)

# return input image size like 512x512, numpy array
def NetPredict(net, input_image):
    net.eval()
    _, crop_label, average_mask = crop_info()

    # input_image is grayscale input image of 512x512
    data = Utils.input_filled_mirroring(input_image, e = 94)
    imgdatas = np.ndarray((1, 1, data.shape[0], data.shape[1]), dtype=np.uint8)
    imgdatas[0] = np.expand_dims(data, 0)
    data = Utils.hist_equalization(imgdatas)
    data = data.astype('float32')
    data /= 255
    data -= data.mean(axis=0)

    img_shape = input_image.shape
    img = np.zeros((img_shape, img_shape))
    for j in range(len(crop_input)):  # training on the crop images and corresponding labels
        ci = crop_input[j]  # crop index for inputs
        x = data.numpy()[:, :, ci[0]:ci[0] + 572, ci[1]:ci[1] + 572]
        x = torch.from_numpy(x)
        x = to_var(x)
        out = F.sigmoid(net(x))
        out = out.cpu()
        out = out[0, 0, :, :]
        img += out.data.numpy()

    img = img / average_mask
    img = img.reshape(-1)
    img[img < 0.5] = 0
    img[img >= 0.5] = 1
    img = img.reshape(img_shape)
    img = np.uint8(img * 255)
    return img


def write_2_log(content):
    path = "log_file.txt"
    output = open(path, "a")
    output.write("\n")
    output.write(content)
    output.close()

def crop_info():
    crop_input = [[0, 0], [128, 0], [0, 128], [128, 128]]
    crop_label = [[0, 0], [124, 0], [0, 124], [124, 124]]
    average_mask = np.ones((512, 512))
    average_mask[124:388, 0:124] = 2
    average_mask[0:124, 124:388] = 2
    average_mask[124:388, 388:512] = 2
    average_mask[388:512, 124:388] = 2
    average_mask[124:388, 124:388] = 4
    return crop_input, crop_label, average_mask

if __name__ == '__main__':
    '''subjects to change for each exp:
    + path to the dataset
    + opt function
    + leg description
    + N_epoch
    + saved_model
    '''
    start_begining = time.time()

    # path = "data/dataset"
    path = "/home/anhxtuan/HanLe/dataset/20aug_10ela_3inten_reflect"
    path = "/home/anhxtuan/HanLe/dataset/20aug_10ela_3inten_reflect_700"

    import os
    print("Does the folder exist?: ", os.path.isdir(path))
    print("Does the path exist?: ", os.path.exists(path))

    imgs_train, imgs_mask_train = Utils.load_train_data(npy_path=path)
    imgs_val, imgs_mask_val = Utils.load_val_data(npy_path=path)
    batch_size = 1
    trainset = zip(imgs_train, imgs_mask_train)
    trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,
                                              shuffle=True, num_workers=2)
    valset = zip(imgs_val, imgs_mask_val)
    valloader = torch.utils.data.DataLoader(valset, batch_size=batch_size,
                                              shuffle=False, num_workers=2)
    # net = Unet.UNet()                     # Unet 1
    # net = Unet_BatchNorm.UNet_BN()          # Unet 2 with batchNorm
    net = Unet_crop.UNET_CROP()

    f1 = open("Unet_crop.py", 'r')     # embede code into the model to be saved later
    f2 = open("UnetTrain_crop.py", 'r')
    f3 = open("Utils.py", 'r')
    model_notes = time.strftime("%c") + "\n" + f1.read() + "\n" + "==="*5 + f2.read() + "\n" + "==="*5 + f3.read()
    f1.close()
    f2.close()
    f3.close()

    criterion = BinaryCrossEntropyLoss2d()
    # criterion = SoftDiceLoss()
    # criterion = nn.BCELoss()

    if torch.cuda.is_available():
        # torch.set_default_tensor_type('torch.cuda.FloatTensor')
        # net.load_state_dict(torch.load("Unet2_model_12epoch_Leg12_droput_0_2_rmSigmoid_20aug_10ela_3inten_reflect"))
        net.cuda()
        # criterion.cuda()

    opt = optim.SGD(net.parameters(), lr=1e-2, momentum=0.99)       # subject to change
    # opt = optim.RMSprop(net.parameters(), lr=2e-4)
    # RMSprop[22](learning rate 0.001) with weight decay set to 0.001.
    # opt = optim.Adam(net.parameters(), lr=1e-3, weight_decay=1e-4)

    train_loss = []
    val_loss = []

    print("[epoch, #image] Loss")
    leg = "Leg22_CROP_dropout_0_2_rmSigmoid_20aug_10ela_3inten_reflect"
    print("Processing: ", leg)
    model_name = ""

    N_epoch = 6
    model_saved = np.arange(1,N_epoch+1,2)
    val_loss_min = 100

    write_2_log("==="*30)
    write_2_log(time.strftime("%c"))       # time, date of exp
    write_2_log(leg)
    write_2_log(model_notes)
    write_2_log(time.strftime("%c"))  # time, date of exp
    write_2_log(leg)
    write_2_log("optim.SGD(net.parameters(), lr=1e-2, momentum=0.99)")
    write_2_log("Number of epoch max: " + str(N_epoch))

    crop_input, crop_label,_ = crop_info()
    min_model_epoch = 0
    for epoch in range(N_epoch):
        running_loss = 0.0; count = 0
        net.train()
        for i, data in enumerate(trainloader, 0):
            if i > 100: break

            inputs, labels = data
            temp = labels.numpy()
            for j in range(len(crop_input)):       # training on the crop images and corresponding labels
                ci = crop_input[j]          # crop index for inputs
                cl = crop_label[j]          # crop index for lables
                # temp = temp[0, 0, :, :]  # labels is numpy array 512x512
                # if np.sum(temp) < 0.01 * np.shape(temp)[0] * np.shape(temp)[1]: break
                x = inputs.numpy()[:, :, ci[0]:ci[0] + 572, ci[1]:ci[1] + 572]
                y = labels.numpy()[:, :, cl[0]: cl[0] + 388, cl[1]:cl[1] + 388]
                x = torch.from_numpy(x)
                y = torch.from_numpy(y)
                x, y = to_var(x), to_var(y)
                opt.zero_grad()
                out = net(x)
                loss = criterion(out, y)
                loss.backward()
                opt.step()
                running_loss += loss.data[0]
                count += 1

        net.eval()
        val_loss_temp = NetEval(net, valloader, criterion)
        if epoch > 0 and val_loss_temp < val_loss_min:        # save the model which has the lowest val_loss, ignore first epoch
            val_loss_min = val_loss_temp
            torch.save(net.state_dict(), "Unet2_model_" + leg + "_min_val_loss")  # save model
            min_model_epoch = epoch + 1

        disp = 'Epoch %d: Train loss: %.6f, Val loss: %.6f' % (epoch + 1, running_loss/count, val_loss_temp)
        write_2_log(disp)
        print(disp)
        val_loss.append(val_loss_temp)
        train_loss.append(running_loss/count); running_loss = 0.0

        if (epoch + 1) in model_saved:        # save checkpoint
            model_name = "Unet2_model_" + str(epoch+1) + "epoch_" + leg
            torch.save(net.state_dict(), model_name)  # save model
            Analysis_crop.analysis(model_file = model_name, valloader = valloader)

    write_2_log("Best model at epoch: " + str(min_model_epoch))
    write_2_log("Total training time: " + str((time.time() - start_begining) / 3600.0))

    val_loss_file = "data/results" + "/val_loss_" + str(N_epoch) + "epoch_" + leg + ".npy"
    train_loss_file = "data/results" + "/training_loss_" + str(N_epoch) + "epoch_" + leg + ".npy"

    np.save(val_loss_file, val_loss)
    np.save(train_loss_file, train_loss)
    print("total processing time in seconds: ", time.time() - start_begining)
    print("total processing time in mins: ", (time.time() - start_begining) / 60.0)
    print("total processing time in hours: ", (time.time() - start_begining) / 3600.0)

    # Analysis.analysis(model_file="Unet2_model_" + leg + "_min_val_loss", valloader=valloader)

    Analysis_crop.PlotLoss(model_file = model_name, loss_train_path = train_loss_file, loss_val_path = val_loss_file, epoch_No = N_epoch)

    write_2_log(time.strftime("%c"))  # time, date of exp
===============
import numpy as np
import torch.nn as nn
import torch
import cv2
from lcn import LecunLCN

LCN_enable = False

def input_filled_mirroring(x, e = 62):      # fill missing data by mirroring the input image
    '''input size 636 --> output size 512'''
    w, h = x.shape
    #e = 62  # extra width on 1 edge
    y = np.zeros((h + e * 2, w + e * 2))
    y[e:h + e, e:w + e] = x
    y[e:e + h, 0:e] = np.flip(y[e:e + h, e:2 * e], 1)  # flip vertically
    y[e:e + h, e + w:2 * e + w] = np.flip(y[e:e + h, w:e + w], 1)  # flip vertically
    y[0:e, 0:2 * e + w] = np.flip(y[e:2 * e, 0:2 * e + w], 0)  # flip horizontally
    y[e + h:2 * e + h, 0:2 * e + w] = np.flip(y[h:e + h, 0:2 * e + w], 0)  # flip horizontally
    return y

def nearest_cells_distance(pos, img):
    # searching in 8 directions to find 2 nearest distances to neighbor cells
    curr_value = img[pos]
    w = img.shape[0];h = img.shape[1]
    count_detect = 0  # detect 2 nearest neighbors. break the search if count_detect = 2
    x, y = pos

    # print("w,h: ", (w, h))
    d1 = 9999999;d2 = 9999999;d3 = 9999999;d4 = 9999999
    d5 = 9999999;d6 = 9999999;d7 = 9999999;d8 = 9999999
    for i in range(1, max(w, h)):
        # (x+1, y), (x+1, y+1), (x+1, y-1),
        # (x, y+1), (x, y-1)
        # (x-1, y), (x-1,y+1), (x-1,y-1),
        if x + i < w:
            if img[(x + i, y)] != curr_value and d1 == 9999999:
                d1 = i; count_detect += 1
            if y + i < h:
                if img[(x + i, y + i)] != curr_value and d2 == 9999999:
                    d2 = i; count_detect += 1
            elif y - i >= 0:
                if img[(x + i, y - i)] != curr_value and d3 == 9999999:
                    d3 = i; count_detect += 1
        if y + i < h:
            if img[(x, y + i)] != curr_value and d4 == 9999999:
                d4 = i; count_detect += 1
        if y - i >= 0:
            if img[(x, y - i)] != curr_value and d5 == 9999999:
                d5 = i; count_detect += 1
        if x - i >= 0:
            if img[(x - i, y)] != curr_value and d6 == 9999999:
                d6 = i; count_detect += 1
            if y + i < h:
                if img[(x - i, y + i)] != curr_value and d7 == 9999999:
                    d7 = i; count_detect += 1
            elif y - i >= 0:
                if img[(x - i, y - i)] != curr_value and d8 == 9999999:
                    d8 = i; count_detect += 1
        if count_detect >= 2: break

    d = [d1, d2, d3, d4, d5, d6, d7, d8]
    min_index = np.argmin(d)
    dist1 = d[min_index]
    d.remove(dist1)
    min_index = np.argmin(d)
    dist2 = d[min_index]
    return dist1, dist2

def create_weight_map(imgs_mask):
        print('-' * 30)
        print('Creating weights for masks ...')
        print('-' * 30)
        weight_map = np.ndarray(
            (len(imgs_mask), 1, np.shape(imgs_mask)[2], np.shape(imgs_mask)[3]), dtype=np.float32)
        w_0 = 10; sigma = 4
        imgs_w, imgs_h = np.shape(imgs_mask)[2], np.shape(imgs_mask)[3]
        total_pixels = imgs_w*imgs_h
        import time
        start = time.time()
        for i in range(len(imgs_mask)):
            if i%10 == 0: print("Done processing: %d images, time passed: %.2f mins" % (i, (time.time() - start)/60.0))
            temp = imgs_mask[i,0,:,:]
            w_border = 1 - np.sum(temp)/total_pixels        # w_c of pixel on the border (black)
            for m in range(imgs_w):
                for n in range(imgs_h):
                    # loop through all pixel of the mask
                    d1,d2 = nearest_cells_distance((m,n), temp)
                    w_c = w_border
                    if temp[m,n] == 0: w_c = 1 - w_border
                    weight_map[i,0,m,n] = w_c*5 + w_0*np.exp(-(d1 + d2)**2/(2*sigma**2))
                    # print("w_0*np.exp(): ", w_0*np.exp(-(d1 + d2)**2/(2*sigma**2)))
                    # print("w_border: ", w_border)

        np.save('data/dataset/weight_map_train.npy', weight_map)

        return weight_map

def load_train_data(npy_path = "data/dataset", hist_equal = False):

    print('-' * 30)
    print('load train images...')

    imgs_train = np.load(npy_path + "/imgs_train.npy")
    imgs_mask_train = np.load(npy_path + "/imgs_mask_train.npy")

    if hist_equal: imgs_train = hist_equalization(imgs_train)

    # weight_map_train = np.load(npy_path + "/weight_map_train.npy")
    # weight_map_train = weight_map_train.astype('float32')

    imgs_train = imgs_train.astype('float32')
    imgs_mask_train = imgs_mask_train.astype('float32')

    if LCN_enable:
        imgs_train = imgs_train.astype('float64')
        imgs_train = LecunLCN(imgs_train, image_shape=imgs_train.shape).output.eval()
        imgs_train = imgs_train.astype('float32')

    if not LCN_enable: imgs_train /= 255

    imgs_train -= imgs_train.mean(axis=0)
    imgs_mask_train /= 255
    imgs_mask_train[imgs_mask_train > 0.5] = 1
    imgs_mask_train[imgs_mask_train <= 0.5] = 0

    # weight_map_train = create_weight_map(imgs_mask_train)

    print("Done loading traing data")
    print('-' * 30)
    return imgs_train, imgs_mask_train

def load_val_data(npy_path = "data/dataset", hist_equal = True):

    print('-' * 30)
    print('load validation images...')

    imgs_train = np.load(npy_path + "/imgs_val.npy")
    imgs_mask_train = np.load(npy_path + "/imgs_mask_val.npy")

    if hist_equal: imgs_train = hist_equalization(imgs_train)

    imgs_train = imgs_train.astype('float32')
    imgs_mask_train = imgs_mask_train.astype('float32')

    if LCN_enable:
        imgs_train = imgs_train.astype('float64')
        imgs_train = LecunLCN(imgs_train, image_shape=imgs_train.shape).output.eval()
        imgs_train = imgs_train.astype('float32')

    if not LCN_enable: imgs_train /= 255
    imgs_train -= imgs_train.mean(axis=0)
    imgs_mask_train /= 255
    imgs_mask_train[imgs_mask_train > 0.5] = 1
    imgs_mask_train[imgs_mask_train <= 0.5] = 0
    print("Done loading validation data")
    print('-' * 30)
    return imgs_train, imgs_mask_train

def load_test_data(npy_path = "data/dataset", hist_equal = True):

    print('-' * 30)
    print('load test images...')

    imgs_test = np.load(npy_path + "/imgs_test.npy")

    if hist_equal: imgs_test = hist_equalization(imgs_test)

    imgs_test = imgs_test.astype('float32')

    if LCN_enable:
        imgs_test = imgs_test.astype('float64')
        imgs_test = LecunLCN(imgs_test, image_shape=imgs_test.shape).output.eval()
        imgs_test = imgs_test.astype('float32')

    if not LCN_enable: imgs_test /= 255

    imgs_test -= imgs_test.mean(axis=0)

    print("Done loading test data")
    print('-' * 30)
    return imgs_test

def load_val_5imgs(npy_path = "data/dataset"):
    print('-' * 30)
    print('load train images...')

    imgs_train = np.load(npy_path + "/imgs_val_5imgs.npy")
    imgs_mask_train = np.load(npy_path + "/imgs_mask_val_5imgs.npy")

    # imgs_train = hist_equalization(imgs_train)

    imgs_train = imgs_train.astype('float64')
    imgs_mask_train = imgs_mask_train.astype('float64')

    if LCN_enable: imgs_train = LecunLCN(imgs_train, image_shape=imgs_train.shape).output.eval()

    if not LCN_enable: imgs_train /= 255

    mean = imgs_train.mean(axis=0)
    imgs_train -= mean


    imgs_mask_train /= 255
    imgs_mask_train[imgs_mask_train > 0.5] = 1
    imgs_mask_train[imgs_mask_train <= 0.5] = 0

    # weight_map_train = self.create_weight_map(imgs_mask_train)

    print("Done loading traing data")
    print('-' * 30)
    return imgs_train, imgs_mask_train

def hist_equalization(inputs):      # inputs are uint8, 0-255, Nx1x636x636
    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))
    output = inputs.copy()
    for i in range(len(inputs)):
        img = inputs[i, 0, :, :]
        # res = cv2.equalizeHist(img)
        res = clahe.apply(img)
        output[i,0,:,:] = res
    return output

### BinaryCrossEntropyLoss2d().forward(logits, labels)
class BinaryCrossEntropyLoss2d(nn.Module):
    def __init__(self, weight=None, size_average=True):
        """
        Binary cross entropy loss 2D
        Args:
            weight:
            size_average:
        """
        super(BinaryCrossEntropyLoss2d, self).__init__()
        self.bce_loss = nn.BCELoss(weight, size_average)

    def forward(self, logits, targets):
        # probs = F.sigmoid(logits)
        probs = logits
        probs_flat = probs.view(-1)  # Flatten
        targets_flat = targets.view(-1)  # Flatten
        return self.bce_loss(probs_flat, targets_flat)      # (output, labels)

class BCE_with_Weights(nn.Module):
    def __init__(self, weights=None):
        """
        Binary cross entropy loss 2D
        Args:
            weights:
        """
        super(BCE_with_Weights, self).__init__()
        self.weights = weights

    def forward(self, output, target):
        if self.weights is not None:
            loss = self.weights * (target * torch.log(output) + (1 - target) * torch.log(1 - output))
        else:
            loss = target * torch.log(output) + (1 - target) * torch.log(1 - output)

        return torch.neg(torch.mean(loss))

class LRN(nn.Module):       # input x is Torch tensor
    def __init__(self, local_size=1, alpha=1.0, beta=0.75, ACROSS_CHANNELS=False):      #LRN(local_size=5, alpha=0.0001, beta=0.75),
        super(LRN, self).__init__()
        self.ACROSS_CHANNELS = ACROSS_CHANNELS
        if self.ACROSS_CHANNELS:
            self.average = nn.AvgPool3d(kernel_size=(local_size, 1, 1),
                                        stride=1, padding=(int((local_size - 1.0) / 2), 0, 0))
        else:
            self.average = nn.AvgPool2d(kernel_size=local_size,
                                        stride=1, padding=int((local_size - 1.0) / 2))
        self.alpha = alpha
        self.beta = beta

    def forward(self, x):
        if self.ACROSS_CHANNELS:
            div = x.pow(2).unsqueeze(1)
            div = self.average(div).squeeze(1)
            div = div.mul(self.alpha).add(1.0).pow(self.beta)
        else:
            div = x.pow(2)
            div = self.average(div)
            div = div.mul(self.alpha).add(1.0).pow(self.beta)
        x = x.div(div)
        return x
Sat Nov 25 01:03:07 2017
Leg22_CROP_dropout_0_2_rmSigmoid_20aug_10ela_3inten_reflect
optim.SGD(net.parameters(), lr=1e-2, momentum=0.99)
Number of epoch max: 6
==========================================================================================
Sat Nov 25 01:05:19 2017
Leg22_CROP_dropout_0_2_rmSigmoid_20aug_10ela_3inten_reflect
Sat Nov 25 01:05:16 2017
import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.autograd import Variable
import math


class ConvBnRelu(nn.Module):
    def __init__(self, in_channels, out_channels, kernel_size, padding, stride):
        super(ConvBnRelu, self).__init__()
        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=kernel_size, padding=padding, stride=stride)
        self.bn = nn.BatchNorm2d(out_channels)
        self.relu = nn.ReLU()

    def forward(self, x):
        x = self.conv(x)
        # x = self.bn(x)
        x = self.relu(x)
        return x


class StackEncoder(nn.Module):
    def __init__(self, in_channels, out_channels):
        super(StackEncoder, self).__init__()
        self.convr1 = ConvBnRelu(in_channels, out_channels, kernel_size=(3, 3), stride=1, padding=0)
        self.convr2 = ConvBnRelu(out_channels, out_channels, kernel_size=(3, 3), stride=1, padding=0)
        self.maxPool = nn.MaxPool2d(kernel_size=(2, 2), stride=2)

    def forward(self, x):
        x = self.convr1(x)
        x = self.convr2(x)
        x_trace = x             # save x to use in concat in the Decoder path
        out = self.maxPool(x)
        return out, x_trace


class StackDecoder(nn.Module):
    def __init__(self, in_channels, out_channels, padding = 0, drop_out=False):
        super(StackDecoder, self).__init__()

        self.drop_out = drop_out
        self.dropout_layer = nn.Dropout2d(p=0.5)

        ''' this is old version
        self.upSample = nn.Upsample(size=upsample_size, scale_factor=(2, 2), mode="bilinear")
        self.convr1 = ConvBnRelu(in_channels, out_channels, kernel_size=(3, 3), stride=1, padding=padding)
        # Crop + concat step between these 2
        self.convr2 = ConvBnRelu(in_channels, out_channels, kernel_size=(3, 3), stride=1, padding=padding)
        '''
        self.upSample = nn.ConvTranspose2d(in_channels, out_channels, 2, stride=2)
        self.convr1 = ConvBnRelu(in_channels, out_channels, kernel_size=(3, 3), stride=1, padding=padding)
        self.convr2 = ConvBnRelu(out_channels, out_channels, kernel_size=(3, 3), stride=1, padding=padding)

    def _crop_concat(self, upsampled, bypass):
        """
         Crop y to the (h, w) of x and concat them.
         Used for the expansive path.
        Returns:
            The concatenated tensor
        """
        c = (bypass.size()[2] - upsampled.size()[2]) // 2
        bypass = F.pad(bypass, (-c, -c, -c, -c))

        return torch.cat((bypass, upsampled), 1)

    def forward(self, x, down_tensor):
        '''old version
        x = self.upSample(x)
        x = self.convr1(x)
        x = self._crop_concat(x, down_tensor)
        x = self.convr2(x)
        '''

        x = self.upSample(x)
        x = self._crop_concat(x, down_tensor)
        x = self.convr1(x)
        if self.drop_out: x = self.dropout_layer(x)
        x = self.convr2(x)
        if self.drop_out: x = self.dropout_layer(x)
        return x


class UNET_CROP(nn.Module):
    def __init__(self):
        super(UNET_CROP, self).__init__()
        # channels, height, width = in_shape

        # self.dropout = dropout

        self.model_code = ""        # variable to save model and main function when loaded

        self.down1 = StackEncoder(1, 64)
        self.down2 = StackEncoder(64, 128)
        self.down3 = StackEncoder(128, 256)
        self.down4 = StackEncoder(256, 512)

        self.center = nn.Sequential(
            # nn.Dropout2d(p=0.2),
            ConvBnRelu(512, 1024, kernel_size=(3, 3), stride=1, padding=0),
            nn.Dropout2d(p=0.2),
            ConvBnRelu(1024, 1024, kernel_size=(3, 3), stride=1, padding=0),
            nn.Dropout2d(p=0.2)
        )

        self.up1 = StackDecoder(in_channels=1024, out_channels=512)
        self.up2 = StackDecoder(in_channels=512, out_channels=256)
        self.up3 = StackDecoder(in_channels=256, out_channels=128)
        self.up4 = StackDecoder(in_channels=128, out_channels=64)

        # 1x1 convolution at the last layer
        # Different from the paper is the output size here
        self.output_seg_map = nn.Conv2d(64, 1, kernel_size=(1, 1), padding=0, stride=1)

        self._initialize_weights()

    def forward(self, x):
        x, x_trace1 = self.down1(x)
        x, x_trace2 = self.down2(x)
        x, x_trace3 = self.down3(x)
        x, x_trace4 = self.down4(x)
        x = self.center(x)
        x = self.up1(x, x_trace4)
        x = self.up2(x, x_trace3)
        x = self.up3(x, x_trace2)
        x = self.up4(x, x_trace1)

        x = self.output_seg_map(x)
        # x = F.sigmoid(x)
        # out = torch.squeeze(out, dim=1)
        return x


    def _initialize_weights(self):
        for m in self.modules():
            if isinstance(m, nn.Conv2d):
                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels
                m.weight.data.normal_(0, math.sqrt(2. / n))
                if m.bias is not None:
                    m.bias.data.zero_()
            elif isinstance(m, nn.BatchNorm2d):
                m.weight.data.fill_(1)
                m.bias.data.zero_()

# x = Variable(torch.randn(1,1,700, 700))       # simulate input image
# net = UNET_CROP()
# out = net(x)
# print("input: ", x)
# print("output: ", out)
===============from __future__ import print_function, division
import torch
from torch import optim
from torch.autograd import Variable
from torch.utils.data import DataLoader
import numpy as np
import torch.nn as nn
import torch.nn.functional as F
import Unet_crop
import tifffile as tiff
import Utils
import time
from sklearn.metrics import average_precision_score, recall_score, f1_score
import Analysis_crop
import cv2

def to_var(x):
    if torch.cuda.is_available():
        return Variable(x.cuda())
    else:
        return Variable(x)

### BinaryCrossEntropyLoss2d().forward(logits, labels)
class BinaryCrossEntropyLoss2d(nn.Module):
    def __init__(self, weight=None, size_average=True):
        """
        Binary cross entropy loss 2D
        Args:
            weight:
            size_average:
        """
        super(BinaryCrossEntropyLoss2d, self).__init__()
        self.bce_loss = nn.BCELoss(weight, size_average)

    def forward(self, probs, targets):
        probs = F.sigmoid(probs)
        probs_flat = probs.view(-1)  # Flatten
        targets_flat = targets.view(-1)  # Flatten
        return self.bce_loss(probs_flat, targets_flat)      # (output, labels)

def NetEval(net,valdata_loader,crit):
    loss = 0.
    count = 0
    net.eval()
    crop_input, crop_label,_ = crop_info()
    for i,data in enumerate(valdata_loader,0):
        if i > 100: break
        inputs, labels = data
        # inputs = inputs.numpy()
        # labels = labels.numpy()
        for j in range(len(crop_input)):  # training on the crop images and corresponding labels
            ci = crop_input[j]  # crop index for inputs
            cl = crop_label[j]  # crop index for lables
            # temp = labels[0, 0, :, :]  # labels is numpy array 512x512
            # if np.sum(temp) < 0.01 * np.shape(temp)[0] * np.shape(temp)[1]: break
            x = inputs.numpy()[:, :, ci[0]:ci[0] + 572, ci[1]:ci[1] + 572]
            y = labels.numpy()[:, :, cl[0]: cl[0] + 388, cl[1]:cl[1] + 388]
            x = torch.from_numpy(x)
            y = torch.from_numpy(y)
            x, y = to_var(x), to_var(y)
            out = net(x)
            l = crit(out, y)
            loss += l.data[0]
            count += 1
    return loss/count

#process the test data and save to separate .tif image
def NetTest(net,testdata_loader,path = "data/results/"):
    net.eval()
    crop_input, crop_label, average_mask = crop_info()
    for i, data in enumerate(testdata_loader, 0):
        if i >= 30: return 1        # for debug
        # data = to_var(data)
        img_shape = 512
        img = np.zeros((img_shape, img_shape))
        for j in range(len(crop_input)):  # training on the crop images and corresponding labels
            ci = crop_input[j]  # crop index for inputs
            x = data.numpy()[:, :, ci[0]:ci[0] + 572, ci[1]:ci[1] + 572]
            x = torch.from_numpy(x)
            x = to_var(x)
            out = F.sigmoid(net(x))
            out = out.cpu()
            out = out[0,0,:,:]
            img += out.data.numpy()

        img = img/average_mask
        img = img.reshape(-1)
        img[img < 0.5] = 0; img[img >= 0.5] = 1
        img = img.reshape(img_shape)
        img = np.uint8(img * 255)
        imgname = path + str(i) + ".tif"
        tiff.imsave(imgname, img)

# return input image size like 512x512, numpy array
def NetPredict(net, input_image):
    net.eval()
    _, crop_label, average_mask = crop_info()

    # input_image is grayscale input image of 512x512
    data = Utils.input_filled_mirroring(input_image, e = 94)
    imgdatas = np.ndarray((1, 1, data.shape[0], data.shape[1]), dtype=np.uint8)
    imgdatas[0] = np.expand_dims(data, 0)
    data = Utils.hist_equalization(imgdatas)
    data = data.astype('float32')
    data /= 255
    data -= data.mean(axis=0)

    img_shape = input_image.shape
    img = np.zeros((img_shape, img_shape))
    for j in range(len(crop_input)):  # training on the crop images and corresponding labels
        ci = crop_input[j]  # crop index for inputs
        x = data.numpy()[:, :, ci[0]:ci[0] + 572, ci[1]:ci[1] + 572]
        x = torch.from_numpy(x)
        x = to_var(x)
        out = F.sigmoid(net(x))
        out = out.cpu()
        out = out[0, 0, :, :]
        img += out.data.numpy()

    img = img / average_mask
    img = img.reshape(-1)
    img[img < 0.5] = 0
    img[img >= 0.5] = 1
    img = img.reshape(img_shape)
    img = np.uint8(img * 255)
    return img


def write_2_log(content):
    path = "log_file.txt"
    output = open(path, "a")
    output.write("\n")
    output.write(content)
    output.close()

def crop_info():
    crop_input = [[0, 0], [128, 0], [0, 128], [128, 128]]
    crop_label = [[0, 0], [124, 0], [0, 124], [124, 124]]
    average_mask = np.ones((512, 512))
    average_mask[124:388, 0:124] = 2
    average_mask[0:124, 124:388] = 2
    average_mask[124:388, 388:512] = 2
    average_mask[388:512, 124:388] = 2
    average_mask[124:388, 124:388] = 4
    return crop_input, crop_label, average_mask

if __name__ == '__main__':
    '''subjects to change for each exp:
    + path to the dataset
    + opt function
    + leg description
    + N_epoch
    + saved_model
    '''
    start_begining = time.time()

    # path = "data/dataset"
    path = "/home/anhxtuan/HanLe/dataset/20aug_10ela_3inten_reflect"
    path = "/home/anhxtuan/HanLe/dataset/20aug_10ela_3inten_reflect_700"

    import os
    print("Does the folder exist?: ", os.path.isdir(path))
    print("Does the path exist?: ", os.path.exists(path))

    imgs_train, imgs_mask_train = Utils.load_train_data(npy_path=path)
    imgs_val, imgs_mask_val = Utils.load_val_data(npy_path=path)
    batch_size = 1
    trainset = zip(imgs_train, imgs_mask_train)
    trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,
                                              shuffle=True, num_workers=2)
    valset = zip(imgs_val, imgs_mask_val)
    valloader = torch.utils.data.DataLoader(valset, batch_size=batch_size,
                                              shuffle=False, num_workers=2)
    # net = Unet.UNet()                     # Unet 1
    # net = Unet_BatchNorm.UNet_BN()          # Unet 2 with batchNorm
    net = Unet_crop.UNET_CROP()

    f1 = open("Unet_crop.py", 'r')     # embede code into the model to be saved later
    f2 = open("UnetTrain_crop.py", 'r')
    f3 = open("Utils.py", 'r')
    model_notes = time.strftime("%c") + "\n" + f1.read() + "\n" + "==="*5 + f2.read() + "\n" + "==="*5 + f3.read()
    f1.close()
    f2.close()
    f3.close()

    criterion = BinaryCrossEntropyLoss2d()
    # criterion = SoftDiceLoss()
    # criterion = nn.BCELoss()

    if torch.cuda.is_available():
        # torch.set_default_tensor_type('torch.cuda.FloatTensor')
        # net.load_state_dict(torch.load("Unet2_model_12epoch_Leg12_droput_0_2_rmSigmoid_20aug_10ela_3inten_reflect"))
        net.cuda()
        # criterion.cuda()

    opt = optim.SGD(net.parameters(), lr=1e-2, momentum=0.99)       # subject to change
    # opt = optim.RMSprop(net.parameters(), lr=2e-4)
    # RMSprop[22](learning rate 0.001) with weight decay set to 0.001.
    # opt = optim.Adam(net.parameters(), lr=1e-3, weight_decay=1e-4)

    train_loss = []
    val_loss = []

    print("[epoch, #image] Loss")
    leg = "Leg22_CROP_dropout_0_2_rmSigmoid_20aug_10ela_3inten_reflect"
    print("Processing: ", leg)
    model_name = ""

    N_epoch = 6
    model_saved = np.arange(1,N_epoch+1,2)
    val_loss_min = 100

    write_2_log("==="*30)
    write_2_log(time.strftime("%c"))       # time, date of exp
    write_2_log(leg)
    write_2_log(model_notes)
    write_2_log(time.strftime("%c"))  # time, date of exp
    write_2_log(leg)
    write_2_log("optim.SGD(net.parameters(), lr=1e-2, momentum=0.99)")
    write_2_log("Number of epoch max: " + str(N_epoch))

    crop_input, crop_label,_ = crop_info()
    min_model_epoch = 0
    for epoch in range(N_epoch):
        running_loss = 0.0; count = 0
        net.train()
        for i, data in enumerate(trainloader, 0):
            if i > 100: break

            inputs, labels = data
            temp = labels.numpy()
            for j in range(len(crop_input)):       # training on the crop images and corresponding labels
                ci = crop_input[j]          # crop index for inputs
                cl = crop_label[j]          # crop index for lables
                # temp = temp[0, 0, :, :]  # labels is numpy array 512x512
                # if np.sum(temp) < 0.01 * np.shape(temp)[0] * np.shape(temp)[1]: break
                x = inputs.numpy()[:, :, ci[0]:ci[0] + 572, ci[1]:ci[1] + 572]
                y = labels.numpy()[:, :, cl[0]: cl[0] + 388, cl[1]:cl[1] + 388]
                x = torch.from_numpy(x)
                y = torch.from_numpy(y)
                x, y = to_var(x), to_var(y)
                opt.zero_grad()
                out = net(x)
                loss = criterion(out, y)
                loss.backward()
                opt.step()
                running_loss += loss.data[0]
                count += 1

        net.eval()
        val_loss_temp = NetEval(net, valloader, criterion)
        if epoch > 0 and val_loss_temp < val_loss_min:        # save the model which has the lowest val_loss, ignore first epoch
            val_loss_min = val_loss_temp
            torch.save(net.state_dict(), "Unet2_model_" + leg + "_min_val_loss")  # save model
            min_model_epoch = epoch + 1

        disp = 'Epoch %d: Train loss: %.6f, Val loss: %.6f' % (epoch + 1, running_loss/count, val_loss_temp)
        write_2_log(disp)
        print(disp)
        val_loss.append(val_loss_temp)
        train_loss.append(running_loss/count); running_loss = 0.0

        if (epoch + 1) in model_saved:        # save checkpoint
            model_name = "Unet2_model_" + str(epoch+1) + "epoch_" + leg
            torch.save(net.state_dict(), model_name)  # save model
            Analysis_crop.analysis(model_file = model_name, valloader = valloader)

    write_2_log("Best model at epoch: " + str(min_model_epoch))
    write_2_log("Total training time: " + str((time.time() - start_begining) / 3600.0))

    val_loss_file = "data/results" + "/val_loss_" + str(N_epoch) + "epoch_" + leg + ".npy"
    train_loss_file = "data/results" + "/training_loss_" + str(N_epoch) + "epoch_" + leg + ".npy"

    np.save(val_loss_file, val_loss)
    np.save(train_loss_file, train_loss)
    print("total processing time in seconds: ", time.time() - start_begining)
    print("total processing time in mins: ", (time.time() - start_begining) / 60.0)
    print("total processing time in hours: ", (time.time() - start_begining) / 3600.0)

    # Analysis.analysis(model_file="Unet2_model_" + leg + "_min_val_loss", valloader=valloader)

    Analysis_crop.PlotLoss(model_file = model_name, loss_train_path = train_loss_file, loss_val_path = val_loss_file, epoch_No = N_epoch)

    write_2_log(time.strftime("%c"))  # time, date of exp
===============
import numpy as np
import torch.nn as nn
import torch
import cv2
from lcn import LecunLCN

LCN_enable = False

def input_filled_mirroring(x, e = 62):      # fill missing data by mirroring the input image
    '''input size 636 --> output size 512'''
    w, h = x.shape
    #e = 62  # extra width on 1 edge
    y = np.zeros((h + e * 2, w + e * 2))
    y[e:h + e, e:w + e] = x
    y[e:e + h, 0:e] = np.flip(y[e:e + h, e:2 * e], 1)  # flip vertically
    y[e:e + h, e + w:2 * e + w] = np.flip(y[e:e + h, w:e + w], 1)  # flip vertically
    y[0:e, 0:2 * e + w] = np.flip(y[e:2 * e, 0:2 * e + w], 0)  # flip horizontally
    y[e + h:2 * e + h, 0:2 * e + w] = np.flip(y[h:e + h, 0:2 * e + w], 0)  # flip horizontally
    return y

def nearest_cells_distance(pos, img):
    # searching in 8 directions to find 2 nearest distances to neighbor cells
    curr_value = img[pos]
    w = img.shape[0];h = img.shape[1]
    count_detect = 0  # detect 2 nearest neighbors. break the search if count_detect = 2
    x, y = pos

    # print("w,h: ", (w, h))
    d1 = 9999999;d2 = 9999999;d3 = 9999999;d4 = 9999999
    d5 = 9999999;d6 = 9999999;d7 = 9999999;d8 = 9999999
    for i in range(1, max(w, h)):
        # (x+1, y), (x+1, y+1), (x+1, y-1),
        # (x, y+1), (x, y-1)
        # (x-1, y), (x-1,y+1), (x-1,y-1),
        if x + i < w:
            if img[(x + i, y)] != curr_value and d1 == 9999999:
                d1 = i; count_detect += 1
            if y + i < h:
                if img[(x + i, y + i)] != curr_value and d2 == 9999999:
                    d2 = i; count_detect += 1
            elif y - i >= 0:
                if img[(x + i, y - i)] != curr_value and d3 == 9999999:
                    d3 = i; count_detect += 1
        if y + i < h:
            if img[(x, y + i)] != curr_value and d4 == 9999999:
                d4 = i; count_detect += 1
        if y - i >= 0:
            if img[(x, y - i)] != curr_value and d5 == 9999999:
                d5 = i; count_detect += 1
        if x - i >= 0:
            if img[(x - i, y)] != curr_value and d6 == 9999999:
                d6 = i; count_detect += 1
            if y + i < h:
                if img[(x - i, y + i)] != curr_value and d7 == 9999999:
                    d7 = i; count_detect += 1
            elif y - i >= 0:
                if img[(x - i, y - i)] != curr_value and d8 == 9999999:
                    d8 = i; count_detect += 1
        if count_detect >= 2: break

    d = [d1, d2, d3, d4, d5, d6, d7, d8]
    min_index = np.argmin(d)
    dist1 = d[min_index]
    d.remove(dist1)
    min_index = np.argmin(d)
    dist2 = d[min_index]
    return dist1, dist2

def create_weight_map(imgs_mask):
        print('-' * 30)
        print('Creating weights for masks ...')
        print('-' * 30)
        weight_map = np.ndarray(
            (len(imgs_mask), 1, np.shape(imgs_mask)[2], np.shape(imgs_mask)[3]), dtype=np.float32)
        w_0 = 10; sigma = 4
        imgs_w, imgs_h = np.shape(imgs_mask)[2], np.shape(imgs_mask)[3]
        total_pixels = imgs_w*imgs_h
        import time
        start = time.time()
        for i in range(len(imgs_mask)):
            if i%10 == 0: print("Done processing: %d images, time passed: %.2f mins" % (i, (time.time() - start)/60.0))
            temp = imgs_mask[i,0,:,:]
            w_border = 1 - np.sum(temp)/total_pixels        # w_c of pixel on the border (black)
            for m in range(imgs_w):
                for n in range(imgs_h):
                    # loop through all pixel of the mask
                    d1,d2 = nearest_cells_distance((m,n), temp)
                    w_c = w_border
                    if temp[m,n] == 0: w_c = 1 - w_border
                    weight_map[i,0,m,n] = w_c*5 + w_0*np.exp(-(d1 + d2)**2/(2*sigma**2))
                    # print("w_0*np.exp(): ", w_0*np.exp(-(d1 + d2)**2/(2*sigma**2)))
                    # print("w_border: ", w_border)

        np.save('data/dataset/weight_map_train.npy', weight_map)

        return weight_map

def load_train_data(npy_path = "data/dataset", hist_equal = False):

    print('-' * 30)
    print('load train images...')

    imgs_train = np.load(npy_path + "/imgs_train.npy")
    imgs_mask_train = np.load(npy_path + "/imgs_mask_train.npy")

    if hist_equal: imgs_train = hist_equalization(imgs_train)

    # weight_map_train = np.load(npy_path + "/weight_map_train.npy")
    # weight_map_train = weight_map_train.astype('float32')

    imgs_train = imgs_train.astype('float32')
    imgs_mask_train = imgs_mask_train.astype('float32')

    if LCN_enable:
        imgs_train = imgs_train.astype('float64')
        imgs_train = LecunLCN(imgs_train, image_shape=imgs_train.shape).output.eval()
        imgs_train = imgs_train.astype('float32')

    if not LCN_enable: imgs_train /= 255

    imgs_train -= imgs_train.mean(axis=0)
    imgs_mask_train /= 255
    imgs_mask_train[imgs_mask_train > 0.5] = 1
    imgs_mask_train[imgs_mask_train <= 0.5] = 0

    # weight_map_train = create_weight_map(imgs_mask_train)

    print("Done loading traing data")
    print('-' * 30)
    return imgs_train, imgs_mask_train

def load_val_data(npy_path = "data/dataset", hist_equal = True):

    print('-' * 30)
    print('load validation images...')

    imgs_train = np.load(npy_path + "/imgs_val.npy")
    imgs_mask_train = np.load(npy_path + "/imgs_mask_val.npy")

    if hist_equal: imgs_train = hist_equalization(imgs_train)

    imgs_train = imgs_train.astype('float32')
    imgs_mask_train = imgs_mask_train.astype('float32')

    if LCN_enable:
        imgs_train = imgs_train.astype('float64')
        imgs_train = LecunLCN(imgs_train, image_shape=imgs_train.shape).output.eval()
        imgs_train = imgs_train.astype('float32')

    if not LCN_enable: imgs_train /= 255
    imgs_train -= imgs_train.mean(axis=0)
    imgs_mask_train /= 255
    imgs_mask_train[imgs_mask_train > 0.5] = 1
    imgs_mask_train[imgs_mask_train <= 0.5] = 0
    print("Done loading validation data")
    print('-' * 30)
    return imgs_train, imgs_mask_train

def load_test_data(npy_path = "data/dataset", hist_equal = True):

    print('-' * 30)
    print('load test images...')

    imgs_test = np.load(npy_path + "/imgs_test.npy")

    if hist_equal: imgs_test = hist_equalization(imgs_test)

    imgs_test = imgs_test.astype('float32')

    if LCN_enable:
        imgs_test = imgs_test.astype('float64')
        imgs_test = LecunLCN(imgs_test, image_shape=imgs_test.shape).output.eval()
        imgs_test = imgs_test.astype('float32')

    if not LCN_enable: imgs_test /= 255

    imgs_test -= imgs_test.mean(axis=0)

    print("Done loading test data")
    print('-' * 30)
    return imgs_test

def load_val_5imgs(npy_path = "data/dataset"):
    print('-' * 30)
    print('load train images...')

    imgs_train = np.load(npy_path + "/imgs_val_5imgs.npy")
    imgs_mask_train = np.load(npy_path + "/imgs_mask_val_5imgs.npy")

    # imgs_train = hist_equalization(imgs_train)

    imgs_train = imgs_train.astype('float64')
    imgs_mask_train = imgs_mask_train.astype('float64')

    if LCN_enable: imgs_train = LecunLCN(imgs_train, image_shape=imgs_train.shape).output.eval()

    if not LCN_enable: imgs_train /= 255

    mean = imgs_train.mean(axis=0)
    imgs_train -= mean


    imgs_mask_train /= 255
    imgs_mask_train[imgs_mask_train > 0.5] = 1
    imgs_mask_train[imgs_mask_train <= 0.5] = 0

    # weight_map_train = self.create_weight_map(imgs_mask_train)

    print("Done loading traing data")
    print('-' * 30)
    return imgs_train, imgs_mask_train

def hist_equalization(inputs):      # inputs are uint8, 0-255, Nx1x636x636
    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))
    output = inputs.copy()
    for i in range(len(inputs)):
        img = inputs[i, 0, :, :]
        # res = cv2.equalizeHist(img)
        res = clahe.apply(img)
        output[i,0,:,:] = res
    return output

### BinaryCrossEntropyLoss2d().forward(logits, labels)
class BinaryCrossEntropyLoss2d(nn.Module):
    def __init__(self, weight=None, size_average=True):
        """
        Binary cross entropy loss 2D
        Args:
            weight:
            size_average:
        """
        super(BinaryCrossEntropyLoss2d, self).__init__()
        self.bce_loss = nn.BCELoss(weight, size_average)

    def forward(self, logits, targets):
        # probs = F.sigmoid(logits)
        probs = logits
        probs_flat = probs.view(-1)  # Flatten
        targets_flat = targets.view(-1)  # Flatten
        return self.bce_loss(probs_flat, targets_flat)      # (output, labels)

class BCE_with_Weights(nn.Module):
    def __init__(self, weights=None):
        """
        Binary cross entropy loss 2D
        Args:
            weights:
        """
        super(BCE_with_Weights, self).__init__()
        self.weights = weights

    def forward(self, output, target):
        if self.weights is not None:
            loss = self.weights * (target * torch.log(output) + (1 - target) * torch.log(1 - output))
        else:
            loss = target * torch.log(output) + (1 - target) * torch.log(1 - output)

        return torch.neg(torch.mean(loss))

class LRN(nn.Module):       # input x is Torch tensor
    def __init__(self, local_size=1, alpha=1.0, beta=0.75, ACROSS_CHANNELS=False):      #LRN(local_size=5, alpha=0.0001, beta=0.75),
        super(LRN, self).__init__()
        self.ACROSS_CHANNELS = ACROSS_CHANNELS
        if self.ACROSS_CHANNELS:
            self.average = nn.AvgPool3d(kernel_size=(local_size, 1, 1),
                                        stride=1, padding=(int((local_size - 1.0) / 2), 0, 0))
        else:
            self.average = nn.AvgPool2d(kernel_size=local_size,
                                        stride=1, padding=int((local_size - 1.0) / 2))
        self.alpha = alpha
        self.beta = beta

    def forward(self, x):
        if self.ACROSS_CHANNELS:
            div = x.pow(2).unsqueeze(1)
            div = self.average(div).squeeze(1)
            div = div.mul(self.alpha).add(1.0).pow(self.beta)
        else:
            div = x.pow(2)
            div = self.average(div)
            div = div.mul(self.alpha).add(1.0).pow(self.beta)
        x = x.div(div)
        return x
Sat Nov 25 01:05:19 2017
Leg22_CROP_dropout_0_2_rmSigmoid_20aug_10ela_3inten_reflect
optim.SGD(net.parameters(), lr=1e-2, momentum=0.99)
Number of epoch max: 6
Epoch 1: Train loss: 0.513917, Val loss: 0.512697
==========================================================================================
Sat Nov 25 01:21:04 2017
Leg22_CROP_dropout_0_2_rmSigmoid_20aug_10ela_3inten_reflect
Sat Nov 25 01:21:02 2017
import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.autograd import Variable
import math


class ConvBnRelu(nn.Module):
    def __init__(self, in_channels, out_channels, kernel_size, padding, stride):
        super(ConvBnRelu, self).__init__()
        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=kernel_size, padding=padding, stride=stride)
        self.bn = nn.BatchNorm2d(out_channels)
        self.relu = nn.ReLU()

    def forward(self, x):
        x = self.conv(x)
        # x = self.bn(x)
        x = self.relu(x)
        return x


class StackEncoder(nn.Module):
    def __init__(self, in_channels, out_channels):
        super(StackEncoder, self).__init__()
        self.convr1 = ConvBnRelu(in_channels, out_channels, kernel_size=(3, 3), stride=1, padding=0)
        self.convr2 = ConvBnRelu(out_channels, out_channels, kernel_size=(3, 3), stride=1, padding=0)
        self.maxPool = nn.MaxPool2d(kernel_size=(2, 2), stride=2)

    def forward(self, x):
        x = self.convr1(x)
        x = self.convr2(x)
        x_trace = x             # save x to use in concat in the Decoder path
        out = self.maxPool(x)
        return out, x_trace


class StackDecoder(nn.Module):
    def __init__(self, in_channels, out_channels, padding = 0, drop_out=False):
        super(StackDecoder, self).__init__()

        self.drop_out = drop_out
        self.dropout_layer = nn.Dropout2d(p=0.5)

        ''' this is old version
        self.upSample = nn.Upsample(size=upsample_size, scale_factor=(2, 2), mode="bilinear")
        self.convr1 = ConvBnRelu(in_channels, out_channels, kernel_size=(3, 3), stride=1, padding=padding)
        # Crop + concat step between these 2
        self.convr2 = ConvBnRelu(in_channels, out_channels, kernel_size=(3, 3), stride=1, padding=padding)
        '''
        self.upSample = nn.ConvTranspose2d(in_channels, out_channels, 2, stride=2)
        self.convr1 = ConvBnRelu(in_channels, out_channels, kernel_size=(3, 3), stride=1, padding=padding)
        self.convr2 = ConvBnRelu(out_channels, out_channels, kernel_size=(3, 3), stride=1, padding=padding)

    def _crop_concat(self, upsampled, bypass):
        """
         Crop y to the (h, w) of x and concat them.
         Used for the expansive path.
        Returns:
            The concatenated tensor
        """
        c = (bypass.size()[2] - upsampled.size()[2]) // 2
        bypass = F.pad(bypass, (-c, -c, -c, -c))

        return torch.cat((bypass, upsampled), 1)

    def forward(self, x, down_tensor):
        '''old version
        x = self.upSample(x)
        x = self.convr1(x)
        x = self._crop_concat(x, down_tensor)
        x = self.convr2(x)
        '''

        x = self.upSample(x)
        x = self._crop_concat(x, down_tensor)
        x = self.convr1(x)
        if self.drop_out: x = self.dropout_layer(x)
        x = self.convr2(x)
        if self.drop_out: x = self.dropout_layer(x)
        return x


class UNET_CROP(nn.Module):
    def __init__(self):
        super(UNET_CROP, self).__init__()
        # channels, height, width = in_shape

        # self.dropout = dropout

        self.model_code = ""        # variable to save model and main function when loaded

        self.down1 = StackEncoder(1, 64)
        self.down2 = StackEncoder(64, 128)
        self.down3 = StackEncoder(128, 256)
        self.down4 = StackEncoder(256, 512)

        self.center = nn.Sequential(
            # nn.Dropout2d(p=0.2),
            ConvBnRelu(512, 1024, kernel_size=(3, 3), stride=1, padding=0),
            nn.Dropout2d(p=0.2),
            ConvBnRelu(1024, 1024, kernel_size=(3, 3), stride=1, padding=0),
            nn.Dropout2d(p=0.2)
        )

        self.up1 = StackDecoder(in_channels=1024, out_channels=512)
        self.up2 = StackDecoder(in_channels=512, out_channels=256)
        self.up3 = StackDecoder(in_channels=256, out_channels=128)
        self.up4 = StackDecoder(in_channels=128, out_channels=64)

        # 1x1 convolution at the last layer
        # Different from the paper is the output size here
        self.output_seg_map = nn.Conv2d(64, 1, kernel_size=(1, 1), padding=0, stride=1)

        self._initialize_weights()

    def forward(self, x):
        x, x_trace1 = self.down1(x)
        x, x_trace2 = self.down2(x)
        x, x_trace3 = self.down3(x)
        x, x_trace4 = self.down4(x)
        x = self.center(x)
        x = self.up1(x, x_trace4)
        x = self.up2(x, x_trace3)
        x = self.up3(x, x_trace2)
        x = self.up4(x, x_trace1)

        x = self.output_seg_map(x)
        # x = F.sigmoid(x)
        # out = torch.squeeze(out, dim=1)
        return x


    def _initialize_weights(self):
        for m in self.modules():
            if isinstance(m, nn.Conv2d):
                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels
                m.weight.data.normal_(0, math.sqrt(2. / n))
                if m.bias is not None:
                    m.bias.data.zero_()
            elif isinstance(m, nn.BatchNorm2d):
                m.weight.data.fill_(1)
                m.bias.data.zero_()

# x = Variable(torch.randn(1,1,700, 700))       # simulate input image
# net = UNET_CROP()
# out = net(x)
# print("input: ", x)
# print("output: ", out)
===============from __future__ import print_function, division
import torch
from torch import optim
from torch.autograd import Variable
from torch.utils.data import DataLoader
import numpy as np
import torch.nn as nn
import torch.nn.functional as F
import Unet_crop
import tifffile as tiff
import Utils
import time
from sklearn.metrics import average_precision_score, recall_score, f1_score
import Analysis_crop
import cv2

def to_var(x):
    if torch.cuda.is_available():
        return Variable(x.cuda())
    else:
        return Variable(x)

### BinaryCrossEntropyLoss2d().forward(logits, labels)
class BinaryCrossEntropyLoss2d(nn.Module):
    def __init__(self, weight=None, size_average=True):
        """
        Binary cross entropy loss 2D
        Args:
            weight:
            size_average:
        """
        super(BinaryCrossEntropyLoss2d, self).__init__()
        self.bce_loss = nn.BCELoss(weight, size_average)

    def forward(self, probs, targets):
        probs = F.sigmoid(probs)
        probs_flat = probs.view(-1)  # Flatten
        targets_flat = targets.view(-1)  # Flatten
        return self.bce_loss(probs_flat, targets_flat)      # (output, labels)

def NetEval(net,valdata_loader,crit):
    loss = 0.
    count = 0
    net.eval()
    crop_input, crop_label,_ = crop_info()
    for i,data in enumerate(valdata_loader,0):
        if i > 100: break
        inputs, labels = data
        # inputs = inputs.numpy()
        # labels = labels.numpy()
        for j in range(len(crop_input)):  # training on the crop images and corresponding labels
            ci = crop_input[j]  # crop index for inputs
            cl = crop_label[j]  # crop index for lables
            # temp = labels[0, 0, :, :]  # labels is numpy array 512x512
            # if np.sum(temp) < 0.01 * np.shape(temp)[0] * np.shape(temp)[1]: break
            x = inputs.numpy()[:, :, ci[0]:ci[0] + 572, ci[1]:ci[1] + 572]
            y = labels.numpy()[:, :, cl[0]: cl[0] + 388, cl[1]:cl[1] + 388]
            x = torch.from_numpy(x)
            y = torch.from_numpy(y)
            x, y = to_var(x), to_var(y)
            out = net(x)
            l = crit(out, y)
            loss += l.data[0]
            count += 1
    return loss/count

#process the test data and save to separate .tif image
def NetTest(net,testdata_loader,path = "data/results/"):
    net.eval()
    crop_input, crop_label, average_mask = crop_info()
    for i, data in enumerate(testdata_loader, 0):
        if i >= 30: return 1        # for debug
        # data = to_var(data)
        img_shape = 512
        img = np.zeros((img_shape, img_shape))
        for j in range(len(crop_input)):  # training on the crop images and corresponding labels
            temp = np.zeros((img_shape, img_shape))
            ci = crop_input[j]  # crop index for inputs
            cl = crop_label[j]
            x = data.numpy()[:, :, ci[0]:ci[0] + 572, ci[1]:ci[1] + 572]
            x = torch.from_numpy(x)
            x = to_var(x)
            out = F.sigmoid(net(x))
            out = out.cpu()
            out = out[0,0,:,:]
            temp[cl[0]: cl[0] + 388, cl[1]:cl[1] + 388] = out.data.numpy()
            img += temp

        img = img/average_mask
        img = img.reshape(-1)
        img[img < 0.5] = 0; img[img >= 0.5] = 1
        img = img.reshape(img_shape)
        img = np.uint8(img * 255)
        imgname = path + str(i) + ".tif"
        tiff.imsave(imgname, img)

# return input image size like 512x512, numpy array
def NetPredict(net, input_image):
    net.eval()
    _, crop_label, average_mask = crop_info()

    # input_image is grayscale input image of 512x512
    data = Utils.input_filled_mirroring(input_image, e = 94)
    imgdatas = np.ndarray((1, 1, data.shape[0], data.shape[1]), dtype=np.uint8)
    imgdatas[0] = np.expand_dims(data, 0)
    data = Utils.hist_equalization(imgdatas)
    data = data.astype('float32')
    data /= 255
    data -= data.mean(axis=0)

    img_shape = input_image.shape
    img = np.zeros((img_shape, img_shape))
    for j in range(len(crop_input)):  # training on the crop images and corresponding labels
        ci = crop_input[j]  # crop index for inputs
        x = data.numpy()[:, :, ci[0]:ci[0] + 572, ci[1]:ci[1] + 572]
        x = torch.from_numpy(x)
        x = to_var(x)
        out = F.sigmoid(net(x))
        out = out.cpu()
        out = out[0, 0, :, :]
        temp[cl[0]: cl[0] + 388, cl[1]:cl[1] + 388] = out.data.numpy()
        img += temp

    img = img / average_mask
    img = img.reshape(-1)
    img[img < 0.5] = 0
    img[img >= 0.5] = 1
    img = img.reshape(img_shape)
    img = np.uint8(img * 255)
    return img


def write_2_log(content):
    path = "log_file.txt"
    output = open(path, "a")
    output.write("\n")
    output.write(content)
    output.close()

def crop_info():
    crop_input = [[0, 0], [128, 0], [0, 128], [128, 128]]
    crop_label = [[0, 0], [124, 0], [0, 124], [124, 124]]
    average_mask = np.ones((512, 512))
    average_mask[124:388, 0:124] = 2
    average_mask[0:124, 124:388] = 2
    average_mask[124:388, 388:512] = 2
    average_mask[388:512, 124:388] = 2
    average_mask[124:388, 124:388] = 4
    return crop_input, crop_label, average_mask

if __name__ == '__main__':
    '''subjects to change for each exp:
    + path to the dataset
    + opt function
    + leg description
    + N_epoch
    + saved_model
    '''
    start_begining = time.time()

    # path = "data/dataset"
    path = "/home/anhxtuan/HanLe/dataset/20aug_10ela_3inten_reflect"
    path = "/home/anhxtuan/HanLe/dataset/20aug_10ela_3inten_reflect_700"

    import os
    print("Does the folder exist?: ", os.path.isdir(path))
    print("Does the path exist?: ", os.path.exists(path))

    imgs_train, imgs_mask_train = Utils.load_train_data(npy_path=path)
    imgs_val, imgs_mask_val = Utils.load_val_data(npy_path=path)
    batch_size = 1
    trainset = zip(imgs_train, imgs_mask_train)
    trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,
                                              shuffle=True, num_workers=2)
    valset = zip(imgs_val, imgs_mask_val)
    valloader = torch.utils.data.DataLoader(valset, batch_size=batch_size,
                                              shuffle=False, num_workers=2)
    # net = Unet.UNet()                     # Unet 1
    # net = Unet_BatchNorm.UNet_BN()          # Unet 2 with batchNorm
    net = Unet_crop.UNET_CROP()

    f1 = open("Unet_crop.py", 'r')     # embede code into the model to be saved later
    f2 = open("UnetTrain_crop.py", 'r')
    f3 = open("Utils.py", 'r')
    model_notes = time.strftime("%c") + "\n" + f1.read() + "\n" + "==="*5 + f2.read() + "\n" + "==="*5 + f3.read()
    f1.close()
    f2.close()
    f3.close()

    criterion = BinaryCrossEntropyLoss2d()
    # criterion = SoftDiceLoss()
    # criterion = nn.BCELoss()

    if torch.cuda.is_available():
        # torch.set_default_tensor_type('torch.cuda.FloatTensor')
        # net.load_state_dict(torch.load("Unet2_model_12epoch_Leg12_droput_0_2_rmSigmoid_20aug_10ela_3inten_reflect"))
        net.cuda()
        # criterion.cuda()

    opt = optim.SGD(net.parameters(), lr=1e-2, momentum=0.99)       # subject to change
    # opt = optim.RMSprop(net.parameters(), lr=2e-4)
    # RMSprop[22](learning rate 0.001) with weight decay set to 0.001.
    # opt = optim.Adam(net.parameters(), lr=1e-3, weight_decay=1e-4)

    train_loss = []
    val_loss = []

    print("[epoch, #image] Loss")
    leg = "Leg22_CROP_dropout_0_2_rmSigmoid_20aug_10ela_3inten_reflect"
    print("Processing: ", leg)
    model_name = ""

    N_epoch = 6
    model_saved = np.arange(1,N_epoch+1,2)
    val_loss_min = 100

    write_2_log("==="*30)
    write_2_log(time.strftime("%c"))       # time, date of exp
    write_2_log(leg)
    write_2_log(model_notes)
    write_2_log(time.strftime("%c"))  # time, date of exp
    write_2_log(leg)
    write_2_log("optim.SGD(net.parameters(), lr=1e-2, momentum=0.99)")
    write_2_log("Number of epoch max: " + str(N_epoch))

    crop_input, crop_label,_ = crop_info()
    min_model_epoch = 0
    for epoch in range(N_epoch):
        running_loss = 0.0; count = 0
        net.train()
        for i, data in enumerate(trainloader, 0):
            if i > 100: break

            inputs, labels = data
            temp = labels.numpy()
            for j in range(len(crop_input)):       # training on the crop images and corresponding labels
                ci = crop_input[j]          # crop index for inputs
                cl = crop_label[j]          # crop index for lables
                # temp = temp[0, 0, :, :]  # labels is numpy array 512x512
                # if np.sum(temp) < 0.01 * np.shape(temp)[0] * np.shape(temp)[1]: break
                x = inputs.numpy()[:, :, ci[0]:ci[0] + 572, ci[1]:ci[1] + 572]
                y = labels.numpy()[:, :, cl[0]: cl[0] + 388, cl[1]:cl[1] + 388]
                x = torch.from_numpy(x)
                y = torch.from_numpy(y)
                x, y = to_var(x), to_var(y)
                opt.zero_grad()
                out = net(x)
                loss = criterion(out, y)
                loss.backward()
                opt.step()
                running_loss += loss.data[0]
                count += 1

        net.eval()
        val_loss_temp = NetEval(net, valloader, criterion)
        if epoch > 0 and val_loss_temp < val_loss_min:        # save the model which has the lowest val_loss, ignore first epoch
            val_loss_min = val_loss_temp
            torch.save(net.state_dict(), "Unet2_model_" + leg + "_min_val_loss")  # save model
            min_model_epoch = epoch + 1

        disp = 'Epoch %d: Train loss: %.6f, Val loss: %.6f' % (epoch + 1, running_loss/count, val_loss_temp)
        write_2_log(disp)
        print(disp)
        val_loss.append(val_loss_temp)
        train_loss.append(running_loss/count); running_loss = 0.0

        if (epoch + 1) in model_saved:        # save checkpoint
            model_name = "Unet2_model_" + str(epoch+1) + "epoch_" + leg
            torch.save(net.state_dict(), model_name)  # save model
            Analysis_crop.analysis(model_file = model_name, valloader = valloader)

    write_2_log("Best model at epoch: " + str(min_model_epoch))
    write_2_log("Total training time: " + str((time.time() - start_begining) / 3600.0))

    val_loss_file = "data/results" + "/val_loss_" + str(N_epoch) + "epoch_" + leg + ".npy"
    train_loss_file = "data/results" + "/training_loss_" + str(N_epoch) + "epoch_" + leg + ".npy"

    np.save(val_loss_file, val_loss)
    np.save(train_loss_file, train_loss)
    print("total processing time in seconds: ", time.time() - start_begining)
    print("total processing time in mins: ", (time.time() - start_begining) / 60.0)
    print("total processing time in hours: ", (time.time() - start_begining) / 3600.0)

    # Analysis.analysis(model_file="Unet2_model_" + leg + "_min_val_loss", valloader=valloader)

    Analysis_crop.PlotLoss(model_file = model_name, loss_train_path = train_loss_file, loss_val_path = val_loss_file, epoch_No = N_epoch)

    write_2_log(time.strftime("%c"))  # time, date of exp
===============
import numpy as np
import torch.nn as nn
import torch
import cv2
from lcn import LecunLCN

LCN_enable = False

def input_filled_mirroring(x, e = 62):      # fill missing data by mirroring the input image
    '''input size 636 --> output size 512'''
    w, h = x.shape
    #e = 62  # extra width on 1 edge
    y = np.zeros((h + e * 2, w + e * 2))
    y[e:h + e, e:w + e] = x
    y[e:e + h, 0:e] = np.flip(y[e:e + h, e:2 * e], 1)  # flip vertically
    y[e:e + h, e + w:2 * e + w] = np.flip(y[e:e + h, w:e + w], 1)  # flip vertically
    y[0:e, 0:2 * e + w] = np.flip(y[e:2 * e, 0:2 * e + w], 0)  # flip horizontally
    y[e + h:2 * e + h, 0:2 * e + w] = np.flip(y[h:e + h, 0:2 * e + w], 0)  # flip horizontally
    return y

def nearest_cells_distance(pos, img):
    # searching in 8 directions to find 2 nearest distances to neighbor cells
    curr_value = img[pos]
    w = img.shape[0];h = img.shape[1]
    count_detect = 0  # detect 2 nearest neighbors. break the search if count_detect = 2
    x, y = pos

    # print("w,h: ", (w, h))
    d1 = 9999999;d2 = 9999999;d3 = 9999999;d4 = 9999999
    d5 = 9999999;d6 = 9999999;d7 = 9999999;d8 = 9999999
    for i in range(1, max(w, h)):
        # (x+1, y), (x+1, y+1), (x+1, y-1),
        # (x, y+1), (x, y-1)
        # (x-1, y), (x-1,y+1), (x-1,y-1),
        if x + i < w:
            if img[(x + i, y)] != curr_value and d1 == 9999999:
                d1 = i; count_detect += 1
            if y + i < h:
                if img[(x + i, y + i)] != curr_value and d2 == 9999999:
                    d2 = i; count_detect += 1
            elif y - i >= 0:
                if img[(x + i, y - i)] != curr_value and d3 == 9999999:
                    d3 = i; count_detect += 1
        if y + i < h:
            if img[(x, y + i)] != curr_value and d4 == 9999999:
                d4 = i; count_detect += 1
        if y - i >= 0:
            if img[(x, y - i)] != curr_value and d5 == 9999999:
                d5 = i; count_detect += 1
        if x - i >= 0:
            if img[(x - i, y)] != curr_value and d6 == 9999999:
                d6 = i; count_detect += 1
            if y + i < h:
                if img[(x - i, y + i)] != curr_value and d7 == 9999999:
                    d7 = i; count_detect += 1
            elif y - i >= 0:
                if img[(x - i, y - i)] != curr_value and d8 == 9999999:
                    d8 = i; count_detect += 1
        if count_detect >= 2: break

    d = [d1, d2, d3, d4, d5, d6, d7, d8]
    min_index = np.argmin(d)
    dist1 = d[min_index]
    d.remove(dist1)
    min_index = np.argmin(d)
    dist2 = d[min_index]
    return dist1, dist2

def create_weight_map(imgs_mask):
        print('-' * 30)
        print('Creating weights for masks ...')
        print('-' * 30)
        weight_map = np.ndarray(
            (len(imgs_mask), 1, np.shape(imgs_mask)[2], np.shape(imgs_mask)[3]), dtype=np.float32)
        w_0 = 10; sigma = 4
        imgs_w, imgs_h = np.shape(imgs_mask)[2], np.shape(imgs_mask)[3]
        total_pixels = imgs_w*imgs_h
        import time
        start = time.time()
        for i in range(len(imgs_mask)):
            if i%10 == 0: print("Done processing: %d images, time passed: %.2f mins" % (i, (time.time() - start)/60.0))
            temp = imgs_mask[i,0,:,:]
            w_border = 1 - np.sum(temp)/total_pixels        # w_c of pixel on the border (black)
            for m in range(imgs_w):
                for n in range(imgs_h):
                    # loop through all pixel of the mask
                    d1,d2 = nearest_cells_distance((m,n), temp)
                    w_c = w_border
                    if temp[m,n] == 0: w_c = 1 - w_border
                    weight_map[i,0,m,n] = w_c*5 + w_0*np.exp(-(d1 + d2)**2/(2*sigma**2))
                    # print("w_0*np.exp(): ", w_0*np.exp(-(d1 + d2)**2/(2*sigma**2)))
                    # print("w_border: ", w_border)

        np.save('data/dataset/weight_map_train.npy', weight_map)

        return weight_map

def load_train_data(npy_path = "data/dataset", hist_equal = False):

    print('-' * 30)
    print('load train images...')

    imgs_train = np.load(npy_path + "/imgs_train.npy")
    imgs_mask_train = np.load(npy_path + "/imgs_mask_train.npy")

    if hist_equal: imgs_train = hist_equalization(imgs_train)

    # weight_map_train = np.load(npy_path + "/weight_map_train.npy")
    # weight_map_train = weight_map_train.astype('float32')

    imgs_train = imgs_train.astype('float32')
    imgs_mask_train = imgs_mask_train.astype('float32')

    if LCN_enable:
        imgs_train = imgs_train.astype('float64')
        imgs_train = LecunLCN(imgs_train, image_shape=imgs_train.shape).output.eval()
        imgs_train = imgs_train.astype('float32')

    if not LCN_enable: imgs_train /= 255

    imgs_train -= imgs_train.mean(axis=0)
    imgs_mask_train /= 255
    imgs_mask_train[imgs_mask_train > 0.5] = 1
    imgs_mask_train[imgs_mask_train <= 0.5] = 0

    # weight_map_train = create_weight_map(imgs_mask_train)

    print("Done loading traing data")
    print('-' * 30)
    return imgs_train, imgs_mask_train

def load_val_data(npy_path = "data/dataset", hist_equal = True):

    print('-' * 30)
    print('load validation images...')

    imgs_train = np.load(npy_path + "/imgs_val.npy")
    imgs_mask_train = np.load(npy_path + "/imgs_mask_val.npy")

    if hist_equal: imgs_train = hist_equalization(imgs_train)

    imgs_train = imgs_train.astype('float32')
    imgs_mask_train = imgs_mask_train.astype('float32')

    if LCN_enable:
        imgs_train = imgs_train.astype('float64')
        imgs_train = LecunLCN(imgs_train, image_shape=imgs_train.shape).output.eval()
        imgs_train = imgs_train.astype('float32')

    if not LCN_enable: imgs_train /= 255
    imgs_train -= imgs_train.mean(axis=0)
    imgs_mask_train /= 255
    imgs_mask_train[imgs_mask_train > 0.5] = 1
    imgs_mask_train[imgs_mask_train <= 0.5] = 0
    print("Done loading validation data")
    print('-' * 30)
    return imgs_train, imgs_mask_train

def load_test_data(npy_path = "data/dataset", hist_equal = True):

    print('-' * 30)
    print('load test images...')

    imgs_test = np.load(npy_path + "/imgs_test.npy")

    if hist_equal: imgs_test = hist_equalization(imgs_test)

    imgs_test = imgs_test.astype('float32')

    if LCN_enable:
        imgs_test = imgs_test.astype('float64')
        imgs_test = LecunLCN(imgs_test, image_shape=imgs_test.shape).output.eval()
        imgs_test = imgs_test.astype('float32')

    if not LCN_enable: imgs_test /= 255

    imgs_test -= imgs_test.mean(axis=0)

    print("Done loading test data")
    print('-' * 30)
    return imgs_test

def load_val_5imgs(npy_path = "data/dataset"):
    print('-' * 30)
    print('load train images...')

    imgs_train = np.load(npy_path + "/imgs_val_5imgs.npy")
    imgs_mask_train = np.load(npy_path + "/imgs_mask_val_5imgs.npy")

    # imgs_train = hist_equalization(imgs_train)

    imgs_train = imgs_train.astype('float64')
    imgs_mask_train = imgs_mask_train.astype('float64')

    if LCN_enable: imgs_train = LecunLCN(imgs_train, image_shape=imgs_train.shape).output.eval()

    if not LCN_enable: imgs_train /= 255

    mean = imgs_train.mean(axis=0)
    imgs_train -= mean


    imgs_mask_train /= 255
    imgs_mask_train[imgs_mask_train > 0.5] = 1
    imgs_mask_train[imgs_mask_train <= 0.5] = 0

    # weight_map_train = self.create_weight_map(imgs_mask_train)

    print("Done loading traing data")
    print('-' * 30)
    return imgs_train, imgs_mask_train

def hist_equalization(inputs):      # inputs are uint8, 0-255, Nx1x636x636
    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))
    output = inputs.copy()
    for i in range(len(inputs)):
        img = inputs[i, 0, :, :]
        # res = cv2.equalizeHist(img)
        res = clahe.apply(img)
        output[i,0,:,:] = res
    return output

### BinaryCrossEntropyLoss2d().forward(logits, labels)
class BinaryCrossEntropyLoss2d(nn.Module):
    def __init__(self, weight=None, size_average=True):
        """
        Binary cross entropy loss 2D
        Args:
            weight:
            size_average:
        """
        super(BinaryCrossEntropyLoss2d, self).__init__()
        self.bce_loss = nn.BCELoss(weight, size_average)

    def forward(self, logits, targets):
        # probs = F.sigmoid(logits)
        probs = logits
        probs_flat = probs.view(-1)  # Flatten
        targets_flat = targets.view(-1)  # Flatten
        return self.bce_loss(probs_flat, targets_flat)      # (output, labels)

class BCE_with_Weights(nn.Module):
    def __init__(self, weights=None):
        """
        Binary cross entropy loss 2D
        Args:
            weights:
        """
        super(BCE_with_Weights, self).__init__()
        self.weights = weights

    def forward(self, output, target):
        if self.weights is not None:
            loss = self.weights * (target * torch.log(output) + (1 - target) * torch.log(1 - output))
        else:
            loss = target * torch.log(output) + (1 - target) * torch.log(1 - output)

        return torch.neg(torch.mean(loss))

class LRN(nn.Module):       # input x is Torch tensor
    def __init__(self, local_size=1, alpha=1.0, beta=0.75, ACROSS_CHANNELS=False):      #LRN(local_size=5, alpha=0.0001, beta=0.75),
        super(LRN, self).__init__()
        self.ACROSS_CHANNELS = ACROSS_CHANNELS
        if self.ACROSS_CHANNELS:
            self.average = nn.AvgPool3d(kernel_size=(local_size, 1, 1),
                                        stride=1, padding=(int((local_size - 1.0) / 2), 0, 0))
        else:
            self.average = nn.AvgPool2d(kernel_size=local_size,
                                        stride=1, padding=int((local_size - 1.0) / 2))
        self.alpha = alpha
        self.beta = beta

    def forward(self, x):
        if self.ACROSS_CHANNELS:
            div = x.pow(2).unsqueeze(1)
            div = self.average(div).squeeze(1)
            div = div.mul(self.alpha).add(1.0).pow(self.beta)
        else:
            div = x.pow(2)
            div = self.average(div)
            div = div.mul(self.alpha).add(1.0).pow(self.beta)
        x = x.div(div)
        return x
Sat Nov 25 01:21:04 2017
Leg22_CROP_dropout_0_2_rmSigmoid_20aug_10ela_3inten_reflect
optim.SGD(net.parameters(), lr=1e-2, momentum=0.99)
Number of epoch max: 6
==========================================================================================
Sat Nov 25 01:21:59 2017
Leg22_CROP_dropout_0_2_rmSigmoid_20aug_10ela_3inten_reflect
Sat Nov 25 01:21:56 2017
import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.autograd import Variable
import math


class ConvBnRelu(nn.Module):
    def __init__(self, in_channels, out_channels, kernel_size, padding, stride):
        super(ConvBnRelu, self).__init__()
        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=kernel_size, padding=padding, stride=stride)
        self.bn = nn.BatchNorm2d(out_channels)
        self.relu = nn.ReLU()

    def forward(self, x):
        x = self.conv(x)
        # x = self.bn(x)
        x = self.relu(x)
        return x


class StackEncoder(nn.Module):
    def __init__(self, in_channels, out_channels):
        super(StackEncoder, self).__init__()
        self.convr1 = ConvBnRelu(in_channels, out_channels, kernel_size=(3, 3), stride=1, padding=0)
        self.convr2 = ConvBnRelu(out_channels, out_channels, kernel_size=(3, 3), stride=1, padding=0)
        self.maxPool = nn.MaxPool2d(kernel_size=(2, 2), stride=2)

    def forward(self, x):
        x = self.convr1(x)
        x = self.convr2(x)
        x_trace = x             # save x to use in concat in the Decoder path
        out = self.maxPool(x)
        return out, x_trace


class StackDecoder(nn.Module):
    def __init__(self, in_channels, out_channels, padding = 0, drop_out=False):
        super(StackDecoder, self).__init__()

        self.drop_out = drop_out
        self.dropout_layer = nn.Dropout2d(p=0.5)

        ''' this is old version
        self.upSample = nn.Upsample(size=upsample_size, scale_factor=(2, 2), mode="bilinear")
        self.convr1 = ConvBnRelu(in_channels, out_channels, kernel_size=(3, 3), stride=1, padding=padding)
        # Crop + concat step between these 2
        self.convr2 = ConvBnRelu(in_channels, out_channels, kernel_size=(3, 3), stride=1, padding=padding)
        '''
        self.upSample = nn.ConvTranspose2d(in_channels, out_channels, 2, stride=2)
        self.convr1 = ConvBnRelu(in_channels, out_channels, kernel_size=(3, 3), stride=1, padding=padding)
        self.convr2 = ConvBnRelu(out_channels, out_channels, kernel_size=(3, 3), stride=1, padding=padding)

    def _crop_concat(self, upsampled, bypass):
        """
         Crop y to the (h, w) of x and concat them.
         Used for the expansive path.
        Returns:
            The concatenated tensor
        """
        c = (bypass.size()[2] - upsampled.size()[2]) // 2
        bypass = F.pad(bypass, (-c, -c, -c, -c))

        return torch.cat((bypass, upsampled), 1)

    def forward(self, x, down_tensor):
        '''old version
        x = self.upSample(x)
        x = self.convr1(x)
        x = self._crop_concat(x, down_tensor)
        x = self.convr2(x)
        '''

        x = self.upSample(x)
        x = self._crop_concat(x, down_tensor)
        x = self.convr1(x)
        if self.drop_out: x = self.dropout_layer(x)
        x = self.convr2(x)
        if self.drop_out: x = self.dropout_layer(x)
        return x


class UNET_CROP(nn.Module):
    def __init__(self):
        super(UNET_CROP, self).__init__()
        # channels, height, width = in_shape

        # self.dropout = dropout

        self.model_code = ""        # variable to save model and main function when loaded

        self.down1 = StackEncoder(1, 64)
        self.down2 = StackEncoder(64, 128)
        self.down3 = StackEncoder(128, 256)
        self.down4 = StackEncoder(256, 512)

        self.center = nn.Sequential(
            # nn.Dropout2d(p=0.2),
            ConvBnRelu(512, 1024, kernel_size=(3, 3), stride=1, padding=0),
            nn.Dropout2d(p=0.2),
            ConvBnRelu(1024, 1024, kernel_size=(3, 3), stride=1, padding=0),
            nn.Dropout2d(p=0.2)
        )

        self.up1 = StackDecoder(in_channels=1024, out_channels=512)
        self.up2 = StackDecoder(in_channels=512, out_channels=256)
        self.up3 = StackDecoder(in_channels=256, out_channels=128)
        self.up4 = StackDecoder(in_channels=128, out_channels=64)

        # 1x1 convolution at the last layer
        # Different from the paper is the output size here
        self.output_seg_map = nn.Conv2d(64, 1, kernel_size=(1, 1), padding=0, stride=1)

        self._initialize_weights()

    def forward(self, x):
        x, x_trace1 = self.down1(x)
        x, x_trace2 = self.down2(x)
        x, x_trace3 = self.down3(x)
        x, x_trace4 = self.down4(x)
        x = self.center(x)
        x = self.up1(x, x_trace4)
        x = self.up2(x, x_trace3)
        x = self.up3(x, x_trace2)
        x = self.up4(x, x_trace1)

        x = self.output_seg_map(x)
        # x = F.sigmoid(x)
        # out = torch.squeeze(out, dim=1)
        return x


    def _initialize_weights(self):
        for m in self.modules():
            if isinstance(m, nn.Conv2d):
                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels
                m.weight.data.normal_(0, math.sqrt(2. / n))
                if m.bias is not None:
                    m.bias.data.zero_()
            elif isinstance(m, nn.BatchNorm2d):
                m.weight.data.fill_(1)
                m.bias.data.zero_()

# x = Variable(torch.randn(1,1,700, 700))       # simulate input image
# net = UNET_CROP()
# out = net(x)
# print("input: ", x)
# print("output: ", out)
===============from __future__ import print_function, division
import torch
from torch import optim
from torch.autograd import Variable
from torch.utils.data import DataLoader
import numpy as np
import torch.nn as nn
import torch.nn.functional as F
import Unet_crop
import tifffile as tiff
import Utils
import time
from sklearn.metrics import average_precision_score, recall_score, f1_score
import Analysis_crop
import cv2

def to_var(x):
    if torch.cuda.is_available():
        return Variable(x.cuda())
    else:
        return Variable(x)

### BinaryCrossEntropyLoss2d().forward(logits, labels)
class BinaryCrossEntropyLoss2d(nn.Module):
    def __init__(self, weight=None, size_average=True):
        """
        Binary cross entropy loss 2D
        Args:
            weight:
            size_average:
        """
        super(BinaryCrossEntropyLoss2d, self).__init__()
        self.bce_loss = nn.BCELoss(weight, size_average)

    def forward(self, probs, targets):
        probs = F.sigmoid(probs)
        probs_flat = probs.view(-1)  # Flatten
        targets_flat = targets.view(-1)  # Flatten
        return self.bce_loss(probs_flat, targets_flat)      # (output, labels)

def NetEval(net,valdata_loader,crit):
    loss = 0.
    count = 0
    net.eval()
    crop_input, crop_label,_ = crop_info()
    for i,data in enumerate(valdata_loader,0):
        if i > 100: break
        inputs, labels = data
        # inputs = inputs.numpy()
        # labels = labels.numpy()
        for j in range(len(crop_input)):  # training on the crop images and corresponding labels
            ci = crop_input[j]  # crop index for inputs
            cl = crop_label[j]  # crop index for lables
            # temp = labels[0, 0, :, :]  # labels is numpy array 512x512
            # if np.sum(temp) < 0.01 * np.shape(temp)[0] * np.shape(temp)[1]: break
            x = inputs.numpy()[:, :, ci[0]:ci[0] + 572, ci[1]:ci[1] + 572]
            y = labels.numpy()[:, :, cl[0]: cl[0] + 388, cl[1]:cl[1] + 388]
            x = torch.from_numpy(x)
            y = torch.from_numpy(y)
            x, y = to_var(x), to_var(y)
            out = net(x)
            l = crit(out, y)
            loss += l.data[0]
            count += 1
    return loss/count

#process the test data and save to separate .tif image
def NetTest(net,testdata_loader,path = "data/results/"):
    net.eval()
    crop_input, crop_label, average_mask = crop_info()
    for i, data in enumerate(testdata_loader, 0):
        if i >= 30: return 1        # for debug
        # data = to_var(data)
        img_shape = 512
        img = np.zeros((img_shape, img_shape))
        for j in range(len(crop_input)):  # training on the crop images and corresponding labels
            temp = np.zeros((img_shape, img_shape))
            ci = crop_input[j]  # crop index for inputs
            cl = crop_label[j]
            x = data.numpy()[:, :, ci[0]:ci[0] + 572, ci[1]:ci[1] + 572]
            x = torch.from_numpy(x)
            x = to_var(x)
            out = F.sigmoid(net(x))
            out = out.cpu()
            out = out[0,0,:,:]
            temp[cl[0]: cl[0] + 388, cl[1]:cl[1] + 388] = out.data.numpy()
            img += temp

        img = img/average_mask
        img = img.reshape(-1)
        img[img < 0.5] = 0; img[img >= 0.5] = 1
        img = img.reshape(img_shape)
        img = np.uint8(img * 255)
        imgname = path + str(i) + ".tif"
        tiff.imsave(imgname, img)

# return input image size like 512x512, numpy array
def NetPredict(net, input_image):
    net.eval()
    _, crop_label, average_mask = crop_info()

    # input_image is grayscale input image of 512x512
    data = Utils.input_filled_mirroring(input_image, e = 94)
    imgdatas = np.ndarray((1, 1, data.shape[0], data.shape[1]), dtype=np.uint8)
    imgdatas[0] = np.expand_dims(data, 0)
    data = Utils.hist_equalization(imgdatas)
    data = data.astype('float32')
    data /= 255
    data -= data.mean(axis=0)

    img_shape = input_image.shape
    img = np.zeros((img_shape, img_shape))
    for j in range(len(crop_input)):  # training on the crop images and corresponding labels
        temp = np.zeros((img_shape, img_shape))
        ci = crop_input[j]  # crop index for inputs
        cl = crop_label[j]
        x = data.numpy()[:, :, ci[0]:ci[0] + 572, ci[1]:ci[1] + 572]
        x = torch.from_numpy(x)
        x = to_var(x)
        out = F.sigmoid(net(x))
        out = out.cpu()
        out = out[0, 0, :, :]
        temp[cl[0]: cl[0] + 388, cl[1]:cl[1] + 388] = out.data.numpy()
        img += temp

    img = img / average_mask
    img = img.reshape(-1)
    img[img < 0.5] = 0
    img[img >= 0.5] = 1
    img = img.reshape(img_shape)
    img = np.uint8(img * 255)
    return img


def write_2_log(content):
    path = "log_file.txt"
    output = open(path, "a")
    output.write("\n")
    output.write(content)
    output.close()

def crop_info():
    crop_input = [[0, 0], [128, 0], [0, 128], [128, 128]]
    crop_label = [[0, 0], [124, 0], [0, 124], [124, 124]]
    average_mask = np.ones((512, 512))
    average_mask[124:388, 0:124] = 2
    average_mask[0:124, 124:388] = 2
    average_mask[124:388, 388:512] = 2
    average_mask[388:512, 124:388] = 2
    average_mask[124:388, 124:388] = 4
    return crop_input, crop_label, average_mask

if __name__ == '__main__':
    '''subjects to change for each exp:
    + path to the dataset
    + opt function
    + leg description
    + N_epoch
    + saved_model
    '''
    start_begining = time.time()

    # path = "data/dataset"
    path = "/home/anhxtuan/HanLe/dataset/20aug_10ela_3inten_reflect"
    path = "/home/anhxtuan/HanLe/dataset/20aug_10ela_3inten_reflect_700"

    import os
    print("Does the folder exist?: ", os.path.isdir(path))
    print("Does the path exist?: ", os.path.exists(path))

    imgs_train, imgs_mask_train = Utils.load_train_data(npy_path=path)
    imgs_val, imgs_mask_val = Utils.load_val_data(npy_path=path)
    batch_size = 1
    trainset = zip(imgs_train, imgs_mask_train)
    trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,
                                              shuffle=True, num_workers=2)
    valset = zip(imgs_val, imgs_mask_val)
    valloader = torch.utils.data.DataLoader(valset, batch_size=batch_size,
                                              shuffle=False, num_workers=2)
    # net = Unet.UNet()                     # Unet 1
    # net = Unet_BatchNorm.UNet_BN()          # Unet 2 with batchNorm
    net = Unet_crop.UNET_CROP()

    f1 = open("Unet_crop.py", 'r')     # embede code into the model to be saved later
    f2 = open("UnetTrain_crop.py", 'r')
    f3 = open("Utils.py", 'r')
    model_notes = time.strftime("%c") + "\n" + f1.read() + "\n" + "==="*5 + f2.read() + "\n" + "==="*5 + f3.read()
    f1.close()
    f2.close()
    f3.close()

    criterion = BinaryCrossEntropyLoss2d()
    # criterion = SoftDiceLoss()
    # criterion = nn.BCELoss()

    if torch.cuda.is_available():
        # torch.set_default_tensor_type('torch.cuda.FloatTensor')
        # net.load_state_dict(torch.load("Unet2_model_12epoch_Leg12_droput_0_2_rmSigmoid_20aug_10ela_3inten_reflect"))
        net.cuda()
        # criterion.cuda()

    opt = optim.SGD(net.parameters(), lr=1e-2, momentum=0.99)       # subject to change
    # opt = optim.RMSprop(net.parameters(), lr=2e-4)
    # RMSprop[22](learning rate 0.001) with weight decay set to 0.001.
    # opt = optim.Adam(net.parameters(), lr=1e-3, weight_decay=1e-4)

    train_loss = []
    val_loss = []

    print("[epoch, #image] Loss")
    leg = "Leg22_CROP_dropout_0_2_rmSigmoid_20aug_10ela_3inten_reflect"
    print("Processing: ", leg)
    model_name = ""

    N_epoch = 6
    model_saved = np.arange(1,N_epoch+1,2)
    val_loss_min = 100

    write_2_log("==="*30)
    write_2_log(time.strftime("%c"))       # time, date of exp
    write_2_log(leg)
    write_2_log(model_notes)
    write_2_log(time.strftime("%c"))  # time, date of exp
    write_2_log(leg)
    write_2_log("optim.SGD(net.parameters(), lr=1e-2, momentum=0.99)")
    write_2_log("Number of epoch max: " + str(N_epoch))

    crop_input, crop_label,_ = crop_info()
    min_model_epoch = 0
    for epoch in range(N_epoch):
        running_loss = 0.0; count = 0
        net.train()
        for i, data in enumerate(trainloader, 0):
            if i > 100: break

            inputs, labels = data
            temp = labels.numpy()
            for j in range(len(crop_input)):       # training on the crop images and corresponding labels
                ci = crop_input[j]          # crop index for inputs
                cl = crop_label[j]          # crop index for lables
                # temp = temp[0, 0, :, :]  # labels is numpy array 512x512
                # if np.sum(temp) < 0.01 * np.shape(temp)[0] * np.shape(temp)[1]: break
                x = inputs.numpy()[:, :, ci[0]:ci[0] + 572, ci[1]:ci[1] + 572]
                y = labels.numpy()[:, :, cl[0]: cl[0] + 388, cl[1]:cl[1] + 388]
                x = torch.from_numpy(x)
                y = torch.from_numpy(y)
                x, y = to_var(x), to_var(y)
                opt.zero_grad()
                out = net(x)
                loss = criterion(out, y)
                loss.backward()
                opt.step()
                running_loss += loss.data[0]
                count += 1

        net.eval()
        val_loss_temp = NetEval(net, valloader, criterion)
        if epoch > 0 and val_loss_temp < val_loss_min:        # save the model which has the lowest val_loss, ignore first epoch
            val_loss_min = val_loss_temp
            torch.save(net.state_dict(), "Unet2_model_" + leg + "_min_val_loss")  # save model
            min_model_epoch = epoch + 1

        disp = 'Epoch %d: Train loss: %.6f, Val loss: %.6f' % (epoch + 1, running_loss/count, val_loss_temp)
        write_2_log(disp)
        print(disp)
        val_loss.append(val_loss_temp)
        train_loss.append(running_loss/count); running_loss = 0.0

        if (epoch + 1) in model_saved:        # save checkpoint
            model_name = "Unet2_model_" + str(epoch+1) + "epoch_" + leg
            torch.save(net.state_dict(), model_name)  # save model
            Analysis_crop.analysis(model_file = model_name, valloader = valloader)

    write_2_log("Best model at epoch: " + str(min_model_epoch))
    write_2_log("Total training time: " + str((time.time() - start_begining) / 3600.0))

    val_loss_file = "data/results" + "/val_loss_" + str(N_epoch) + "epoch_" + leg + ".npy"
    train_loss_file = "data/results" + "/training_loss_" + str(N_epoch) + "epoch_" + leg + ".npy"

    np.save(val_loss_file, val_loss)
    np.save(train_loss_file, train_loss)
    print("total processing time in seconds: ", time.time() - start_begining)
    print("total processing time in mins: ", (time.time() - start_begining) / 60.0)
    print("total processing time in hours: ", (time.time() - start_begining) / 3600.0)

    # Analysis.analysis(model_file="Unet2_model_" + leg + "_min_val_loss", valloader=valloader)

    Analysis_crop.PlotLoss(model_file = model_name, loss_train_path = train_loss_file, loss_val_path = val_loss_file, epoch_No = N_epoch)

    write_2_log(time.strftime("%c"))  # time, date of exp
===============
import numpy as np
import torch.nn as nn
import torch
import cv2
from lcn import LecunLCN

LCN_enable = False

def input_filled_mirroring(x, e = 62):      # fill missing data by mirroring the input image
    '''input size 636 --> output size 512'''
    w, h = x.shape
    #e = 62  # extra width on 1 edge
    y = np.zeros((h + e * 2, w + e * 2))
    y[e:h + e, e:w + e] = x
    y[e:e + h, 0:e] = np.flip(y[e:e + h, e:2 * e], 1)  # flip vertically
    y[e:e + h, e + w:2 * e + w] = np.flip(y[e:e + h, w:e + w], 1)  # flip vertically
    y[0:e, 0:2 * e + w] = np.flip(y[e:2 * e, 0:2 * e + w], 0)  # flip horizontally
    y[e + h:2 * e + h, 0:2 * e + w] = np.flip(y[h:e + h, 0:2 * e + w], 0)  # flip horizontally
    return y

def nearest_cells_distance(pos, img):
    # searching in 8 directions to find 2 nearest distances to neighbor cells
    curr_value = img[pos]
    w = img.shape[0];h = img.shape[1]
    count_detect = 0  # detect 2 nearest neighbors. break the search if count_detect = 2
    x, y = pos

    # print("w,h: ", (w, h))
    d1 = 9999999;d2 = 9999999;d3 = 9999999;d4 = 9999999
    d5 = 9999999;d6 = 9999999;d7 = 9999999;d8 = 9999999
    for i in range(1, max(w, h)):
        # (x+1, y), (x+1, y+1), (x+1, y-1),
        # (x, y+1), (x, y-1)
        # (x-1, y), (x-1,y+1), (x-1,y-1),
        if x + i < w:
            if img[(x + i, y)] != curr_value and d1 == 9999999:
                d1 = i; count_detect += 1
            if y + i < h:
                if img[(x + i, y + i)] != curr_value and d2 == 9999999:
                    d2 = i; count_detect += 1
            elif y - i >= 0:
                if img[(x + i, y - i)] != curr_value and d3 == 9999999:
                    d3 = i; count_detect += 1
        if y + i < h:
            if img[(x, y + i)] != curr_value and d4 == 9999999:
                d4 = i; count_detect += 1
        if y - i >= 0:
            if img[(x, y - i)] != curr_value and d5 == 9999999:
                d5 = i; count_detect += 1
        if x - i >= 0:
            if img[(x - i, y)] != curr_value and d6 == 9999999:
                d6 = i; count_detect += 1
            if y + i < h:
                if img[(x - i, y + i)] != curr_value and d7 == 9999999:
                    d7 = i; count_detect += 1
            elif y - i >= 0:
                if img[(x - i, y - i)] != curr_value and d8 == 9999999:
                    d8 = i; count_detect += 1
        if count_detect >= 2: break

    d = [d1, d2, d3, d4, d5, d6, d7, d8]
    min_index = np.argmin(d)
    dist1 = d[min_index]
    d.remove(dist1)
    min_index = np.argmin(d)
    dist2 = d[min_index]
    return dist1, dist2

def create_weight_map(imgs_mask):
        print('-' * 30)
        print('Creating weights for masks ...')
        print('-' * 30)
        weight_map = np.ndarray(
            (len(imgs_mask), 1, np.shape(imgs_mask)[2], np.shape(imgs_mask)[3]), dtype=np.float32)
        w_0 = 10; sigma = 4
        imgs_w, imgs_h = np.shape(imgs_mask)[2], np.shape(imgs_mask)[3]
        total_pixels = imgs_w*imgs_h
        import time
        start = time.time()
        for i in range(len(imgs_mask)):
            if i%10 == 0: print("Done processing: %d images, time passed: %.2f mins" % (i, (time.time() - start)/60.0))
            temp = imgs_mask[i,0,:,:]
            w_border = 1 - np.sum(temp)/total_pixels        # w_c of pixel on the border (black)
            for m in range(imgs_w):
                for n in range(imgs_h):
                    # loop through all pixel of the mask
                    d1,d2 = nearest_cells_distance((m,n), temp)
                    w_c = w_border
                    if temp[m,n] == 0: w_c = 1 - w_border
                    weight_map[i,0,m,n] = w_c*5 + w_0*np.exp(-(d1 + d2)**2/(2*sigma**2))
                    # print("w_0*np.exp(): ", w_0*np.exp(-(d1 + d2)**2/(2*sigma**2)))
                    # print("w_border: ", w_border)

        np.save('data/dataset/weight_map_train.npy', weight_map)

        return weight_map

def load_train_data(npy_path = "data/dataset", hist_equal = False):

    print('-' * 30)
    print('load train images...')

    imgs_train = np.load(npy_path + "/imgs_train.npy")
    imgs_mask_train = np.load(npy_path + "/imgs_mask_train.npy")

    if hist_equal: imgs_train = hist_equalization(imgs_train)

    # weight_map_train = np.load(npy_path + "/weight_map_train.npy")
    # weight_map_train = weight_map_train.astype('float32')

    imgs_train = imgs_train.astype('float32')
    imgs_mask_train = imgs_mask_train.astype('float32')

    if LCN_enable:
        imgs_train = imgs_train.astype('float64')
        imgs_train = LecunLCN(imgs_train, image_shape=imgs_train.shape).output.eval()
        imgs_train = imgs_train.astype('float32')

    if not LCN_enable: imgs_train /= 255

    imgs_train -= imgs_train.mean(axis=0)
    imgs_mask_train /= 255
    imgs_mask_train[imgs_mask_train > 0.5] = 1
    imgs_mask_train[imgs_mask_train <= 0.5] = 0

    # weight_map_train = create_weight_map(imgs_mask_train)

    print("Done loading traing data")
    print('-' * 30)
    return imgs_train, imgs_mask_train

def load_val_data(npy_path = "data/dataset", hist_equal = True):

    print('-' * 30)
    print('load validation images...')

    imgs_train = np.load(npy_path + "/imgs_val.npy")
    imgs_mask_train = np.load(npy_path + "/imgs_mask_val.npy")

    if hist_equal: imgs_train = hist_equalization(imgs_train)

    imgs_train = imgs_train.astype('float32')
    imgs_mask_train = imgs_mask_train.astype('float32')

    if LCN_enable:
        imgs_train = imgs_train.astype('float64')
        imgs_train = LecunLCN(imgs_train, image_shape=imgs_train.shape).output.eval()
        imgs_train = imgs_train.astype('float32')

    if not LCN_enable: imgs_train /= 255
    imgs_train -= imgs_train.mean(axis=0)
    imgs_mask_train /= 255
    imgs_mask_train[imgs_mask_train > 0.5] = 1
    imgs_mask_train[imgs_mask_train <= 0.5] = 0
    print("Done loading validation data")
    print('-' * 30)
    return imgs_train, imgs_mask_train

def load_test_data(npy_path = "data/dataset", hist_equal = True):

    print('-' * 30)
    print('load test images...')

    imgs_test = np.load(npy_path + "/imgs_test.npy")

    if hist_equal: imgs_test = hist_equalization(imgs_test)

    imgs_test = imgs_test.astype('float32')

    if LCN_enable:
        imgs_test = imgs_test.astype('float64')
        imgs_test = LecunLCN(imgs_test, image_shape=imgs_test.shape).output.eval()
        imgs_test = imgs_test.astype('float32')

    if not LCN_enable: imgs_test /= 255

    imgs_test -= imgs_test.mean(axis=0)

    print("Done loading test data")
    print('-' * 30)
    return imgs_test

def load_val_5imgs(npy_path = "data/dataset"):
    print('-' * 30)
    print('load train images...')

    imgs_train = np.load(npy_path + "/imgs_val_5imgs.npy")
    imgs_mask_train = np.load(npy_path + "/imgs_mask_val_5imgs.npy")

    # imgs_train = hist_equalization(imgs_train)

    imgs_train = imgs_train.astype('float64')
    imgs_mask_train = imgs_mask_train.astype('float64')

    if LCN_enable: imgs_train = LecunLCN(imgs_train, image_shape=imgs_train.shape).output.eval()

    if not LCN_enable: imgs_train /= 255

    mean = imgs_train.mean(axis=0)
    imgs_train -= mean


    imgs_mask_train /= 255
    imgs_mask_train[imgs_mask_train > 0.5] = 1
    imgs_mask_train[imgs_mask_train <= 0.5] = 0

    # weight_map_train = self.create_weight_map(imgs_mask_train)

    print("Done loading traing data")
    print('-' * 30)
    return imgs_train, imgs_mask_train

def hist_equalization(inputs):      # inputs are uint8, 0-255, Nx1x636x636
    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))
    output = inputs.copy()
    for i in range(len(inputs)):
        img = inputs[i, 0, :, :]
        # res = cv2.equalizeHist(img)
        res = clahe.apply(img)
        output[i,0,:,:] = res
    return output

### BinaryCrossEntropyLoss2d().forward(logits, labels)
class BinaryCrossEntropyLoss2d(nn.Module):
    def __init__(self, weight=None, size_average=True):
        """
        Binary cross entropy loss 2D
        Args:
            weight:
            size_average:
        """
        super(BinaryCrossEntropyLoss2d, self).__init__()
        self.bce_loss = nn.BCELoss(weight, size_average)

    def forward(self, logits, targets):
        # probs = F.sigmoid(logits)
        probs = logits
        probs_flat = probs.view(-1)  # Flatten
        targets_flat = targets.view(-1)  # Flatten
        return self.bce_loss(probs_flat, targets_flat)      # (output, labels)

class BCE_with_Weights(nn.Module):
    def __init__(self, weights=None):
        """
        Binary cross entropy loss 2D
        Args:
            weights:
        """
        super(BCE_with_Weights, self).__init__()
        self.weights = weights

    def forward(self, output, target):
        if self.weights is not None:
            loss = self.weights * (target * torch.log(output) + (1 - target) * torch.log(1 - output))
        else:
            loss = target * torch.log(output) + (1 - target) * torch.log(1 - output)

        return torch.neg(torch.mean(loss))

class LRN(nn.Module):       # input x is Torch tensor
    def __init__(self, local_size=1, alpha=1.0, beta=0.75, ACROSS_CHANNELS=False):      #LRN(local_size=5, alpha=0.0001, beta=0.75),
        super(LRN, self).__init__()
        self.ACROSS_CHANNELS = ACROSS_CHANNELS
        if self.ACROSS_CHANNELS:
            self.average = nn.AvgPool3d(kernel_size=(local_size, 1, 1),
                                        stride=1, padding=(int((local_size - 1.0) / 2), 0, 0))
        else:
            self.average = nn.AvgPool2d(kernel_size=local_size,
                                        stride=1, padding=int((local_size - 1.0) / 2))
        self.alpha = alpha
        self.beta = beta

    def forward(self, x):
        if self.ACROSS_CHANNELS:
            div = x.pow(2).unsqueeze(1)
            div = self.average(div).squeeze(1)
            div = div.mul(self.alpha).add(1.0).pow(self.beta)
        else:
            div = x.pow(2)
            div = self.average(div)
            div = div.mul(self.alpha).add(1.0).pow(self.beta)
        x = x.div(div)
        return x
Sat Nov 25 01:21:59 2017
Leg22_CROP_dropout_0_2_rmSigmoid_20aug_10ela_3inten_reflect
optim.SGD(net.parameters(), lr=1e-2, momentum=0.99)
Number of epoch max: 6
Epoch 1: Train loss: 0.512783, Val loss: 0.502407
==========================================================================================
Sat Nov 25 01:34:27 2017
Leg22_CROP_dropout_0_2_rmSigmoid_20aug_10ela_3inten_reflect
Sat Nov 25 01:34:24 2017
import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.autograd import Variable
import math


class ConvBnRelu(nn.Module):
    def __init__(self, in_channels, out_channels, kernel_size, padding, stride):
        super(ConvBnRelu, self).__init__()
        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=kernel_size, padding=padding, stride=stride)
        self.bn = nn.BatchNorm2d(out_channels)
        self.relu = nn.ReLU()

    def forward(self, x):
        x = self.conv(x)
        # x = self.bn(x)
        x = self.relu(x)
        return x


class StackEncoder(nn.Module):
    def __init__(self, in_channels, out_channels):
        super(StackEncoder, self).__init__()
        self.convr1 = ConvBnRelu(in_channels, out_channels, kernel_size=(3, 3), stride=1, padding=0)
        self.convr2 = ConvBnRelu(out_channels, out_channels, kernel_size=(3, 3), stride=1, padding=0)
        self.maxPool = nn.MaxPool2d(kernel_size=(2, 2), stride=2)

    def forward(self, x):
        x = self.convr1(x)
        x = self.convr2(x)
        x_trace = x             # save x to use in concat in the Decoder path
        out = self.maxPool(x)
        return out, x_trace


class StackDecoder(nn.Module):
    def __init__(self, in_channels, out_channels, padding = 0, drop_out=False):
        super(StackDecoder, self).__init__()

        self.drop_out = drop_out
        self.dropout_layer = nn.Dropout2d(p=0.5)

        ''' this is old version
        self.upSample = nn.Upsample(size=upsample_size, scale_factor=(2, 2), mode="bilinear")
        self.convr1 = ConvBnRelu(in_channels, out_channels, kernel_size=(3, 3), stride=1, padding=padding)
        # Crop + concat step between these 2
        self.convr2 = ConvBnRelu(in_channels, out_channels, kernel_size=(3, 3), stride=1, padding=padding)
        '''
        self.upSample = nn.ConvTranspose2d(in_channels, out_channels, 2, stride=2)
        self.convr1 = ConvBnRelu(in_channels, out_channels, kernel_size=(3, 3), stride=1, padding=padding)
        self.convr2 = ConvBnRelu(out_channels, out_channels, kernel_size=(3, 3), stride=1, padding=padding)

    def _crop_concat(self, upsampled, bypass):
        """
         Crop y to the (h, w) of x and concat them.
         Used for the expansive path.
        Returns:
            The concatenated tensor
        """
        c = (bypass.size()[2] - upsampled.size()[2]) // 2
        bypass = F.pad(bypass, (-c, -c, -c, -c))

        return torch.cat((bypass, upsampled), 1)

    def forward(self, x, down_tensor):
        '''old version
        x = self.upSample(x)
        x = self.convr1(x)
        x = self._crop_concat(x, down_tensor)
        x = self.convr2(x)
        '''

        x = self.upSample(x)
        x = self._crop_concat(x, down_tensor)
        x = self.convr1(x)
        if self.drop_out: x = self.dropout_layer(x)
        x = self.convr2(x)
        if self.drop_out: x = self.dropout_layer(x)
        return x


class UNET_CROP(nn.Module):
    def __init__(self):
        super(UNET_CROP, self).__init__()
        # channels, height, width = in_shape

        # self.dropout = dropout

        self.model_code = ""        # variable to save model and main function when loaded

        self.down1 = StackEncoder(1, 64)
        self.down2 = StackEncoder(64, 128)
        self.down3 = StackEncoder(128, 256)
        self.down4 = StackEncoder(256, 512)

        self.center = nn.Sequential(
            # nn.Dropout2d(p=0.2),
            ConvBnRelu(512, 1024, kernel_size=(3, 3), stride=1, padding=0),
            nn.Dropout2d(p=0.2),
            ConvBnRelu(1024, 1024, kernel_size=(3, 3), stride=1, padding=0),
            nn.Dropout2d(p=0.2)
        )

        self.up1 = StackDecoder(in_channels=1024, out_channels=512)
        self.up2 = StackDecoder(in_channels=512, out_channels=256)
        self.up3 = StackDecoder(in_channels=256, out_channels=128)
        self.up4 = StackDecoder(in_channels=128, out_channels=64)

        # 1x1 convolution at the last layer
        # Different from the paper is the output size here
        self.output_seg_map = nn.Conv2d(64, 1, kernel_size=(1, 1), padding=0, stride=1)

        self._initialize_weights()

    def forward(self, x):
        x, x_trace1 = self.down1(x)
        x, x_trace2 = self.down2(x)
        x, x_trace3 = self.down3(x)
        x, x_trace4 = self.down4(x)
        x = self.center(x)
        x = self.up1(x, x_trace4)
        x = self.up2(x, x_trace3)
        x = self.up3(x, x_trace2)
        x = self.up4(x, x_trace1)

        x = self.output_seg_map(x)
        # x = F.sigmoid(x)
        # out = torch.squeeze(out, dim=1)
        return x


    def _initialize_weights(self):
        for m in self.modules():
            if isinstance(m, nn.Conv2d):
                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels
                m.weight.data.normal_(0, math.sqrt(2. / n))
                if m.bias is not None:
                    m.bias.data.zero_()
            elif isinstance(m, nn.BatchNorm2d):
                m.weight.data.fill_(1)
                m.bias.data.zero_()

# x = Variable(torch.randn(1,1,700, 700))       # simulate input image
# net = UNET_CROP()
# out = net(x)
# print("input: ", x)
# print("output: ", out)
===============from __future__ import print_function, division
import torch
from torch import optim
from torch.autograd import Variable
from torch.utils.data import DataLoader
import numpy as np
import torch.nn as nn
import torch.nn.functional as F
import Unet_crop
import tifffile as tiff
import Utils
import time
from sklearn.metrics import average_precision_score, recall_score, f1_score
import Analysis_crop
import cv2

def to_var(x):
    if torch.cuda.is_available():
        return Variable(x.cuda())
    else:
        return Variable(x)

### BinaryCrossEntropyLoss2d().forward(logits, labels)
class BinaryCrossEntropyLoss2d(nn.Module):
    def __init__(self, weight=None, size_average=True):
        """
        Binary cross entropy loss 2D
        Args:
            weight:
            size_average:
        """
        super(BinaryCrossEntropyLoss2d, self).__init__()
        self.bce_loss = nn.BCELoss(weight, size_average)

    def forward(self, probs, targets):
        probs = F.sigmoid(probs)
        probs_flat = probs.view(-1)  # Flatten
        targets_flat = targets.view(-1)  # Flatten
        return self.bce_loss(probs_flat, targets_flat)      # (output, labels)

def NetEval(net,valdata_loader,crit):
    loss = 0.
    count = 0
    net.eval()
    crop_input, crop_label,_ = crop_info()
    for i,data in enumerate(valdata_loader,0):
        if i > 10: break
        inputs, labels = data
        # inputs = inputs.numpy()
        # labels = labels.numpy()
        for j in range(len(crop_input)):  # training on the crop images and corresponding labels
            ci = crop_input[j]  # crop index for inputs
            cl = crop_label[j]  # crop index for lables
            # temp = labels[0, 0, :, :]  # labels is numpy array 512x512
            # if np.sum(temp) < 0.01 * np.shape(temp)[0] * np.shape(temp)[1]: break
            x = inputs.numpy()[:, :, ci[0]:ci[0] + 572, ci[1]:ci[1] + 572]
            y = labels.numpy()[:, :, cl[0]: cl[0] + 388, cl[1]:cl[1] + 388]
            x = torch.from_numpy(x)
            y = torch.from_numpy(y)
            x, y = to_var(x), to_var(y)
            out = net(x)
            l = crit(out, y)
            loss += l.data[0]
            count += 1
    return loss/count

#process the test data and save to separate .tif image
def NetTest(net,testdata_loader,path = "data/results/"):
    net.eval()
    crop_input, crop_label, average_mask = crop_info()
    for i, data in enumerate(testdata_loader, 0):
        if i >= 30: return 1        # for debug
        # data = to_var(data)
        img_shape = 512
        img = np.zeros((img_shape, img_shape))
        for j in range(len(crop_input)):  # training on the crop images and corresponding labels
            temp = np.zeros((img_shape, img_shape))
            ci = crop_input[j]  # crop index for inputs
            cl = crop_label[j]
            x = data.numpy()[:, :, ci[0]:ci[0] + 572, ci[1]:ci[1] + 572]
            x = torch.from_numpy(x)
            x = to_var(x)
            out = F.sigmoid(net(x))
            out = out.cpu()
            out = out[0,0,:,:]
            print("j: ", j)
            print("size of temp: ", np.shape(temp))
            print("size of output: ", np.shape(out.data.numpy()))
            temp[cl[0]: cl[0] + 388, cl[1]:cl[1] + 388] = out.data.numpy()
            img += temp

        img = img/average_mask
        img = img.reshape(-1)
        img[img < 0.5] = 0; img[img >= 0.5] = 1
        img = img.reshape(img_shape)
        img = np.uint8(img * 255)
        imgname = path + str(i) + ".tif"
        tiff.imsave(imgname, img)

# return input image size like 512x512, numpy array
def NetPredict(net, input_image):
    net.eval()
    _, crop_label, average_mask = crop_info()

    # input_image is grayscale input image of 512x512
    data = Utils.input_filled_mirroring(input_image, e = 94)
    imgdatas = np.ndarray((1, 1, data.shape[0], data.shape[1]), dtype=np.uint8)
    imgdatas[0] = np.expand_dims(data, 0)
    data = Utils.hist_equalization(imgdatas)
    data = data.astype('float32')
    data /= 255
    data -= data.mean(axis=0)

    img_shape = input_image.shape
    img = np.zeros((img_shape, img_shape))
    for j in range(len(crop_input)):  # training on the crop images and corresponding labels
        temp = np.zeros((img_shape, img_shape))
        ci = crop_input[j]  # crop index for inputs
        cl = crop_label[j]
        x = data.numpy()[:, :, ci[0]:ci[0] + 572, ci[1]:ci[1] + 572]
        x = torch.from_numpy(x)
        x = to_var(x)
        out = F.sigmoid(net(x))
        out = out.cpu()
        out = out[0, 0, :, :]
        temp[cl[0]: cl[0] + 388, cl[1]:cl[1] + 388] = out.data.numpy()
        img += temp

    img = img / average_mask
    img = img.reshape(-1)
    img[img < 0.5] = 0
    img[img >= 0.5] = 1
    img = img.reshape(img_shape)
    img = np.uint8(img * 255)
    return img


def write_2_log(content):
    path = "log_file.txt"
    output = open(path, "a")
    output.write("\n")
    output.write(content)
    output.close()

def crop_info():
    crop_input = [[0, 0], [128, 0], [0, 128], [128, 128]]
    crop_label = [[0, 0], [124, 0], [0, 124], [124, 124]]
    average_mask = np.ones((512, 512))
    average_mask[124:388, 0:124] = 2
    average_mask[0:124, 124:388] = 2
    average_mask[124:388, 388:512] = 2
    average_mask[388:512, 124:388] = 2
    average_mask[124:388, 124:388] = 4
    return crop_input, crop_label, average_mask

if __name__ == '__main__':
    '''subjects to change for each exp:
    + path to the dataset
    + opt function
    + leg description
    + N_epoch
    + saved_model
    '''
    start_begining = time.time()

    # path = "data/dataset"
    path = "/home/anhxtuan/HanLe/dataset/20aug_10ela_3inten_reflect"
    path = "/home/anhxtuan/HanLe/dataset/20aug_10ela_3inten_reflect_700"

    import os
    print("Does the folder exist?: ", os.path.isdir(path))
    print("Does the path exist?: ", os.path.exists(path))

    imgs_train, imgs_mask_train = Utils.load_train_data(npy_path=path)
    imgs_val, imgs_mask_val = Utils.load_val_data(npy_path=path)
    batch_size = 1
    trainset = zip(imgs_train, imgs_mask_train)
    trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,
                                              shuffle=True, num_workers=2)
    valset = zip(imgs_val, imgs_mask_val)
    valloader = torch.utils.data.DataLoader(valset, batch_size=batch_size,
                                              shuffle=False, num_workers=2)
    # net = Unet.UNet()                     # Unet 1
    # net = Unet_BatchNorm.UNet_BN()          # Unet 2 with batchNorm
    net = Unet_crop.UNET_CROP()

    f1 = open("Unet_crop.py", 'r')     # embede code into the model to be saved later
    f2 = open("UnetTrain_crop.py", 'r')
    f3 = open("Utils.py", 'r')
    model_notes = time.strftime("%c") + "\n" + f1.read() + "\n" + "==="*5 + f2.read() + "\n" + "==="*5 + f3.read()
    f1.close()
    f2.close()
    f3.close()

    criterion = BinaryCrossEntropyLoss2d()
    # criterion = SoftDiceLoss()
    # criterion = nn.BCELoss()

    if torch.cuda.is_available():
        # torch.set_default_tensor_type('torch.cuda.FloatTensor')
        # net.load_state_dict(torch.load("Unet2_model_12epoch_Leg12_droput_0_2_rmSigmoid_20aug_10ela_3inten_reflect"))
        net.cuda()
        # criterion.cuda()

    opt = optim.SGD(net.parameters(), lr=1e-2, momentum=0.99)       # subject to change
    # opt = optim.RMSprop(net.parameters(), lr=2e-4)
    # RMSprop[22](learning rate 0.001) with weight decay set to 0.001.
    # opt = optim.Adam(net.parameters(), lr=1e-3, weight_decay=1e-4)

    train_loss = []
    val_loss = []

    print("[epoch, #image] Loss")
    leg = "Leg22_CROP_dropout_0_2_rmSigmoid_20aug_10ela_3inten_reflect"
    print("Processing: ", leg)
    model_name = ""

    N_epoch = 6
    model_saved = np.arange(1,N_epoch+1,2)
    val_loss_min = 100

    write_2_log("==="*30)
    write_2_log(time.strftime("%c"))       # time, date of exp
    write_2_log(leg)
    write_2_log(model_notes)
    write_2_log(time.strftime("%c"))  # time, date of exp
    write_2_log(leg)
    write_2_log("optim.SGD(net.parameters(), lr=1e-2, momentum=0.99)")
    write_2_log("Number of epoch max: " + str(N_epoch))

    crop_input, crop_label,_ = crop_info()
    min_model_epoch = 0
    for epoch in range(N_epoch):
        running_loss = 0.0; count = 0
        net.train()
        for i, data in enumerate(trainloader, 0):
            if i > 10: break

            inputs, labels = data
            temp = labels.numpy()
            for j in range(len(crop_input)):       # training on the crop images and corresponding labels
                ci = crop_input[j]          # crop index for inputs
                cl = crop_label[j]          # crop index for lables
                # temp = temp[0, 0, :, :]  # labels is numpy array 512x512
                # if np.sum(temp) < 0.01 * np.shape(temp)[0] * np.shape(temp)[1]: break
                x = inputs.numpy()[:, :, ci[0]:ci[0] + 572, ci[1]:ci[1] + 572]
                y = labels.numpy()[:, :, cl[0]: cl[0] + 388, cl[1]:cl[1] + 388]
                x = torch.from_numpy(x)
                y = torch.from_numpy(y)
                x, y = to_var(x), to_var(y)
                opt.zero_grad()
                out = net(x)
                loss = criterion(out, y)
                loss.backward()
                opt.step()
                running_loss += loss.data[0]
                count += 1

        net.eval()
        val_loss_temp = NetEval(net, valloader, criterion)
        if epoch > 0 and val_loss_temp < val_loss_min:        # save the model which has the lowest val_loss, ignore first epoch
            val_loss_min = val_loss_temp
            torch.save(net.state_dict(), "Unet2_model_" + leg + "_min_val_loss")  # save model
            min_model_epoch = epoch + 1

        disp = 'Epoch %d: Train loss: %.6f, Val loss: %.6f' % (epoch + 1, running_loss/count, val_loss_temp)
        write_2_log(disp)
        print(disp)
        val_loss.append(val_loss_temp)
        train_loss.append(running_loss/count); running_loss = 0.0

        if (epoch + 1) in model_saved:        # save checkpoint
            model_name = "Unet2_model_" + str(epoch+1) + "epoch_" + leg
            torch.save(net.state_dict(), model_name)  # save model
            Analysis_crop.analysis(model_file = model_name, valloader = valloader)

    write_2_log("Best model at epoch: " + str(min_model_epoch))
    write_2_log("Total training time: " + str((time.time() - start_begining) / 3600.0))

    val_loss_file = "data/results" + "/val_loss_" + str(N_epoch) + "epoch_" + leg + ".npy"
    train_loss_file = "data/results" + "/training_loss_" + str(N_epoch) + "epoch_" + leg + ".npy"

    np.save(val_loss_file, val_loss)
    np.save(train_loss_file, train_loss)
    print("total processing time in seconds: ", time.time() - start_begining)
    print("total processing time in mins: ", (time.time() - start_begining) / 60.0)
    print("total processing time in hours: ", (time.time() - start_begining) / 3600.0)

    # Analysis.analysis(model_file="Unet2_model_" + leg + "_min_val_loss", valloader=valloader)

    Analysis_crop.PlotLoss(model_file = model_name, loss_train_path = train_loss_file, loss_val_path = val_loss_file, epoch_No = N_epoch)

    write_2_log(time.strftime("%c"))  # time, date of exp
===============
import numpy as np
import torch.nn as nn
import torch
import cv2
from lcn import LecunLCN

LCN_enable = False

def input_filled_mirroring(x, e = 62):      # fill missing data by mirroring the input image
    '''input size 636 --> output size 512'''
    w, h = x.shape
    #e = 62  # extra width on 1 edge
    y = np.zeros((h + e * 2, w + e * 2))
    y[e:h + e, e:w + e] = x
    y[e:e + h, 0:e] = np.flip(y[e:e + h, e:2 * e], 1)  # flip vertically
    y[e:e + h, e + w:2 * e + w] = np.flip(y[e:e + h, w:e + w], 1)  # flip vertically
    y[0:e, 0:2 * e + w] = np.flip(y[e:2 * e, 0:2 * e + w], 0)  # flip horizontally
    y[e + h:2 * e + h, 0:2 * e + w] = np.flip(y[h:e + h, 0:2 * e + w], 0)  # flip horizontally
    return y

def nearest_cells_distance(pos, img):
    # searching in 8 directions to find 2 nearest distances to neighbor cells
    curr_value = img[pos]
    w = img.shape[0];h = img.shape[1]
    count_detect = 0  # detect 2 nearest neighbors. break the search if count_detect = 2
    x, y = pos

    # print("w,h: ", (w, h))
    d1 = 9999999;d2 = 9999999;d3 = 9999999;d4 = 9999999
    d5 = 9999999;d6 = 9999999;d7 = 9999999;d8 = 9999999
    for i in range(1, max(w, h)):
        # (x+1, y), (x+1, y+1), (x+1, y-1),
        # (x, y+1), (x, y-1)
        # (x-1, y), (x-1,y+1), (x-1,y-1),
        if x + i < w:
            if img[(x + i, y)] != curr_value and d1 == 9999999:
                d1 = i; count_detect += 1
            if y + i < h:
                if img[(x + i, y + i)] != curr_value and d2 == 9999999:
                    d2 = i; count_detect += 1
            elif y - i >= 0:
                if img[(x + i, y - i)] != curr_value and d3 == 9999999:
                    d3 = i; count_detect += 1
        if y + i < h:
            if img[(x, y + i)] != curr_value and d4 == 9999999:
                d4 = i; count_detect += 1
        if y - i >= 0:
            if img[(x, y - i)] != curr_value and d5 == 9999999:
                d5 = i; count_detect += 1
        if x - i >= 0:
            if img[(x - i, y)] != curr_value and d6 == 9999999:
                d6 = i; count_detect += 1
            if y + i < h:
                if img[(x - i, y + i)] != curr_value and d7 == 9999999:
                    d7 = i; count_detect += 1
            elif y - i >= 0:
                if img[(x - i, y - i)] != curr_value and d8 == 9999999:
                    d8 = i; count_detect += 1
        if count_detect >= 2: break

    d = [d1, d2, d3, d4, d5, d6, d7, d8]
    min_index = np.argmin(d)
    dist1 = d[min_index]
    d.remove(dist1)
    min_index = np.argmin(d)
    dist2 = d[min_index]
    return dist1, dist2

def create_weight_map(imgs_mask):
        print('-' * 30)
        print('Creating weights for masks ...')
        print('-' * 30)
        weight_map = np.ndarray(
            (len(imgs_mask), 1, np.shape(imgs_mask)[2], np.shape(imgs_mask)[3]), dtype=np.float32)
        w_0 = 10; sigma = 4
        imgs_w, imgs_h = np.shape(imgs_mask)[2], np.shape(imgs_mask)[3]
        total_pixels = imgs_w*imgs_h
        import time
        start = time.time()
        for i in range(len(imgs_mask)):
            if i%10 == 0: print("Done processing: %d images, time passed: %.2f mins" % (i, (time.time() - start)/60.0))
            temp = imgs_mask[i,0,:,:]
            w_border = 1 - np.sum(temp)/total_pixels        # w_c of pixel on the border (black)
            for m in range(imgs_w):
                for n in range(imgs_h):
                    # loop through all pixel of the mask
                    d1,d2 = nearest_cells_distance((m,n), temp)
                    w_c = w_border
                    if temp[m,n] == 0: w_c = 1 - w_border
                    weight_map[i,0,m,n] = w_c*5 + w_0*np.exp(-(d1 + d2)**2/(2*sigma**2))
                    # print("w_0*np.exp(): ", w_0*np.exp(-(d1 + d2)**2/(2*sigma**2)))
                    # print("w_border: ", w_border)

        np.save('data/dataset/weight_map_train.npy', weight_map)

        return weight_map

def load_train_data(npy_path = "data/dataset", hist_equal = False):

    print('-' * 30)
    print('load train images...')

    imgs_train = np.load(npy_path + "/imgs_train.npy")
    imgs_mask_train = np.load(npy_path + "/imgs_mask_train.npy")

    if hist_equal: imgs_train = hist_equalization(imgs_train)

    # weight_map_train = np.load(npy_path + "/weight_map_train.npy")
    # weight_map_train = weight_map_train.astype('float32')

    imgs_train = imgs_train.astype('float32')
    imgs_mask_train = imgs_mask_train.astype('float32')

    if LCN_enable:
        imgs_train = imgs_train.astype('float64')
        imgs_train = LecunLCN(imgs_train, image_shape=imgs_train.shape).output.eval()
        imgs_train = imgs_train.astype('float32')

    if not LCN_enable: imgs_train /= 255

    imgs_train -= imgs_train.mean(axis=0)
    imgs_mask_train /= 255
    imgs_mask_train[imgs_mask_train > 0.5] = 1
    imgs_mask_train[imgs_mask_train <= 0.5] = 0

    # weight_map_train = create_weight_map(imgs_mask_train)

    print("Done loading traing data")
    print('-' * 30)
    return imgs_train, imgs_mask_train

def load_val_data(npy_path = "data/dataset", hist_equal = True):

    print('-' * 30)
    print('load validation images...')

    imgs_train = np.load(npy_path + "/imgs_val.npy")
    imgs_mask_train = np.load(npy_path + "/imgs_mask_val.npy")

    if hist_equal: imgs_train = hist_equalization(imgs_train)

    imgs_train = imgs_train.astype('float32')
    imgs_mask_train = imgs_mask_train.astype('float32')

    if LCN_enable:
        imgs_train = imgs_train.astype('float64')
        imgs_train = LecunLCN(imgs_train, image_shape=imgs_train.shape).output.eval()
        imgs_train = imgs_train.astype('float32')

    if not LCN_enable: imgs_train /= 255
    imgs_train -= imgs_train.mean(axis=0)
    imgs_mask_train /= 255
    imgs_mask_train[imgs_mask_train > 0.5] = 1
    imgs_mask_train[imgs_mask_train <= 0.5] = 0
    print("Done loading validation data")
    print('-' * 30)
    return imgs_train, imgs_mask_train

def load_test_data(npy_path = "data/dataset", hist_equal = True):

    print('-' * 30)
    print('load test images...')

    imgs_test = np.load(npy_path + "/imgs_test.npy")

    if hist_equal: imgs_test = hist_equalization(imgs_test)

    imgs_test = imgs_test.astype('float32')

    if LCN_enable:
        imgs_test = imgs_test.astype('float64')
        imgs_test = LecunLCN(imgs_test, image_shape=imgs_test.shape).output.eval()
        imgs_test = imgs_test.astype('float32')

    if not LCN_enable: imgs_test /= 255

    imgs_test -= imgs_test.mean(axis=0)

    print("Done loading test data")
    print('-' * 30)
    return imgs_test

def load_val_5imgs(npy_path = "data/dataset"):
    print('-' * 30)
    print('load train images...')

    imgs_train = np.load(npy_path + "/imgs_val_5imgs.npy")
    imgs_mask_train = np.load(npy_path + "/imgs_mask_val_5imgs.npy")

    # imgs_train = hist_equalization(imgs_train)

    imgs_train = imgs_train.astype('float64')
    imgs_mask_train = imgs_mask_train.astype('float64')

    if LCN_enable: imgs_train = LecunLCN(imgs_train, image_shape=imgs_train.shape).output.eval()

    if not LCN_enable: imgs_train /= 255

    mean = imgs_train.mean(axis=0)
    imgs_train -= mean


    imgs_mask_train /= 255
    imgs_mask_train[imgs_mask_train > 0.5] = 1
    imgs_mask_train[imgs_mask_train <= 0.5] = 0

    # weight_map_train = self.create_weight_map(imgs_mask_train)

    print("Done loading traing data")
    print('-' * 30)
    return imgs_train, imgs_mask_train

def hist_equalization(inputs):      # inputs are uint8, 0-255, Nx1x636x636
    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))
    output = inputs.copy()
    for i in range(len(inputs)):
        img = inputs[i, 0, :, :]
        # res = cv2.equalizeHist(img)
        res = clahe.apply(img)
        output[i,0,:,:] = res
    return output

### BinaryCrossEntropyLoss2d().forward(logits, labels)
class BinaryCrossEntropyLoss2d(nn.Module):
    def __init__(self, weight=None, size_average=True):
        """
        Binary cross entropy loss 2D
        Args:
            weight:
            size_average:
        """
        super(BinaryCrossEntropyLoss2d, self).__init__()
        self.bce_loss = nn.BCELoss(weight, size_average)

    def forward(self, logits, targets):
        # probs = F.sigmoid(logits)
        probs = logits
        probs_flat = probs.view(-1)  # Flatten
        targets_flat = targets.view(-1)  # Flatten
        return self.bce_loss(probs_flat, targets_flat)      # (output, labels)

class BCE_with_Weights(nn.Module):
    def __init__(self, weights=None):
        """
        Binary cross entropy loss 2D
        Args:
            weights:
        """
        super(BCE_with_Weights, self).__init__()
        self.weights = weights

    def forward(self, output, target):
        if self.weights is not None:
            loss = self.weights * (target * torch.log(output) + (1 - target) * torch.log(1 - output))
        else:
            loss = target * torch.log(output) + (1 - target) * torch.log(1 - output)

        return torch.neg(torch.mean(loss))

class LRN(nn.Module):       # input x is Torch tensor
    def __init__(self, local_size=1, alpha=1.0, beta=0.75, ACROSS_CHANNELS=False):      #LRN(local_size=5, alpha=0.0001, beta=0.75),
        super(LRN, self).__init__()
        self.ACROSS_CHANNELS = ACROSS_CHANNELS
        if self.ACROSS_CHANNELS:
            self.average = nn.AvgPool3d(kernel_size=(local_size, 1, 1),
                                        stride=1, padding=(int((local_size - 1.0) / 2), 0, 0))
        else:
            self.average = nn.AvgPool2d(kernel_size=local_size,
                                        stride=1, padding=int((local_size - 1.0) / 2))
        self.alpha = alpha
        self.beta = beta

    def forward(self, x):
        if self.ACROSS_CHANNELS:
            div = x.pow(2).unsqueeze(1)
            div = self.average(div).squeeze(1)
            div = div.mul(self.alpha).add(1.0).pow(self.beta)
        else:
            div = x.pow(2)
            div = self.average(div)
            div = div.mul(self.alpha).add(1.0).pow(self.beta)
        x = x.div(div)
        return x
Sat Nov 25 01:34:27 2017
Leg22_CROP_dropout_0_2_rmSigmoid_20aug_10ela_3inten_reflect
optim.SGD(net.parameters(), lr=1e-2, momentum=0.99)
Number of epoch max: 6
Epoch 1: Train loss: 0.491430, Val loss: 0.455494
==========================================================================================
Sat Nov 25 01:45:53 2017
Leg22_CROP_dropout_0_2_rmSigmoid_20aug_10ela_3inten_reflect
Sat Nov 25 01:45:51 2017
import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.autograd import Variable
import math


class ConvBnRelu(nn.Module):
    def __init__(self, in_channels, out_channels, kernel_size, padding, stride):
        super(ConvBnRelu, self).__init__()
        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=kernel_size, padding=padding, stride=stride)
        self.bn = nn.BatchNorm2d(out_channels)
        self.relu = nn.ReLU()

    def forward(self, x):
        x = self.conv(x)
        # x = self.bn(x)
        x = self.relu(x)
        return x


class StackEncoder(nn.Module):
    def __init__(self, in_channels, out_channels):
        super(StackEncoder, self).__init__()
        self.convr1 = ConvBnRelu(in_channels, out_channels, kernel_size=(3, 3), stride=1, padding=0)
        self.convr2 = ConvBnRelu(out_channels, out_channels, kernel_size=(3, 3), stride=1, padding=0)
        self.maxPool = nn.MaxPool2d(kernel_size=(2, 2), stride=2)

    def forward(self, x):
        x = self.convr1(x)
        x = self.convr2(x)
        x_trace = x             # save x to use in concat in the Decoder path
        out = self.maxPool(x)
        return out, x_trace


class StackDecoder(nn.Module):
    def __init__(self, in_channels, out_channels, padding = 0, drop_out=False):
        super(StackDecoder, self).__init__()

        self.drop_out = drop_out
        self.dropout_layer = nn.Dropout2d(p=0.5)

        ''' this is old version
        self.upSample = nn.Upsample(size=upsample_size, scale_factor=(2, 2), mode="bilinear")
        self.convr1 = ConvBnRelu(in_channels, out_channels, kernel_size=(3, 3), stride=1, padding=padding)
        # Crop + concat step between these 2
        self.convr2 = ConvBnRelu(in_channels, out_channels, kernel_size=(3, 3), stride=1, padding=padding)
        '''
        self.upSample = nn.ConvTranspose2d(in_channels, out_channels, 2, stride=2)
        self.convr1 = ConvBnRelu(in_channels, out_channels, kernel_size=(3, 3), stride=1, padding=padding)
        self.convr2 = ConvBnRelu(out_channels, out_channels, kernel_size=(3, 3), stride=1, padding=padding)

    def _crop_concat(self, upsampled, bypass):
        """
         Crop y to the (h, w) of x and concat them.
         Used for the expansive path.
        Returns:
            The concatenated tensor
        """
        c = (bypass.size()[2] - upsampled.size()[2]) // 2
        bypass = F.pad(bypass, (-c, -c, -c, -c))

        return torch.cat((bypass, upsampled), 1)

    def forward(self, x, down_tensor):
        '''old version
        x = self.upSample(x)
        x = self.convr1(x)
        x = self._crop_concat(x, down_tensor)
        x = self.convr2(x)
        '''

        x = self.upSample(x)
        x = self._crop_concat(x, down_tensor)
        x = self.convr1(x)
        if self.drop_out: x = self.dropout_layer(x)
        x = self.convr2(x)
        if self.drop_out: x = self.dropout_layer(x)
        return x


class UNET_CROP(nn.Module):
    def __init__(self):
        super(UNET_CROP, self).__init__()
        # channels, height, width = in_shape

        # self.dropout = dropout

        self.model_code = ""        # variable to save model and main function when loaded

        self.down1 = StackEncoder(1, 64)
        self.down2 = StackEncoder(64, 128)
        self.down3 = StackEncoder(128, 256)
        self.down4 = StackEncoder(256, 512)

        self.center = nn.Sequential(
            # nn.Dropout2d(p=0.2),
            ConvBnRelu(512, 1024, kernel_size=(3, 3), stride=1, padding=0),
            nn.Dropout2d(p=0.2),
            ConvBnRelu(1024, 1024, kernel_size=(3, 3), stride=1, padding=0),
            nn.Dropout2d(p=0.2)
        )

        self.up1 = StackDecoder(in_channels=1024, out_channels=512)
        self.up2 = StackDecoder(in_channels=512, out_channels=256)
        self.up3 = StackDecoder(in_channels=256, out_channels=128)
        self.up4 = StackDecoder(in_channels=128, out_channels=64)

        # 1x1 convolution at the last layer
        # Different from the paper is the output size here
        self.output_seg_map = nn.Conv2d(64, 1, kernel_size=(1, 1), padding=0, stride=1)

        self._initialize_weights()

    def forward(self, x):
        x, x_trace1 = self.down1(x)
        x, x_trace2 = self.down2(x)
        x, x_trace3 = self.down3(x)
        x, x_trace4 = self.down4(x)
        x = self.center(x)
        x = self.up1(x, x_trace4)
        x = self.up2(x, x_trace3)
        x = self.up3(x, x_trace2)
        x = self.up4(x, x_trace1)

        x = self.output_seg_map(x)
        # x = F.sigmoid(x)
        # out = torch.squeeze(out, dim=1)
        return x


    def _initialize_weights(self):
        for m in self.modules():
            if isinstance(m, nn.Conv2d):
                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels
                m.weight.data.normal_(0, math.sqrt(2. / n))
                if m.bias is not None:
                    m.bias.data.zero_()
            elif isinstance(m, nn.BatchNorm2d):
                m.weight.data.fill_(1)
                m.bias.data.zero_()

# x = Variable(torch.randn(1,1,700, 700))       # simulate input image
# net = UNET_CROP()
# out = net(x)
# print("input: ", x)
# print("output: ", out)
===============from __future__ import print_function, division
import torch
from torch import optim
from torch.autograd import Variable
from torch.utils.data import DataLoader
import numpy as np
import torch.nn as nn
import torch.nn.functional as F
import Unet_crop
import tifffile as tiff
import Utils
import time
from sklearn.metrics import average_precision_score, recall_score, f1_score
import Analysis_crop
import cv2

def to_var(x):
    if torch.cuda.is_available():
        return Variable(x.cuda())
    else:
        return Variable(x)

### BinaryCrossEntropyLoss2d().forward(logits, labels)
class BinaryCrossEntropyLoss2d(nn.Module):
    def __init__(self, weight=None, size_average=True):
        """
        Binary cross entropy loss 2D
        Args:
            weight:
            size_average:
        """
        super(BinaryCrossEntropyLoss2d, self).__init__()
        self.bce_loss = nn.BCELoss(weight, size_average)

    def forward(self, probs, targets):
        probs = F.sigmoid(probs)
        probs_flat = probs.view(-1)  # Flatten
        targets_flat = targets.view(-1)  # Flatten
        return self.bce_loss(probs_flat, targets_flat)      # (output, labels)

def NetEval(net,valdata_loader,crit):
    loss = 0.
    count = 0
    net.eval()
    crop_input, crop_label,_ = crop_info()
    for i,data in enumerate(valdata_loader,0):
        if i > 10: break
        inputs, labels = data
        # inputs = inputs.numpy()
        # labels = labels.numpy()
        for j in range(len(crop_input)):  # training on the crop images and corresponding labels
            ci = crop_input[j]  # crop index for inputs
            cl = crop_label[j]  # crop index for lables
            # temp = labels[0, 0, :, :]  # labels is numpy array 512x512
            # if np.sum(temp) < 0.01 * np.shape(temp)[0] * np.shape(temp)[1]: break
            x = inputs.numpy()[:, :, ci[0]:ci[0] + 572, ci[1]:ci[1] + 572]
            y = labels.numpy()[:, :, cl[0]: cl[0] + 388, cl[1]:cl[1] + 388]
            x = torch.from_numpy(x)
            y = torch.from_numpy(y)
            x, y = to_var(x), to_var(y)
            out = net(x)
            l = crit(out, y)
            loss += l.data[0]
            count += 1
    return loss/count

#process the test data and save to separate .tif image
def NetTest(net,testdata_loader,path = "data/results/"):
    net.eval()
    crop_input, crop_label, average_mask = crop_info()
    for i, data in enumerate(testdata_loader, 0):
        if i >= 30: return 1        # for debug
        # data = to_var(data)
        img_shape = 512
        img = np.zeros((img_shape, img_shape))
        for j in range(len(crop_input)):  # training on the crop images and corresponding labels
            temp = np.zeros((img_shape, img_shape))
            ci = crop_input[j]  # crop index for inputs
            cl = crop_label[j]
            x = data.numpy()[:, :, ci[0]:ci[0] + 572, ci[1]:ci[1] + 572]
            x = torch.from_numpy(x)
            x = to_var(x)
            out = F.sigmoid(net(x))
            out = out.cpu()
            out = out[0,0,:,:]
            print("j: ", j)
            print("size of temp: ", np.shape(temp))
            print("size of output: ", np.shape(out.data.numpy()))
            temp[cl[0]: cl[0] + 388, cl[1]:cl[1] + 388] = out.data.numpy()
            img += temp

        img = img/average_mask
        img = img.reshape(-1)
        img[img < 0.5] = 0; img[img >= 0.5] = 1
        img = img.reshape(img_shape)
        img = np.uint8(img * 255)
        imgname = path + str(i) + ".tif"
        tiff.imsave(imgname, img)

# return input image size like 512x512, numpy array
def NetPredict(net, input_image):
    net.eval()
    _, crop_label, average_mask = crop_info()

    # input_image is grayscale input image of 512x512
    data = Utils.input_filled_mirroring(input_image, e = 94)
    imgdatas = np.ndarray((1, 1, data.shape[0], data.shape[1]), dtype=np.uint8)
    imgdatas[0] = np.expand_dims(data, 0)
    data = Utils.hist_equalization(imgdatas)
    data = data.astype('float32')
    data /= 255
    data -= data.mean(axis=0)

    img_shape = input_image.shape
    img = np.zeros((img_shape, img_shape))
    for j in range(len(crop_input)):  # training on the crop images and corresponding labels
        temp = np.zeros((img_shape, img_shape))
        ci = crop_input[j]  # crop index for inputs
        cl = crop_label[j]
        x = data.numpy()[:, :, ci[0]:ci[0] + 572, ci[1]:ci[1] + 572]
        x = torch.from_numpy(x)
        x = to_var(x)
        out = F.sigmoid(net(x))
        out = out.cpu()
        out = out[0, 0, :, :]
        temp[cl[0]: cl[0] + 388, cl[1]:cl[1] + 388] = out.data.numpy()
        img += temp

    img = img / average_mask
    img = img.reshape(-1)
    img[img < 0.5] = 0
    img[img >= 0.5] = 1
    img = img.reshape(img_shape)
    img = np.uint8(img * 255)
    return img


def write_2_log(content):
    path = "log_file.txt"
    output = open(path, "a")
    output.write("\n")
    output.write(content)
    output.close()

def crop_info():
    crop_input = [[0, 0], [128, 0], [0, 128], [128, 128]]
    crop_label = [[0, 0], [124, 0], [0, 124], [124, 124]]
    average_mask = np.ones((512, 512))
    average_mask[124:388, 0:124] = 2
    average_mask[0:124, 124:388] = 2
    average_mask[124:388, 388:512] = 2
    average_mask[388:512, 124:388] = 2
    average_mask[124:388, 124:388] = 4
    return crop_input, crop_label, average_mask

if __name__ == '__main__':
    '''subjects to change for each exp:
    + path to the dataset
    + opt function
    + leg description
    + N_epoch
    + saved_model
    '''
    start_begining = time.time()

    # path = "data/dataset"
    path = "/home/anhxtuan/HanLe/dataset/20aug_10ela_3inten_reflect"
    path = "/home/anhxtuan/HanLe/dataset/20aug_10ela_3inten_reflect_700"

    import os
    print("Does the folder exist?: ", os.path.isdir(path))
    print("Does the path exist?: ", os.path.exists(path))

    imgs_train, imgs_mask_train = Utils.load_train_data(npy_path=path)
    imgs_val, imgs_mask_val = Utils.load_val_data(npy_path=path)
    batch_size = 1
    trainset = zip(imgs_train, imgs_mask_train)
    trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,
                                              shuffle=True, num_workers=2)
    valset = zip(imgs_val, imgs_mask_val)
    valloader = torch.utils.data.DataLoader(valset, batch_size=batch_size,
                                              shuffle=False, num_workers=2)
    # net = Unet.UNet()                     # Unet 1
    # net = Unet_BatchNorm.UNet_BN()          # Unet 2 with batchNorm
    net = Unet_crop.UNET_CROP()

    f1 = open("Unet_crop.py", 'r')     # embede code into the model to be saved later
    f2 = open("UnetTrain_crop.py", 'r')
    f3 = open("Utils.py", 'r')
    model_notes = time.strftime("%c") + "\n" + f1.read() + "\n" + "==="*5 + f2.read() + "\n" + "==="*5 + f3.read()
    f1.close()
    f2.close()
    f3.close()

    criterion = BinaryCrossEntropyLoss2d()
    # criterion = SoftDiceLoss()
    # criterion = nn.BCELoss()

    if torch.cuda.is_available():
        # torch.set_default_tensor_type('torch.cuda.FloatTensor')
        # net.load_state_dict(torch.load("Unet2_model_12epoch_Leg12_droput_0_2_rmSigmoid_20aug_10ela_3inten_reflect"))
        net.cuda()
        # criterion.cuda()

    opt = optim.SGD(net.parameters(), lr=1e-2, momentum=0.99)       # subject to change
    # opt = optim.RMSprop(net.parameters(), lr=2e-4)
    # RMSprop[22](learning rate 0.001) with weight decay set to 0.001.
    # opt = optim.Adam(net.parameters(), lr=1e-3, weight_decay=1e-4)

    train_loss = []
    val_loss = []

    print("[epoch, #image] Loss")
    leg = "Leg22_CROP_dropout_0_2_rmSigmoid_20aug_10ela_3inten_reflect"
    print("Processing: ", leg)
    model_name = ""

    N_epoch = 6
    model_saved = np.arange(1,N_epoch+1,2)
    val_loss_min = 100

    write_2_log("==="*30)
    write_2_log(time.strftime("%c"))       # time, date of exp
    write_2_log(leg)
    write_2_log(model_notes)
    write_2_log(time.strftime("%c"))  # time, date of exp
    write_2_log(leg)
    write_2_log("optim.SGD(net.parameters(), lr=1e-2, momentum=0.99)")
    write_2_log("Number of epoch max: " + str(N_epoch))

    crop_input, crop_label,_ = crop_info()
    min_model_epoch = 0
    for epoch in range(N_epoch):
        running_loss = 0.0; count = 0
        net.train()
        for i, data in enumerate(trainloader, 0):
            if i > 10: break

            inputs, labels = data
            temp = labels.numpy()
            for j in range(len(crop_input)):       # training on the crop images and corresponding labels
                ci = crop_input[j]          # crop index for inputs
                cl = crop_label[j]          # crop index for lables
                # temp = temp[0, 0, :, :]  # labels is numpy array 512x512
                # if np.sum(temp) < 0.01 * np.shape(temp)[0] * np.shape(temp)[1]: break
                x = inputs.numpy()[:, :, ci[0]:ci[0] + 572, ci[1]:ci[1] + 572]
                y = labels.numpy()[:, :, cl[0]: cl[0] + 388, cl[1]:cl[1] + 388]
                x = torch.from_numpy(x)
                y = torch.from_numpy(y)
                x, y = to_var(x), to_var(y)
                opt.zero_grad()
                out = net(x)
                loss = criterion(out, y)
                loss.backward()
                opt.step()
                running_loss += loss.data[0]
                count += 1

        net.eval()
        val_loss_temp = NetEval(net, valloader, criterion)
        if epoch > 0 and val_loss_temp < val_loss_min:        # save the model which has the lowest val_loss, ignore first epoch
            val_loss_min = val_loss_temp
            torch.save(net.state_dict(), "Unet2_model_" + leg + "_min_val_loss")  # save model
            min_model_epoch = epoch + 1

        disp = 'Epoch %d: Train loss: %.6f, Val loss: %.6f' % (epoch + 1, running_loss/count, val_loss_temp)
        write_2_log(disp)
        print(disp)
        val_loss.append(val_loss_temp)
        train_loss.append(running_loss/count); running_loss = 0.0

        if (epoch + 1) in model_saved:        # save checkpoint
            model_name = "Unet2_model_" + str(epoch+1) + "epoch_" + leg
            torch.save(net.state_dict(), model_name)  # save model
            Analysis_crop.analysis(model_file = model_name, valloader = valloader)

    write_2_log("Best model at epoch: " + str(min_model_epoch))
    write_2_log("Total training time: " + str((time.time() - start_begining) / 3600.0))

    val_loss_file = "data/results" + "/val_loss_" + str(N_epoch) + "epoch_" + leg + ".npy"
    train_loss_file = "data/results" + "/training_loss_" + str(N_epoch) + "epoch_" + leg + ".npy"

    np.save(val_loss_file, val_loss)
    np.save(train_loss_file, train_loss)
    print("total processing time in seconds: ", time.time() - start_begining)
    print("total processing time in mins: ", (time.time() - start_begining) / 60.0)
    print("total processing time in hours: ", (time.time() - start_begining) / 3600.0)

    # Analysis.analysis(model_file="Unet2_model_" + leg + "_min_val_loss", valloader=valloader)

    Analysis_crop.PlotLoss(model_file = model_name, loss_train_path = train_loss_file, loss_val_path = val_loss_file, epoch_No = N_epoch)

    write_2_log(time.strftime("%c"))  # time, date of exp
===============
import numpy as np
import torch.nn as nn
import torch
import cv2
from lcn import LecunLCN

LCN_enable = False

def input_filled_mirroring(x, e = 62):      # fill missing data by mirroring the input image
    '''input size 636 --> output size 512'''
    w, h = x.shape
    #e = 62  # extra width on 1 edge
    y = np.zeros((h + e * 2, w + e * 2))
    y[e:h + e, e:w + e] = x
    y[e:e + h, 0:e] = np.flip(y[e:e + h, e:2 * e], 1)  # flip vertically
    y[e:e + h, e + w:2 * e + w] = np.flip(y[e:e + h, w:e + w], 1)  # flip vertically
    y[0:e, 0:2 * e + w] = np.flip(y[e:2 * e, 0:2 * e + w], 0)  # flip horizontally
    y[e + h:2 * e + h, 0:2 * e + w] = np.flip(y[h:e + h, 0:2 * e + w], 0)  # flip horizontally
    return y

def nearest_cells_distance(pos, img):
    # searching in 8 directions to find 2 nearest distances to neighbor cells
    curr_value = img[pos]
    w = img.shape[0];h = img.shape[1]
    count_detect = 0  # detect 2 nearest neighbors. break the search if count_detect = 2
    x, y = pos

    # print("w,h: ", (w, h))
    d1 = 9999999;d2 = 9999999;d3 = 9999999;d4 = 9999999
    d5 = 9999999;d6 = 9999999;d7 = 9999999;d8 = 9999999
    for i in range(1, max(w, h)):
        # (x+1, y), (x+1, y+1), (x+1, y-1),
        # (x, y+1), (x, y-1)
        # (x-1, y), (x-1,y+1), (x-1,y-1),
        if x + i < w:
            if img[(x + i, y)] != curr_value and d1 == 9999999:
                d1 = i; count_detect += 1
            if y + i < h:
                if img[(x + i, y + i)] != curr_value and d2 == 9999999:
                    d2 = i; count_detect += 1
            elif y - i >= 0:
                if img[(x + i, y - i)] != curr_value and d3 == 9999999:
                    d3 = i; count_detect += 1
        if y + i < h:
            if img[(x, y + i)] != curr_value and d4 == 9999999:
                d4 = i; count_detect += 1
        if y - i >= 0:
            if img[(x, y - i)] != curr_value and d5 == 9999999:
                d5 = i; count_detect += 1
        if x - i >= 0:
            if img[(x - i, y)] != curr_value and d6 == 9999999:
                d6 = i; count_detect += 1
            if y + i < h:
                if img[(x - i, y + i)] != curr_value and d7 == 9999999:
                    d7 = i; count_detect += 1
            elif y - i >= 0:
                if img[(x - i, y - i)] != curr_value and d8 == 9999999:
                    d8 = i; count_detect += 1
        if count_detect >= 2: break

    d = [d1, d2, d3, d4, d5, d6, d7, d8]
    min_index = np.argmin(d)
    dist1 = d[min_index]
    d.remove(dist1)
    min_index = np.argmin(d)
    dist2 = d[min_index]
    return dist1, dist2

def create_weight_map(imgs_mask):
        print('-' * 30)
        print('Creating weights for masks ...')
        print('-' * 30)
        weight_map = np.ndarray(
            (len(imgs_mask), 1, np.shape(imgs_mask)[2], np.shape(imgs_mask)[3]), dtype=np.float32)
        w_0 = 10; sigma = 4
        imgs_w, imgs_h = np.shape(imgs_mask)[2], np.shape(imgs_mask)[3]
        total_pixels = imgs_w*imgs_h
        import time
        start = time.time()
        for i in range(len(imgs_mask)):
            if i%10 == 0: print("Done processing: %d images, time passed: %.2f mins" % (i, (time.time() - start)/60.0))
            temp = imgs_mask[i,0,:,:]
            w_border = 1 - np.sum(temp)/total_pixels        # w_c of pixel on the border (black)
            for m in range(imgs_w):
                for n in range(imgs_h):
                    # loop through all pixel of the mask
                    d1,d2 = nearest_cells_distance((m,n), temp)
                    w_c = w_border
                    if temp[m,n] == 0: w_c = 1 - w_border
                    weight_map[i,0,m,n] = w_c*5 + w_0*np.exp(-(d1 + d2)**2/(2*sigma**2))
                    # print("w_0*np.exp(): ", w_0*np.exp(-(d1 + d2)**2/(2*sigma**2)))
                    # print("w_border: ", w_border)

        np.save('data/dataset/weight_map_train.npy', weight_map)

        return weight_map

def load_train_data(npy_path = "data/dataset", hist_equal = False):

    print('-' * 30)
    print('load train images...')

    imgs_train = np.load(npy_path + "/imgs_train.npy")
    imgs_mask_train = np.load(npy_path + "/imgs_mask_train.npy")

    if hist_equal: imgs_train = hist_equalization(imgs_train)

    # weight_map_train = np.load(npy_path + "/weight_map_train.npy")
    # weight_map_train = weight_map_train.astype('float32')

    imgs_train = imgs_train.astype('float32')
    imgs_mask_train = imgs_mask_train.astype('float32')

    if LCN_enable:
        imgs_train = imgs_train.astype('float64')
        imgs_train = LecunLCN(imgs_train, image_shape=imgs_train.shape).output.eval()
        imgs_train = imgs_train.astype('float32')

    if not LCN_enable: imgs_train /= 255

    imgs_train -= imgs_train.mean(axis=0)
    imgs_mask_train /= 255
    imgs_mask_train[imgs_mask_train > 0.5] = 1
    imgs_mask_train[imgs_mask_train <= 0.5] = 0

    # weight_map_train = create_weight_map(imgs_mask_train)

    print("Done loading traing data")
    print('-' * 30)
    return imgs_train, imgs_mask_train

def load_val_data(npy_path = "data/dataset", hist_equal = True):

    print('-' * 30)
    print('load validation images...')

    imgs_train = np.load(npy_path + "/imgs_val.npy")
    imgs_mask_train = np.load(npy_path + "/imgs_mask_val.npy")

    if hist_equal: imgs_train = hist_equalization(imgs_train)

    imgs_train = imgs_train.astype('float32')
    imgs_mask_train = imgs_mask_train.astype('float32')

    if LCN_enable:
        imgs_train = imgs_train.astype('float64')
        imgs_train = LecunLCN(imgs_train, image_shape=imgs_train.shape).output.eval()
        imgs_train = imgs_train.astype('float32')

    if not LCN_enable: imgs_train /= 255
    imgs_train -= imgs_train.mean(axis=0)
    imgs_mask_train /= 255
    imgs_mask_train[imgs_mask_train > 0.5] = 1
    imgs_mask_train[imgs_mask_train <= 0.5] = 0
    print("Done loading validation data")
    print('-' * 30)
    return imgs_train, imgs_mask_train

def load_test_data(npy_path = "data/dataset", hist_equal = True):

    print('-' * 30)
    print('load test images...')

    imgs_test = np.load(npy_path + "/imgs_test.npy")

    if hist_equal: imgs_test = hist_equalization(imgs_test)

    imgs_test = imgs_test.astype('float32')

    if LCN_enable:
        imgs_test = imgs_test.astype('float64')
        imgs_test = LecunLCN(imgs_test, image_shape=imgs_test.shape).output.eval()
        imgs_test = imgs_test.astype('float32')

    if not LCN_enable: imgs_test /= 255

    imgs_test -= imgs_test.mean(axis=0)

    print("Done loading test data")
    print('-' * 30)
    return imgs_test

def load_val_5imgs(npy_path = "data/dataset"):
    print('-' * 30)
    print('load train images...')

    imgs_train = np.load(npy_path + "/imgs_val_5imgs.npy")
    imgs_mask_train = np.load(npy_path + "/imgs_mask_val_5imgs.npy")

    # imgs_train = hist_equalization(imgs_train)

    imgs_train = imgs_train.astype('float64')
    imgs_mask_train = imgs_mask_train.astype('float64')

    if LCN_enable: imgs_train = LecunLCN(imgs_train, image_shape=imgs_train.shape).output.eval()

    if not LCN_enable: imgs_train /= 255

    mean = imgs_train.mean(axis=0)
    imgs_train -= mean


    imgs_mask_train /= 255
    imgs_mask_train[imgs_mask_train > 0.5] = 1
    imgs_mask_train[imgs_mask_train <= 0.5] = 0

    # weight_map_train = self.create_weight_map(imgs_mask_train)

    print("Done loading traing data")
    print('-' * 30)
    return imgs_train, imgs_mask_train

def hist_equalization(inputs):      # inputs are uint8, 0-255, Nx1x636x636
    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))
    output = inputs.copy()
    for i in range(len(inputs)):
        img = inputs[i, 0, :, :]
        # res = cv2.equalizeHist(img)
        res = clahe.apply(img)
        output[i,0,:,:] = res
    return output

### BinaryCrossEntropyLoss2d().forward(logits, labels)
class BinaryCrossEntropyLoss2d(nn.Module):
    def __init__(self, weight=None, size_average=True):
        """
        Binary cross entropy loss 2D
        Args:
            weight:
            size_average:
        """
        super(BinaryCrossEntropyLoss2d, self).__init__()
        self.bce_loss = nn.BCELoss(weight, size_average)

    def forward(self, logits, targets):
        # probs = F.sigmoid(logits)
        probs = logits
        probs_flat = probs.view(-1)  # Flatten
        targets_flat = targets.view(-1)  # Flatten
        return self.bce_loss(probs_flat, targets_flat)      # (output, labels)

class BCE_with_Weights(nn.Module):
    def __init__(self, weights=None):
        """
        Binary cross entropy loss 2D
        Args:
            weights:
        """
        super(BCE_with_Weights, self).__init__()
        self.weights = weights

    def forward(self, output, target):
        if self.weights is not None:
            loss = self.weights * (target * torch.log(output) + (1 - target) * torch.log(1 - output))
        else:
            loss = target * torch.log(output) + (1 - target) * torch.log(1 - output)

        return torch.neg(torch.mean(loss))

class LRN(nn.Module):       # input x is Torch tensor
    def __init__(self, local_size=1, alpha=1.0, beta=0.75, ACROSS_CHANNELS=False):      #LRN(local_size=5, alpha=0.0001, beta=0.75),
        super(LRN, self).__init__()
        self.ACROSS_CHANNELS = ACROSS_CHANNELS
        if self.ACROSS_CHANNELS:
            self.average = nn.AvgPool3d(kernel_size=(local_size, 1, 1),
                                        stride=1, padding=(int((local_size - 1.0) / 2), 0, 0))
        else:
            self.average = nn.AvgPool2d(kernel_size=local_size,
                                        stride=1, padding=int((local_size - 1.0) / 2))
        self.alpha = alpha
        self.beta = beta

    def forward(self, x):
        if self.ACROSS_CHANNELS:
            div = x.pow(2).unsqueeze(1)
            div = self.average(div).squeeze(1)
            div = div.mul(self.alpha).add(1.0).pow(self.beta)
        else:
            div = x.pow(2)
            div = self.average(div)
            div = div.mul(self.alpha).add(1.0).pow(self.beta)
        x = x.div(div)
        return x
Sat Nov 25 01:45:53 2017
Leg22_CROP_dropout_0_2_rmSigmoid_20aug_10ela_3inten_reflect
optim.SGD(net.parameters(), lr=1e-2, momentum=0.99)
Number of epoch max: 6
Epoch 1: Train loss: 0.491725, Val loss: 0.419198
==========================================================================================
Sat Nov 25 01:49:05 2017
Leg22_CROP_dropout_0_2_rmSigmoid_20aug_10ela_3inten_reflect
Sat Nov 25 01:49:03 2017
import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.autograd import Variable
import math


class ConvBnRelu(nn.Module):
    def __init__(self, in_channels, out_channels, kernel_size, padding, stride):
        super(ConvBnRelu, self).__init__()
        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=kernel_size, padding=padding, stride=stride)
        self.bn = nn.BatchNorm2d(out_channels)
        self.relu = nn.ReLU()

    def forward(self, x):
        x = self.conv(x)
        # x = self.bn(x)
        x = self.relu(x)
        return x


class StackEncoder(nn.Module):
    def __init__(self, in_channels, out_channels):
        super(StackEncoder, self).__init__()
        self.convr1 = ConvBnRelu(in_channels, out_channels, kernel_size=(3, 3), stride=1, padding=0)
        self.convr2 = ConvBnRelu(out_channels, out_channels, kernel_size=(3, 3), stride=1, padding=0)
        self.maxPool = nn.MaxPool2d(kernel_size=(2, 2), stride=2)

    def forward(self, x):
        x = self.convr1(x)
        x = self.convr2(x)
        x_trace = x             # save x to use in concat in the Decoder path
        out = self.maxPool(x)
        return out, x_trace


class StackDecoder(nn.Module):
    def __init__(self, in_channels, out_channels, padding = 0, drop_out=False):
        super(StackDecoder, self).__init__()

        self.drop_out = drop_out
        self.dropout_layer = nn.Dropout2d(p=0.5)

        ''' this is old version
        self.upSample = nn.Upsample(size=upsample_size, scale_factor=(2, 2), mode="bilinear")
        self.convr1 = ConvBnRelu(in_channels, out_channels, kernel_size=(3, 3), stride=1, padding=padding)
        # Crop + concat step between these 2
        self.convr2 = ConvBnRelu(in_channels, out_channels, kernel_size=(3, 3), stride=1, padding=padding)
        '''
        self.upSample = nn.ConvTranspose2d(in_channels, out_channels, 2, stride=2)
        self.convr1 = ConvBnRelu(in_channels, out_channels, kernel_size=(3, 3), stride=1, padding=padding)
        self.convr2 = ConvBnRelu(out_channels, out_channels, kernel_size=(3, 3), stride=1, padding=padding)

    def _crop_concat(self, upsampled, bypass):
        """
         Crop y to the (h, w) of x and concat them.
         Used for the expansive path.
        Returns:
            The concatenated tensor
        """
        c = (bypass.size()[2] - upsampled.size()[2]) // 2
        bypass = F.pad(bypass, (-c, -c, -c, -c))

        return torch.cat((bypass, upsampled), 1)

    def forward(self, x, down_tensor):
        '''old version
        x = self.upSample(x)
        x = self.convr1(x)
        x = self._crop_concat(x, down_tensor)
        x = self.convr2(x)
        '''

        x = self.upSample(x)
        x = self._crop_concat(x, down_tensor)
        x = self.convr1(x)
        if self.drop_out: x = self.dropout_layer(x)
        x = self.convr2(x)
        if self.drop_out: x = self.dropout_layer(x)
        return x


class UNET_CROP(nn.Module):
    def __init__(self):
        super(UNET_CROP, self).__init__()
        # channels, height, width = in_shape

        # self.dropout = dropout

        self.model_code = ""        # variable to save model and main function when loaded

        self.down1 = StackEncoder(1, 64)
        self.down2 = StackEncoder(64, 128)
        self.down3 = StackEncoder(128, 256)
        self.down4 = StackEncoder(256, 512)

        self.center = nn.Sequential(
            # nn.Dropout2d(p=0.2),
            ConvBnRelu(512, 1024, kernel_size=(3, 3), stride=1, padding=0),
            nn.Dropout2d(p=0.2),
            ConvBnRelu(1024, 1024, kernel_size=(3, 3), stride=1, padding=0),
            nn.Dropout2d(p=0.2)
        )

        self.up1 = StackDecoder(in_channels=1024, out_channels=512)
        self.up2 = StackDecoder(in_channels=512, out_channels=256)
        self.up3 = StackDecoder(in_channels=256, out_channels=128)
        self.up4 = StackDecoder(in_channels=128, out_channels=64)

        # 1x1 convolution at the last layer
        # Different from the paper is the output size here
        self.output_seg_map = nn.Conv2d(64, 1, kernel_size=(1, 1), padding=0, stride=1)

        self._initialize_weights()

    def forward(self, x):
        x, x_trace1 = self.down1(x)
        x, x_trace2 = self.down2(x)
        x, x_trace3 = self.down3(x)
        x, x_trace4 = self.down4(x)
        x = self.center(x)
        x = self.up1(x, x_trace4)
        x = self.up2(x, x_trace3)
        x = self.up3(x, x_trace2)
        x = self.up4(x, x_trace1)

        x = self.output_seg_map(x)
        # x = F.sigmoid(x)
        # out = torch.squeeze(out, dim=1)
        return x


    def _initialize_weights(self):
        for m in self.modules():
            if isinstance(m, nn.Conv2d):
                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels
                m.weight.data.normal_(0, math.sqrt(2. / n))
                if m.bias is not None:
                    m.bias.data.zero_()
            elif isinstance(m, nn.BatchNorm2d):
                m.weight.data.fill_(1)
                m.bias.data.zero_()

# x = Variable(torch.randn(1,1,700, 700))       # simulate input image
# net = UNET_CROP()
# out = net(x)
# print("input: ", x)
# print("output: ", out)
===============from __future__ import print_function, division
import torch
from torch import optim
from torch.autograd import Variable
from torch.utils.data import DataLoader
import numpy as np
import torch.nn as nn
import torch.nn.functional as F
import Unet_crop
import tifffile as tiff
import Utils
import time
from sklearn.metrics import average_precision_score, recall_score, f1_score
import Analysis_crop
import cv2

def to_var(x):
    if torch.cuda.is_available():
        return Variable(x.cuda())
    else:
        return Variable(x)

### BinaryCrossEntropyLoss2d().forward(logits, labels)
class BinaryCrossEntropyLoss2d(nn.Module):
    def __init__(self, weight=None, size_average=True):
        """
        Binary cross entropy loss 2D
        Args:
            weight:
            size_average:
        """
        super(BinaryCrossEntropyLoss2d, self).__init__()
        self.bce_loss = nn.BCELoss(weight, size_average)

    def forward(self, probs, targets):
        probs = F.sigmoid(probs)
        probs_flat = probs.view(-1)  # Flatten
        targets_flat = targets.view(-1)  # Flatten
        return self.bce_loss(probs_flat, targets_flat)      # (output, labels)

def NetEval(net,valdata_loader,crit):
    loss = 0.
    count = 0
    net.eval()
    crop_input, crop_label,_ = crop_info()
    for i,data in enumerate(valdata_loader,0):
        if i > 10: break
        inputs, labels = data
        # inputs = inputs.numpy()
        # labels = labels.numpy()
        for j in range(len(crop_input)):  # training on the crop images and corresponding labels
            ci = crop_input[j]  # crop index for inputs
            cl = crop_label[j]  # crop index for lables
            # temp = labels[0, 0, :, :]  # labels is numpy array 512x512
            # if np.sum(temp) < 0.01 * np.shape(temp)[0] * np.shape(temp)[1]: break
            x = inputs.numpy()[:, :, ci[0]:ci[0] + 572, ci[1]:ci[1] + 572]
            y = labels.numpy()[:, :, cl[0]: cl[0] + 388, cl[1]:cl[1] + 388]
            x = torch.from_numpy(x)
            y = torch.from_numpy(y)
            x, y = to_var(x), to_var(y)
            out = net(x)
            l = crit(out, y)
            loss += l.data[0]
            count += 1
    return loss/count

#process the test data and save to separate .tif image
def NetTest(net,testdata_loader,path = "data/results/"):
    net.eval()
    crop_input, crop_label, average_mask = crop_info()
    for i, data in enumerate(testdata_loader, 0):
        if i >= 30: return 1        # for debug
        # data = to_var(data)
        img_shape = 512
        img = np.zeros((img_shape, img_shape))
        for j in range(len(crop_input)):  # training on the crop images and corresponding labels
            temp = np.zeros((img_shape, img_shape))
            ci = crop_input[j]  # crop index for inputs
            cl = crop_label[j]
            x = data.numpy()[:, :, ci[0]:ci[0] + 572, ci[1]:ci[1] + 572]
            x = torch.from_numpy(x)
            x = to_var(x)
            out = F.sigmoid(net(x))
            out = out.cpu()
            out = out[0,0,:,:]
            print("j: ", j)
            print("size of temp: ", np.shape(temp))
            print("size of output: ", np.shape(out.data.numpy()))
            temp[cl[0]: cl[0] + 388, cl[1]:cl[1] + 388] = out.data.numpy()
            img += temp

        img = img/average_mask
        img = img.reshape(-1)
        img[img < 0.5] = 0; img[img >= 0.5] = 1
        img = img.reshape(img_shape, img_shape)
        img = np.uint8(img * 255)
        imgname = path + str(i) + ".tif"
        tiff.imsave(imgname, img)

# return input image size like 512x512, numpy array
def NetPredict(net, input_image):
    net.eval()
    _, crop_label, average_mask = crop_info()

    # input_image is grayscale input image of 512x512
    data = Utils.input_filled_mirroring(input_image, e = 94)
    imgdatas = np.ndarray((1, 1, data.shape[0], data.shape[1]), dtype=np.uint8)
    imgdatas[0] = np.expand_dims(data, 0)
    data = Utils.hist_equalization(imgdatas)
    data = data.astype('float32')
    data /= 255
    data -= data.mean(axis=0)

    img_shape = input_image.shape
    img = np.zeros((img_shape, img_shape))
    for j in range(len(crop_input)):  # training on the crop images and corresponding labels
        temp = np.zeros((img_shape, img_shape))
        ci = crop_input[j]  # crop index for inputs
        cl = crop_label[j]
        x = data.numpy()[:, :, ci[0]:ci[0] + 572, ci[1]:ci[1] + 572]
        x = torch.from_numpy(x)
        x = to_var(x)
        out = F.sigmoid(net(x))
        out = out.cpu()
        out = out[0, 0, :, :]
        temp[cl[0]: cl[0] + 388, cl[1]:cl[1] + 388] = out.data.numpy()
        img += temp

    img = img / average_mask
    img = img.reshape(-1)
    img[img < 0.5] = 0
    img[img >= 0.5] = 1
    img = img.reshape(img_shape)
    img = np.uint8(img * 255)
    return img


def write_2_log(content):
    path = "log_file.txt"
    output = open(path, "a")
    output.write("\n")
    output.write(content)
    output.close()

def crop_info():
    crop_input = [[0, 0], [128, 0], [0, 128], [128, 128]]
    crop_label = [[0, 0], [124, 0], [0, 124], [124, 124]]
    average_mask = np.ones((512, 512))
    average_mask[124:388, 0:124] = 2
    average_mask[0:124, 124:388] = 2
    average_mask[124:388, 388:512] = 2
    average_mask[388:512, 124:388] = 2
    average_mask[124:388, 124:388] = 4
    return crop_input, crop_label, average_mask

if __name__ == '__main__':
    '''subjects to change for each exp:
    + path to the dataset
    + opt function
    + leg description
    + N_epoch
    + saved_model
    '''
    start_begining = time.time()

    # path = "data/dataset"
    path = "/home/anhxtuan/HanLe/dataset/20aug_10ela_3inten_reflect"
    path = "/home/anhxtuan/HanLe/dataset/20aug_10ela_3inten_reflect_700"

    import os
    print("Does the folder exist?: ", os.path.isdir(path))
    print("Does the path exist?: ", os.path.exists(path))

    imgs_train, imgs_mask_train = Utils.load_train_data(npy_path=path)
    imgs_val, imgs_mask_val = Utils.load_val_data(npy_path=path)
    batch_size = 1
    trainset = zip(imgs_train, imgs_mask_train)
    trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,
                                              shuffle=True, num_workers=2)
    valset = zip(imgs_val, imgs_mask_val)
    valloader = torch.utils.data.DataLoader(valset, batch_size=batch_size,
                                              shuffle=False, num_workers=2)
    # net = Unet.UNet()                     # Unet 1
    # net = Unet_BatchNorm.UNet_BN()          # Unet 2 with batchNorm
    net = Unet_crop.UNET_CROP()

    f1 = open("Unet_crop.py", 'r')     # embede code into the model to be saved later
    f2 = open("UnetTrain_crop.py", 'r')
    f3 = open("Utils.py", 'r')
    model_notes = time.strftime("%c") + "\n" + f1.read() + "\n" + "==="*5 + f2.read() + "\n" + "==="*5 + f3.read()
    f1.close()
    f2.close()
    f3.close()

    criterion = BinaryCrossEntropyLoss2d()
    # criterion = SoftDiceLoss()
    # criterion = nn.BCELoss()

    if torch.cuda.is_available():
        # torch.set_default_tensor_type('torch.cuda.FloatTensor')
        # net.load_state_dict(torch.load("Unet2_model_12epoch_Leg12_droput_0_2_rmSigmoid_20aug_10ela_3inten_reflect"))
        net.cuda()
        # criterion.cuda()

    opt = optim.SGD(net.parameters(), lr=1e-2, momentum=0.99)       # subject to change
    # opt = optim.RMSprop(net.parameters(), lr=2e-4)
    # RMSprop[22](learning rate 0.001) with weight decay set to 0.001.
    # opt = optim.Adam(net.parameters(), lr=1e-3, weight_decay=1e-4)

    train_loss = []
    val_loss = []

    print("[epoch, #image] Loss")
    leg = "Leg22_CROP_dropout_0_2_rmSigmoid_20aug_10ela_3inten_reflect"
    print("Processing: ", leg)
    model_name = ""

    N_epoch = 6
    model_saved = np.arange(1,N_epoch+1,2)
    val_loss_min = 100

    write_2_log("==="*30)
    write_2_log(time.strftime("%c"))       # time, date of exp
    write_2_log(leg)
    write_2_log(model_notes)
    write_2_log(time.strftime("%c"))  # time, date of exp
    write_2_log(leg)
    write_2_log("optim.SGD(net.parameters(), lr=1e-2, momentum=0.99)")
    write_2_log("Number of epoch max: " + str(N_epoch))

    crop_input, crop_label,_ = crop_info()
    min_model_epoch = 0
    for epoch in range(N_epoch):
        running_loss = 0.0; count = 0
        net.train()
        for i, data in enumerate(trainloader, 0):
            if i > 10: break

            inputs, labels = data
            temp = labels.numpy()
            for j in range(len(crop_input)):       # training on the crop images and corresponding labels
                ci = crop_input[j]          # crop index for inputs
                cl = crop_label[j]          # crop index for lables
                # temp = temp[0, 0, :, :]  # labels is numpy array 512x512
                # if np.sum(temp) < 0.01 * np.shape(temp)[0] * np.shape(temp)[1]: break
                x = inputs.numpy()[:, :, ci[0]:ci[0] + 572, ci[1]:ci[1] + 572]
                y = labels.numpy()[:, :, cl[0]: cl[0] + 388, cl[1]:cl[1] + 388]
                x = torch.from_numpy(x)
                y = torch.from_numpy(y)
                x, y = to_var(x), to_var(y)
                opt.zero_grad()
                out = net(x)
                loss = criterion(out, y)
                loss.backward()
                opt.step()
                running_loss += loss.data[0]
                count += 1

        net.eval()
        val_loss_temp = NetEval(net, valloader, criterion)
        if epoch > 0 and val_loss_temp < val_loss_min:        # save the model which has the lowest val_loss, ignore first epoch
            val_loss_min = val_loss_temp
            torch.save(net.state_dict(), "Unet2_model_" + leg + "_min_val_loss")  # save model
            min_model_epoch = epoch + 1

        disp = 'Epoch %d: Train loss: %.6f, Val loss: %.6f' % (epoch + 1, running_loss/count, val_loss_temp)
        write_2_log(disp)
        print(disp)
        val_loss.append(val_loss_temp)
        train_loss.append(running_loss/count); running_loss = 0.0

        if (epoch + 1) in model_saved:        # save checkpoint
            model_name = "Unet2_model_" + str(epoch+1) + "epoch_" + leg
            torch.save(net.state_dict(), model_name)  # save model
            Analysis_crop.analysis(model_file = model_name, valloader = valloader)

    write_2_log("Best model at epoch: " + str(min_model_epoch))
    write_2_log("Total training time: " + str((time.time() - start_begining) / 3600.0))

    val_loss_file = "data/results" + "/val_loss_" + str(N_epoch) + "epoch_" + leg + ".npy"
    train_loss_file = "data/results" + "/training_loss_" + str(N_epoch) + "epoch_" + leg + ".npy"

    np.save(val_loss_file, val_loss)
    np.save(train_loss_file, train_loss)
    print("total processing time in seconds: ", time.time() - start_begining)
    print("total processing time in mins: ", (time.time() - start_begining) / 60.0)
    print("total processing time in hours: ", (time.time() - start_begining) / 3600.0)

    # Analysis.analysis(model_file="Unet2_model_" + leg + "_min_val_loss", valloader=valloader)

    Analysis_crop.PlotLoss(model_file = model_name, loss_train_path = train_loss_file, loss_val_path = val_loss_file, epoch_No = N_epoch)

    write_2_log(time.strftime("%c"))  # time, date of exp
===============
import numpy as np
import torch.nn as nn
import torch
import cv2
from lcn import LecunLCN

LCN_enable = False

def input_filled_mirroring(x, e = 62):      # fill missing data by mirroring the input image
    '''input size 636 --> output size 512'''
    w, h = x.shape
    #e = 62  # extra width on 1 edge
    y = np.zeros((h + e * 2, w + e * 2))
    y[e:h + e, e:w + e] = x
    y[e:e + h, 0:e] = np.flip(y[e:e + h, e:2 * e], 1)  # flip vertically
    y[e:e + h, e + w:2 * e + w] = np.flip(y[e:e + h, w:e + w], 1)  # flip vertically
    y[0:e, 0:2 * e + w] = np.flip(y[e:2 * e, 0:2 * e + w], 0)  # flip horizontally
    y[e + h:2 * e + h, 0:2 * e + w] = np.flip(y[h:e + h, 0:2 * e + w], 0)  # flip horizontally
    return y

def nearest_cells_distance(pos, img):
    # searching in 8 directions to find 2 nearest distances to neighbor cells
    curr_value = img[pos]
    w = img.shape[0];h = img.shape[1]
    count_detect = 0  # detect 2 nearest neighbors. break the search if count_detect = 2
    x, y = pos

    # print("w,h: ", (w, h))
    d1 = 9999999;d2 = 9999999;d3 = 9999999;d4 = 9999999
    d5 = 9999999;d6 = 9999999;d7 = 9999999;d8 = 9999999
    for i in range(1, max(w, h)):
        # (x+1, y), (x+1, y+1), (x+1, y-1),
        # (x, y+1), (x, y-1)
        # (x-1, y), (x-1,y+1), (x-1,y-1),
        if x + i < w:
            if img[(x + i, y)] != curr_value and d1 == 9999999:
                d1 = i; count_detect += 1
            if y + i < h:
                if img[(x + i, y + i)] != curr_value and d2 == 9999999:
                    d2 = i; count_detect += 1
            elif y - i >= 0:
                if img[(x + i, y - i)] != curr_value and d3 == 9999999:
                    d3 = i; count_detect += 1
        if y + i < h:
            if img[(x, y + i)] != curr_value and d4 == 9999999:
                d4 = i; count_detect += 1
        if y - i >= 0:
            if img[(x, y - i)] != curr_value and d5 == 9999999:
                d5 = i; count_detect += 1
        if x - i >= 0:
            if img[(x - i, y)] != curr_value and d6 == 9999999:
                d6 = i; count_detect += 1
            if y + i < h:
                if img[(x - i, y + i)] != curr_value and d7 == 9999999:
                    d7 = i; count_detect += 1
            elif y - i >= 0:
                if img[(x - i, y - i)] != curr_value and d8 == 9999999:
                    d8 = i; count_detect += 1
        if count_detect >= 2: break

    d = [d1, d2, d3, d4, d5, d6, d7, d8]
    min_index = np.argmin(d)
    dist1 = d[min_index]
    d.remove(dist1)
    min_index = np.argmin(d)
    dist2 = d[min_index]
    return dist1, dist2

def create_weight_map(imgs_mask):
        print('-' * 30)
        print('Creating weights for masks ...')
        print('-' * 30)
        weight_map = np.ndarray(
            (len(imgs_mask), 1, np.shape(imgs_mask)[2], np.shape(imgs_mask)[3]), dtype=np.float32)
        w_0 = 10; sigma = 4
        imgs_w, imgs_h = np.shape(imgs_mask)[2], np.shape(imgs_mask)[3]
        total_pixels = imgs_w*imgs_h
        import time
        start = time.time()
        for i in range(len(imgs_mask)):
            if i%10 == 0: print("Done processing: %d images, time passed: %.2f mins" % (i, (time.time() - start)/60.0))
            temp = imgs_mask[i,0,:,:]
            w_border = 1 - np.sum(temp)/total_pixels        # w_c of pixel on the border (black)
            for m in range(imgs_w):
                for n in range(imgs_h):
                    # loop through all pixel of the mask
                    d1,d2 = nearest_cells_distance((m,n), temp)
                    w_c = w_border
                    if temp[m,n] == 0: w_c = 1 - w_border
                    weight_map[i,0,m,n] = w_c*5 + w_0*np.exp(-(d1 + d2)**2/(2*sigma**2))
                    # print("w_0*np.exp(): ", w_0*np.exp(-(d1 + d2)**2/(2*sigma**2)))
                    # print("w_border: ", w_border)

        np.save('data/dataset/weight_map_train.npy', weight_map)

        return weight_map

def load_train_data(npy_path = "data/dataset", hist_equal = False):

    print('-' * 30)
    print('load train images...')

    imgs_train = np.load(npy_path + "/imgs_train.npy")
    imgs_mask_train = np.load(npy_path + "/imgs_mask_train.npy")

    if hist_equal: imgs_train = hist_equalization(imgs_train)

    # weight_map_train = np.load(npy_path + "/weight_map_train.npy")
    # weight_map_train = weight_map_train.astype('float32')

    imgs_train = imgs_train.astype('float32')
    imgs_mask_train = imgs_mask_train.astype('float32')

    if LCN_enable:
        imgs_train = imgs_train.astype('float64')
        imgs_train = LecunLCN(imgs_train, image_shape=imgs_train.shape).output.eval()
        imgs_train = imgs_train.astype('float32')

    if not LCN_enable: imgs_train /= 255

    imgs_train -= imgs_train.mean(axis=0)
    imgs_mask_train /= 255
    imgs_mask_train[imgs_mask_train > 0.5] = 1
    imgs_mask_train[imgs_mask_train <= 0.5] = 0

    # weight_map_train = create_weight_map(imgs_mask_train)

    print("Done loading traing data")
    print('-' * 30)
    return imgs_train, imgs_mask_train

def load_val_data(npy_path = "data/dataset", hist_equal = True):

    print('-' * 30)
    print('load validation images...')

    imgs_train = np.load(npy_path + "/imgs_val.npy")
    imgs_mask_train = np.load(npy_path + "/imgs_mask_val.npy")

    if hist_equal: imgs_train = hist_equalization(imgs_train)

    imgs_train = imgs_train.astype('float32')
    imgs_mask_train = imgs_mask_train.astype('float32')

    if LCN_enable:
        imgs_train = imgs_train.astype('float64')
        imgs_train = LecunLCN(imgs_train, image_shape=imgs_train.shape).output.eval()
        imgs_train = imgs_train.astype('float32')

    if not LCN_enable: imgs_train /= 255
    imgs_train -= imgs_train.mean(axis=0)
    imgs_mask_train /= 255
    imgs_mask_train[imgs_mask_train > 0.5] = 1
    imgs_mask_train[imgs_mask_train <= 0.5] = 0
    print("Done loading validation data")
    print('-' * 30)
    return imgs_train, imgs_mask_train

def load_test_data(npy_path = "data/dataset", hist_equal = True):

    print('-' * 30)
    print('load test images...')

    imgs_test = np.load(npy_path + "/imgs_test.npy")

    if hist_equal: imgs_test = hist_equalization(imgs_test)

    imgs_test = imgs_test.astype('float32')

    if LCN_enable:
        imgs_test = imgs_test.astype('float64')
        imgs_test = LecunLCN(imgs_test, image_shape=imgs_test.shape).output.eval()
        imgs_test = imgs_test.astype('float32')

    if not LCN_enable: imgs_test /= 255

    imgs_test -= imgs_test.mean(axis=0)

    print("Done loading test data")
    print('-' * 30)
    return imgs_test

def load_val_5imgs(npy_path = "data/dataset"):
    print('-' * 30)
    print('load train images...')

    imgs_train = np.load(npy_path + "/imgs_val_5imgs.npy")
    imgs_mask_train = np.load(npy_path + "/imgs_mask_val_5imgs.npy")

    # imgs_train = hist_equalization(imgs_train)

    imgs_train = imgs_train.astype('float64')
    imgs_mask_train = imgs_mask_train.astype('float64')

    if LCN_enable: imgs_train = LecunLCN(imgs_train, image_shape=imgs_train.shape).output.eval()

    if not LCN_enable: imgs_train /= 255

    mean = imgs_train.mean(axis=0)
    imgs_train -= mean


    imgs_mask_train /= 255
    imgs_mask_train[imgs_mask_train > 0.5] = 1
    imgs_mask_train[imgs_mask_train <= 0.5] = 0

    # weight_map_train = self.create_weight_map(imgs_mask_train)

    print("Done loading traing data")
    print('-' * 30)
    return imgs_train, imgs_mask_train

def hist_equalization(inputs):      # inputs are uint8, 0-255, Nx1x636x636
    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))
    output = inputs.copy()
    for i in range(len(inputs)):
        img = inputs[i, 0, :, :]
        # res = cv2.equalizeHist(img)
        res = clahe.apply(img)
        output[i,0,:,:] = res
    return output

### BinaryCrossEntropyLoss2d().forward(logits, labels)
class BinaryCrossEntropyLoss2d(nn.Module):
    def __init__(self, weight=None, size_average=True):
        """
        Binary cross entropy loss 2D
        Args:
            weight:
            size_average:
        """
        super(BinaryCrossEntropyLoss2d, self).__init__()
        self.bce_loss = nn.BCELoss(weight, size_average)

    def forward(self, logits, targets):
        # probs = F.sigmoid(logits)
        probs = logits
        probs_flat = probs.view(-1)  # Flatten
        targets_flat = targets.view(-1)  # Flatten
        return self.bce_loss(probs_flat, targets_flat)      # (output, labels)

class BCE_with_Weights(nn.Module):
    def __init__(self, weights=None):
        """
        Binary cross entropy loss 2D
        Args:
            weights:
        """
        super(BCE_with_Weights, self).__init__()
        self.weights = weights

    def forward(self, output, target):
        if self.weights is not None:
            loss = self.weights * (target * torch.log(output) + (1 - target) * torch.log(1 - output))
        else:
            loss = target * torch.log(output) + (1 - target) * torch.log(1 - output)

        return torch.neg(torch.mean(loss))

class LRN(nn.Module):       # input x is Torch tensor
    def __init__(self, local_size=1, alpha=1.0, beta=0.75, ACROSS_CHANNELS=False):      #LRN(local_size=5, alpha=0.0001, beta=0.75),
        super(LRN, self).__init__()
        self.ACROSS_CHANNELS = ACROSS_CHANNELS
        if self.ACROSS_CHANNELS:
            self.average = nn.AvgPool3d(kernel_size=(local_size, 1, 1),
                                        stride=1, padding=(int((local_size - 1.0) / 2), 0, 0))
        else:
            self.average = nn.AvgPool2d(kernel_size=local_size,
                                        stride=1, padding=int((local_size - 1.0) / 2))
        self.alpha = alpha
        self.beta = beta

    def forward(self, x):
        if self.ACROSS_CHANNELS:
            div = x.pow(2).unsqueeze(1)
            div = self.average(div).squeeze(1)
            div = div.mul(self.alpha).add(1.0).pow(self.beta)
        else:
            div = x.pow(2)
            div = self.average(div)
            div = div.mul(self.alpha).add(1.0).pow(self.beta)
        x = x.div(div)
        return x
Sat Nov 25 01:49:05 2017
Leg22_CROP_dropout_0_2_rmSigmoid_20aug_10ela_3inten_reflect
optim.SGD(net.parameters(), lr=1e-2, momentum=0.99)
Number of epoch max: 6
Epoch 1: Train loss: 0.523680, Val loss: 0.487574
Epoch 2: Train loss: 0.471159, Val loss: 0.472090
Epoch 3: Train loss: 0.498690, Val loss: 0.477905
==========================================================================================
Sat Nov 25 01:50:30 2017
Leg22_CROP_dropout_0_2_rmSigmoid_20aug_10ela_3inten_reflect
Sat Nov 25 01:50:28 2017
import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.autograd import Variable
import math


class ConvBnRelu(nn.Module):
    def __init__(self, in_channels, out_channels, kernel_size, padding, stride):
        super(ConvBnRelu, self).__init__()
        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=kernel_size, padding=padding, stride=stride)
        self.bn = nn.BatchNorm2d(out_channels)
        self.relu = nn.ReLU()

    def forward(self, x):
        x = self.conv(x)
        # x = self.bn(x)
        x = self.relu(x)
        return x


class StackEncoder(nn.Module):
    def __init__(self, in_channels, out_channels):
        super(StackEncoder, self).__init__()
        self.convr1 = ConvBnRelu(in_channels, out_channels, kernel_size=(3, 3), stride=1, padding=0)
        self.convr2 = ConvBnRelu(out_channels, out_channels, kernel_size=(3, 3), stride=1, padding=0)
        self.maxPool = nn.MaxPool2d(kernel_size=(2, 2), stride=2)

    def forward(self, x):
        x = self.convr1(x)
        x = self.convr2(x)
        x_trace = x             # save x to use in concat in the Decoder path
        out = self.maxPool(x)
        return out, x_trace


class StackDecoder(nn.Module):
    def __init__(self, in_channels, out_channels, padding = 0, drop_out=False):
        super(StackDecoder, self).__init__()

        self.drop_out = drop_out
        self.dropout_layer = nn.Dropout2d(p=0.5)

        ''' this is old version
        self.upSample = nn.Upsample(size=upsample_size, scale_factor=(2, 2), mode="bilinear")
        self.convr1 = ConvBnRelu(in_channels, out_channels, kernel_size=(3, 3), stride=1, padding=padding)
        # Crop + concat step between these 2
        self.convr2 = ConvBnRelu(in_channels, out_channels, kernel_size=(3, 3), stride=1, padding=padding)
        '''
        self.upSample = nn.ConvTranspose2d(in_channels, out_channels, 2, stride=2)
        self.convr1 = ConvBnRelu(in_channels, out_channels, kernel_size=(3, 3), stride=1, padding=padding)
        self.convr2 = ConvBnRelu(out_channels, out_channels, kernel_size=(3, 3), stride=1, padding=padding)

    def _crop_concat(self, upsampled, bypass):
        """
         Crop y to the (h, w) of x and concat them.
         Used for the expansive path.
        Returns:
            The concatenated tensor
        """
        c = (bypass.size()[2] - upsampled.size()[2]) // 2
        bypass = F.pad(bypass, (-c, -c, -c, -c))

        return torch.cat((bypass, upsampled), 1)

    def forward(self, x, down_tensor):
        '''old version
        x = self.upSample(x)
        x = self.convr1(x)
        x = self._crop_concat(x, down_tensor)
        x = self.convr2(x)
        '''

        x = self.upSample(x)
        x = self._crop_concat(x, down_tensor)
        x = self.convr1(x)
        if self.drop_out: x = self.dropout_layer(x)
        x = self.convr2(x)
        if self.drop_out: x = self.dropout_layer(x)
        return x


class UNET_CROP(nn.Module):
    def __init__(self):
        super(UNET_CROP, self).__init__()
        # channels, height, width = in_shape

        # self.dropout = dropout

        self.model_code = ""        # variable to save model and main function when loaded

        self.down1 = StackEncoder(1, 64)
        self.down2 = StackEncoder(64, 128)
        self.down3 = StackEncoder(128, 256)
        self.down4 = StackEncoder(256, 512)

        self.center = nn.Sequential(
            # nn.Dropout2d(p=0.2),
            ConvBnRelu(512, 1024, kernel_size=(3, 3), stride=1, padding=0),
            nn.Dropout2d(p=0.2),
            ConvBnRelu(1024, 1024, kernel_size=(3, 3), stride=1, padding=0),
            nn.Dropout2d(p=0.2)
        )

        self.up1 = StackDecoder(in_channels=1024, out_channels=512)
        self.up2 = StackDecoder(in_channels=512, out_channels=256)
        self.up3 = StackDecoder(in_channels=256, out_channels=128)
        self.up4 = StackDecoder(in_channels=128, out_channels=64)

        # 1x1 convolution at the last layer
        # Different from the paper is the output size here
        self.output_seg_map = nn.Conv2d(64, 1, kernel_size=(1, 1), padding=0, stride=1)

        self._initialize_weights()

    def forward(self, x):
        x, x_trace1 = self.down1(x)
        x, x_trace2 = self.down2(x)
        x, x_trace3 = self.down3(x)
        x, x_trace4 = self.down4(x)
        x = self.center(x)
        x = self.up1(x, x_trace4)
        x = self.up2(x, x_trace3)
        x = self.up3(x, x_trace2)
        x = self.up4(x, x_trace1)

        x = self.output_seg_map(x)
        # x = F.sigmoid(x)
        # out = torch.squeeze(out, dim=1)
        return x


    def _initialize_weights(self):
        for m in self.modules():
            if isinstance(m, nn.Conv2d):
                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels
                m.weight.data.normal_(0, math.sqrt(2. / n))
                if m.bias is not None:
                    m.bias.data.zero_()
            elif isinstance(m, nn.BatchNorm2d):
                m.weight.data.fill_(1)
                m.bias.data.zero_()

# x = Variable(torch.randn(1,1,700, 700))       # simulate input image
# net = UNET_CROP()
# out = net(x)
# print("input: ", x)
# print("output: ", out)
===============from __future__ import print_function, division
import torch
from torch import optim
from torch.autograd import Variable
from torch.utils.data import DataLoader
import numpy as np
import torch.nn as nn
import torch.nn.functional as F
import Unet_crop
import tifffile as tiff
import Utils
import time
from sklearn.metrics import average_precision_score, recall_score, f1_score
import Analysis_crop
import cv2

def to_var(x):
    if torch.cuda.is_available():
        return Variable(x.cuda())
    else:
        return Variable(x)

### BinaryCrossEntropyLoss2d().forward(logits, labels)
class BinaryCrossEntropyLoss2d(nn.Module):
    def __init__(self, weight=None, size_average=True):
        """
        Binary cross entropy loss 2D
        Args:
            weight:
            size_average:
        """
        super(BinaryCrossEntropyLoss2d, self).__init__()
        self.bce_loss = nn.BCELoss(weight, size_average)

    def forward(self, probs, targets):
        probs = F.sigmoid(probs)
        probs_flat = probs.view(-1)  # Flatten
        targets_flat = targets.view(-1)  # Flatten
        return self.bce_loss(probs_flat, targets_flat)      # (output, labels)

def NetEval(net,valdata_loader,crit):
    loss = 0.
    count = 0
    net.eval()
    crop_input, crop_label,_ = crop_info()
    for i,data in enumerate(valdata_loader,0):
        if i > 10: break
        inputs, labels = data
        # inputs = inputs.numpy()
        # labels = labels.numpy()
        for j in range(len(crop_input)):  # training on the crop images and corresponding labels
            ci = crop_input[j]  # crop index for inputs
            cl = crop_label[j]  # crop index for lables
            # temp = labels[0, 0, :, :]  # labels is numpy array 512x512
            # if np.sum(temp) < 0.01 * np.shape(temp)[0] * np.shape(temp)[1]: break
            x = inputs.numpy()[:, :, ci[0]:ci[0] + 572, ci[1]:ci[1] + 572]
            y = labels.numpy()[:, :, cl[0]: cl[0] + 388, cl[1]:cl[1] + 388]
            x = torch.from_numpy(x)
            y = torch.from_numpy(y)
            x, y = to_var(x), to_var(y)
            out = net(x)
            l = crit(out, y)
            loss += l.data[0]
            count += 1
    return loss/count

#process the test data and save to separate .tif image
def NetTest(net,testdata_loader,path = "data/results/"):
    net.eval()
    crop_input, crop_label, average_mask = crop_info()
    for i, data in enumerate(testdata_loader, 0):
        if i >= 30: return 1        # for debug
        # data = to_var(data)
        img_shape = 512
        img = np.zeros((img_shape, img_shape))
        for j in range(len(crop_input)):  # training on the crop images and corresponding labels
            temp = np.zeros((img_shape, img_shape))
            ci = crop_input[j]  # crop index for inputs
            cl = crop_label[j]
            x = data.numpy()[:, :, ci[0]:ci[0] + 572, ci[1]:ci[1] + 572]
            x = torch.from_numpy(x)
            x = to_var(x)
            out = F.sigmoid(net(x))
            out = out.cpu()
            out = out[0,0,:,:]
            # print("j: ", j)
            # print("size of temp: ", np.shape(temp))
            # print("size of output: ", np.shape(out.data.numpy()))
            temp[cl[0]: cl[0] + 388, cl[1]:cl[1] + 388] = out.data.numpy()
            img += temp

        img = img/average_mask
        img = img.reshape(-1)
        img[img < 0.5] = 0; img[img >= 0.5] = 1
        img = img.reshape(img_shape, img_shape)
        img = np.uint8(img * 255)
        imgname = path + str(i) + ".tif"
        tiff.imsave(imgname, img)

# return input image size like 512x512, numpy array
def NetPredict(net, input_image):
    net.eval()
    _, crop_label, average_mask = crop_info()

    # input_image is grayscale input image of 512x512
    data = Utils.input_filled_mirroring(input_image, e = 94)
    imgdatas = np.ndarray((1, 1, data.shape[0], data.shape[1]), dtype=np.uint8)
    imgdatas[0] = np.expand_dims(data, 0)
    data = Utils.hist_equalization(imgdatas)
    data = data.astype('float32')
    data /= 255
    data -= data.mean(axis=0)

    img_shape = input_image.shape
    img = np.zeros((img_shape, img_shape))
    for j in range(len(crop_input)):  # training on the crop images and corresponding labels
        temp = np.zeros((img_shape, img_shape))
        ci = crop_input[j]  # crop index for inputs
        cl = crop_label[j]
        x = data.numpy()[:, :, ci[0]:ci[0] + 572, ci[1]:ci[1] + 572]
        x = torch.from_numpy(x)
        x = to_var(x)
        out = F.sigmoid(net(x))
        out = out.cpu()
        out = out[0, 0, :, :]
        temp[cl[0]: cl[0] + 388, cl[1]:cl[1] + 388] = out.data.numpy()
        img += temp

    img = img / average_mask
    img = img.reshape(-1)
    img[img < 0.5] = 0
    img[img >= 0.5] = 1
    img = img.reshape(img_shape)
    img = np.uint8(img * 255)
    return img


def write_2_log(content):
    path = "log_file.txt"
    output = open(path, "a")
    output.write("\n")
    output.write(content)
    output.close()

def crop_info():
    crop_input = [[0, 0], [128, 0], [0, 128], [128, 128]]
    crop_label = [[0, 0], [124, 0], [0, 124], [124, 124]]
    average_mask = np.ones((512, 512))
    average_mask[124:388, 0:124] = 2
    average_mask[0:124, 124:388] = 2
    average_mask[124:388, 388:512] = 2
    average_mask[388:512, 124:388] = 2
    average_mask[124:388, 124:388] = 4
    return crop_input, crop_label, average_mask

if __name__ == '__main__':
    '''subjects to change for each exp:
    + path to the dataset
    + opt function
    + leg description
    + N_epoch
    + saved_model
    '''
    start_begining = time.time()

    # path = "data/dataset"
    path = "/home/anhxtuan/HanLe/dataset/20aug_10ela_3inten_reflect"
    path = "/home/anhxtuan/HanLe/dataset/20aug_10ela_3inten_reflect_700"

    import os
    print("Does the folder exist?: ", os.path.isdir(path))
    print("Does the path exist?: ", os.path.exists(path))

    imgs_train, imgs_mask_train = Utils.load_train_data(npy_path=path)
    imgs_val, imgs_mask_val = Utils.load_val_data(npy_path=path)
    batch_size = 1
    trainset = zip(imgs_train, imgs_mask_train)
    trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,
                                              shuffle=True, num_workers=2)
    valset = zip(imgs_val, imgs_mask_val)
    valloader = torch.utils.data.DataLoader(valset, batch_size=batch_size,
                                              shuffle=False, num_workers=2)
    # net = Unet.UNet()                     # Unet 1
    # net = Unet_BatchNorm.UNet_BN()          # Unet 2 with batchNorm
    net = Unet_crop.UNET_CROP()

    f1 = open("Unet_crop.py", 'r')     # embede code into the model to be saved later
    f2 = open("UnetTrain_crop.py", 'r')
    f3 = open("Utils.py", 'r')
    model_notes = time.strftime("%c") + "\n" + f1.read() + "\n" + "==="*5 + f2.read() + "\n" + "==="*5 + f3.read()
    f1.close()
    f2.close()
    f3.close()

    criterion = BinaryCrossEntropyLoss2d()
    # criterion = SoftDiceLoss()
    # criterion = nn.BCELoss()

    if torch.cuda.is_available():
        # torch.set_default_tensor_type('torch.cuda.FloatTensor')
        # net.load_state_dict(torch.load("Unet2_model_12epoch_Leg12_droput_0_2_rmSigmoid_20aug_10ela_3inten_reflect"))
        net.cuda()
        # criterion.cuda()

    opt = optim.SGD(net.parameters(), lr=1e-2, momentum=0.99)       # subject to change
    # opt = optim.RMSprop(net.parameters(), lr=2e-4)
    # RMSprop[22](learning rate 0.001) with weight decay set to 0.001.
    # opt = optim.Adam(net.parameters(), lr=1e-3, weight_decay=1e-4)

    train_loss = []
    val_loss = []

    print("[epoch, #image] Loss")
    leg = "Leg22_CROP_dropout_0_2_rmSigmoid_20aug_10ela_3inten_reflect"
    print("Processing: ", leg)
    model_name = ""

    N_epoch = 6
    model_saved = np.arange(1,N_epoch+1,2)
    val_loss_min = 100

    write_2_log("==="*30)
    write_2_log(time.strftime("%c"))       # time, date of exp
    write_2_log(leg)
    write_2_log(model_notes)
    write_2_log(time.strftime("%c"))  # time, date of exp
    write_2_log(leg)
    write_2_log("optim.SGD(net.parameters(), lr=1e-2, momentum=0.99)")
    write_2_log("Number of epoch max: " + str(N_epoch))

    crop_input, crop_label,_ = crop_info()
    min_model_epoch = 0
    for epoch in range(N_epoch):
        running_loss = 0.0; count = 0
        net.train()
        for i, data in enumerate(trainloader, 0):
            if i > 10: break

            inputs, labels = data
            temp = labels.numpy()
            for j in range(len(crop_input)):       # training on the crop images and corresponding labels
                ci = crop_input[j]          # crop index for inputs
                cl = crop_label[j]          # crop index for lables
                # temp = temp[0, 0, :, :]  # labels is numpy array 512x512
                # if np.sum(temp) < 0.01 * np.shape(temp)[0] * np.shape(temp)[1]: break
                x = inputs.numpy()[:, :, ci[0]:ci[0] + 572, ci[1]:ci[1] + 572]
                y = labels.numpy()[:, :, cl[0]: cl[0] + 388, cl[1]:cl[1] + 388]
                x = torch.from_numpy(x)
                y = torch.from_numpy(y)
                x, y = to_var(x), to_var(y)
                opt.zero_grad()
                out = net(x)
                loss = criterion(out, y)
                loss.backward()
                opt.step()
                running_loss += loss.data[0]
                count += 1

        net.eval()
        val_loss_temp = NetEval(net, valloader, criterion)
        if epoch > 0 and val_loss_temp < val_loss_min:        # save the model which has the lowest val_loss, ignore first epoch
            val_loss_min = val_loss_temp
            torch.save(net.state_dict(), "Unet2_model_" + leg + "_min_val_loss")  # save model
            min_model_epoch = epoch + 1

        disp = 'Epoch %d: Train loss: %.6f, Val loss: %.6f' % (epoch + 1, running_loss/count, val_loss_temp)
        write_2_log(disp)
        print(disp)
        val_loss.append(val_loss_temp)
        train_loss.append(running_loss/count); running_loss = 0.0

        if (epoch + 1) in model_saved:        # save checkpoint
            model_name = "Unet2_model_" + str(epoch+1) + "epoch_" + leg
            torch.save(net.state_dict(), model_name)  # save model
            Analysis_crop.analysis(model_file = model_name, valloader = valloader)

    write_2_log("Best model at epoch: " + str(min_model_epoch))
    write_2_log("Total training time: " + str((time.time() - start_begining) / 3600.0))

    val_loss_file = "data/results" + "/val_loss_" + str(N_epoch) + "epoch_" + leg + ".npy"
    train_loss_file = "data/results" + "/training_loss_" + str(N_epoch) + "epoch_" + leg + ".npy"

    np.save(val_loss_file, val_loss)
    np.save(train_loss_file, train_loss)
    print("total processing time in seconds: ", time.time() - start_begining)
    print("total processing time in mins: ", (time.time() - start_begining) / 60.0)
    print("total processing time in hours: ", (time.time() - start_begining) / 3600.0)

    # Analysis.analysis(model_file="Unet2_model_" + leg + "_min_val_loss", valloader=valloader)

    Analysis_crop.PlotLoss(model_file = model_name, loss_train_path = train_loss_file, loss_val_path = val_loss_file, epoch_No = N_epoch)

    write_2_log(time.strftime("%c"))  # time, date of exp
===============
import numpy as np
import torch.nn as nn
import torch
import cv2
from lcn import LecunLCN

LCN_enable = False

def input_filled_mirroring(x, e = 62):      # fill missing data by mirroring the input image
    '''input size 636 --> output size 512'''
    w, h = x.shape
    #e = 62  # extra width on 1 edge
    y = np.zeros((h + e * 2, w + e * 2))
    y[e:h + e, e:w + e] = x
    y[e:e + h, 0:e] = np.flip(y[e:e + h, e:2 * e], 1)  # flip vertically
    y[e:e + h, e + w:2 * e + w] = np.flip(y[e:e + h, w:e + w], 1)  # flip vertically
    y[0:e, 0:2 * e + w] = np.flip(y[e:2 * e, 0:2 * e + w], 0)  # flip horizontally
    y[e + h:2 * e + h, 0:2 * e + w] = np.flip(y[h:e + h, 0:2 * e + w], 0)  # flip horizontally
    return y

def nearest_cells_distance(pos, img):
    # searching in 8 directions to find 2 nearest distances to neighbor cells
    curr_value = img[pos]
    w = img.shape[0];h = img.shape[1]
    count_detect = 0  # detect 2 nearest neighbors. break the search if count_detect = 2
    x, y = pos

    # print("w,h: ", (w, h))
    d1 = 9999999;d2 = 9999999;d3 = 9999999;d4 = 9999999
    d5 = 9999999;d6 = 9999999;d7 = 9999999;d8 = 9999999
    for i in range(1, max(w, h)):
        # (x+1, y), (x+1, y+1), (x+1, y-1),
        # (x, y+1), (x, y-1)
        # (x-1, y), (x-1,y+1), (x-1,y-1),
        if x + i < w:
            if img[(x + i, y)] != curr_value and d1 == 9999999:
                d1 = i; count_detect += 1
            if y + i < h:
                if img[(x + i, y + i)] != curr_value and d2 == 9999999:
                    d2 = i; count_detect += 1
            elif y - i >= 0:
                if img[(x + i, y - i)] != curr_value and d3 == 9999999:
                    d3 = i; count_detect += 1
        if y + i < h:
            if img[(x, y + i)] != curr_value and d4 == 9999999:
                d4 = i; count_detect += 1
        if y - i >= 0:
            if img[(x, y - i)] != curr_value and d5 == 9999999:
                d5 = i; count_detect += 1
        if x - i >= 0:
            if img[(x - i, y)] != curr_value and d6 == 9999999:
                d6 = i; count_detect += 1
            if y + i < h:
                if img[(x - i, y + i)] != curr_value and d7 == 9999999:
                    d7 = i; count_detect += 1
            elif y - i >= 0:
                if img[(x - i, y - i)] != curr_value and d8 == 9999999:
                    d8 = i; count_detect += 1
        if count_detect >= 2: break

    d = [d1, d2, d3, d4, d5, d6, d7, d8]
    min_index = np.argmin(d)
    dist1 = d[min_index]
    d.remove(dist1)
    min_index = np.argmin(d)
    dist2 = d[min_index]
    return dist1, dist2

def create_weight_map(imgs_mask):
        print('-' * 30)
        print('Creating weights for masks ...')
        print('-' * 30)
        weight_map = np.ndarray(
            (len(imgs_mask), 1, np.shape(imgs_mask)[2], np.shape(imgs_mask)[3]), dtype=np.float32)
        w_0 = 10; sigma = 4
        imgs_w, imgs_h = np.shape(imgs_mask)[2], np.shape(imgs_mask)[3]
        total_pixels = imgs_w*imgs_h
        import time
        start = time.time()
        for i in range(len(imgs_mask)):
            if i%10 == 0: print("Done processing: %d images, time passed: %.2f mins" % (i, (time.time() - start)/60.0))
            temp = imgs_mask[i,0,:,:]
            w_border = 1 - np.sum(temp)/total_pixels        # w_c of pixel on the border (black)
            for m in range(imgs_w):
                for n in range(imgs_h):
                    # loop through all pixel of the mask
                    d1,d2 = nearest_cells_distance((m,n), temp)
                    w_c = w_border
                    if temp[m,n] == 0: w_c = 1 - w_border
                    weight_map[i,0,m,n] = w_c*5 + w_0*np.exp(-(d1 + d2)**2/(2*sigma**2))
                    # print("w_0*np.exp(): ", w_0*np.exp(-(d1 + d2)**2/(2*sigma**2)))
                    # print("w_border: ", w_border)

        np.save('data/dataset/weight_map_train.npy', weight_map)

        return weight_map

def load_train_data(npy_path = "data/dataset", hist_equal = False):

    print('-' * 30)
    print('load train images...')

    imgs_train = np.load(npy_path + "/imgs_train.npy")
    imgs_mask_train = np.load(npy_path + "/imgs_mask_train.npy")

    if hist_equal: imgs_train = hist_equalization(imgs_train)

    # weight_map_train = np.load(npy_path + "/weight_map_train.npy")
    # weight_map_train = weight_map_train.astype('float32')

    imgs_train = imgs_train.astype('float32')
    imgs_mask_train = imgs_mask_train.astype('float32')

    if LCN_enable:
        imgs_train = imgs_train.astype('float64')
        imgs_train = LecunLCN(imgs_train, image_shape=imgs_train.shape).output.eval()
        imgs_train = imgs_train.astype('float32')

    if not LCN_enable: imgs_train /= 255

    imgs_train -= imgs_train.mean(axis=0)
    imgs_mask_train /= 255
    imgs_mask_train[imgs_mask_train > 0.5] = 1
    imgs_mask_train[imgs_mask_train <= 0.5] = 0

    # weight_map_train = create_weight_map(imgs_mask_train)

    print("Done loading traing data")
    print('-' * 30)
    return imgs_train, imgs_mask_train

def load_val_data(npy_path = "data/dataset", hist_equal = True):

    print('-' * 30)
    print('load validation images...')

    imgs_train = np.load(npy_path + "/imgs_val.npy")
    imgs_mask_train = np.load(npy_path + "/imgs_mask_val.npy")

    if hist_equal: imgs_train = hist_equalization(imgs_train)

    imgs_train = imgs_train.astype('float32')
    imgs_mask_train = imgs_mask_train.astype('float32')

    if LCN_enable:
        imgs_train = imgs_train.astype('float64')
        imgs_train = LecunLCN(imgs_train, image_shape=imgs_train.shape).output.eval()
        imgs_train = imgs_train.astype('float32')

    if not LCN_enable: imgs_train /= 255
    imgs_train -= imgs_train.mean(axis=0)
    imgs_mask_train /= 255
    imgs_mask_train[imgs_mask_train > 0.5] = 1
    imgs_mask_train[imgs_mask_train <= 0.5] = 0
    print("Done loading validation data")
    print('-' * 30)
    return imgs_train, imgs_mask_train

def load_test_data(npy_path = "data/dataset", hist_equal = True):

    print('-' * 30)
    print('load test images...')

    imgs_test = np.load(npy_path + "/imgs_test.npy")

    if hist_equal: imgs_test = hist_equalization(imgs_test)

    imgs_test = imgs_test.astype('float32')

    if LCN_enable:
        imgs_test = imgs_test.astype('float64')
        imgs_test = LecunLCN(imgs_test, image_shape=imgs_test.shape).output.eval()
        imgs_test = imgs_test.astype('float32')

    if not LCN_enable: imgs_test /= 255

    imgs_test -= imgs_test.mean(axis=0)

    print("Done loading test data")
    print('-' * 30)
    return imgs_test

def load_val_5imgs(npy_path = "data/dataset"):
    print('-' * 30)
    print('load train images...')

    imgs_train = np.load(npy_path + "/imgs_val_5imgs.npy")
    imgs_mask_train = np.load(npy_path + "/imgs_mask_val_5imgs.npy")

    # imgs_train = hist_equalization(imgs_train)

    imgs_train = imgs_train.astype('float64')
    imgs_mask_train = imgs_mask_train.astype('float64')

    if LCN_enable: imgs_train = LecunLCN(imgs_train, image_shape=imgs_train.shape).output.eval()

    if not LCN_enable: imgs_train /= 255

    mean = imgs_train.mean(axis=0)
    imgs_train -= mean


    imgs_mask_train /= 255
    imgs_mask_train[imgs_mask_train > 0.5] = 1
    imgs_mask_train[imgs_mask_train <= 0.5] = 0

    # weight_map_train = self.create_weight_map(imgs_mask_train)

    print("Done loading traing data")
    print('-' * 30)
    return imgs_train, imgs_mask_train

def hist_equalization(inputs):      # inputs are uint8, 0-255, Nx1x636x636
    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))
    output = inputs.copy()
    for i in range(len(inputs)):
        img = inputs[i, 0, :, :]
        # res = cv2.equalizeHist(img)
        res = clahe.apply(img)
        output[i,0,:,:] = res
    return output

### BinaryCrossEntropyLoss2d().forward(logits, labels)
class BinaryCrossEntropyLoss2d(nn.Module):
    def __init__(self, weight=None, size_average=True):
        """
        Binary cross entropy loss 2D
        Args:
            weight:
            size_average:
        """
        super(BinaryCrossEntropyLoss2d, self).__init__()
        self.bce_loss = nn.BCELoss(weight, size_average)

    def forward(self, logits, targets):
        # probs = F.sigmoid(logits)
        probs = logits
        probs_flat = probs.view(-1)  # Flatten
        targets_flat = targets.view(-1)  # Flatten
        return self.bce_loss(probs_flat, targets_flat)      # (output, labels)

class BCE_with_Weights(nn.Module):
    def __init__(self, weights=None):
        """
        Binary cross entropy loss 2D
        Args:
            weights:
        """
        super(BCE_with_Weights, self).__init__()
        self.weights = weights

    def forward(self, output, target):
        if self.weights is not None:
            loss = self.weights * (target * torch.log(output) + (1 - target) * torch.log(1 - output))
        else:
            loss = target * torch.log(output) + (1 - target) * torch.log(1 - output)

        return torch.neg(torch.mean(loss))

class LRN(nn.Module):       # input x is Torch tensor
    def __init__(self, local_size=1, alpha=1.0, beta=0.75, ACROSS_CHANNELS=False):      #LRN(local_size=5, alpha=0.0001, beta=0.75),
        super(LRN, self).__init__()
        self.ACROSS_CHANNELS = ACROSS_CHANNELS
        if self.ACROSS_CHANNELS:
            self.average = nn.AvgPool3d(kernel_size=(local_size, 1, 1),
                                        stride=1, padding=(int((local_size - 1.0) / 2), 0, 0))
        else:
            self.average = nn.AvgPool2d(kernel_size=local_size,
                                        stride=1, padding=int((local_size - 1.0) / 2))
        self.alpha = alpha
        self.beta = beta

    def forward(self, x):
        if self.ACROSS_CHANNELS:
            div = x.pow(2).unsqueeze(1)
            div = self.average(div).squeeze(1)
            div = div.mul(self.alpha).add(1.0).pow(self.beta)
        else:
            div = x.pow(2)
            div = self.average(div)
            div = div.mul(self.alpha).add(1.0).pow(self.beta)
        x = x.div(div)
        return x
Sat Nov 25 01:50:30 2017
Leg22_CROP_dropout_0_2_rmSigmoid_20aug_10ela_3inten_reflect
optim.SGD(net.parameters(), lr=1e-2, momentum=0.99)
Number of epoch max: 6
Epoch 1: Train loss: 0.495097, Val loss: 0.419310
Epoch 2: Train loss: 0.436213, Val loss: 0.438592
Epoch 3: Train loss: 0.509407, Val loss: 0.579153
Epoch 4: Train loss: 0.502864, Val loss: 0.436299
Epoch 5: Train loss: 0.501558, Val loss: 0.422656
Epoch 6: Train loss: 0.424863, Val loss: 0.426105
Best model at epoch: 5
Total training time: 0.0245654241906
Sat Nov 25 01:51:28 2017
==========================================================================================
Sat Nov 25 01:55:36 2017
Leg22_CROP_dropout_0_2_rmSigmoid_20aug_10ela_3inten_reflect
Sat Nov 25 01:55:34 2017
import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.autograd import Variable
import math


class ConvBnRelu(nn.Module):
    def __init__(self, in_channels, out_channels, kernel_size, padding, stride):
        super(ConvBnRelu, self).__init__()
        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=kernel_size, padding=padding, stride=stride)
        self.bn = nn.BatchNorm2d(out_channels)
        self.relu = nn.ReLU()

    def forward(self, x):
        x = self.conv(x)
        # x = self.bn(x)
        x = self.relu(x)
        return x


class StackEncoder(nn.Module):
    def __init__(self, in_channels, out_channels):
        super(StackEncoder, self).__init__()
        self.convr1 = ConvBnRelu(in_channels, out_channels, kernel_size=(3, 3), stride=1, padding=0)
        self.convr2 = ConvBnRelu(out_channels, out_channels, kernel_size=(3, 3), stride=1, padding=0)
        self.maxPool = nn.MaxPool2d(kernel_size=(2, 2), stride=2)

    def forward(self, x):
        x = self.convr1(x)
        x = self.convr2(x)
        x_trace = x             # save x to use in concat in the Decoder path
        out = self.maxPool(x)
        return out, x_trace


class StackDecoder(nn.Module):
    def __init__(self, in_channels, out_channels, padding = 0, drop_out=False):
        super(StackDecoder, self).__init__()

        self.drop_out = drop_out
        self.dropout_layer = nn.Dropout2d(p=0.5)

        ''' this is old version
        self.upSample = nn.Upsample(size=upsample_size, scale_factor=(2, 2), mode="bilinear")
        self.convr1 = ConvBnRelu(in_channels, out_channels, kernel_size=(3, 3), stride=1, padding=padding)
        # Crop + concat step between these 2
        self.convr2 = ConvBnRelu(in_channels, out_channels, kernel_size=(3, 3), stride=1, padding=padding)
        '''
        self.upSample = nn.ConvTranspose2d(in_channels, out_channels, 2, stride=2)
        self.convr1 = ConvBnRelu(in_channels, out_channels, kernel_size=(3, 3), stride=1, padding=padding)
        self.convr2 = ConvBnRelu(out_channels, out_channels, kernel_size=(3, 3), stride=1, padding=padding)

    def _crop_concat(self, upsampled, bypass):
        """
         Crop y to the (h, w) of x and concat them.
         Used for the expansive path.
        Returns:
            The concatenated tensor
        """
        c = (bypass.size()[2] - upsampled.size()[2]) // 2
        bypass = F.pad(bypass, (-c, -c, -c, -c))

        return torch.cat((bypass, upsampled), 1)

    def forward(self, x, down_tensor):
        '''old version
        x = self.upSample(x)
        x = self.convr1(x)
        x = self._crop_concat(x, down_tensor)
        x = self.convr2(x)
        '''

        x = self.upSample(x)
        x = self._crop_concat(x, down_tensor)
        x = self.convr1(x)
        if self.drop_out: x = self.dropout_layer(x)
        x = self.convr2(x)
        if self.drop_out: x = self.dropout_layer(x)
        return x


class UNET_CROP(nn.Module):
    def __init__(self):
        super(UNET_CROP, self).__init__()
        # channels, height, width = in_shape

        # self.dropout = dropout

        self.model_code = ""        # variable to save model and main function when loaded

        self.down1 = StackEncoder(1, 64)
        self.down2 = StackEncoder(64, 128)
        self.down3 = StackEncoder(128, 256)
        self.down4 = StackEncoder(256, 512)

        self.center = nn.Sequential(
            # nn.Dropout2d(p=0.2),
            ConvBnRelu(512, 1024, kernel_size=(3, 3), stride=1, padding=0),
            nn.Dropout2d(p=0.2),
            ConvBnRelu(1024, 1024, kernel_size=(3, 3), stride=1, padding=0),
            nn.Dropout2d(p=0.2)
        )

        self.up1 = StackDecoder(in_channels=1024, out_channels=512)
        self.up2 = StackDecoder(in_channels=512, out_channels=256)
        self.up3 = StackDecoder(in_channels=256, out_channels=128)
        self.up4 = StackDecoder(in_channels=128, out_channels=64)

        # 1x1 convolution at the last layer
        # Different from the paper is the output size here
        self.output_seg_map = nn.Conv2d(64, 1, kernel_size=(1, 1), padding=0, stride=1)

        self._initialize_weights()

    def forward(self, x):
        x, x_trace1 = self.down1(x)
        x, x_trace2 = self.down2(x)
        x, x_trace3 = self.down3(x)
        x, x_trace4 = self.down4(x)
        x = self.center(x)
        x = self.up1(x, x_trace4)
        x = self.up2(x, x_trace3)
        x = self.up3(x, x_trace2)
        x = self.up4(x, x_trace1)

        x = self.output_seg_map(x)
        # x = F.sigmoid(x)
        # out = torch.squeeze(out, dim=1)
        return x


    def _initialize_weights(self):
        for m in self.modules():
            if isinstance(m, nn.Conv2d):
                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels
                m.weight.data.normal_(0, math.sqrt(2. / n))
                if m.bias is not None:
                    m.bias.data.zero_()
            elif isinstance(m, nn.BatchNorm2d):
                m.weight.data.fill_(1)
                m.bias.data.zero_()

# x = Variable(torch.randn(1,1,700, 700))       # simulate input image
# net = UNET_CROP()
# out = net(x)
# print("input: ", x)
# print("output: ", out)
===============from __future__ import print_function, division
import torch
from torch import optim
from torch.autograd import Variable
from torch.utils.data import DataLoader
import numpy as np
import torch.nn as nn
import torch.nn.functional as F
import Unet_crop
import tifffile as tiff
import Utils
import time
from sklearn.metrics import average_precision_score, recall_score, f1_score
import Analysis_crop
import cv2

def to_var(x):
    if torch.cuda.is_available():
        return Variable(x.cuda())
    else:
        return Variable(x)

### BinaryCrossEntropyLoss2d().forward(logits, labels)
class BinaryCrossEntropyLoss2d(nn.Module):
    def __init__(self, weight=None, size_average=True):
        """
        Binary cross entropy loss 2D
        Args:
            weight:
            size_average:
        """
        super(BinaryCrossEntropyLoss2d, self).__init__()
        self.bce_loss = nn.BCELoss(weight, size_average)

    def forward(self, probs, targets):
        probs = F.sigmoid(probs)
        probs_flat = probs.view(-1)  # Flatten
        targets_flat = targets.view(-1)  # Flatten
        return self.bce_loss(probs_flat, targets_flat)      # (output, labels)

def NetEval(net,valdata_loader,crit):
    loss = 0.
    count = 0
    net.eval()
    crop_input, crop_label,_ = crop_info()
    for i,data in enumerate(valdata_loader,0):
        # if i > 10: break
        inputs, labels = data
        # inputs = inputs.numpy()
        # labels = labels.numpy()
        for j in range(len(crop_input)):  # training on the crop images and corresponding labels
            ci = crop_input[j]  # crop index for inputs
            cl = crop_label[j]  # crop index for lables
            # temp = labels[0, 0, :, :]  # labels is numpy array 512x512
            # if np.sum(temp) < 0.01 * np.shape(temp)[0] * np.shape(temp)[1]: break
            x = inputs.numpy()[:, :, ci[0]:ci[0] + 572, ci[1]:ci[1] + 572]
            y = labels.numpy()[:, :, cl[0]: cl[0] + 388, cl[1]:cl[1] + 388]
            x = torch.from_numpy(x)
            y = torch.from_numpy(y)
            x, y = to_var(x), to_var(y)
            out = net(x)
            l = crit(out, y)
            loss += l.data[0]
            count += 1
    return loss/count

#process the test data and save to separate .tif image
def NetTest(net,testdata_loader,path = "data/results/"):
    net.eval()
    crop_input, crop_label, average_mask = crop_info()
    for i, data in enumerate(testdata_loader, 0):
        if i >= 30: return 1        # for debug
        # data = to_var(data)
        img_shape = 512
        img = np.zeros((img_shape, img_shape))
        for j in range(len(crop_input)):  # training on the crop images and corresponding labels
            temp = np.zeros((img_shape, img_shape))
            ci = crop_input[j]  # crop index for inputs
            cl = crop_label[j]
            x = data.numpy()[:, :, ci[0]:ci[0] + 572, ci[1]:ci[1] + 572]
            x = torch.from_numpy(x)
            x = to_var(x)
            out = F.sigmoid(net(x))
            out = out.cpu()
            out = out[0,0,:,:]
            # print("j: ", j)
            # print("size of temp: ", np.shape(temp))
            # print("size of output: ", np.shape(out.data.numpy()))
            temp[cl[0]: cl[0] + 388, cl[1]:cl[1] + 388] = out.data.numpy()
            img += temp

        img = img/average_mask
        img = img.reshape(-1)
        img[img < 0.5] = 0; img[img >= 0.5] = 1
        img = img.reshape(img_shape, img_shape)
        img = np.uint8(img * 255)
        imgname = path + str(i) + ".tif"
        tiff.imsave(imgname, img)

# return input image size like 512x512, numpy array
def NetPredict(net, input_image):
    net.eval()
    _, crop_label, average_mask = crop_info()

    # input_image is grayscale input image of 512x512
    data = Utils.input_filled_mirroring(input_image, e = 94)
    imgdatas = np.ndarray((1, 1, data.shape[0], data.shape[1]), dtype=np.uint8)
    imgdatas[0] = np.expand_dims(data, 0)
    data = Utils.hist_equalization(imgdatas)
    data = data.astype('float32')
    data /= 255
    data -= data.mean(axis=0)

    img_shape = input_image.shape
    img = np.zeros((img_shape, img_shape))
    for j in range(len(crop_input)):  # training on the crop images and corresponding labels
        temp = np.zeros((img_shape, img_shape))
        ci = crop_input[j]  # crop index for inputs
        cl = crop_label[j]
        x = data.numpy()[:, :, ci[0]:ci[0] + 572, ci[1]:ci[1] + 572]
        x = torch.from_numpy(x)
        x = to_var(x)
        out = F.sigmoid(net(x))
        out = out.cpu()
        out = out[0, 0, :, :]
        temp[cl[0]: cl[0] + 388, cl[1]:cl[1] + 388] = out.data.numpy()
        img += temp

    img = img / average_mask
    img = img.reshape(-1)
    img[img < 0.5] = 0
    img[img >= 0.5] = 1
    img = img.reshape(img_shape)
    img = np.uint8(img * 255)
    return img


def write_2_log(content):
    path = "log_file.txt"
    output = open(path, "a")
    output.write("\n")
    output.write(content)
    output.close()

def crop_info():
    crop_input = [[0, 0], [128, 0], [0, 128], [128, 128]]
    crop_label = [[0, 0], [124, 0], [0, 124], [124, 124]]
    average_mask = np.ones((512, 512))
    average_mask[124:388, 0:124] = 2
    average_mask[0:124, 124:388] = 2
    average_mask[124:388, 388:512] = 2
    average_mask[388:512, 124:388] = 2
    average_mask[124:388, 124:388] = 4
    return crop_input, crop_label, average_mask

if __name__ == '__main__':
    '''subjects to change for each exp:
    + path to the dataset
    + opt function
    + leg description
    + N_epoch
    + saved_model
    '''
    start_begining = time.time()

    # path = "data/dataset"
    path = "/home/anhxtuan/HanLe/dataset/20aug_10ela_3inten_reflect"
    path = "/home/anhxtuan/HanLe/dataset/20aug_10ela_3inten_reflect_700"

    import os
    print("Does the folder exist?: ", os.path.isdir(path))
    print("Does the path exist?: ", os.path.exists(path))

    imgs_train, imgs_mask_train = Utils.load_train_data(npy_path=path)
    imgs_val, imgs_mask_val = Utils.load_val_data(npy_path=path)
    batch_size = 1
    trainset = zip(imgs_train, imgs_mask_train)
    trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,
                                              shuffle=True, num_workers=2)
    valset = zip(imgs_val, imgs_mask_val)
    valloader = torch.utils.data.DataLoader(valset, batch_size=batch_size,
                                              shuffle=False, num_workers=2)
    # net = Unet.UNet()                     # Unet 1
    # net = Unet_BatchNorm.UNet_BN()          # Unet 2 with batchNorm
    net = Unet_crop.UNET_CROP()

    f1 = open("Unet_crop.py", 'r')     # embede code into the model to be saved later
    f2 = open("UnetTrain_crop.py", 'r')
    f3 = open("Utils.py", 'r')
    model_notes = time.strftime("%c") + "\n" + f1.read() + "\n" + "==="*5 + f2.read() + "\n" + "==="*5 + f3.read()
    f1.close()
    f2.close()
    f3.close()

    criterion = BinaryCrossEntropyLoss2d()
    # criterion = SoftDiceLoss()
    # criterion = nn.BCELoss()

    if torch.cuda.is_available():
        # torch.set_default_tensor_type('torch.cuda.FloatTensor')
        # net.load_state_dict(torch.load("Unet2_model_12epoch_Leg12_droput_0_2_rmSigmoid_20aug_10ela_3inten_reflect"))
        net.cuda()
        # criterion.cuda()

    opt = optim.SGD(net.parameters(), lr=1e-2, momentum=0.99)       # subject to change
    # opt = optim.RMSprop(net.parameters(), lr=2e-4)
    # RMSprop[22](learning rate 0.001) with weight decay set to 0.001.
    # opt = optim.Adam(net.parameters(), lr=1e-3, weight_decay=1e-4)

    train_loss = []
    val_loss = []

    print("[epoch, #image] Loss")
    leg = "Leg22_CROP_dropout_0_2_rmSigmoid_20aug_10ela_3inten_reflect"
    print("Processing: ", leg)
    model_name = ""

    N_epoch = 6
    model_saved = np.arange(2,N_epoch+1,2)
    val_loss_min = 100

    write_2_log("==="*30)
    write_2_log(time.strftime("%c"))       # time, date of exp
    write_2_log(leg)
    write_2_log(model_notes)
    write_2_log(time.strftime("%c"))  # time, date of exp
    write_2_log(leg)
    write_2_log("optim.SGD(net.parameters(), lr=1e-2, momentum=0.99)")
    write_2_log("Number of epoch max: " + str(N_epoch))

    crop_input, crop_label,_ = crop_info()
    min_model_epoch = 0
    for epoch in range(N_epoch):
        running_loss = 0.0; count = 0
        net.train()
        for i, data in enumerate(trainloader, 0):
            # if i > 10: break

            inputs, labels = data
            temp = labels.numpy()
            for j in range(len(crop_input)):       # training on the crop images and corresponding labels
                ci = crop_input[j]          # crop index for inputs
                cl = crop_label[j]          # crop index for lables
                # temp = temp[0, 0, :, :]  # labels is numpy array 512x512
                # if np.sum(temp) < 0.01 * np.shape(temp)[0] * np.shape(temp)[1]: break
                x = inputs.numpy()[:, :, ci[0]:ci[0] + 572, ci[1]:ci[1] + 572]
                y = labels.numpy()[:, :, cl[0]: cl[0] + 388, cl[1]:cl[1] + 388]
                x = torch.from_numpy(x)
                y = torch.from_numpy(y)
                x, y = to_var(x), to_var(y)
                opt.zero_grad()
                out = net(x)
                loss = criterion(out, y)
                loss.backward()
                opt.step()
                running_loss += loss.data[0]
                count += 1

        net.eval()
        val_loss_temp = NetEval(net, valloader, criterion)
        if epoch > 0 and val_loss_temp < val_loss_min:        # save the model which has the lowest val_loss, ignore first epoch
            val_loss_min = val_loss_temp
            torch.save(net.state_dict(), "Unet2_model_" + leg + "_min_val_loss")  # save model
            min_model_epoch = epoch + 1

        disp = 'Epoch %d: Train loss: %.6f, Val loss: %.6f' % (epoch + 1, running_loss/count, val_loss_temp)
        write_2_log(disp)
        print(disp)
        val_loss.append(val_loss_temp)
        train_loss.append(running_loss/count); running_loss = 0.0

        if (epoch + 1) in model_saved or epoch == 0:        # save checkpoint
            model_name = "Unet2_model_" + str(epoch+1) + "epoch_" + leg
            torch.save(net.state_dict(), model_name)  # save model
            Analysis_crop.analysis(model_file = model_name, valloader = valloader)

    write_2_log("Best model at epoch: " + str(min_model_epoch))
    write_2_log("Total training time: " + str((time.time() - start_begining) / 3600.0))

    val_loss_file = "data/results" + "/val_loss_" + str(N_epoch) + "epoch_" + leg + ".npy"
    train_loss_file = "data/results" + "/training_loss_" + str(N_epoch) + "epoch_" + leg + ".npy"

    np.save(val_loss_file, val_loss)
    np.save(train_loss_file, train_loss)
    print("total processing time in seconds: ", time.time() - start_begining)
    print("total processing time in mins: ", (time.time() - start_begining) / 60.0)
    print("total processing time in hours: ", (time.time() - start_begining) / 3600.0)

    # Analysis.analysis(model_file="Unet2_model_" + leg + "_min_val_loss", valloader=valloader)

    Analysis_crop.PlotLoss(model_file = model_name, loss_train_path = train_loss_file, loss_val_path = val_loss_file, epoch_No = N_epoch)

    write_2_log(time.strftime("%c"))  # time, date of exp
===============
import numpy as np
import torch.nn as nn
import torch
import cv2
from lcn import LecunLCN

LCN_enable = False

def input_filled_mirroring(x, e = 62):      # fill missing data by mirroring the input image
    '''input size 636 --> output size 512'''
    w, h = x.shape
    #e = 62  # extra width on 1 edge
    y = np.zeros((h + e * 2, w + e * 2))
    y[e:h + e, e:w + e] = x
    y[e:e + h, 0:e] = np.flip(y[e:e + h, e:2 * e], 1)  # flip vertically
    y[e:e + h, e + w:2 * e + w] = np.flip(y[e:e + h, w:e + w], 1)  # flip vertically
    y[0:e, 0:2 * e + w] = np.flip(y[e:2 * e, 0:2 * e + w], 0)  # flip horizontally
    y[e + h:2 * e + h, 0:2 * e + w] = np.flip(y[h:e + h, 0:2 * e + w], 0)  # flip horizontally
    return y

def nearest_cells_distance(pos, img):
    # searching in 8 directions to find 2 nearest distances to neighbor cells
    curr_value = img[pos]
    w = img.shape[0];h = img.shape[1]
    count_detect = 0  # detect 2 nearest neighbors. break the search if count_detect = 2
    x, y = pos

    # print("w,h: ", (w, h))
    d1 = 9999999;d2 = 9999999;d3 = 9999999;d4 = 9999999
    d5 = 9999999;d6 = 9999999;d7 = 9999999;d8 = 9999999
    for i in range(1, max(w, h)):
        # (x+1, y), (x+1, y+1), (x+1, y-1),
        # (x, y+1), (x, y-1)
        # (x-1, y), (x-1,y+1), (x-1,y-1),
        if x + i < w:
            if img[(x + i, y)] != curr_value and d1 == 9999999:
                d1 = i; count_detect += 1
            if y + i < h:
                if img[(x + i, y + i)] != curr_value and d2 == 9999999:
                    d2 = i; count_detect += 1
            elif y - i >= 0:
                if img[(x + i, y - i)] != curr_value and d3 == 9999999:
                    d3 = i; count_detect += 1
        if y + i < h:
            if img[(x, y + i)] != curr_value and d4 == 9999999:
                d4 = i; count_detect += 1
        if y - i >= 0:
            if img[(x, y - i)] != curr_value and d5 == 9999999:
                d5 = i; count_detect += 1
        if x - i >= 0:
            if img[(x - i, y)] != curr_value and d6 == 9999999:
                d6 = i; count_detect += 1
            if y + i < h:
                if img[(x - i, y + i)] != curr_value and d7 == 9999999:
                    d7 = i; count_detect += 1
            elif y - i >= 0:
                if img[(x - i, y - i)] != curr_value and d8 == 9999999:
                    d8 = i; count_detect += 1
        if count_detect >= 2: break

    d = [d1, d2, d3, d4, d5, d6, d7, d8]
    min_index = np.argmin(d)
    dist1 = d[min_index]
    d.remove(dist1)
    min_index = np.argmin(d)
    dist2 = d[min_index]
    return dist1, dist2

def create_weight_map(imgs_mask):
        print('-' * 30)
        print('Creating weights for masks ...')
        print('-' * 30)
        weight_map = np.ndarray(
            (len(imgs_mask), 1, np.shape(imgs_mask)[2], np.shape(imgs_mask)[3]), dtype=np.float32)
        w_0 = 10; sigma = 4
        imgs_w, imgs_h = np.shape(imgs_mask)[2], np.shape(imgs_mask)[3]
        total_pixels = imgs_w*imgs_h
        import time
        start = time.time()
        for i in range(len(imgs_mask)):
            if i%10 == 0: print("Done processing: %d images, time passed: %.2f mins" % (i, (time.time() - start)/60.0))
            temp = imgs_mask[i,0,:,:]
            w_border = 1 - np.sum(temp)/total_pixels        # w_c of pixel on the border (black)
            for m in range(imgs_w):
                for n in range(imgs_h):
                    # loop through all pixel of the mask
                    d1,d2 = nearest_cells_distance((m,n), temp)
                    w_c = w_border
                    if temp[m,n] == 0: w_c = 1 - w_border
                    weight_map[i,0,m,n] = w_c*5 + w_0*np.exp(-(d1 + d2)**2/(2*sigma**2))
                    # print("w_0*np.exp(): ", w_0*np.exp(-(d1 + d2)**2/(2*sigma**2)))
                    # print("w_border: ", w_border)

        np.save('data/dataset/weight_map_train.npy', weight_map)

        return weight_map

def load_train_data(npy_path = "data/dataset", hist_equal = False):

    print('-' * 30)
    print('load train images...')

    imgs_train = np.load(npy_path + "/imgs_train.npy")
    imgs_mask_train = np.load(npy_path + "/imgs_mask_train.npy")

    if hist_equal: imgs_train = hist_equalization(imgs_train)

    # weight_map_train = np.load(npy_path + "/weight_map_train.npy")
    # weight_map_train = weight_map_train.astype('float32')

    imgs_train = imgs_train.astype('float32')
    imgs_mask_train = imgs_mask_train.astype('float32')

    if LCN_enable:
        imgs_train = imgs_train.astype('float64')
        imgs_train = LecunLCN(imgs_train, image_shape=imgs_train.shape).output.eval()
        imgs_train = imgs_train.astype('float32')

    if not LCN_enable: imgs_train /= 255

    imgs_train -= imgs_train.mean(axis=0)
    imgs_mask_train /= 255
    imgs_mask_train[imgs_mask_train > 0.5] = 1
    imgs_mask_train[imgs_mask_train <= 0.5] = 0

    # weight_map_train = create_weight_map(imgs_mask_train)

    print("Done loading traing data")
    print('-' * 30)
    return imgs_train, imgs_mask_train

def load_val_data(npy_path = "data/dataset", hist_equal = True):

    print('-' * 30)
    print('load validation images...')

    imgs_train = np.load(npy_path + "/imgs_val.npy")
    imgs_mask_train = np.load(npy_path + "/imgs_mask_val.npy")

    if hist_equal: imgs_train = hist_equalization(imgs_train)

    imgs_train = imgs_train.astype('float32')
    imgs_mask_train = imgs_mask_train.astype('float32')

    if LCN_enable:
        imgs_train = imgs_train.astype('float64')
        imgs_train = LecunLCN(imgs_train, image_shape=imgs_train.shape).output.eval()
        imgs_train = imgs_train.astype('float32')

    if not LCN_enable: imgs_train /= 255
    imgs_train -= imgs_train.mean(axis=0)
    imgs_mask_train /= 255
    imgs_mask_train[imgs_mask_train > 0.5] = 1
    imgs_mask_train[imgs_mask_train <= 0.5] = 0
    print("Done loading validation data")
    print('-' * 30)
    return imgs_train, imgs_mask_train

def load_test_data(npy_path = "data/dataset", hist_equal = True):

    print('-' * 30)
    print('load test images...')

    imgs_test = np.load(npy_path + "/imgs_test.npy")

    if hist_equal: imgs_test = hist_equalization(imgs_test)

    imgs_test = imgs_test.astype('float32')

    if LCN_enable:
        imgs_test = imgs_test.astype('float64')
        imgs_test = LecunLCN(imgs_test, image_shape=imgs_test.shape).output.eval()
        imgs_test = imgs_test.astype('float32')

    if not LCN_enable: imgs_test /= 255

    imgs_test -= imgs_test.mean(axis=0)

    print("Done loading test data")
    print('-' * 30)
    return imgs_test

def load_val_5imgs(npy_path = "data/dataset"):
    print('-' * 30)
    print('load train images...')

    imgs_train = np.load(npy_path + "/imgs_val_5imgs.npy")
    imgs_mask_train = np.load(npy_path + "/imgs_mask_val_5imgs.npy")

    # imgs_train = hist_equalization(imgs_train)

    imgs_train = imgs_train.astype('float64')
    imgs_mask_train = imgs_mask_train.astype('float64')

    if LCN_enable: imgs_train = LecunLCN(imgs_train, image_shape=imgs_train.shape).output.eval()

    if not LCN_enable: imgs_train /= 255

    mean = imgs_train.mean(axis=0)
    imgs_train -= mean


    imgs_mask_train /= 255
    imgs_mask_train[imgs_mask_train > 0.5] = 1
    imgs_mask_train[imgs_mask_train <= 0.5] = 0

    # weight_map_train = self.create_weight_map(imgs_mask_train)

    print("Done loading traing data")
    print('-' * 30)
    return imgs_train, imgs_mask_train

def hist_equalization(inputs):      # inputs are uint8, 0-255, Nx1x636x636
    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))
    output = inputs.copy()
    for i in range(len(inputs)):
        img = inputs[i, 0, :, :]
        # res = cv2.equalizeHist(img)
        res = clahe.apply(img)
        output[i,0,:,:] = res
    return output

### BinaryCrossEntropyLoss2d().forward(logits, labels)
class BinaryCrossEntropyLoss2d(nn.Module):
    def __init__(self, weight=None, size_average=True):
        """
        Binary cross entropy loss 2D
        Args:
            weight:
            size_average:
        """
        super(BinaryCrossEntropyLoss2d, self).__init__()
        self.bce_loss = nn.BCELoss(weight, size_average)

    def forward(self, logits, targets):
        # probs = F.sigmoid(logits)
        probs = logits
        probs_flat = probs.view(-1)  # Flatten
        targets_flat = targets.view(-1)  # Flatten
        return self.bce_loss(probs_flat, targets_flat)      # (output, labels)

class BCE_with_Weights(nn.Module):
    def __init__(self, weights=None):
        """
        Binary cross entropy loss 2D
        Args:
            weights:
        """
        super(BCE_with_Weights, self).__init__()
        self.weights = weights

    def forward(self, output, target):
        if self.weights is not None:
            loss = self.weights * (target * torch.log(output) + (1 - target) * torch.log(1 - output))
        else:
            loss = target * torch.log(output) + (1 - target) * torch.log(1 - output)

        return torch.neg(torch.mean(loss))

class LRN(nn.Module):       # input x is Torch tensor
    def __init__(self, local_size=1, alpha=1.0, beta=0.75, ACROSS_CHANNELS=False):      #LRN(local_size=5, alpha=0.0001, beta=0.75),
        super(LRN, self).__init__()
        self.ACROSS_CHANNELS = ACROSS_CHANNELS
        if self.ACROSS_CHANNELS:
            self.average = nn.AvgPool3d(kernel_size=(local_size, 1, 1),
                                        stride=1, padding=(int((local_size - 1.0) / 2), 0, 0))
        else:
            self.average = nn.AvgPool2d(kernel_size=local_size,
                                        stride=1, padding=int((local_size - 1.0) / 2))
        self.alpha = alpha
        self.beta = beta

    def forward(self, x):
        if self.ACROSS_CHANNELS:
            div = x.pow(2).unsqueeze(1)
            div = self.average(div).squeeze(1)
            div = div.mul(self.alpha).add(1.0).pow(self.beta)
        else:
            div = x.pow(2)
            div = self.average(div)
            div = div.mul(self.alpha).add(1.0).pow(self.beta)
        x = x.div(div)
        return x
Sat Nov 25 01:55:36 2017
Leg22_CROP_dropout_0_2_rmSigmoid_20aug_10ela_3inten_reflect
optim.SGD(net.parameters(), lr=1e-2, momentum=0.99)
Number of epoch max: 6
Epoch 1: Train loss: 0.534950, Val loss: 0.522429
==========================================================================================
Sat Nov 25 03:04:23 2017
Leg22_CROP_dropout_0_2_rmSigmoid_20aug_10ela_3inten_reflect
Sat Nov 25 03:04:21 2017
import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.autograd import Variable
import math


class ConvBnRelu(nn.Module):
    def __init__(self, in_channels, out_channels, kernel_size, padding, stride):
        super(ConvBnRelu, self).__init__()
        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=kernel_size, padding=padding, stride=stride)
        self.bn = nn.BatchNorm2d(out_channels)
        self.relu = nn.ReLU()

    def forward(self, x):
        x = self.conv(x)
        # x = self.bn(x)
        x = self.relu(x)
        return x


class StackEncoder(nn.Module):
    def __init__(self, in_channels, out_channels):
        super(StackEncoder, self).__init__()
        self.convr1 = ConvBnRelu(in_channels, out_channels, kernel_size=(3, 3), stride=1, padding=0)
        self.convr2 = ConvBnRelu(out_channels, out_channels, kernel_size=(3, 3), stride=1, padding=0)
        self.maxPool = nn.MaxPool2d(kernel_size=(2, 2), stride=2)

    def forward(self, x):
        x = self.convr1(x)
        x = self.convr2(x)
        x_trace = x             # save x to use in concat in the Decoder path
        out = self.maxPool(x)
        return out, x_trace


class StackDecoder(nn.Module):
    def __init__(self, in_channels, out_channels, padding = 0, drop_out=False):
        super(StackDecoder, self).__init__()

        self.drop_out = drop_out
        self.dropout_layer = nn.Dropout2d(p=0.5)

        ''' this is old version
        self.upSample = nn.Upsample(size=upsample_size, scale_factor=(2, 2), mode="bilinear")
        self.convr1 = ConvBnRelu(in_channels, out_channels, kernel_size=(3, 3), stride=1, padding=padding)
        # Crop + concat step between these 2
        self.convr2 = ConvBnRelu(in_channels, out_channels, kernel_size=(3, 3), stride=1, padding=padding)
        '''
        self.upSample = nn.ConvTranspose2d(in_channels, out_channels, 2, stride=2)
        self.convr1 = ConvBnRelu(in_channels, out_channels, kernel_size=(3, 3), stride=1, padding=padding)
        self.convr2 = ConvBnRelu(out_channels, out_channels, kernel_size=(3, 3), stride=1, padding=padding)

    def _crop_concat(self, upsampled, bypass):
        """
         Crop y to the (h, w) of x and concat them.
         Used for the expansive path.
        Returns:
            The concatenated tensor
        """
        c = (bypass.size()[2] - upsampled.size()[2]) // 2
        bypass = F.pad(bypass, (-c, -c, -c, -c))

        return torch.cat((bypass, upsampled), 1)

    def forward(self, x, down_tensor):
        '''old version
        x = self.upSample(x)
        x = self.convr1(x)
        x = self._crop_concat(x, down_tensor)
        x = self.convr2(x)
        '''

        x = self.upSample(x)
        x = self._crop_concat(x, down_tensor)
        x = self.convr1(x)
        if self.drop_out: x = self.dropout_layer(x)
        x = self.convr2(x)
        if self.drop_out: x = self.dropout_layer(x)
        return x


class UNET_CROP(nn.Module):
    def __init__(self):
        super(UNET_CROP, self).__init__()
        # channels, height, width = in_shape

        # self.dropout = dropout

        self.model_code = ""        # variable to save model and main function when loaded

        self.down1 = StackEncoder(1, 64)
        self.down2 = StackEncoder(64, 128)
        self.down3 = StackEncoder(128, 256)
        self.down4 = StackEncoder(256, 512)

        self.center = nn.Sequential(
            # nn.Dropout2d(p=0.2),
            ConvBnRelu(512, 1024, kernel_size=(3, 3), stride=1, padding=0),
            nn.Dropout2d(p=0.2),
            ConvBnRelu(1024, 1024, kernel_size=(3, 3), stride=1, padding=0),
            nn.Dropout2d(p=0.2)
        )

        self.up1 = StackDecoder(in_channels=1024, out_channels=512)
        self.up2 = StackDecoder(in_channels=512, out_channels=256)
        self.up3 = StackDecoder(in_channels=256, out_channels=128)
        self.up4 = StackDecoder(in_channels=128, out_channels=64)

        # 1x1 convolution at the last layer
        # Different from the paper is the output size here
        self.output_seg_map = nn.Conv2d(64, 1, kernel_size=(1, 1), padding=0, stride=1)

        self._initialize_weights()

    def forward(self, x):
        x, x_trace1 = self.down1(x)
        x, x_trace2 = self.down2(x)
        x, x_trace3 = self.down3(x)
        x, x_trace4 = self.down4(x)
        x = self.center(x)
        x = self.up1(x, x_trace4)
        x = self.up2(x, x_trace3)
        x = self.up3(x, x_trace2)
        x = self.up4(x, x_trace1)

        x = self.output_seg_map(x)
        # x = F.sigmoid(x)
        # out = torch.squeeze(out, dim=1)
        return x


    def _initialize_weights(self):
        for m in self.modules():
            if isinstance(m, nn.Conv2d):
                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels
                m.weight.data.normal_(0, math.sqrt(2. / n))
                if m.bias is not None:
                    m.bias.data.zero_()
            elif isinstance(m, nn.BatchNorm2d):
                m.weight.data.fill_(1)
                m.bias.data.zero_()

# x = Variable(torch.randn(1,1,700, 700))       # simulate input image
# net = UNET_CROP()
# out = net(x)
# print("input: ", x)
# print("output: ", out)
===============from __future__ import print_function, division
import torch
from torch import optim
from torch.autograd import Variable
from torch.utils.data import DataLoader
import numpy as np
import torch.nn as nn
import torch.nn.functional as F
import Unet_crop
import tifffile as tiff
import Utils
import time
from sklearn.metrics import average_precision_score, recall_score, f1_score
import Analysis_crop
import cv2

def to_var(x):
    if torch.cuda.is_available():
        return Variable(x.cuda())
    else:
        return Variable(x)

### BinaryCrossEntropyLoss2d().forward(logits, labels)
class BinaryCrossEntropyLoss2d(nn.Module):
    def __init__(self, weight=None, size_average=True):
        """
        Binary cross entropy loss 2D
        Args:
            weight:
            size_average:
        """
        super(BinaryCrossEntropyLoss2d, self).__init__()
        self.bce_loss = nn.BCELoss(weight, size_average)

    def forward(self, probs, targets):
        probs = F.sigmoid(probs)
        probs_flat = probs.view(-1)  # Flatten
        targets_flat = targets.view(-1)  # Flatten
        return self.bce_loss(probs_flat, targets_flat)      # (output, labels)

def NetEval(net,valdata_loader,crit):
    loss = 0.
    count = 0
    net.eval()
    crop_input, crop_label,_ = crop_info()
    for i,data in enumerate(valdata_loader,0):
        # if i > 10: break
        inputs, labels = data
        # inputs = inputs.numpy()
        # labels = labels.numpy()
        for j in range(len(crop_input)):  # training on the crop images and corresponding labels
            ci = crop_input[j]  # crop index for inputs
            cl = crop_label[j]  # crop index for lables
            # temp = labels[0, 0, :, :]  # labels is numpy array 512x512
            # if np.sum(temp) < 0.01 * np.shape(temp)[0] * np.shape(temp)[1]: break
            x = inputs.numpy()[:, :, ci[0]:ci[0] + 572, ci[1]:ci[1] + 572]
            y = labels.numpy()[:, :, cl[0]: cl[0] + 388, cl[1]:cl[1] + 388]
            x = torch.from_numpy(x)
            y = torch.from_numpy(y)
            x, y = to_var(x), to_var(y)
            out = net(x)
            l = crit(out, y)
            loss += l.data[0]
            count += 1
    return loss/count

#process the test data and save to separate .tif image
def NetTest(net,testdata_loader,path = "data/results/"):
    net.eval()
    crop_input, crop_label, average_mask = crop_info()
    for i, data in enumerate(testdata_loader, 0):
        if i >= 30: return 1        # for debug
        # data = to_var(data)
        img_shape = 512
        img = np.zeros((img_shape, img_shape))
        for j in range(len(crop_input)):  # training on the crop images and corresponding labels
            temp = np.zeros((img_shape, img_shape))
            ci = crop_input[j]  # crop index for inputs
            cl = crop_label[j]
            x = data.numpy()[:, :, ci[0]:ci[0] + 572, ci[1]:ci[1] + 572]
            x = torch.from_numpy(x)
            x = to_var(x)
            out = F.sigmoid(net(x))
            out = out.cpu()
            out = out[0,0,:,:]
            # print("j: ", j)
            # print("size of temp: ", np.shape(temp))
            # print("size of output: ", np.shape(out.data.numpy()))
            temp[cl[0]: cl[0] + 388, cl[1]:cl[1] + 388] = out.data.numpy()
            img += temp

        img = img/average_mask
        img = img.reshape(-1)
        img[img < 0.5] = 0; img[img >= 0.5] = 1
        img = img.reshape(img_shape, img_shape)
        img = np.uint8(img * 255)
        imgname = path + str(i) + ".tif"
        tiff.imsave(imgname, img)

# return input image size like 512x512, numpy array
def NetPredict(net, input_image):
    net.eval()
    _, crop_label, average_mask = crop_info()

    # input_image is grayscale input image of 512x512
    data = Utils.input_filled_mirroring(input_image, e = 94)
    imgdatas = np.ndarray((1, 1, data.shape[0], data.shape[1]), dtype=np.uint8)
    imgdatas[0] = np.expand_dims(data, 0)
    data = Utils.hist_equalization(imgdatas)
    data = data.astype('float32')
    data /= 255
    data -= data.mean(axis=0)

    img_shape = input_image.shape
    img = np.zeros((img_shape, img_shape))
    for j in range(len(crop_input)):  # training on the crop images and corresponding labels
        temp = np.zeros((img_shape, img_shape))
        ci = crop_input[j]  # crop index for inputs
        cl = crop_label[j]
        x = data.numpy()[:, :, ci[0]:ci[0] + 572, ci[1]:ci[1] + 572]
        x = torch.from_numpy(x)
        x = to_var(x)
        out = F.sigmoid(net(x))
        out = out.cpu()
        out = out[0, 0, :, :]
        temp[cl[0]: cl[0] + 388, cl[1]:cl[1] + 388] = out.data.numpy()
        img += temp

    img = img / average_mask
    img = img.reshape(-1)
    img[img < 0.5] = 0
    img[img >= 0.5] = 1
    img = img.reshape(img_shape)
    img = np.uint8(img * 255)
    return img


def write_2_log(content):
    path = "log_file.txt"
    output = open(path, "a")
    output.write("\n")
    output.write(content)
    output.close()

def crop_info():
    crop_input = [[0, 0], [128, 0], [0, 128], [128, 128]]
    crop_label = [[0, 0], [124, 0], [0, 124], [124, 124]]
    average_mask = np.ones((512, 512))
    average_mask[124:388, 0:124] = 2
    average_mask[0:124, 124:388] = 2
    average_mask[124:388, 388:512] = 2
    average_mask[388:512, 124:388] = 2
    average_mask[124:388, 124:388] = 4
    return crop_input, crop_label, average_mask

if __name__ == '__main__':
    '''subjects to change for each exp:
    + path to the dataset
    + opt function
    + leg description
    + N_epoch
    + saved_model
    '''
    start_begining = time.time()

    # path = "data/dataset"
    path = "/home/anhxtuan/HanLe/dataset/20aug_10ela_3inten_reflect"
    path = "/home/anhxtuan/HanLe/dataset/20aug_10ela_3inten_reflect_700"

    import os
    print("Does the folder exist?: ", os.path.isdir(path))
    print("Does the path exist?: ", os.path.exists(path))

    imgs_train, imgs_mask_train = Utils.load_train_data(npy_path=path)
    imgs_val, imgs_mask_val = Utils.load_val_data(npy_path=path)
    batch_size = 1
    trainset = zip(imgs_train, imgs_mask_train)
    trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,
                                              shuffle=True, num_workers=2)
    valset = zip(imgs_val, imgs_mask_val)
    valloader = torch.utils.data.DataLoader(valset, batch_size=batch_size,
                                              shuffle=False, num_workers=2)
    # net = Unet.UNet()                     # Unet 1
    # net = Unet_BatchNorm.UNet_BN()          # Unet 2 with batchNorm
    net = Unet_crop.UNET_CROP()

    f1 = open("Unet_crop.py", 'r')     # embede code into the model to be saved later
    f2 = open("UnetTrain_crop.py", 'r')
    f3 = open("Utils.py", 'r')
    model_notes = time.strftime("%c") + "\n" + f1.read() + "\n" + "==="*5 + f2.read() + "\n" + "==="*5 + f3.read()
    f1.close()
    f2.close()
    f3.close()

    criterion = BinaryCrossEntropyLoss2d()
    # criterion = SoftDiceLoss()
    # criterion = nn.BCELoss()

    if torch.cuda.is_available():
        # torch.set_default_tensor_type('torch.cuda.FloatTensor')
        # net.load_state_dict(torch.load("Unet2_model_12epoch_Leg12_droput_0_2_rmSigmoid_20aug_10ela_3inten_reflect"))
        net.cuda()
        # criterion.cuda()

    opt = optim.SGD(net.parameters(), lr=1e-2, momentum=0.99)       # subject to change
    # opt = optim.RMSprop(net.parameters(), lr=2e-4)
    # RMSprop[22](learning rate 0.001) with weight decay set to 0.001.
    # opt = optim.Adam(net.parameters(), lr=1e-3, weight_decay=1e-4)

    train_loss = []
    val_loss = []

    print("[epoch, #image] Loss")
    leg = "Leg22_CROP_dropout_0_2_rmSigmoid_20aug_10ela_3inten_reflect"
    print("Processing: ", leg)
    model_name = ""

    N_epoch = 6
    model_saved = np.arange(2,N_epoch+1,2)
    val_loss_min = 100

    write_2_log("==="*30)
    write_2_log(time.strftime("%c"))       # time, date of exp
    write_2_log(leg)
    write_2_log(model_notes)
    write_2_log(time.strftime("%c"))  # time, date of exp
    write_2_log(leg)
    write_2_log("optim.SGD(net.parameters(), lr=1e-2, momentum=0.99)")
    write_2_log("Number of epoch max: " + str(N_epoch))

    crop_input, crop_label,_ = crop_info()
    min_model_epoch = 0
    for epoch in range(N_epoch):
        running_loss = 0.0; count = 0
        net.train()
        for i, data in enumerate(trainloader, 0):
            # if i > 10: break

            inputs, labels = data
            temp = labels.numpy()
            for j in range(len(crop_input)):       # training on the crop images and corresponding labels
                ci = crop_input[j]          # crop index for inputs
                cl = crop_label[j]          # crop index for lables
                # temp = temp[0, 0, :, :]  # labels is numpy array 512x512
                # if np.sum(temp) < 0.01 * np.shape(temp)[0] * np.shape(temp)[1]: break
                x = inputs.numpy()[:, :, ci[0]:ci[0] + 572, ci[1]:ci[1] + 572]
                y = labels.numpy()[:, :, cl[0]: cl[0] + 388, cl[1]:cl[1] + 388]
                import matplotlib.pyplot as plt
                plt.subplot(121); plt.imshow(x, cmap='gray')
                plt.subplot(122); plt.imshow(y, cmap='gray')
                x = torch.from_numpy(x)
                y = torch.from_numpy(y)
                x, y = to_var(x), to_var(y)
                opt.zero_grad()
                out = net(x)
                loss = criterion(out, y)
                loss.backward()
                opt.step()
                running_loss += loss.data[0]
                count += 1

        net.eval()
        val_loss_temp = NetEval(net, valloader, criterion)
        if epoch > 0 and val_loss_temp < val_loss_min:        # save the model which has the lowest val_loss, ignore first epoch
            val_loss_min = val_loss_temp
            torch.save(net.state_dict(), "Unet2_model_" + leg + "_min_val_loss")  # save model
            min_model_epoch = epoch + 1

        disp = 'Epoch %d: Train loss: %.6f, Val loss: %.6f' % (epoch + 1, running_loss/count, val_loss_temp)
        write_2_log(disp)
        print(disp)
        val_loss.append(val_loss_temp)
        train_loss.append(running_loss/count); running_loss = 0.0

        if (epoch + 1) in model_saved or epoch == 0:        # save checkpoint
            model_name = "Unet2_model_" + str(epoch+1) + "epoch_" + leg
            torch.save(net.state_dict(), model_name)  # save model
            Analysis_crop.analysis(model_file = model_name, valloader = valloader)

    write_2_log("Best model at epoch: " + str(min_model_epoch))
    write_2_log("Total training time: " + str((time.time() - start_begining) / 3600.0))

    val_loss_file = "data/results" + "/val_loss_" + str(N_epoch) + "epoch_" + leg + ".npy"
    train_loss_file = "data/results" + "/training_loss_" + str(N_epoch) + "epoch_" + leg + ".npy"

    np.save(val_loss_file, val_loss)
    np.save(train_loss_file, train_loss)
    print("total processing time in seconds: ", time.time() - start_begining)
    print("total processing time in mins: ", (time.time() - start_begining) / 60.0)
    print("total processing time in hours: ", (time.time() - start_begining) / 3600.0)

    # Analysis.analysis(model_file="Unet2_model_" + leg + "_min_val_loss", valloader=valloader)

    Analysis_crop.PlotLoss(model_file = model_name, loss_train_path = train_loss_file, loss_val_path = val_loss_file, epoch_No = N_epoch)

    write_2_log(time.strftime("%c"))  # time, date of exp
===============
import numpy as np
import torch.nn as nn
import torch
import cv2
from lcn import LecunLCN

LCN_enable = False

def input_filled_mirroring(x, e = 62):      # fill missing data by mirroring the input image
    '''input size 636 --> output size 512'''
    w, h = x.shape
    #e = 62  # extra width on 1 edge
    y = np.zeros((h + e * 2, w + e * 2))
    y[e:h + e, e:w + e] = x
    y[e:e + h, 0:e] = np.flip(y[e:e + h, e:2 * e], 1)  # flip vertically
    y[e:e + h, e + w:2 * e + w] = np.flip(y[e:e + h, w:e + w], 1)  # flip vertically
    y[0:e, 0:2 * e + w] = np.flip(y[e:2 * e, 0:2 * e + w], 0)  # flip horizontally
    y[e + h:2 * e + h, 0:2 * e + w] = np.flip(y[h:e + h, 0:2 * e + w], 0)  # flip horizontally
    return y

def nearest_cells_distance(pos, img):
    # searching in 8 directions to find 2 nearest distances to neighbor cells
    curr_value = img[pos]
    w = img.shape[0];h = img.shape[1]
    count_detect = 0  # detect 2 nearest neighbors. break the search if count_detect = 2
    x, y = pos

    # print("w,h: ", (w, h))
    d1 = 9999999;d2 = 9999999;d3 = 9999999;d4 = 9999999
    d5 = 9999999;d6 = 9999999;d7 = 9999999;d8 = 9999999
    for i in range(1, max(w, h)):
        # (x+1, y), (x+1, y+1), (x+1, y-1),
        # (x, y+1), (x, y-1)
        # (x-1, y), (x-1,y+1), (x-1,y-1),
        if x + i < w:
            if img[(x + i, y)] != curr_value and d1 == 9999999:
                d1 = i; count_detect += 1
            if y + i < h:
                if img[(x + i, y + i)] != curr_value and d2 == 9999999:
                    d2 = i; count_detect += 1
            elif y - i >= 0:
                if img[(x + i, y - i)] != curr_value and d3 == 9999999:
                    d3 = i; count_detect += 1
        if y + i < h:
            if img[(x, y + i)] != curr_value and d4 == 9999999:
                d4 = i; count_detect += 1
        if y - i >= 0:
            if img[(x, y - i)] != curr_value and d5 == 9999999:
                d5 = i; count_detect += 1
        if x - i >= 0:
            if img[(x - i, y)] != curr_value and d6 == 9999999:
                d6 = i; count_detect += 1
            if y + i < h:
                if img[(x - i, y + i)] != curr_value and d7 == 9999999:
                    d7 = i; count_detect += 1
            elif y - i >= 0:
                if img[(x - i, y - i)] != curr_value and d8 == 9999999:
                    d8 = i; count_detect += 1
        if count_detect >= 2: break

    d = [d1, d2, d3, d4, d5, d6, d7, d8]
    min_index = np.argmin(d)
    dist1 = d[min_index]
    d.remove(dist1)
    min_index = np.argmin(d)
    dist2 = d[min_index]
    return dist1, dist2

def create_weight_map(imgs_mask):
        print('-' * 30)
        print('Creating weights for masks ...')
        print('-' * 30)
        weight_map = np.ndarray(
            (len(imgs_mask), 1, np.shape(imgs_mask)[2], np.shape(imgs_mask)[3]), dtype=np.float32)
        w_0 = 10; sigma = 4
        imgs_w, imgs_h = np.shape(imgs_mask)[2], np.shape(imgs_mask)[3]
        total_pixels = imgs_w*imgs_h
        import time
        start = time.time()
        for i in range(len(imgs_mask)):
            if i%10 == 0: print("Done processing: %d images, time passed: %.2f mins" % (i, (time.time() - start)/60.0))
            temp = imgs_mask[i,0,:,:]
            w_border = 1 - np.sum(temp)/total_pixels        # w_c of pixel on the border (black)
            for m in range(imgs_w):
                for n in range(imgs_h):
                    # loop through all pixel of the mask
                    d1,d2 = nearest_cells_distance((m,n), temp)
                    w_c = w_border
                    if temp[m,n] == 0: w_c = 1 - w_border
                    weight_map[i,0,m,n] = w_c*5 + w_0*np.exp(-(d1 + d2)**2/(2*sigma**2))
                    # print("w_0*np.exp(): ", w_0*np.exp(-(d1 + d2)**2/(2*sigma**2)))
                    # print("w_border: ", w_border)

        np.save('data/dataset/weight_map_train.npy', weight_map)

        return weight_map

def load_train_data(npy_path = "data/dataset", hist_equal = False):

    print('-' * 30)
    print('load train images...')

    imgs_train = np.load(npy_path + "/imgs_train.npy")
    imgs_mask_train = np.load(npy_path + "/imgs_mask_train.npy")

    if hist_equal: imgs_train = hist_equalization(imgs_train)

    # weight_map_train = np.load(npy_path + "/weight_map_train.npy")
    # weight_map_train = weight_map_train.astype('float32')

    imgs_train = imgs_train.astype('float32')
    imgs_mask_train = imgs_mask_train.astype('float32')

    if LCN_enable:
        imgs_train = imgs_train.astype('float64')
        imgs_train = LecunLCN(imgs_train, image_shape=imgs_train.shape).output.eval()
        imgs_train = imgs_train.astype('float32')

    if not LCN_enable: imgs_train /= 255

    imgs_train -= imgs_train.mean(axis=0)
    imgs_mask_train /= 255
    imgs_mask_train[imgs_mask_train > 0.5] = 1
    imgs_mask_train[imgs_mask_train <= 0.5] = 0

    # weight_map_train = create_weight_map(imgs_mask_train)

    print("Done loading traing data")
    print('-' * 30)
    return imgs_train, imgs_mask_train

def load_val_data(npy_path = "data/dataset", hist_equal = True):

    print('-' * 30)
    print('load validation images...')

    imgs_train = np.load(npy_path + "/imgs_val.npy")
    imgs_mask_train = np.load(npy_path + "/imgs_mask_val.npy")

    if hist_equal: imgs_train = hist_equalization(imgs_train)

    imgs_train = imgs_train.astype('float32')
    imgs_mask_train = imgs_mask_train.astype('float32')

    if LCN_enable:
        imgs_train = imgs_train.astype('float64')
        imgs_train = LecunLCN(imgs_train, image_shape=imgs_train.shape).output.eval()
        imgs_train = imgs_train.astype('float32')

    if not LCN_enable: imgs_train /= 255
    imgs_train -= imgs_train.mean(axis=0)
    imgs_mask_train /= 255
    imgs_mask_train[imgs_mask_train > 0.5] = 1
    imgs_mask_train[imgs_mask_train <= 0.5] = 0
    print("Done loading validation data")
    print('-' * 30)
    return imgs_train, imgs_mask_train

def load_test_data(npy_path = "data/dataset", hist_equal = True):

    print('-' * 30)
    print('load test images...')

    imgs_test = np.load(npy_path + "/imgs_test.npy")

    if hist_equal: imgs_test = hist_equalization(imgs_test)

    imgs_test = imgs_test.astype('float32')

    if LCN_enable:
        imgs_test = imgs_test.astype('float64')
        imgs_test = LecunLCN(imgs_test, image_shape=imgs_test.shape).output.eval()
        imgs_test = imgs_test.astype('float32')

    if not LCN_enable: imgs_test /= 255

    imgs_test -= imgs_test.mean(axis=0)

    print("Done loading test data")
    print('-' * 30)
    return imgs_test

def load_val_5imgs(npy_path = "data/dataset"):
    print('-' * 30)
    print('load train images...')

    imgs_train = np.load(npy_path + "/imgs_val_5imgs.npy")
    imgs_mask_train = np.load(npy_path + "/imgs_mask_val_5imgs.npy")

    # imgs_train = hist_equalization(imgs_train)

    imgs_train = imgs_train.astype('float64')
    imgs_mask_train = imgs_mask_train.astype('float64')

    if LCN_enable: imgs_train = LecunLCN(imgs_train, image_shape=imgs_train.shape).output.eval()

    if not LCN_enable: imgs_train /= 255

    mean = imgs_train.mean(axis=0)
    imgs_train -= mean


    imgs_mask_train /= 255
    imgs_mask_train[imgs_mask_train > 0.5] = 1
    imgs_mask_train[imgs_mask_train <= 0.5] = 0

    # weight_map_train = self.create_weight_map(imgs_mask_train)

    print("Done loading traing data")
    print('-' * 30)
    return imgs_train, imgs_mask_train

def hist_equalization(inputs):      # inputs are uint8, 0-255, Nx1x636x636
    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))
    output = inputs.copy()
    for i in range(len(inputs)):
        img = inputs[i, 0, :, :]
        # res = cv2.equalizeHist(img)
        res = clahe.apply(img)
        output[i,0,:,:] = res
    return output

### BinaryCrossEntropyLoss2d().forward(logits, labels)
class BinaryCrossEntropyLoss2d(nn.Module):
    def __init__(self, weight=None, size_average=True):
        """
        Binary cross entropy loss 2D
        Args:
            weight:
            size_average:
        """
        super(BinaryCrossEntropyLoss2d, self).__init__()
        self.bce_loss = nn.BCELoss(weight, size_average)

    def forward(self, logits, targets):
        # probs = F.sigmoid(logits)
        probs = logits
        probs_flat = probs.view(-1)  # Flatten
        targets_flat = targets.view(-1)  # Flatten
        return self.bce_loss(probs_flat, targets_flat)      # (output, labels)

class BCE_with_Weights(nn.Module):
    def __init__(self, weights=None):
        """
        Binary cross entropy loss 2D
        Args:
            weights:
        """
        super(BCE_with_Weights, self).__init__()
        self.weights = weights

    def forward(self, output, target):
        if self.weights is not None:
            loss = self.weights * (target * torch.log(output) + (1 - target) * torch.log(1 - output))
        else:
            loss = target * torch.log(output) + (1 - target) * torch.log(1 - output)

        return torch.neg(torch.mean(loss))

class LRN(nn.Module):       # input x is Torch tensor
    def __init__(self, local_size=1, alpha=1.0, beta=0.75, ACROSS_CHANNELS=False):      #LRN(local_size=5, alpha=0.0001, beta=0.75),
        super(LRN, self).__init__()
        self.ACROSS_CHANNELS = ACROSS_CHANNELS
        if self.ACROSS_CHANNELS:
            self.average = nn.AvgPool3d(kernel_size=(local_size, 1, 1),
                                        stride=1, padding=(int((local_size - 1.0) / 2), 0, 0))
        else:
            self.average = nn.AvgPool2d(kernel_size=local_size,
                                        stride=1, padding=int((local_size - 1.0) / 2))
        self.alpha = alpha
        self.beta = beta

    def forward(self, x):
        if self.ACROSS_CHANNELS:
            div = x.pow(2).unsqueeze(1)
            div = self.average(div).squeeze(1)
            div = div.mul(self.alpha).add(1.0).pow(self.beta)
        else:
            div = x.pow(2)
            div = self.average(div)
            div = div.mul(self.alpha).add(1.0).pow(self.beta)
        x = x.div(div)
        return x
Sat Nov 25 03:04:23 2017
Leg22_CROP_dropout_0_2_rmSigmoid_20aug_10ela_3inten_reflect
optim.SGD(net.parameters(), lr=1e-2, momentum=0.99)
Number of epoch max: 6
==========================================================================================
Sat Nov 25 03:06:07 2017
Leg22_CROP_dropout_0_2_rmSigmoid_20aug_10ela_3inten_reflect
Sat Nov 25 03:06:04 2017
import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.autograd import Variable
import math


class ConvBnRelu(nn.Module):
    def __init__(self, in_channels, out_channels, kernel_size, padding, stride):
        super(ConvBnRelu, self).__init__()
        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=kernel_size, padding=padding, stride=stride)
        self.bn = nn.BatchNorm2d(out_channels)
        self.relu = nn.ReLU()

    def forward(self, x):
        x = self.conv(x)
        # x = self.bn(x)
        x = self.relu(x)
        return x


class StackEncoder(nn.Module):
    def __init__(self, in_channels, out_channels):
        super(StackEncoder, self).__init__()
        self.convr1 = ConvBnRelu(in_channels, out_channels, kernel_size=(3, 3), stride=1, padding=0)
        self.convr2 = ConvBnRelu(out_channels, out_channels, kernel_size=(3, 3), stride=1, padding=0)
        self.maxPool = nn.MaxPool2d(kernel_size=(2, 2), stride=2)

    def forward(self, x):
        x = self.convr1(x)
        x = self.convr2(x)
        x_trace = x             # save x to use in concat in the Decoder path
        out = self.maxPool(x)
        return out, x_trace


class StackDecoder(nn.Module):
    def __init__(self, in_channels, out_channels, padding = 0, drop_out=False):
        super(StackDecoder, self).__init__()

        self.drop_out = drop_out
        self.dropout_layer = nn.Dropout2d(p=0.5)

        ''' this is old version
        self.upSample = nn.Upsample(size=upsample_size, scale_factor=(2, 2), mode="bilinear")
        self.convr1 = ConvBnRelu(in_channels, out_channels, kernel_size=(3, 3), stride=1, padding=padding)
        # Crop + concat step between these 2
        self.convr2 = ConvBnRelu(in_channels, out_channels, kernel_size=(3, 3), stride=1, padding=padding)
        '''
        self.upSample = nn.ConvTranspose2d(in_channels, out_channels, 2, stride=2)
        self.convr1 = ConvBnRelu(in_channels, out_channels, kernel_size=(3, 3), stride=1, padding=padding)
        self.convr2 = ConvBnRelu(out_channels, out_channels, kernel_size=(3, 3), stride=1, padding=padding)

    def _crop_concat(self, upsampled, bypass):
        """
         Crop y to the (h, w) of x and concat them.
         Used for the expansive path.
        Returns:
            The concatenated tensor
        """
        c = (bypass.size()[2] - upsampled.size()[2]) // 2
        bypass = F.pad(bypass, (-c, -c, -c, -c))

        return torch.cat((bypass, upsampled), 1)

    def forward(self, x, down_tensor):
        '''old version
        x = self.upSample(x)
        x = self.convr1(x)
        x = self._crop_concat(x, down_tensor)
        x = self.convr2(x)
        '''

        x = self.upSample(x)
        x = self._crop_concat(x, down_tensor)
        x = self.convr1(x)
        if self.drop_out: x = self.dropout_layer(x)
        x = self.convr2(x)
        if self.drop_out: x = self.dropout_layer(x)
        return x


class UNET_CROP(nn.Module):
    def __init__(self):
        super(UNET_CROP, self).__init__()
        # channels, height, width = in_shape

        # self.dropout = dropout

        self.model_code = ""        # variable to save model and main function when loaded

        self.down1 = StackEncoder(1, 64)
        self.down2 = StackEncoder(64, 128)
        self.down3 = StackEncoder(128, 256)
        self.down4 = StackEncoder(256, 512)

        self.center = nn.Sequential(
            # nn.Dropout2d(p=0.2),
            ConvBnRelu(512, 1024, kernel_size=(3, 3), stride=1, padding=0),
            nn.Dropout2d(p=0.2),
            ConvBnRelu(1024, 1024, kernel_size=(3, 3), stride=1, padding=0),
            nn.Dropout2d(p=0.2)
        )

        self.up1 = StackDecoder(in_channels=1024, out_channels=512)
        self.up2 = StackDecoder(in_channels=512, out_channels=256)
        self.up3 = StackDecoder(in_channels=256, out_channels=128)
        self.up4 = StackDecoder(in_channels=128, out_channels=64)

        # 1x1 convolution at the last layer
        # Different from the paper is the output size here
        self.output_seg_map = nn.Conv2d(64, 1, kernel_size=(1, 1), padding=0, stride=1)

        self._initialize_weights()

    def forward(self, x):
        x, x_trace1 = self.down1(x)
        x, x_trace2 = self.down2(x)
        x, x_trace3 = self.down3(x)
        x, x_trace4 = self.down4(x)
        x = self.center(x)
        x = self.up1(x, x_trace4)
        x = self.up2(x, x_trace3)
        x = self.up3(x, x_trace2)
        x = self.up4(x, x_trace1)

        x = self.output_seg_map(x)
        # x = F.sigmoid(x)
        # out = torch.squeeze(out, dim=1)
        return x


    def _initialize_weights(self):
        for m in self.modules():
            if isinstance(m, nn.Conv2d):
                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels
                m.weight.data.normal_(0, math.sqrt(2. / n))
                if m.bias is not None:
                    m.bias.data.zero_()
            elif isinstance(m, nn.BatchNorm2d):
                m.weight.data.fill_(1)
                m.bias.data.zero_()

# x = Variable(torch.randn(1,1,700, 700))       # simulate input image
# net = UNET_CROP()
# out = net(x)
# print("input: ", x)
# print("output: ", out)
===============from __future__ import print_function, division
import torch
from torch import optim
from torch.autograd import Variable
from torch.utils.data import DataLoader
import numpy as np
import torch.nn as nn
import torch.nn.functional as F
import Unet_crop
import tifffile as tiff
import Utils
import time
from sklearn.metrics import average_precision_score, recall_score, f1_score
import Analysis_crop
import cv2

def to_var(x):
    if torch.cuda.is_available():
        return Variable(x.cuda())
    else:
        return Variable(x)

### BinaryCrossEntropyLoss2d().forward(logits, labels)
class BinaryCrossEntropyLoss2d(nn.Module):
    def __init__(self, weight=None, size_average=True):
        """
        Binary cross entropy loss 2D
        Args:
            weight:
            size_average:
        """
        super(BinaryCrossEntropyLoss2d, self).__init__()
        self.bce_loss = nn.BCELoss(weight, size_average)

    def forward(self, probs, targets):
        probs = F.sigmoid(probs)
        probs_flat = probs.view(-1)  # Flatten
        targets_flat = targets.view(-1)  # Flatten
        return self.bce_loss(probs_flat, targets_flat)      # (output, labels)

def NetEval(net,valdata_loader,crit):
    loss = 0.
    count = 0
    net.eval()
    crop_input, crop_label,_ = crop_info()
    for i,data in enumerate(valdata_loader,0):
        # if i > 10: break
        inputs, labels = data
        # inputs = inputs.numpy()
        # labels = labels.numpy()
        for j in range(len(crop_input)):  # training on the crop images and corresponding labels
            ci = crop_input[j]  # crop index for inputs
            cl = crop_label[j]  # crop index for lables
            # temp = labels[0, 0, :, :]  # labels is numpy array 512x512
            # if np.sum(temp) < 0.01 * np.shape(temp)[0] * np.shape(temp)[1]: break
            x = inputs.numpy()[:, :, ci[0]:ci[0] + 572, ci[1]:ci[1] + 572]
            y = labels.numpy()[:, :, cl[0]: cl[0] + 388, cl[1]:cl[1] + 388]
            x = torch.from_numpy(x)
            y = torch.from_numpy(y)
            x, y = to_var(x), to_var(y)
            out = net(x)
            l = crit(out, y)
            loss += l.data[0]
            count += 1
    return loss/count

#process the test data and save to separate .tif image
def NetTest(net,testdata_loader,path = "data/results/"):
    net.eval()
    crop_input, crop_label, average_mask = crop_info()
    for i, data in enumerate(testdata_loader, 0):
        if i >= 30: return 1        # for debug
        # data = to_var(data)
        img_shape = 512
        img = np.zeros((img_shape, img_shape))
        for j in range(len(crop_input)):  # training on the crop images and corresponding labels
            temp = np.zeros((img_shape, img_shape))
            ci = crop_input[j]  # crop index for inputs
            cl = crop_label[j]
            x = data.numpy()[:, :, ci[0]:ci[0] + 572, ci[1]:ci[1] + 572]
            x = torch.from_numpy(x)
            x = to_var(x)
            out = F.sigmoid(net(x))
            out = out.cpu()
            out = out[0,0,:,:]
            # print("j: ", j)
            # print("size of temp: ", np.shape(temp))
            # print("size of output: ", np.shape(out.data.numpy()))
            temp[cl[0]: cl[0] + 388, cl[1]:cl[1] + 388] = out.data.numpy()
            img += temp

        img = img/average_mask
        img = img.reshape(-1)
        img[img < 0.5] = 0; img[img >= 0.5] = 1
        img = img.reshape(img_shape, img_shape)
        img = np.uint8(img * 255)
        imgname = path + str(i) + ".tif"
        tiff.imsave(imgname, img)

# return input image size like 512x512, numpy array
def NetPredict(net, input_image):
    net.eval()
    _, crop_label, average_mask = crop_info()

    # input_image is grayscale input image of 512x512
    data = Utils.input_filled_mirroring(input_image, e = 94)
    imgdatas = np.ndarray((1, 1, data.shape[0], data.shape[1]), dtype=np.uint8)
    imgdatas[0] = np.expand_dims(data, 0)
    data = Utils.hist_equalization(imgdatas)
    data = data.astype('float32')
    data /= 255
    data -= data.mean(axis=0)

    img_shape = input_image.shape
    img = np.zeros((img_shape, img_shape))
    for j in range(len(crop_input)):  # training on the crop images and corresponding labels
        temp = np.zeros((img_shape, img_shape))
        ci = crop_input[j]  # crop index for inputs
        cl = crop_label[j]
        x = data.numpy()[:, :, ci[0]:ci[0] + 572, ci[1]:ci[1] + 572]
        x = torch.from_numpy(x)
        x = to_var(x)
        out = F.sigmoid(net(x))
        out = out.cpu()
        out = out[0, 0, :, :]
        temp[cl[0]: cl[0] + 388, cl[1]:cl[1] + 388] = out.data.numpy()
        img += temp

    img = img / average_mask
    img = img.reshape(-1)
    img[img < 0.5] = 0
    img[img >= 0.5] = 1
    img = img.reshape(img_shape)
    img = np.uint8(img * 255)
    return img


def write_2_log(content):
    path = "log_file.txt"
    output = open(path, "a")
    output.write("\n")
    output.write(content)
    output.close()

def crop_info():
    crop_input = [[0, 0], [128, 0], [0, 128], [128, 128]]
    crop_label = [[0, 0], [124, 0], [0, 124], [124, 124]]
    average_mask = np.ones((512, 512))
    average_mask[124:388, 0:124] = 2
    average_mask[0:124, 124:388] = 2
    average_mask[124:388, 388:512] = 2
    average_mask[388:512, 124:388] = 2
    average_mask[124:388, 124:388] = 4
    return crop_input, crop_label, average_mask

if __name__ == '__main__':
    '''subjects to change for each exp:
    + path to the dataset
    + opt function
    + leg description
    + N_epoch
    + saved_model
    '''
    start_begining = time.time()

    # path = "data/dataset"
    path = "/home/anhxtuan/HanLe/dataset/20aug_10ela_3inten_reflect"
    path = "/home/anhxtuan/HanLe/dataset/20aug_10ela_3inten_reflect_700"

    import os
    print("Does the folder exist?: ", os.path.isdir(path))
    print("Does the path exist?: ", os.path.exists(path))

    imgs_train, imgs_mask_train = Utils.load_train_data(npy_path=path)
    imgs_val, imgs_mask_val = Utils.load_val_data(npy_path=path)
    batch_size = 1
    trainset = zip(imgs_train, imgs_mask_train)
    trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,
                                              shuffle=True, num_workers=2)
    valset = zip(imgs_val, imgs_mask_val)
    valloader = torch.utils.data.DataLoader(valset, batch_size=batch_size,
                                              shuffle=False, num_workers=2)
    # net = Unet.UNet()                     # Unet 1
    # net = Unet_BatchNorm.UNet_BN()          # Unet 2 with batchNorm
    net = Unet_crop.UNET_CROP()

    f1 = open("Unet_crop.py", 'r')     # embede code into the model to be saved later
    f2 = open("UnetTrain_crop.py", 'r')
    f3 = open("Utils.py", 'r')
    model_notes = time.strftime("%c") + "\n" + f1.read() + "\n" + "==="*5 + f2.read() + "\n" + "==="*5 + f3.read()
    f1.close()
    f2.close()
    f3.close()

    criterion = BinaryCrossEntropyLoss2d()
    # criterion = SoftDiceLoss()
    # criterion = nn.BCELoss()

    if torch.cuda.is_available():
        # torch.set_default_tensor_type('torch.cuda.FloatTensor')
        # net.load_state_dict(torch.load("Unet2_model_12epoch_Leg12_droput_0_2_rmSigmoid_20aug_10ela_3inten_reflect"))
        net.cuda()
        # criterion.cuda()

    opt = optim.SGD(net.parameters(), lr=1e-2, momentum=0.99)       # subject to change
    # opt = optim.RMSprop(net.parameters(), lr=2e-4)
    # RMSprop[22](learning rate 0.001) with weight decay set to 0.001.
    # opt = optim.Adam(net.parameters(), lr=1e-3, weight_decay=1e-4)

    train_loss = []
    val_loss = []

    print("[epoch, #image] Loss")
    leg = "Leg22_CROP_dropout_0_2_rmSigmoid_20aug_10ela_3inten_reflect"
    print("Processing: ", leg)
    model_name = ""

    N_epoch = 6
    model_saved = np.arange(2,N_epoch+1,2)
    val_loss_min = 100

    write_2_log("==="*30)
    write_2_log(time.strftime("%c"))       # time, date of exp
    write_2_log(leg)
    write_2_log(model_notes)
    write_2_log(time.strftime("%c"))  # time, date of exp
    write_2_log(leg)
    write_2_log("optim.SGD(net.parameters(), lr=1e-2, momentum=0.99)")
    write_2_log("Number of epoch max: " + str(N_epoch))

    crop_input, crop_label,_ = crop_info()
    min_model_epoch = 0
    for epoch in range(N_epoch):
        running_loss = 0.0; count = 0
        net.train()
        for i, data in enumerate(trainloader, 0):
            # if i > 10: break

            inputs, labels = data
            temp = labels.numpy()
            for j in range(len(crop_input)):       # training on the crop images and corresponding labels
                ci = crop_input[j]          # crop index for inputs
                cl = crop_label[j]          # crop index for lables
                # temp = temp[0, 0, :, :]  # labels is numpy array 512x512
                # if np.sum(temp) < 0.01 * np.shape(temp)[0] * np.shape(temp)[1]: break
                x = inputs.numpy()[:, :, ci[0]:ci[0] + 572, ci[1]:ci[1] + 572]
                y = labels.numpy()[:, :, cl[0]: cl[0] + 388, cl[1]:cl[1] + 388]
                import matplotlib.pyplot as plt
                plt.subplot(121); plt.imshow(x[0,0,:,:], cmap='gray')
                plt.subplot(122); plt.imshow(y[0,0,:,:], cmap='gray')
                x = torch.from_numpy(x)
                y = torch.from_numpy(y)
                x, y = to_var(x), to_var(y)
                opt.zero_grad()
                out = net(x)
                loss = criterion(out, y)
                loss.backward()
                opt.step()
                running_loss += loss.data[0]
                count += 1

        net.eval()
        val_loss_temp = NetEval(net, valloader, criterion)
        if epoch > 0 and val_loss_temp < val_loss_min:        # save the model which has the lowest val_loss, ignore first epoch
            val_loss_min = val_loss_temp
            torch.save(net.state_dict(), "Unet2_model_" + leg + "_min_val_loss")  # save model
            min_model_epoch = epoch + 1

        disp = 'Epoch %d: Train loss: %.6f, Val loss: %.6f' % (epoch + 1, running_loss/count, val_loss_temp)
        write_2_log(disp)
        print(disp)
        val_loss.append(val_loss_temp)
        train_loss.append(running_loss/count); running_loss = 0.0

        if (epoch + 1) in model_saved or epoch == 0:        # save checkpoint
            model_name = "Unet2_model_" + str(epoch+1) + "epoch_" + leg
            torch.save(net.state_dict(), model_name)  # save model
            Analysis_crop.analysis(model_file = model_name, valloader = valloader)

    write_2_log("Best model at epoch: " + str(min_model_epoch))
    write_2_log("Total training time: " + str((time.time() - start_begining) / 3600.0))

    val_loss_file = "data/results" + "/val_loss_" + str(N_epoch) + "epoch_" + leg + ".npy"
    train_loss_file = "data/results" + "/training_loss_" + str(N_epoch) + "epoch_" + leg + ".npy"

    np.save(val_loss_file, val_loss)
    np.save(train_loss_file, train_loss)
    print("total processing time in seconds: ", time.time() - start_begining)
    print("total processing time in mins: ", (time.time() - start_begining) / 60.0)
    print("total processing time in hours: ", (time.time() - start_begining) / 3600.0)

    # Analysis.analysis(model_file="Unet2_model_" + leg + "_min_val_loss", valloader=valloader)

    Analysis_crop.PlotLoss(model_file = model_name, loss_train_path = train_loss_file, loss_val_path = val_loss_file, epoch_No = N_epoch)

    write_2_log(time.strftime("%c"))  # time, date of exp
===============
import numpy as np
import torch.nn as nn
import torch
import cv2
from lcn import LecunLCN

LCN_enable = False

def input_filled_mirroring(x, e = 62):      # fill missing data by mirroring the input image
    '''input size 636 --> output size 512'''
    w, h = x.shape
    #e = 62  # extra width on 1 edge
    y = np.zeros((h + e * 2, w + e * 2))
    y[e:h + e, e:w + e] = x
    y[e:e + h, 0:e] = np.flip(y[e:e + h, e:2 * e], 1)  # flip vertically
    y[e:e + h, e + w:2 * e + w] = np.flip(y[e:e + h, w:e + w], 1)  # flip vertically
    y[0:e, 0:2 * e + w] = np.flip(y[e:2 * e, 0:2 * e + w], 0)  # flip horizontally
    y[e + h:2 * e + h, 0:2 * e + w] = np.flip(y[h:e + h, 0:2 * e + w], 0)  # flip horizontally
    return y

def nearest_cells_distance(pos, img):
    # searching in 8 directions to find 2 nearest distances to neighbor cells
    curr_value = img[pos]
    w = img.shape[0];h = img.shape[1]
    count_detect = 0  # detect 2 nearest neighbors. break the search if count_detect = 2
    x, y = pos

    # print("w,h: ", (w, h))
    d1 = 9999999;d2 = 9999999;d3 = 9999999;d4 = 9999999
    d5 = 9999999;d6 = 9999999;d7 = 9999999;d8 = 9999999
    for i in range(1, max(w, h)):
        # (x+1, y), (x+1, y+1), (x+1, y-1),
        # (x, y+1), (x, y-1)
        # (x-1, y), (x-1,y+1), (x-1,y-1),
        if x + i < w:
            if img[(x + i, y)] != curr_value and d1 == 9999999:
                d1 = i; count_detect += 1
            if y + i < h:
                if img[(x + i, y + i)] != curr_value and d2 == 9999999:
                    d2 = i; count_detect += 1
            elif y - i >= 0:
                if img[(x + i, y - i)] != curr_value and d3 == 9999999:
                    d3 = i; count_detect += 1
        if y + i < h:
            if img[(x, y + i)] != curr_value and d4 == 9999999:
                d4 = i; count_detect += 1
        if y - i >= 0:
            if img[(x, y - i)] != curr_value and d5 == 9999999:
                d5 = i; count_detect += 1
        if x - i >= 0:
            if img[(x - i, y)] != curr_value and d6 == 9999999:
                d6 = i; count_detect += 1
            if y + i < h:
                if img[(x - i, y + i)] != curr_value and d7 == 9999999:
                    d7 = i; count_detect += 1
            elif y - i >= 0:
                if img[(x - i, y - i)] != curr_value and d8 == 9999999:
                    d8 = i; count_detect += 1
        if count_detect >= 2: break

    d = [d1, d2, d3, d4, d5, d6, d7, d8]
    min_index = np.argmin(d)
    dist1 = d[min_index]
    d.remove(dist1)
    min_index = np.argmin(d)
    dist2 = d[min_index]
    return dist1, dist2

def create_weight_map(imgs_mask):
        print('-' * 30)
        print('Creating weights for masks ...')
        print('-' * 30)
        weight_map = np.ndarray(
            (len(imgs_mask), 1, np.shape(imgs_mask)[2], np.shape(imgs_mask)[3]), dtype=np.float32)
        w_0 = 10; sigma = 4
        imgs_w, imgs_h = np.shape(imgs_mask)[2], np.shape(imgs_mask)[3]
        total_pixels = imgs_w*imgs_h
        import time
        start = time.time()
        for i in range(len(imgs_mask)):
            if i%10 == 0: print("Done processing: %d images, time passed: %.2f mins" % (i, (time.time() - start)/60.0))
            temp = imgs_mask[i,0,:,:]
            w_border = 1 - np.sum(temp)/total_pixels        # w_c of pixel on the border (black)
            for m in range(imgs_w):
                for n in range(imgs_h):
                    # loop through all pixel of the mask
                    d1,d2 = nearest_cells_distance((m,n), temp)
                    w_c = w_border
                    if temp[m,n] == 0: w_c = 1 - w_border
                    weight_map[i,0,m,n] = w_c*5 + w_0*np.exp(-(d1 + d2)**2/(2*sigma**2))
                    # print("w_0*np.exp(): ", w_0*np.exp(-(d1 + d2)**2/(2*sigma**2)))
                    # print("w_border: ", w_border)

        np.save('data/dataset/weight_map_train.npy', weight_map)

        return weight_map

def load_train_data(npy_path = "data/dataset", hist_equal = False):

    print('-' * 30)
    print('load train images...')

    imgs_train = np.load(npy_path + "/imgs_train.npy")
    imgs_mask_train = np.load(npy_path + "/imgs_mask_train.npy")

    if hist_equal: imgs_train = hist_equalization(imgs_train)

    # weight_map_train = np.load(npy_path + "/weight_map_train.npy")
    # weight_map_train = weight_map_train.astype('float32')

    imgs_train = imgs_train.astype('float32')
    imgs_mask_train = imgs_mask_train.astype('float32')

    if LCN_enable:
        imgs_train = imgs_train.astype('float64')
        imgs_train = LecunLCN(imgs_train, image_shape=imgs_train.shape).output.eval()
        imgs_train = imgs_train.astype('float32')

    if not LCN_enable: imgs_train /= 255

    imgs_train -= imgs_train.mean(axis=0)
    imgs_mask_train /= 255
    imgs_mask_train[imgs_mask_train > 0.5] = 1
    imgs_mask_train[imgs_mask_train <= 0.5] = 0

    # weight_map_train = create_weight_map(imgs_mask_train)

    print("Done loading traing data")
    print('-' * 30)
    return imgs_train, imgs_mask_train

def load_val_data(npy_path = "data/dataset", hist_equal = True):

    print('-' * 30)
    print('load validation images...')

    imgs_train = np.load(npy_path + "/imgs_val.npy")
    imgs_mask_train = np.load(npy_path + "/imgs_mask_val.npy")

    if hist_equal: imgs_train = hist_equalization(imgs_train)

    imgs_train = imgs_train.astype('float32')
    imgs_mask_train = imgs_mask_train.astype('float32')

    if LCN_enable:
        imgs_train = imgs_train.astype('float64')
        imgs_train = LecunLCN(imgs_train, image_shape=imgs_train.shape).output.eval()
        imgs_train = imgs_train.astype('float32')

    if not LCN_enable: imgs_train /= 255
    imgs_train -= imgs_train.mean(axis=0)
    imgs_mask_train /= 255
    imgs_mask_train[imgs_mask_train > 0.5] = 1
    imgs_mask_train[imgs_mask_train <= 0.5] = 0
    print("Done loading validation data")
    print('-' * 30)
    return imgs_train, imgs_mask_train

def load_test_data(npy_path = "data/dataset", hist_equal = True):

    print('-' * 30)
    print('load test images...')

    imgs_test = np.load(npy_path + "/imgs_test.npy")

    if hist_equal: imgs_test = hist_equalization(imgs_test)

    imgs_test = imgs_test.astype('float32')

    if LCN_enable:
        imgs_test = imgs_test.astype('float64')
        imgs_test = LecunLCN(imgs_test, image_shape=imgs_test.shape).output.eval()
        imgs_test = imgs_test.astype('float32')

    if not LCN_enable: imgs_test /= 255

    imgs_test -= imgs_test.mean(axis=0)

    print("Done loading test data")
    print('-' * 30)
    return imgs_test

def load_val_5imgs(npy_path = "data/dataset"):
    print('-' * 30)
    print('load train images...')

    imgs_train = np.load(npy_path + "/imgs_val_5imgs.npy")
    imgs_mask_train = np.load(npy_path + "/imgs_mask_val_5imgs.npy")

    # imgs_train = hist_equalization(imgs_train)

    imgs_train = imgs_train.astype('float64')
    imgs_mask_train = imgs_mask_train.astype('float64')

    if LCN_enable: imgs_train = LecunLCN(imgs_train, image_shape=imgs_train.shape).output.eval()

    if not LCN_enable: imgs_train /= 255

    mean = imgs_train.mean(axis=0)
    imgs_train -= mean


    imgs_mask_train /= 255
    imgs_mask_train[imgs_mask_train > 0.5] = 1
    imgs_mask_train[imgs_mask_train <= 0.5] = 0

    # weight_map_train = self.create_weight_map(imgs_mask_train)

    print("Done loading traing data")
    print('-' * 30)
    return imgs_train, imgs_mask_train

def hist_equalization(inputs):      # inputs are uint8, 0-255, Nx1x636x636
    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))
    output = inputs.copy()
    for i in range(len(inputs)):
        img = inputs[i, 0, :, :]
        # res = cv2.equalizeHist(img)
        res = clahe.apply(img)
        output[i,0,:,:] = res
    return output

### BinaryCrossEntropyLoss2d().forward(logits, labels)
class BinaryCrossEntropyLoss2d(nn.Module):
    def __init__(self, weight=None, size_average=True):
        """
        Binary cross entropy loss 2D
        Args:
            weight:
            size_average:
        """
        super(BinaryCrossEntropyLoss2d, self).__init__()
        self.bce_loss = nn.BCELoss(weight, size_average)

    def forward(self, logits, targets):
        # probs = F.sigmoid(logits)
        probs = logits
        probs_flat = probs.view(-1)  # Flatten
        targets_flat = targets.view(-1)  # Flatten
        return self.bce_loss(probs_flat, targets_flat)      # (output, labels)

class BCE_with_Weights(nn.Module):
    def __init__(self, weights=None):
        """
        Binary cross entropy loss 2D
        Args:
            weights:
        """
        super(BCE_with_Weights, self).__init__()
        self.weights = weights

    def forward(self, output, target):
        if self.weights is not None:
            loss = self.weights * (target * torch.log(output) + (1 - target) * torch.log(1 - output))
        else:
            loss = target * torch.log(output) + (1 - target) * torch.log(1 - output)

        return torch.neg(torch.mean(loss))

class LRN(nn.Module):       # input x is Torch tensor
    def __init__(self, local_size=1, alpha=1.0, beta=0.75, ACROSS_CHANNELS=False):      #LRN(local_size=5, alpha=0.0001, beta=0.75),
        super(LRN, self).__init__()
        self.ACROSS_CHANNELS = ACROSS_CHANNELS
        if self.ACROSS_CHANNELS:
            self.average = nn.AvgPool3d(kernel_size=(local_size, 1, 1),
                                        stride=1, padding=(int((local_size - 1.0) / 2), 0, 0))
        else:
            self.average = nn.AvgPool2d(kernel_size=local_size,
                                        stride=1, padding=int((local_size - 1.0) / 2))
        self.alpha = alpha
        self.beta = beta

    def forward(self, x):
        if self.ACROSS_CHANNELS:
            div = x.pow(2).unsqueeze(1)
            div = self.average(div).squeeze(1)
            div = div.mul(self.alpha).add(1.0).pow(self.beta)
        else:
            div = x.pow(2)
            div = self.average(div)
            div = div.mul(self.alpha).add(1.0).pow(self.beta)
        x = x.div(div)
        return x
Sat Nov 25 03:06:07 2017
Leg22_CROP_dropout_0_2_rmSigmoid_20aug_10ela_3inten_reflect
optim.SGD(net.parameters(), lr=1e-2, momentum=0.99)
Number of epoch max: 6
==========================================================================================
Sat Nov 25 03:07:35 2017
Leg22_CROP_dropout_0_2_rmSigmoid_20aug_10ela_3inten_reflect
Sat Nov 25 03:07:32 2017
import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.autograd import Variable
import math


class ConvBnRelu(nn.Module):
    def __init__(self, in_channels, out_channels, kernel_size, padding, stride):
        super(ConvBnRelu, self).__init__()
        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=kernel_size, padding=padding, stride=stride)
        self.bn = nn.BatchNorm2d(out_channels)
        self.relu = nn.ReLU()

    def forward(self, x):
        x = self.conv(x)
        # x = self.bn(x)
        x = self.relu(x)
        return x


class StackEncoder(nn.Module):
    def __init__(self, in_channels, out_channels):
        super(StackEncoder, self).__init__()
        self.convr1 = ConvBnRelu(in_channels, out_channels, kernel_size=(3, 3), stride=1, padding=0)
        self.convr2 = ConvBnRelu(out_channels, out_channels, kernel_size=(3, 3), stride=1, padding=0)
        self.maxPool = nn.MaxPool2d(kernel_size=(2, 2), stride=2)

    def forward(self, x):
        x = self.convr1(x)
        x = self.convr2(x)
        x_trace = x             # save x to use in concat in the Decoder path
        out = self.maxPool(x)
        return out, x_trace


class StackDecoder(nn.Module):
    def __init__(self, in_channels, out_channels, padding = 0, drop_out=False):
        super(StackDecoder, self).__init__()

        self.drop_out = drop_out
        self.dropout_layer = nn.Dropout2d(p=0.5)

        ''' this is old version
        self.upSample = nn.Upsample(size=upsample_size, scale_factor=(2, 2), mode="bilinear")
        self.convr1 = ConvBnRelu(in_channels, out_channels, kernel_size=(3, 3), stride=1, padding=padding)
        # Crop + concat step between these 2
        self.convr2 = ConvBnRelu(in_channels, out_channels, kernel_size=(3, 3), stride=1, padding=padding)
        '''
        self.upSample = nn.ConvTranspose2d(in_channels, out_channels, 2, stride=2)
        self.convr1 = ConvBnRelu(in_channels, out_channels, kernel_size=(3, 3), stride=1, padding=padding)
        self.convr2 = ConvBnRelu(out_channels, out_channels, kernel_size=(3, 3), stride=1, padding=padding)

    def _crop_concat(self, upsampled, bypass):
        """
         Crop y to the (h, w) of x and concat them.
         Used for the expansive path.
        Returns:
            The concatenated tensor
        """
        c = (bypass.size()[2] - upsampled.size()[2]) // 2
        bypass = F.pad(bypass, (-c, -c, -c, -c))

        return torch.cat((bypass, upsampled), 1)

    def forward(self, x, down_tensor):
        '''old version
        x = self.upSample(x)
        x = self.convr1(x)
        x = self._crop_concat(x, down_tensor)
        x = self.convr2(x)
        '''

        x = self.upSample(x)
        x = self._crop_concat(x, down_tensor)
        x = self.convr1(x)
        if self.drop_out: x = self.dropout_layer(x)
        x = self.convr2(x)
        if self.drop_out: x = self.dropout_layer(x)
        return x


class UNET_CROP(nn.Module):
    def __init__(self):
        super(UNET_CROP, self).__init__()
        # channels, height, width = in_shape

        # self.dropout = dropout

        self.model_code = ""        # variable to save model and main function when loaded

        self.down1 = StackEncoder(1, 64)
        self.down2 = StackEncoder(64, 128)
        self.down3 = StackEncoder(128, 256)
        self.down4 = StackEncoder(256, 512)

        self.center = nn.Sequential(
            # nn.Dropout2d(p=0.2),
            ConvBnRelu(512, 1024, kernel_size=(3, 3), stride=1, padding=0),
            nn.Dropout2d(p=0.2),
            ConvBnRelu(1024, 1024, kernel_size=(3, 3), stride=1, padding=0),
            nn.Dropout2d(p=0.2)
        )

        self.up1 = StackDecoder(in_channels=1024, out_channels=512)
        self.up2 = StackDecoder(in_channels=512, out_channels=256)
        self.up3 = StackDecoder(in_channels=256, out_channels=128)
        self.up4 = StackDecoder(in_channels=128, out_channels=64)

        # 1x1 convolution at the last layer
        # Different from the paper is the output size here
        self.output_seg_map = nn.Conv2d(64, 1, kernel_size=(1, 1), padding=0, stride=1)

        self._initialize_weights()

    def forward(self, x):
        x, x_trace1 = self.down1(x)
        x, x_trace2 = self.down2(x)
        x, x_trace3 = self.down3(x)
        x, x_trace4 = self.down4(x)
        x = self.center(x)
        x = self.up1(x, x_trace4)
        x = self.up2(x, x_trace3)
        x = self.up3(x, x_trace2)
        x = self.up4(x, x_trace1)

        x = self.output_seg_map(x)
        # x = F.sigmoid(x)
        # out = torch.squeeze(out, dim=1)
        return x


    def _initialize_weights(self):
        for m in self.modules():
            if isinstance(m, nn.Conv2d):
                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels
                m.weight.data.normal_(0, math.sqrt(2. / n))
                if m.bias is not None:
                    m.bias.data.zero_()
            elif isinstance(m, nn.BatchNorm2d):
                m.weight.data.fill_(1)
                m.bias.data.zero_()

# x = Variable(torch.randn(1,1,700, 700))       # simulate input image
# net = UNET_CROP()
# out = net(x)
# print("input: ", x)
# print("output: ", out)
===============from __future__ import print_function, division
import torch
from torch import optim
from torch.autograd import Variable
from torch.utils.data import DataLoader
import numpy as np
import torch.nn as nn
import torch.nn.functional as F
import Unet_crop
import tifffile as tiff
import Utils
import time
from sklearn.metrics import average_precision_score, recall_score, f1_score
import Analysis_crop
import cv2

def to_var(x):
    if torch.cuda.is_available():
        return Variable(x.cuda())
    else:
        return Variable(x)

### BinaryCrossEntropyLoss2d().forward(logits, labels)
class BinaryCrossEntropyLoss2d(nn.Module):
    def __init__(self, weight=None, size_average=True):
        """
        Binary cross entropy loss 2D
        Args:
            weight:
            size_average:
        """
        super(BinaryCrossEntropyLoss2d, self).__init__()
        self.bce_loss = nn.BCELoss(weight, size_average)

    def forward(self, probs, targets):
        probs = F.sigmoid(probs)
        probs_flat = probs.view(-1)  # Flatten
        targets_flat = targets.view(-1)  # Flatten
        return self.bce_loss(probs_flat, targets_flat)      # (output, labels)

def NetEval(net,valdata_loader,crit):
    loss = 0.
    count = 0
    net.eval()
    crop_input, crop_label,_ = crop_info()
    for i,data in enumerate(valdata_loader,0):
        # if i > 10: break
        inputs, labels = data
        # inputs = inputs.numpy()
        # labels = labels.numpy()
        for j in range(len(crop_input)):  # training on the crop images and corresponding labels
            ci = crop_input[j]  # crop index for inputs
            cl = crop_label[j]  # crop index for lables
            # temp = labels[0, 0, :, :]  # labels is numpy array 512x512
            # if np.sum(temp) < 0.01 * np.shape(temp)[0] * np.shape(temp)[1]: break
            x = inputs.numpy()[:, :, ci[0]:ci[0] + 572, ci[1]:ci[1] + 572]
            y = labels.numpy()[:, :, cl[0]: cl[0] + 388, cl[1]:cl[1] + 388]
            x = torch.from_numpy(x)
            y = torch.from_numpy(y)
            x, y = to_var(x), to_var(y)
            out = net(x)
            l = crit(out, y)
            loss += l.data[0]
            count += 1
    return loss/count

#process the test data and save to separate .tif image
def NetTest(net,testdata_loader,path = "data/results/"):
    net.eval()
    crop_input, crop_label, average_mask = crop_info()
    for i, data in enumerate(testdata_loader, 0):
        if i >= 30: return 1        # for debug
        # data = to_var(data)
        img_shape = 512
        img = np.zeros((img_shape, img_shape))
        for j in range(len(crop_input)):  # training on the crop images and corresponding labels
            temp = np.zeros((img_shape, img_shape))
            ci = crop_input[j]  # crop index for inputs
            cl = crop_label[j]
            x = data.numpy()[:, :, ci[0]:ci[0] + 572, ci[1]:ci[1] + 572]
            x = torch.from_numpy(x)
            x = to_var(x)
            out = F.sigmoid(net(x))
            out = out.cpu()
            out = out[0,0,:,:]
            # print("j: ", j)
            # print("size of temp: ", np.shape(temp))
            # print("size of output: ", np.shape(out.data.numpy()))
            temp[cl[0]: cl[0] + 388, cl[1]:cl[1] + 388] = out.data.numpy()
            img += temp

        img = img/average_mask
        img = img.reshape(-1)
        img[img < 0.5] = 0; img[img >= 0.5] = 1
        img = img.reshape(img_shape, img_shape)
        img = np.uint8(img * 255)
        imgname = path + str(i) + ".tif"
        tiff.imsave(imgname, img)

# return input image size like 512x512, numpy array
def NetPredict(net, input_image):
    net.eval()
    _, crop_label, average_mask = crop_info()

    # input_image is grayscale input image of 512x512
    data = Utils.input_filled_mirroring(input_image, e = 94)
    imgdatas = np.ndarray((1, 1, data.shape[0], data.shape[1]), dtype=np.uint8)
    imgdatas[0] = np.expand_dims(data, 0)
    data = Utils.hist_equalization(imgdatas)
    data = data.astype('float32')
    data /= 255
    data -= data.mean(axis=0)

    img_shape = input_image.shape
    img = np.zeros((img_shape, img_shape))
    for j in range(len(crop_input)):  # training on the crop images and corresponding labels
        temp = np.zeros((img_shape, img_shape))
        ci = crop_input[j]  # crop index for inputs
        cl = crop_label[j]
        x = data.numpy()[:, :, ci[0]:ci[0] + 572, ci[1]:ci[1] + 572]
        x = torch.from_numpy(x)
        x = to_var(x)
        out = F.sigmoid(net(x))
        out = out.cpu()
        out = out[0, 0, :, :]
        temp[cl[0]: cl[0] + 388, cl[1]:cl[1] + 388] = out.data.numpy()
        img += temp

    img = img / average_mask
    img = img.reshape(-1)
    img[img < 0.5] = 0
    img[img >= 0.5] = 1
    img = img.reshape(img_shape)
    img = np.uint8(img * 255)
    return img


def write_2_log(content):
    path = "log_file.txt"
    output = open(path, "a")
    output.write("\n")
    output.write(content)
    output.close()

def crop_info():
    crop_input = [[0, 0], [128, 0], [0, 128], [128, 128]]
    crop_label = [[0, 0], [124, 0], [0, 124], [124, 124]]
    average_mask = np.ones((512, 512))
    average_mask[124:388, 0:124] = 2
    average_mask[0:124, 124:388] = 2
    average_mask[124:388, 388:512] = 2
    average_mask[388:512, 124:388] = 2
    average_mask[124:388, 124:388] = 4
    return crop_input, crop_label, average_mask

if __name__ == '__main__':
    '''subjects to change for each exp:
    + path to the dataset
    + opt function
    + leg description
    + N_epoch
    + saved_model
    '''
    start_begining = time.time()

    # path = "data/dataset"
    path = "/home/anhxtuan/HanLe/dataset/20aug_10ela_3inten_reflect"
    path = "/home/anhxtuan/HanLe/dataset/20aug_10ela_3inten_reflect_700"

    import os
    print("Does the folder exist?: ", os.path.isdir(path))
    print("Does the path exist?: ", os.path.exists(path))

    imgs_train, imgs_mask_train = Utils.load_train_data(npy_path=path)
    imgs_val, imgs_mask_val = Utils.load_val_data(npy_path=path)
    batch_size = 1
    trainset = zip(imgs_train, imgs_mask_train)
    trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,
                                              shuffle=True, num_workers=2)
    valset = zip(imgs_val, imgs_mask_val)
    valloader = torch.utils.data.DataLoader(valset, batch_size=batch_size,
                                              shuffle=False, num_workers=2)
    # net = Unet.UNet()                     # Unet 1
    # net = Unet_BatchNorm.UNet_BN()          # Unet 2 with batchNorm
    net = Unet_crop.UNET_CROP()

    f1 = open("Unet_crop.py", 'r')     # embede code into the model to be saved later
    f2 = open("UnetTrain_crop.py", 'r')
    f3 = open("Utils.py", 'r')
    model_notes = time.strftime("%c") + "\n" + f1.read() + "\n" + "==="*5 + f2.read() + "\n" + "==="*5 + f3.read()
    f1.close()
    f2.close()
    f3.close()

    criterion = BinaryCrossEntropyLoss2d()
    # criterion = SoftDiceLoss()
    # criterion = nn.BCELoss()

    if torch.cuda.is_available():
        # torch.set_default_tensor_type('torch.cuda.FloatTensor')
        # net.load_state_dict(torch.load("Unet2_model_12epoch_Leg12_droput_0_2_rmSigmoid_20aug_10ela_3inten_reflect"))
        net.cuda()
        # criterion.cuda()

    opt = optim.SGD(net.parameters(), lr=1e-2, momentum=0.99)       # subject to change
    # opt = optim.RMSprop(net.parameters(), lr=2e-4)
    # RMSprop[22](learning rate 0.001) with weight decay set to 0.001.
    # opt = optim.Adam(net.parameters(), lr=1e-3, weight_decay=1e-4)

    train_loss = []
    val_loss = []

    print("[epoch, #image] Loss")
    leg = "Leg22_CROP_dropout_0_2_rmSigmoid_20aug_10ela_3inten_reflect"
    print("Processing: ", leg)
    model_name = ""

    N_epoch = 6
    model_saved = np.arange(2,N_epoch+1,2)
    val_loss_min = 100

    write_2_log("==="*30)
    write_2_log(time.strftime("%c"))       # time, date of exp
    write_2_log(leg)
    write_2_log(model_notes)
    write_2_log(time.strftime("%c"))  # time, date of exp
    write_2_log(leg)
    write_2_log("optim.SGD(net.parameters(), lr=1e-2, momentum=0.99)")
    write_2_log("Number of epoch max: " + str(N_epoch))

    crop_input, crop_label,_ = crop_info()
    min_model_epoch = 0
    for epoch in range(N_epoch):
        running_loss = 0.0; count = 0
        net.train()
        for i, data in enumerate(trainloader, 0):
            # if i > 10: break

            inputs, labels = data
            temp = labels.numpy()
            for j in range(len(crop_input)):       # training on the crop images and corresponding labels
                ci = crop_input[j]          # crop index for inputs
                cl = crop_label[j]          # crop index for lables
                # temp = temp[0, 0, :, :]  # labels is numpy array 512x512
                # if np.sum(temp) < 0.01 * np.shape(temp)[0] * np.shape(temp)[1]: break
                x = inputs.numpy()[:, :, ci[0]:ci[0] + 572, ci[1]:ci[1] + 572]
                y = labels.numpy()[:, :, cl[0]: cl[0] + 388, cl[1]:cl[1] + 388]
                print("size of x: ", x.shape)
                print("size of y: ", y.shape)
                import matplotlib.pyplot as plt
                plt.subplot(121); plt.imshow(x[0,0,:,:], cmap='gray')
                plt.subplot(122); plt.imshow(y[0,0,:,:], cmap='gray')
                x = torch.from_numpy(x)
                y = torch.from_numpy(y)
                x, y = to_var(x), to_var(y)
                opt.zero_grad()
                out = net(x)
                loss = criterion(out, y)
                loss.backward()
                opt.step()
                running_loss += loss.data[0]
                count += 1

        net.eval()
        val_loss_temp = NetEval(net, valloader, criterion)
        if epoch > 0 and val_loss_temp < val_loss_min:        # save the model which has the lowest val_loss, ignore first epoch
            val_loss_min = val_loss_temp
            torch.save(net.state_dict(), "Unet2_model_" + leg + "_min_val_loss")  # save model
            min_model_epoch = epoch + 1

        disp = 'Epoch %d: Train loss: %.6f, Val loss: %.6f' % (epoch + 1, running_loss/count, val_loss_temp)
        write_2_log(disp)
        print(disp)
        val_loss.append(val_loss_temp)
        train_loss.append(running_loss/count); running_loss = 0.0

        if (epoch + 1) in model_saved or epoch == 0:        # save checkpoint
            model_name = "Unet2_model_" + str(epoch+1) + "epoch_" + leg
            torch.save(net.state_dict(), model_name)  # save model
            Analysis_crop.analysis(model_file = model_name, valloader = valloader)

    write_2_log("Best model at epoch: " + str(min_model_epoch))
    write_2_log("Total training time: " + str((time.time() - start_begining) / 3600.0))

    val_loss_file = "data/results" + "/val_loss_" + str(N_epoch) + "epoch_" + leg + ".npy"
    train_loss_file = "data/results" + "/training_loss_" + str(N_epoch) + "epoch_" + leg + ".npy"

    np.save(val_loss_file, val_loss)
    np.save(train_loss_file, train_loss)
    print("total processing time in seconds: ", time.time() - start_begining)
    print("total processing time in mins: ", (time.time() - start_begining) / 60.0)
    print("total processing time in hours: ", (time.time() - start_begining) / 3600.0)

    # Analysis.analysis(model_file="Unet2_model_" + leg + "_min_val_loss", valloader=valloader)

    Analysis_crop.PlotLoss(model_file = model_name, loss_train_path = train_loss_file, loss_val_path = val_loss_file, epoch_No = N_epoch)

    write_2_log(time.strftime("%c"))  # time, date of exp
===============
import numpy as np
import torch.nn as nn
import torch
import cv2
from lcn import LecunLCN

LCN_enable = False

def input_filled_mirroring(x, e = 62):      # fill missing data by mirroring the input image
    '''input size 636 --> output size 512'''
    w, h = x.shape
    #e = 62  # extra width on 1 edge
    y = np.zeros((h + e * 2, w + e * 2))
    y[e:h + e, e:w + e] = x
    y[e:e + h, 0:e] = np.flip(y[e:e + h, e:2 * e], 1)  # flip vertically
    y[e:e + h, e + w:2 * e + w] = np.flip(y[e:e + h, w:e + w], 1)  # flip vertically
    y[0:e, 0:2 * e + w] = np.flip(y[e:2 * e, 0:2 * e + w], 0)  # flip horizontally
    y[e + h:2 * e + h, 0:2 * e + w] = np.flip(y[h:e + h, 0:2 * e + w], 0)  # flip horizontally
    return y

def nearest_cells_distance(pos, img):
    # searching in 8 directions to find 2 nearest distances to neighbor cells
    curr_value = img[pos]
    w = img.shape[0];h = img.shape[1]
    count_detect = 0  # detect 2 nearest neighbors. break the search if count_detect = 2
    x, y = pos

    # print("w,h: ", (w, h))
    d1 = 9999999;d2 = 9999999;d3 = 9999999;d4 = 9999999
    d5 = 9999999;d6 = 9999999;d7 = 9999999;d8 = 9999999
    for i in range(1, max(w, h)):
        # (x+1, y), (x+1, y+1), (x+1, y-1),
        # (x, y+1), (x, y-1)
        # (x-1, y), (x-1,y+1), (x-1,y-1),
        if x + i < w:
            if img[(x + i, y)] != curr_value and d1 == 9999999:
                d1 = i; count_detect += 1
            if y + i < h:
                if img[(x + i, y + i)] != curr_value and d2 == 9999999:
                    d2 = i; count_detect += 1
            elif y - i >= 0:
                if img[(x + i, y - i)] != curr_value and d3 == 9999999:
                    d3 = i; count_detect += 1
        if y + i < h:
            if img[(x, y + i)] != curr_value and d4 == 9999999:
                d4 = i; count_detect += 1
        if y - i >= 0:
            if img[(x, y - i)] != curr_value and d5 == 9999999:
                d5 = i; count_detect += 1
        if x - i >= 0:
            if img[(x - i, y)] != curr_value and d6 == 9999999:
                d6 = i; count_detect += 1
            if y + i < h:
                if img[(x - i, y + i)] != curr_value and d7 == 9999999:
                    d7 = i; count_detect += 1
            elif y - i >= 0:
                if img[(x - i, y - i)] != curr_value and d8 == 9999999:
                    d8 = i; count_detect += 1
        if count_detect >= 2: break

    d = [d1, d2, d3, d4, d5, d6, d7, d8]
    min_index = np.argmin(d)
    dist1 = d[min_index]
    d.remove(dist1)
    min_index = np.argmin(d)
    dist2 = d[min_index]
    return dist1, dist2

def create_weight_map(imgs_mask):
        print('-' * 30)
        print('Creating weights for masks ...')
        print('-' * 30)
        weight_map = np.ndarray(
            (len(imgs_mask), 1, np.shape(imgs_mask)[2], np.shape(imgs_mask)[3]), dtype=np.float32)
        w_0 = 10; sigma = 4
        imgs_w, imgs_h = np.shape(imgs_mask)[2], np.shape(imgs_mask)[3]
        total_pixels = imgs_w*imgs_h
        import time
        start = time.time()
        for i in range(len(imgs_mask)):
            if i%10 == 0: print("Done processing: %d images, time passed: %.2f mins" % (i, (time.time() - start)/60.0))
            temp = imgs_mask[i,0,:,:]
            w_border = 1 - np.sum(temp)/total_pixels        # w_c of pixel on the border (black)
            for m in range(imgs_w):
                for n in range(imgs_h):
                    # loop through all pixel of the mask
                    d1,d2 = nearest_cells_distance((m,n), temp)
                    w_c = w_border
                    if temp[m,n] == 0: w_c = 1 - w_border
                    weight_map[i,0,m,n] = w_c*5 + w_0*np.exp(-(d1 + d2)**2/(2*sigma**2))
                    # print("w_0*np.exp(): ", w_0*np.exp(-(d1 + d2)**2/(2*sigma**2)))
                    # print("w_border: ", w_border)

        np.save('data/dataset/weight_map_train.npy', weight_map)

        return weight_map

def load_train_data(npy_path = "data/dataset", hist_equal = False):

    print('-' * 30)
    print('load train images...')

    imgs_train = np.load(npy_path + "/imgs_train.npy")
    imgs_mask_train = np.load(npy_path + "/imgs_mask_train.npy")

    if hist_equal: imgs_train = hist_equalization(imgs_train)

    # weight_map_train = np.load(npy_path + "/weight_map_train.npy")
    # weight_map_train = weight_map_train.astype('float32')

    imgs_train = imgs_train.astype('float32')
    imgs_mask_train = imgs_mask_train.astype('float32')

    if LCN_enable:
        imgs_train = imgs_train.astype('float64')
        imgs_train = LecunLCN(imgs_train, image_shape=imgs_train.shape).output.eval()
        imgs_train = imgs_train.astype('float32')

    if not LCN_enable: imgs_train /= 255

    imgs_train -= imgs_train.mean(axis=0)
    imgs_mask_train /= 255
    imgs_mask_train[imgs_mask_train > 0.5] = 1
    imgs_mask_train[imgs_mask_train <= 0.5] = 0

    # weight_map_train = create_weight_map(imgs_mask_train)

    print("Done loading traing data")
    print('-' * 30)
    return imgs_train, imgs_mask_train

def load_val_data(npy_path = "data/dataset", hist_equal = True):

    print('-' * 30)
    print('load validation images...')

    imgs_train = np.load(npy_path + "/imgs_val.npy")
    imgs_mask_train = np.load(npy_path + "/imgs_mask_val.npy")

    if hist_equal: imgs_train = hist_equalization(imgs_train)

    imgs_train = imgs_train.astype('float32')
    imgs_mask_train = imgs_mask_train.astype('float32')

    if LCN_enable:
        imgs_train = imgs_train.astype('float64')
        imgs_train = LecunLCN(imgs_train, image_shape=imgs_train.shape).output.eval()
        imgs_train = imgs_train.astype('float32')

    if not LCN_enable: imgs_train /= 255
    imgs_train -= imgs_train.mean(axis=0)
    imgs_mask_train /= 255
    imgs_mask_train[imgs_mask_train > 0.5] = 1
    imgs_mask_train[imgs_mask_train <= 0.5] = 0
    print("Done loading validation data")
    print('-' * 30)
    return imgs_train, imgs_mask_train

def load_test_data(npy_path = "data/dataset", hist_equal = True):

    print('-' * 30)
    print('load test images...')

    imgs_test = np.load(npy_path + "/imgs_test.npy")

    if hist_equal: imgs_test = hist_equalization(imgs_test)

    imgs_test = imgs_test.astype('float32')

    if LCN_enable:
        imgs_test = imgs_test.astype('float64')
        imgs_test = LecunLCN(imgs_test, image_shape=imgs_test.shape).output.eval()
        imgs_test = imgs_test.astype('float32')

    if not LCN_enable: imgs_test /= 255

    imgs_test -= imgs_test.mean(axis=0)

    print("Done loading test data")
    print('-' * 30)
    return imgs_test

def load_val_5imgs(npy_path = "data/dataset"):
    print('-' * 30)
    print('load train images...')

    imgs_train = np.load(npy_path + "/imgs_val_5imgs.npy")
    imgs_mask_train = np.load(npy_path + "/imgs_mask_val_5imgs.npy")

    # imgs_train = hist_equalization(imgs_train)

    imgs_train = imgs_train.astype('float64')
    imgs_mask_train = imgs_mask_train.astype('float64')

    if LCN_enable: imgs_train = LecunLCN(imgs_train, image_shape=imgs_train.shape).output.eval()

    if not LCN_enable: imgs_train /= 255

    mean = imgs_train.mean(axis=0)
    imgs_train -= mean


    imgs_mask_train /= 255
    imgs_mask_train[imgs_mask_train > 0.5] = 1
    imgs_mask_train[imgs_mask_train <= 0.5] = 0

    # weight_map_train = self.create_weight_map(imgs_mask_train)

    print("Done loading traing data")
    print('-' * 30)
    return imgs_train, imgs_mask_train

def hist_equalization(inputs):      # inputs are uint8, 0-255, Nx1x636x636
    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))
    output = inputs.copy()
    for i in range(len(inputs)):
        img = inputs[i, 0, :, :]
        # res = cv2.equalizeHist(img)
        res = clahe.apply(img)
        output[i,0,:,:] = res
    return output

### BinaryCrossEntropyLoss2d().forward(logits, labels)
class BinaryCrossEntropyLoss2d(nn.Module):
    def __init__(self, weight=None, size_average=True):
        """
        Binary cross entropy loss 2D
        Args:
            weight:
            size_average:
        """
        super(BinaryCrossEntropyLoss2d, self).__init__()
        self.bce_loss = nn.BCELoss(weight, size_average)

    def forward(self, logits, targets):
        # probs = F.sigmoid(logits)
        probs = logits
        probs_flat = probs.view(-1)  # Flatten
        targets_flat = targets.view(-1)  # Flatten
        return self.bce_loss(probs_flat, targets_flat)      # (output, labels)

class BCE_with_Weights(nn.Module):
    def __init__(self, weights=None):
        """
        Binary cross entropy loss 2D
        Args:
            weights:
        """
        super(BCE_with_Weights, self).__init__()
        self.weights = weights

    def forward(self, output, target):
        if self.weights is not None:
            loss = self.weights * (target * torch.log(output) + (1 - target) * torch.log(1 - output))
        else:
            loss = target * torch.log(output) + (1 - target) * torch.log(1 - output)

        return torch.neg(torch.mean(loss))

class LRN(nn.Module):       # input x is Torch tensor
    def __init__(self, local_size=1, alpha=1.0, beta=0.75, ACROSS_CHANNELS=False):      #LRN(local_size=5, alpha=0.0001, beta=0.75),
        super(LRN, self).__init__()
        self.ACROSS_CHANNELS = ACROSS_CHANNELS
        if self.ACROSS_CHANNELS:
            self.average = nn.AvgPool3d(kernel_size=(local_size, 1, 1),
                                        stride=1, padding=(int((local_size - 1.0) / 2), 0, 0))
        else:
            self.average = nn.AvgPool2d(kernel_size=local_size,
                                        stride=1, padding=int((local_size - 1.0) / 2))
        self.alpha = alpha
        self.beta = beta

    def forward(self, x):
        if self.ACROSS_CHANNELS:
            div = x.pow(2).unsqueeze(1)
            div = self.average(div).squeeze(1)
            div = div.mul(self.alpha).add(1.0).pow(self.beta)
        else:
            div = x.pow(2)
            div = self.average(div)
            div = div.mul(self.alpha).add(1.0).pow(self.beta)
        x = x.div(div)
        return x
Sat Nov 25 03:07:35 2017
Leg22_CROP_dropout_0_2_rmSigmoid_20aug_10ela_3inten_reflect
optim.SGD(net.parameters(), lr=1e-2, momentum=0.99)
Number of epoch max: 6
==========================================================================================
Sat Nov 25 03:08:46 2017
Leg22_CROP_dropout_0_2_rmSigmoid_20aug_10ela_3inten_reflect
Sat Nov 25 03:08:43 2017
import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.autograd import Variable
import math


class ConvBnRelu(nn.Module):
    def __init__(self, in_channels, out_channels, kernel_size, padding, stride):
        super(ConvBnRelu, self).__init__()
        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=kernel_size, padding=padding, stride=stride)
        self.bn = nn.BatchNorm2d(out_channels)
        self.relu = nn.ReLU()

    def forward(self, x):
        x = self.conv(x)
        # x = self.bn(x)
        x = self.relu(x)
        return x


class StackEncoder(nn.Module):
    def __init__(self, in_channels, out_channels):
        super(StackEncoder, self).__init__()
        self.convr1 = ConvBnRelu(in_channels, out_channels, kernel_size=(3, 3), stride=1, padding=0)
        self.convr2 = ConvBnRelu(out_channels, out_channels, kernel_size=(3, 3), stride=1, padding=0)
        self.maxPool = nn.MaxPool2d(kernel_size=(2, 2), stride=2)

    def forward(self, x):
        x = self.convr1(x)
        x = self.convr2(x)
        x_trace = x             # save x to use in concat in the Decoder path
        out = self.maxPool(x)
        return out, x_trace


class StackDecoder(nn.Module):
    def __init__(self, in_channels, out_channels, padding = 0, drop_out=False):
        super(StackDecoder, self).__init__()

        self.drop_out = drop_out
        self.dropout_layer = nn.Dropout2d(p=0.5)

        ''' this is old version
        self.upSample = nn.Upsample(size=upsample_size, scale_factor=(2, 2), mode="bilinear")
        self.convr1 = ConvBnRelu(in_channels, out_channels, kernel_size=(3, 3), stride=1, padding=padding)
        # Crop + concat step between these 2
        self.convr2 = ConvBnRelu(in_channels, out_channels, kernel_size=(3, 3), stride=1, padding=padding)
        '''
        self.upSample = nn.ConvTranspose2d(in_channels, out_channels, 2, stride=2)
        self.convr1 = ConvBnRelu(in_channels, out_channels, kernel_size=(3, 3), stride=1, padding=padding)
        self.convr2 = ConvBnRelu(out_channels, out_channels, kernel_size=(3, 3), stride=1, padding=padding)

    def _crop_concat(self, upsampled, bypass):
        """
         Crop y to the (h, w) of x and concat them.
         Used for the expansive path.
        Returns:
            The concatenated tensor
        """
        c = (bypass.size()[2] - upsampled.size()[2]) // 2
        bypass = F.pad(bypass, (-c, -c, -c, -c))

        return torch.cat((bypass, upsampled), 1)

    def forward(self, x, down_tensor):
        '''old version
        x = self.upSample(x)
        x = self.convr1(x)
        x = self._crop_concat(x, down_tensor)
        x = self.convr2(x)
        '''

        x = self.upSample(x)
        x = self._crop_concat(x, down_tensor)
        x = self.convr1(x)
        if self.drop_out: x = self.dropout_layer(x)
        x = self.convr2(x)
        if self.drop_out: x = self.dropout_layer(x)
        return x


class UNET_CROP(nn.Module):
    def __init__(self):
        super(UNET_CROP, self).__init__()
        # channels, height, width = in_shape

        # self.dropout = dropout

        self.model_code = ""        # variable to save model and main function when loaded

        self.down1 = StackEncoder(1, 64)
        self.down2 = StackEncoder(64, 128)
        self.down3 = StackEncoder(128, 256)
        self.down4 = StackEncoder(256, 512)

        self.center = nn.Sequential(
            # nn.Dropout2d(p=0.2),
            ConvBnRelu(512, 1024, kernel_size=(3, 3), stride=1, padding=0),
            nn.Dropout2d(p=0.2),
            ConvBnRelu(1024, 1024, kernel_size=(3, 3), stride=1, padding=0),
            nn.Dropout2d(p=0.2)
        )

        self.up1 = StackDecoder(in_channels=1024, out_channels=512)
        self.up2 = StackDecoder(in_channels=512, out_channels=256)
        self.up3 = StackDecoder(in_channels=256, out_channels=128)
        self.up4 = StackDecoder(in_channels=128, out_channels=64)

        # 1x1 convolution at the last layer
        # Different from the paper is the output size here
        self.output_seg_map = nn.Conv2d(64, 1, kernel_size=(1, 1), padding=0, stride=1)

        self._initialize_weights()

    def forward(self, x):
        x, x_trace1 = self.down1(x)
        x, x_trace2 = self.down2(x)
        x, x_trace3 = self.down3(x)
        x, x_trace4 = self.down4(x)
        x = self.center(x)
        x = self.up1(x, x_trace4)
        x = self.up2(x, x_trace3)
        x = self.up3(x, x_trace2)
        x = self.up4(x, x_trace1)

        x = self.output_seg_map(x)
        # x = F.sigmoid(x)
        # out = torch.squeeze(out, dim=1)
        return x


    def _initialize_weights(self):
        for m in self.modules():
            if isinstance(m, nn.Conv2d):
                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels
                m.weight.data.normal_(0, math.sqrt(2. / n))
                if m.bias is not None:
                    m.bias.data.zero_()
            elif isinstance(m, nn.BatchNorm2d):
                m.weight.data.fill_(1)
                m.bias.data.zero_()

# x = Variable(torch.randn(1,1,700, 700))       # simulate input image
# net = UNET_CROP()
# out = net(x)
# print("input: ", x)
# print("output: ", out)
===============from __future__ import print_function, division
import torch
from torch import optim
from torch.autograd import Variable
from torch.utils.data import DataLoader
import numpy as np
import torch.nn as nn
import torch.nn.functional as F
import Unet_crop
import tifffile as tiff
import Utils
import time
from sklearn.metrics import average_precision_score, recall_score, f1_score
import Analysis_crop
import cv2

def to_var(x):
    if torch.cuda.is_available():
        return Variable(x.cuda())
    else:
        return Variable(x)

### BinaryCrossEntropyLoss2d().forward(logits, labels)
class BinaryCrossEntropyLoss2d(nn.Module):
    def __init__(self, weight=None, size_average=True):
        """
        Binary cross entropy loss 2D
        Args:
            weight:
            size_average:
        """
        super(BinaryCrossEntropyLoss2d, self).__init__()
        self.bce_loss = nn.BCELoss(weight, size_average)

    def forward(self, probs, targets):
        probs = F.sigmoid(probs)
        probs_flat = probs.view(-1)  # Flatten
        targets_flat = targets.view(-1)  # Flatten
        return self.bce_loss(probs_flat, targets_flat)      # (output, labels)

def NetEval(net,valdata_loader,crit):
    loss = 0.
    count = 0
    net.eval()
    crop_input, crop_label,_ = crop_info()
    for i,data in enumerate(valdata_loader,0):
        # if i > 10: break
        inputs, labels = data
        # inputs = inputs.numpy()
        # labels = labels.numpy()
        for j in range(len(crop_input)):  # training on the crop images and corresponding labels
            ci = crop_input[j]  # crop index for inputs
            cl = crop_label[j]  # crop index for lables
            # temp = labels[0, 0, :, :]  # labels is numpy array 512x512
            # if np.sum(temp) < 0.01 * np.shape(temp)[0] * np.shape(temp)[1]: break
            x = inputs.numpy()[:, :, ci[0]:ci[0] + 572, ci[1]:ci[1] + 572]
            y = labels.numpy()[:, :, cl[0]: cl[0] + 388, cl[1]:cl[1] + 388]
            x = torch.from_numpy(x)
            y = torch.from_numpy(y)
            x, y = to_var(x), to_var(y)
            out = net(x)
            l = crit(out, y)
            loss += l.data[0]
            count += 1
    return loss/count

#process the test data and save to separate .tif image
def NetTest(net,testdata_loader,path = "data/results/"):
    net.eval()
    crop_input, crop_label, average_mask = crop_info()
    for i, data in enumerate(testdata_loader, 0):
        if i >= 30: return 1        # for debug
        # data = to_var(data)
        img_shape = 512
        img = np.zeros((img_shape, img_shape))
        for j in range(len(crop_input)):  # training on the crop images and corresponding labels
            temp = np.zeros((img_shape, img_shape))
            ci = crop_input[j]  # crop index for inputs
            cl = crop_label[j]
            x = data.numpy()[:, :, ci[0]:ci[0] + 572, ci[1]:ci[1] + 572]
            x = torch.from_numpy(x)
            x = to_var(x)
            out = F.sigmoid(net(x))
            out = out.cpu()
            out = out[0,0,:,:]
            # print("j: ", j)
            # print("size of temp: ", np.shape(temp))
            # print("size of output: ", np.shape(out.data.numpy()))
            temp[cl[0]: cl[0] + 388, cl[1]:cl[1] + 388] = out.data.numpy()
            img += temp

        img = img/average_mask
        img = img.reshape(-1)
        img[img < 0.5] = 0; img[img >= 0.5] = 1
        img = img.reshape(img_shape, img_shape)
        img = np.uint8(img * 255)
        imgname = path + str(i) + ".tif"
        tiff.imsave(imgname, img)

# return input image size like 512x512, numpy array
def NetPredict(net, input_image):
    net.eval()
    _, crop_label, average_mask = crop_info()

    # input_image is grayscale input image of 512x512
    data = Utils.input_filled_mirroring(input_image, e = 94)
    imgdatas = np.ndarray((1, 1, data.shape[0], data.shape[1]), dtype=np.uint8)
    imgdatas[0] = np.expand_dims(data, 0)
    data = Utils.hist_equalization(imgdatas)
    data = data.astype('float32')
    data /= 255
    data -= data.mean(axis=0)

    img_shape = input_image.shape
    img = np.zeros((img_shape, img_shape))
    for j in range(len(crop_input)):  # training on the crop images and corresponding labels
        temp = np.zeros((img_shape, img_shape))
        ci = crop_input[j]  # crop index for inputs
        cl = crop_label[j]
        x = data.numpy()[:, :, ci[0]:ci[0] + 572, ci[1]:ci[1] + 572]
        x = torch.from_numpy(x)
        x = to_var(x)
        out = F.sigmoid(net(x))
        out = out.cpu()
        out = out[0, 0, :, :]
        temp[cl[0]: cl[0] + 388, cl[1]:cl[1] + 388] = out.data.numpy()
        img += temp

    img = img / average_mask
    img = img.reshape(-1)
    img[img < 0.5] = 0
    img[img >= 0.5] = 1
    img = img.reshape(img_shape)
    img = np.uint8(img * 255)
    return img


def write_2_log(content):
    path = "log_file.txt"
    output = open(path, "a")
    output.write("\n")
    output.write(content)
    output.close()

def crop_info():
    crop_input = [[0, 0], [128, 0], [0, 128], [128, 128]]
    crop_label = [[0, 0], [124, 0], [0, 124], [124, 124]]
    average_mask = np.ones((512, 512))
    average_mask[124:388, 0:124] = 2
    average_mask[0:124, 124:388] = 2
    average_mask[124:388, 388:512] = 2
    average_mask[388:512, 124:388] = 2
    average_mask[124:388, 124:388] = 4
    return crop_input, crop_label, average_mask

if __name__ == '__main__':
    '''subjects to change for each exp:
    + path to the dataset
    + opt function
    + leg description
    + N_epoch
    + saved_model
    '''
    start_begining = time.time()

    # path = "data/dataset"
    path = "/home/anhxtuan/HanLe/dataset/20aug_10ela_3inten_reflect"
    path = "/home/anhxtuan/HanLe/dataset/20aug_10ela_3inten_reflect_700"

    import os
    print("Does the folder exist?: ", os.path.isdir(path))
    print("Does the path exist?: ", os.path.exists(path))

    imgs_train, imgs_mask_train = Utils.load_train_data(npy_path=path)
    imgs_val, imgs_mask_val = Utils.load_val_data(npy_path=path)
    batch_size = 1
    trainset = zip(imgs_train, imgs_mask_train)
    trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,
                                              shuffle=True, num_workers=2)
    valset = zip(imgs_val, imgs_mask_val)
    valloader = torch.utils.data.DataLoader(valset, batch_size=batch_size,
                                              shuffle=False, num_workers=2)
    # net = Unet.UNet()                     # Unet 1
    # net = Unet_BatchNorm.UNet_BN()          # Unet 2 with batchNorm
    net = Unet_crop.UNET_CROP()

    f1 = open("Unet_crop.py", 'r')     # embede code into the model to be saved later
    f2 = open("UnetTrain_crop.py", 'r')
    f3 = open("Utils.py", 'r')
    model_notes = time.strftime("%c") + "\n" + f1.read() + "\n" + "==="*5 + f2.read() + "\n" + "==="*5 + f3.read()
    f1.close()
    f2.close()
    f3.close()

    criterion = BinaryCrossEntropyLoss2d()
    # criterion = SoftDiceLoss()
    # criterion = nn.BCELoss()

    if torch.cuda.is_available():
        # torch.set_default_tensor_type('torch.cuda.FloatTensor')
        # net.load_state_dict(torch.load("Unet2_model_12epoch_Leg12_droput_0_2_rmSigmoid_20aug_10ela_3inten_reflect"))
        net.cuda()
        # criterion.cuda()

    opt = optim.SGD(net.parameters(), lr=1e-2, momentum=0.99)       # subject to change
    # opt = optim.RMSprop(net.parameters(), lr=2e-4)
    # RMSprop[22](learning rate 0.001) with weight decay set to 0.001.
    # opt = optim.Adam(net.parameters(), lr=1e-3, weight_decay=1e-4)

    train_loss = []
    val_loss = []

    print("[epoch, #image] Loss")
    leg = "Leg22_CROP_dropout_0_2_rmSigmoid_20aug_10ela_3inten_reflect"
    print("Processing: ", leg)
    model_name = ""

    N_epoch = 6
    model_saved = np.arange(2,N_epoch+1,2)
    val_loss_min = 100

    write_2_log("==="*30)
    write_2_log(time.strftime("%c"))       # time, date of exp
    write_2_log(leg)
    write_2_log(model_notes)
    write_2_log(time.strftime("%c"))  # time, date of exp
    write_2_log(leg)
    write_2_log("optim.SGD(net.parameters(), lr=1e-2, momentum=0.99)")
    write_2_log("Number of epoch max: " + str(N_epoch))

    crop_input, crop_label,_ = crop_info()
    min_model_epoch = 0
    for epoch in range(N_epoch):
        running_loss = 0.0; count = 0
        net.train()
        for i, data in enumerate(trainloader, 0):
            # if i > 10: break

            inputs, labels = data
            temp = labels.numpy()
            for j in range(len(crop_input)):       # training on the crop images and corresponding labels
                ci = crop_input[j]          # crop index for inputs
                cl = crop_label[j]          # crop index for lables
                # temp = temp[0, 0, :, :]  # labels is numpy array 512x512
                # if np.sum(temp) < 0.01 * np.shape(temp)[0] * np.shape(temp)[1]: break
                x = inputs.numpy()[:, :, ci[0]:ci[0] + 572, ci[1]:ci[1] + 572]
                y = labels.numpy()[:, :, cl[0]: cl[0] + 388, cl[1]:cl[1] + 388]
                print("size of x: ", x.shape)
                print("size of y: ", y.shape)
                import matplotlib.pyplot as plt
                plt.subplot(121); plt.imshow(x[0,0,:,:], cmap='gray')
                plt.subplot(122); plt.imshow(y[0,0,:,:], cmap='gray')
                plt.show()
                x = torch.from_numpy(x)
                y = torch.from_numpy(y)
                x, y = to_var(x), to_var(y)
                opt.zero_grad()
                out = net(x)
                loss = criterion(out, y)
                loss.backward()
                opt.step()
                running_loss += loss.data[0]
                count += 1

        net.eval()
        val_loss_temp = NetEval(net, valloader, criterion)
        if epoch > 0 and val_loss_temp < val_loss_min:        # save the model which has the lowest val_loss, ignore first epoch
            val_loss_min = val_loss_temp
            torch.save(net.state_dict(), "Unet2_model_" + leg + "_min_val_loss")  # save model
            min_model_epoch = epoch + 1

        disp = 'Epoch %d: Train loss: %.6f, Val loss: %.6f' % (epoch + 1, running_loss/count, val_loss_temp)
        write_2_log(disp)
        print(disp)
        val_loss.append(val_loss_temp)
        train_loss.append(running_loss/count); running_loss = 0.0

        if (epoch + 1) in model_saved or epoch == 0:        # save checkpoint
            model_name = "Unet2_model_" + str(epoch+1) + "epoch_" + leg
            torch.save(net.state_dict(), model_name)  # save model
            Analysis_crop.analysis(model_file = model_name, valloader = valloader)

    write_2_log("Best model at epoch: " + str(min_model_epoch))
    write_2_log("Total training time: " + str((time.time() - start_begining) / 3600.0))

    val_loss_file = "data/results" + "/val_loss_" + str(N_epoch) + "epoch_" + leg + ".npy"
    train_loss_file = "data/results" + "/training_loss_" + str(N_epoch) + "epoch_" + leg + ".npy"

    np.save(val_loss_file, val_loss)
    np.save(train_loss_file, train_loss)
    print("total processing time in seconds: ", time.time() - start_begining)
    print("total processing time in mins: ", (time.time() - start_begining) / 60.0)
    print("total processing time in hours: ", (time.time() - start_begining) / 3600.0)

    # Analysis.analysis(model_file="Unet2_model_" + leg + "_min_val_loss", valloader=valloader)

    Analysis_crop.PlotLoss(model_file = model_name, loss_train_path = train_loss_file, loss_val_path = val_loss_file, epoch_No = N_epoch)

    write_2_log(time.strftime("%c"))  # time, date of exp
===============
import numpy as np
import torch.nn as nn
import torch
import cv2
from lcn import LecunLCN

LCN_enable = False

def input_filled_mirroring(x, e = 62):      # fill missing data by mirroring the input image
    '''input size 636 --> output size 512'''
    w, h = x.shape
    #e = 62  # extra width on 1 edge
    y = np.zeros((h + e * 2, w + e * 2))
    y[e:h + e, e:w + e] = x
    y[e:e + h, 0:e] = np.flip(y[e:e + h, e:2 * e], 1)  # flip vertically
    y[e:e + h, e + w:2 * e + w] = np.flip(y[e:e + h, w:e + w], 1)  # flip vertically
    y[0:e, 0:2 * e + w] = np.flip(y[e:2 * e, 0:2 * e + w], 0)  # flip horizontally
    y[e + h:2 * e + h, 0:2 * e + w] = np.flip(y[h:e + h, 0:2 * e + w], 0)  # flip horizontally
    return y

def nearest_cells_distance(pos, img):
    # searching in 8 directions to find 2 nearest distances to neighbor cells
    curr_value = img[pos]
    w = img.shape[0];h = img.shape[1]
    count_detect = 0  # detect 2 nearest neighbors. break the search if count_detect = 2
    x, y = pos

    # print("w,h: ", (w, h))
    d1 = 9999999;d2 = 9999999;d3 = 9999999;d4 = 9999999
    d5 = 9999999;d6 = 9999999;d7 = 9999999;d8 = 9999999
    for i in range(1, max(w, h)):
        # (x+1, y), (x+1, y+1), (x+1, y-1),
        # (x, y+1), (x, y-1)
        # (x-1, y), (x-1,y+1), (x-1,y-1),
        if x + i < w:
            if img[(x + i, y)] != curr_value and d1 == 9999999:
                d1 = i; count_detect += 1
            if y + i < h:
                if img[(x + i, y + i)] != curr_value and d2 == 9999999:
                    d2 = i; count_detect += 1
            elif y - i >= 0:
                if img[(x + i, y - i)] != curr_value and d3 == 9999999:
                    d3 = i; count_detect += 1
        if y + i < h:
            if img[(x, y + i)] != curr_value and d4 == 9999999:
                d4 = i; count_detect += 1
        if y - i >= 0:
            if img[(x, y - i)] != curr_value and d5 == 9999999:
                d5 = i; count_detect += 1
        if x - i >= 0:
            if img[(x - i, y)] != curr_value and d6 == 9999999:
                d6 = i; count_detect += 1
            if y + i < h:
                if img[(x - i, y + i)] != curr_value and d7 == 9999999:
                    d7 = i; count_detect += 1
            elif y - i >= 0:
                if img[(x - i, y - i)] != curr_value and d8 == 9999999:
                    d8 = i; count_detect += 1
        if count_detect >= 2: break

    d = [d1, d2, d3, d4, d5, d6, d7, d8]
    min_index = np.argmin(d)
    dist1 = d[min_index]
    d.remove(dist1)
    min_index = np.argmin(d)
    dist2 = d[min_index]
    return dist1, dist2

def create_weight_map(imgs_mask):
        print('-' * 30)
        print('Creating weights for masks ...')
        print('-' * 30)
        weight_map = np.ndarray(
            (len(imgs_mask), 1, np.shape(imgs_mask)[2], np.shape(imgs_mask)[3]), dtype=np.float32)
        w_0 = 10; sigma = 4
        imgs_w, imgs_h = np.shape(imgs_mask)[2], np.shape(imgs_mask)[3]
        total_pixels = imgs_w*imgs_h
        import time
        start = time.time()
        for i in range(len(imgs_mask)):
            if i%10 == 0: print("Done processing: %d images, time passed: %.2f mins" % (i, (time.time() - start)/60.0))
            temp = imgs_mask[i,0,:,:]
            w_border = 1 - np.sum(temp)/total_pixels        # w_c of pixel on the border (black)
            for m in range(imgs_w):
                for n in range(imgs_h):
                    # loop through all pixel of the mask
                    d1,d2 = nearest_cells_distance((m,n), temp)
                    w_c = w_border
                    if temp[m,n] == 0: w_c = 1 - w_border
                    weight_map[i,0,m,n] = w_c*5 + w_0*np.exp(-(d1 + d2)**2/(2*sigma**2))
                    # print("w_0*np.exp(): ", w_0*np.exp(-(d1 + d2)**2/(2*sigma**2)))
                    # print("w_border: ", w_border)

        np.save('data/dataset/weight_map_train.npy', weight_map)

        return weight_map

def load_train_data(npy_path = "data/dataset", hist_equal = False):

    print('-' * 30)
    print('load train images...')

    imgs_train = np.load(npy_path + "/imgs_train.npy")
    imgs_mask_train = np.load(npy_path + "/imgs_mask_train.npy")

    if hist_equal: imgs_train = hist_equalization(imgs_train)

    # weight_map_train = np.load(npy_path + "/weight_map_train.npy")
    # weight_map_train = weight_map_train.astype('float32')

    imgs_train = imgs_train.astype('float32')
    imgs_mask_train = imgs_mask_train.astype('float32')

    if LCN_enable:
        imgs_train = imgs_train.astype('float64')
        imgs_train = LecunLCN(imgs_train, image_shape=imgs_train.shape).output.eval()
        imgs_train = imgs_train.astype('float32')

    if not LCN_enable: imgs_train /= 255

    imgs_train -= imgs_train.mean(axis=0)
    imgs_mask_train /= 255
    imgs_mask_train[imgs_mask_train > 0.5] = 1
    imgs_mask_train[imgs_mask_train <= 0.5] = 0

    # weight_map_train = create_weight_map(imgs_mask_train)

    print("Done loading traing data")
    print('-' * 30)
    return imgs_train, imgs_mask_train

def load_val_data(npy_path = "data/dataset", hist_equal = True):

    print('-' * 30)
    print('load validation images...')

    imgs_train = np.load(npy_path + "/imgs_val.npy")
    imgs_mask_train = np.load(npy_path + "/imgs_mask_val.npy")

    if hist_equal: imgs_train = hist_equalization(imgs_train)

    imgs_train = imgs_train.astype('float32')
    imgs_mask_train = imgs_mask_train.astype('float32')

    if LCN_enable:
        imgs_train = imgs_train.astype('float64')
        imgs_train = LecunLCN(imgs_train, image_shape=imgs_train.shape).output.eval()
        imgs_train = imgs_train.astype('float32')

    if not LCN_enable: imgs_train /= 255
    imgs_train -= imgs_train.mean(axis=0)
    imgs_mask_train /= 255
    imgs_mask_train[imgs_mask_train > 0.5] = 1
    imgs_mask_train[imgs_mask_train <= 0.5] = 0
    print("Done loading validation data")
    print('-' * 30)
    return imgs_train, imgs_mask_train

def load_test_data(npy_path = "data/dataset", hist_equal = True):

    print('-' * 30)
    print('load test images...')

    imgs_test = np.load(npy_path + "/imgs_test.npy")

    if hist_equal: imgs_test = hist_equalization(imgs_test)

    imgs_test = imgs_test.astype('float32')

    if LCN_enable:
        imgs_test = imgs_test.astype('float64')
        imgs_test = LecunLCN(imgs_test, image_shape=imgs_test.shape).output.eval()
        imgs_test = imgs_test.astype('float32')

    if not LCN_enable: imgs_test /= 255

    imgs_test -= imgs_test.mean(axis=0)

    print("Done loading test data")
    print('-' * 30)
    return imgs_test

def load_val_5imgs(npy_path = "data/dataset"):
    print('-' * 30)
    print('load train images...')

    imgs_train = np.load(npy_path + "/imgs_val_5imgs.npy")
    imgs_mask_train = np.load(npy_path + "/imgs_mask_val_5imgs.npy")

    # imgs_train = hist_equalization(imgs_train)

    imgs_train = imgs_train.astype('float64')
    imgs_mask_train = imgs_mask_train.astype('float64')

    if LCN_enable: imgs_train = LecunLCN(imgs_train, image_shape=imgs_train.shape).output.eval()

    if not LCN_enable: imgs_train /= 255

    mean = imgs_train.mean(axis=0)
    imgs_train -= mean


    imgs_mask_train /= 255
    imgs_mask_train[imgs_mask_train > 0.5] = 1
    imgs_mask_train[imgs_mask_train <= 0.5] = 0

    # weight_map_train = self.create_weight_map(imgs_mask_train)

    print("Done loading traing data")
    print('-' * 30)
    return imgs_train, imgs_mask_train

def hist_equalization(inputs):      # inputs are uint8, 0-255, Nx1x636x636
    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))
    output = inputs.copy()
    for i in range(len(inputs)):
        img = inputs[i, 0, :, :]
        # res = cv2.equalizeHist(img)
        res = clahe.apply(img)
        output[i,0,:,:] = res
    return output

### BinaryCrossEntropyLoss2d().forward(logits, labels)
class BinaryCrossEntropyLoss2d(nn.Module):
    def __init__(self, weight=None, size_average=True):
        """
        Binary cross entropy loss 2D
        Args:
            weight:
            size_average:
        """
        super(BinaryCrossEntropyLoss2d, self).__init__()
        self.bce_loss = nn.BCELoss(weight, size_average)

    def forward(self, logits, targets):
        # probs = F.sigmoid(logits)
        probs = logits
        probs_flat = probs.view(-1)  # Flatten
        targets_flat = targets.view(-1)  # Flatten
        return self.bce_loss(probs_flat, targets_flat)      # (output, labels)

class BCE_with_Weights(nn.Module):
    def __init__(self, weights=None):
        """
        Binary cross entropy loss 2D
        Args:
            weights:
        """
        super(BCE_with_Weights, self).__init__()
        self.weights = weights

    def forward(self, output, target):
        if self.weights is not None:
            loss = self.weights * (target * torch.log(output) + (1 - target) * torch.log(1 - output))
        else:
            loss = target * torch.log(output) + (1 - target) * torch.log(1 - output)

        return torch.neg(torch.mean(loss))

class LRN(nn.Module):       # input x is Torch tensor
    def __init__(self, local_size=1, alpha=1.0, beta=0.75, ACROSS_CHANNELS=False):      #LRN(local_size=5, alpha=0.0001, beta=0.75),
        super(LRN, self).__init__()
        self.ACROSS_CHANNELS = ACROSS_CHANNELS
        if self.ACROSS_CHANNELS:
            self.average = nn.AvgPool3d(kernel_size=(local_size, 1, 1),
                                        stride=1, padding=(int((local_size - 1.0) / 2), 0, 0))
        else:
            self.average = nn.AvgPool2d(kernel_size=local_size,
                                        stride=1, padding=int((local_size - 1.0) / 2))
        self.alpha = alpha
        self.beta = beta

    def forward(self, x):
        if self.ACROSS_CHANNELS:
            div = x.pow(2).unsqueeze(1)
            div = self.average(div).squeeze(1)
            div = div.mul(self.alpha).add(1.0).pow(self.beta)
        else:
            div = x.pow(2)
            div = self.average(div)
            div = div.mul(self.alpha).add(1.0).pow(self.beta)
        x = x.div(div)
        return x
Sat Nov 25 03:08:46 2017
Leg22_CROP_dropout_0_2_rmSigmoid_20aug_10ela_3inten_reflect
optim.SGD(net.parameters(), lr=1e-2, momentum=0.99)
Number of epoch max: 6
==========================================================================================
Sat Nov 25 03:12:20 2017
Leg22_CROP_dropout_0_2_rmSigmoid_20aug_10ela_3inten_reflect
Sat Nov 25 03:12:18 2017
import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.autograd import Variable
import math


class ConvBnRelu(nn.Module):
    def __init__(self, in_channels, out_channels, kernel_size, padding, stride):
        super(ConvBnRelu, self).__init__()
        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=kernel_size, padding=padding, stride=stride)
        self.bn = nn.BatchNorm2d(out_channels)
        self.relu = nn.ReLU()

    def forward(self, x):
        x = self.conv(x)
        # x = self.bn(x)
        x = self.relu(x)
        return x


class StackEncoder(nn.Module):
    def __init__(self, in_channels, out_channels):
        super(StackEncoder, self).__init__()
        self.convr1 = ConvBnRelu(in_channels, out_channels, kernel_size=(3, 3), stride=1, padding=0)
        self.convr2 = ConvBnRelu(out_channels, out_channels, kernel_size=(3, 3), stride=1, padding=0)
        self.maxPool = nn.MaxPool2d(kernel_size=(2, 2), stride=2)

    def forward(self, x):
        x = self.convr1(x)
        x = self.convr2(x)
        x_trace = x             # save x to use in concat in the Decoder path
        out = self.maxPool(x)
        return out, x_trace


class StackDecoder(nn.Module):
    def __init__(self, in_channels, out_channels, padding = 0, drop_out=False):
        super(StackDecoder, self).__init__()

        self.drop_out = drop_out
        self.dropout_layer = nn.Dropout2d(p=0.5)

        ''' this is old version
        self.upSample = nn.Upsample(size=upsample_size, scale_factor=(2, 2), mode="bilinear")
        self.convr1 = ConvBnRelu(in_channels, out_channels, kernel_size=(3, 3), stride=1, padding=padding)
        # Crop + concat step between these 2
        self.convr2 = ConvBnRelu(in_channels, out_channels, kernel_size=(3, 3), stride=1, padding=padding)
        '''
        self.upSample = nn.ConvTranspose2d(in_channels, out_channels, 2, stride=2)
        self.convr1 = ConvBnRelu(in_channels, out_channels, kernel_size=(3, 3), stride=1, padding=padding)
        self.convr2 = ConvBnRelu(out_channels, out_channels, kernel_size=(3, 3), stride=1, padding=padding)

    def _crop_concat(self, upsampled, bypass):
        """
         Crop y to the (h, w) of x and concat them.
         Used for the expansive path.
        Returns:
            The concatenated tensor
        """
        c = (bypass.size()[2] - upsampled.size()[2]) // 2
        bypass = F.pad(bypass, (-c, -c, -c, -c))

        return torch.cat((bypass, upsampled), 1)

    def forward(self, x, down_tensor):
        '''old version
        x = self.upSample(x)
        x = self.convr1(x)
        x = self._crop_concat(x, down_tensor)
        x = self.convr2(x)
        '''

        x = self.upSample(x)
        x = self._crop_concat(x, down_tensor)
        x = self.convr1(x)
        if self.drop_out: x = self.dropout_layer(x)
        x = self.convr2(x)
        if self.drop_out: x = self.dropout_layer(x)
        return x


class UNET_CROP(nn.Module):
    def __init__(self):
        super(UNET_CROP, self).__init__()
        # channels, height, width = in_shape

        # self.dropout = dropout

        self.model_code = ""        # variable to save model and main function when loaded

        self.down1 = StackEncoder(1, 64)
        self.down2 = StackEncoder(64, 128)
        self.down3 = StackEncoder(128, 256)
        self.down4 = StackEncoder(256, 512)

        self.center = nn.Sequential(
            # nn.Dropout2d(p=0.2),
            ConvBnRelu(512, 1024, kernel_size=(3, 3), stride=1, padding=0),
            nn.Dropout2d(p=0.2),
            ConvBnRelu(1024, 1024, kernel_size=(3, 3), stride=1, padding=0),
            nn.Dropout2d(p=0.2)
        )

        self.up1 = StackDecoder(in_channels=1024, out_channels=512)
        self.up2 = StackDecoder(in_channels=512, out_channels=256)
        self.up3 = StackDecoder(in_channels=256, out_channels=128)
        self.up4 = StackDecoder(in_channels=128, out_channels=64)

        # 1x1 convolution at the last layer
        # Different from the paper is the output size here
        self.output_seg_map = nn.Conv2d(64, 1, kernel_size=(1, 1), padding=0, stride=1)

        self._initialize_weights()

    def forward(self, x):
        x, x_trace1 = self.down1(x)
        x, x_trace2 = self.down2(x)
        x, x_trace3 = self.down3(x)
        x, x_trace4 = self.down4(x)
        x = self.center(x)
        x = self.up1(x, x_trace4)
        x = self.up2(x, x_trace3)
        x = self.up3(x, x_trace2)
        x = self.up4(x, x_trace1)

        x = self.output_seg_map(x)
        # x = F.sigmoid(x)
        # out = torch.squeeze(out, dim=1)
        return x


    def _initialize_weights(self):
        for m in self.modules():
            if isinstance(m, nn.Conv2d):
                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels
                m.weight.data.normal_(0, math.sqrt(2. / n))
                if m.bias is not None:
                    m.bias.data.zero_()
            elif isinstance(m, nn.BatchNorm2d):
                m.weight.data.fill_(1)
                m.bias.data.zero_()

# x = Variable(torch.randn(1,1,700, 700))       # simulate input image
# net = UNET_CROP()
# out = net(x)
# print("input: ", x)
# print("output: ", out)
===============from __future__ import print_function, division
import torch
from torch import optim
from torch.autograd import Variable
from torch.utils.data import DataLoader
import numpy as np
import torch.nn as nn
import torch.nn.functional as F
import Unet_crop
import tifffile as tiff
import Utils
import time
from sklearn.metrics import average_precision_score, recall_score, f1_score
import Analysis_crop
import cv2

def to_var(x):
    if torch.cuda.is_available():
        return Variable(x.cuda())
    else:
        return Variable(x)

### BinaryCrossEntropyLoss2d().forward(logits, labels)
class BinaryCrossEntropyLoss2d(nn.Module):
    def __init__(self, weight=None, size_average=True):
        """
        Binary cross entropy loss 2D
        Args:
            weight:
            size_average:
        """
        super(BinaryCrossEntropyLoss2d, self).__init__()
        self.bce_loss = nn.BCELoss(weight, size_average)

    def forward(self, probs, targets):
        probs = F.sigmoid(probs)
        probs_flat = probs.view(-1)  # Flatten
        targets_flat = targets.view(-1)  # Flatten
        return self.bce_loss(probs_flat, targets_flat)      # (output, labels)

def NetEval(net,valdata_loader,crit):
    loss = 0.
    count = 0
    net.eval()
    crop_input, crop_label,_ = crop_info()
    for i,data in enumerate(valdata_loader,0):
        # if i > 10: break
        inputs, labels = data
        # inputs = inputs.numpy()
        # labels = labels.numpy()
        for j in range(len(crop_input)):  # training on the crop images and corresponding labels
            ci = crop_input[j]  # crop index for inputs
            cl = crop_label[j]  # crop index for lables
            # temp = labels[0, 0, :, :]  # labels is numpy array 512x512
            # if np.sum(temp) < 0.01 * np.shape(temp)[0] * np.shape(temp)[1]: break
            x = inputs.numpy()[:, :, ci[0]:ci[0] + 572, ci[1]:ci[1] + 572]
            y = labels.numpy()[:, :, cl[0]: cl[0] + 388, cl[1]:cl[1] + 388]
            x = torch.from_numpy(x)
            y = torch.from_numpy(y)
            x, y = to_var(x), to_var(y)
            out = net(x)
            l = crit(out, y)
            loss += l.data[0]
            count += 1
    return loss/count

#process the test data and save to separate .tif image
def NetTest(net,testdata_loader,path = "data/results/"):
    net.eval()
    crop_input, crop_label, average_mask = crop_info()
    for i, data in enumerate(testdata_loader, 0):
        if i >= 30: return 1        # for debug
        # data = to_var(data)
        img_shape = 512
        img = np.zeros((img_shape, img_shape))
        for j in range(len(crop_input)):  # training on the crop images and corresponding labels
            temp = np.zeros((img_shape, img_shape))
            ci = crop_input[j]  # crop index for inputs
            cl = crop_label[j]
            x = data.numpy()[:, :, ci[0]:ci[0] + 572, ci[1]:ci[1] + 572]
            x = torch.from_numpy(x)
            x = to_var(x)
            out = F.sigmoid(net(x))
            out = out.cpu()
            out = out[0,0,:,:]
            # print("j: ", j)
            # print("size of temp: ", np.shape(temp))
            # print("size of output: ", np.shape(out.data.numpy()))
            temp[cl[0]: cl[0] + 388, cl[1]:cl[1] + 388] = out.data.numpy()
            img += temp

        img = img/average_mask
        img = img.reshape(-1)
        img[img < 0.5] = 0; img[img >= 0.5] = 1
        img = img.reshape(img_shape, img_shape)
        img = np.uint8(img * 255)
        imgname = path + str(i) + ".tif"
        tiff.imsave(imgname, img)

# return input image size like 512x512, numpy array
def NetPredict(net, input_image):
    net.eval()
    _, crop_label, average_mask = crop_info()

    # input_image is grayscale input image of 512x512
    data = Utils.input_filled_mirroring(input_image, e = 94)
    imgdatas = np.ndarray((1, 1, data.shape[0], data.shape[1]), dtype=np.uint8)
    imgdatas[0] = np.expand_dims(data, 0)
    data = Utils.hist_equalization(imgdatas)
    data = data.astype('float32')
    data /= 255
    data -= data.mean(axis=0)

    img_shape = input_image.shape
    img = np.zeros((img_shape, img_shape))
    for j in range(len(crop_input)):  # training on the crop images and corresponding labels
        temp = np.zeros((img_shape, img_shape))
        ci = crop_input[j]  # crop index for inputs
        cl = crop_label[j]
        x = data.numpy()[:, :, ci[0]:ci[0] + 572, ci[1]:ci[1] + 572]
        x = torch.from_numpy(x)
        x = to_var(x)
        out = F.sigmoid(net(x))
        out = out.cpu()
        out = out[0, 0, :, :]
        temp[cl[0]: cl[0] + 388, cl[1]:cl[1] + 388] = out.data.numpy()
        img += temp

    img = img / average_mask
    img = img.reshape(-1)
    img[img < 0.5] = 0
    img[img >= 0.5] = 1
    img = img.reshape(img_shape)
    img = np.uint8(img * 255)
    return img


def write_2_log(content):
    path = "log_file.txt"
    output = open(path, "a")
    output.write("\n")
    output.write(content)
    output.close()

def crop_info():
    crop_input = [[0, 0], [128, 0], [0, 128], [128, 128]]
    crop_label = [[0, 0], [124, 0], [0, 124], [124, 124]]
    average_mask = np.ones((512, 512))
    average_mask[124:388, 0:124] = 2
    average_mask[0:124, 124:388] = 2
    average_mask[124:388, 388:512] = 2
    average_mask[388:512, 124:388] = 2
    average_mask[124:388, 124:388] = 4
    return crop_input, crop_label, average_mask

if __name__ == '__main__':
    '''subjects to change for each exp:
    + path to the dataset
    + opt function
    + leg description
    + N_epoch
    + saved_model
    '''
    start_begining = time.time()

    # path = "data/dataset"
    path = "/home/anhxtuan/HanLe/dataset/20aug_10ela_3inten_reflect"
    path = "/home/anhxtuan/HanLe/dataset/20aug_10ela_3inten_reflect_700"

    import os
    print("Does the folder exist?: ", os.path.isdir(path))
    print("Does the path exist?: ", os.path.exists(path))

    imgs_train, imgs_mask_train = Utils.load_train_data(npy_path=path)
    imgs_val, imgs_mask_val = Utils.load_val_data(npy_path=path)
    batch_size = 1
    trainset = zip(imgs_train, imgs_mask_train)
    trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,
                                              shuffle=True, num_workers=2)
    valset = zip(imgs_val, imgs_mask_val)
    valloader = torch.utils.data.DataLoader(valset, batch_size=batch_size,
                                              shuffle=False, num_workers=2)
    # net = Unet.UNet()                     # Unet 1
    # net = Unet_BatchNorm.UNet_BN()          # Unet 2 with batchNorm
    net = Unet_crop.UNET_CROP()

    f1 = open("Unet_crop.py", 'r')     # embede code into the model to be saved later
    f2 = open("UnetTrain_crop.py", 'r')
    f3 = open("Utils.py", 'r')
    model_notes = time.strftime("%c") + "\n" + f1.read() + "\n" + "==="*5 + f2.read() + "\n" + "==="*5 + f3.read()
    f1.close()
    f2.close()
    f3.close()

    criterion = BinaryCrossEntropyLoss2d()
    # criterion = SoftDiceLoss()
    # criterion = nn.BCELoss()

    if torch.cuda.is_available():
        # torch.set_default_tensor_type('torch.cuda.FloatTensor')
        # net.load_state_dict(torch.load("Unet2_model_12epoch_Leg12_droput_0_2_rmSigmoid_20aug_10ela_3inten_reflect"))
        net.cuda()
        # criterion.cuda()

    opt = optim.SGD(net.parameters(), lr=1e-2, momentum=0.99)       # subject to change
    # opt = optim.RMSprop(net.parameters(), lr=2e-4)
    # RMSprop[22](learning rate 0.001) with weight decay set to 0.001.
    # opt = optim.Adam(net.parameters(), lr=1e-3, weight_decay=1e-4)

    train_loss = []
    val_loss = []

    print("[epoch, #image] Loss")
    leg = "Leg22_CROP_dropout_0_2_rmSigmoid_20aug_10ela_3inten_reflect"
    print("Processing: ", leg)
    model_name = ""

    N_epoch = 6
    model_saved = np.arange(2,N_epoch+1,2)
    val_loss_min = 100

    write_2_log("==="*30)
    write_2_log(time.strftime("%c"))       # time, date of exp
    write_2_log(leg)
    write_2_log(model_notes)
    write_2_log(time.strftime("%c"))  # time, date of exp
    write_2_log(leg)
    write_2_log("optim.SGD(net.parameters(), lr=1e-2, momentum=0.99)")
    write_2_log("Number of epoch max: " + str(N_epoch))

    crop_input, crop_label,_ = crop_info()
    min_model_epoch = 0
    for epoch in range(N_epoch):
        running_loss = 0.0; count = 0
        net.train()
        for i, data in enumerate(trainloader, 0):
            # if i > 10: break

            inputs, labels = data
            temp = labels.numpy()
            for j in range(len(crop_input)):       # training on the crop images and corresponding labels
                ci = crop_input[j]          # crop index for inputs
                cl = crop_label[j]          # crop index for lables
                # temp = temp[0, 0, :, :]  # labels is numpy array 512x512
                # if np.sum(temp) < 0.01 * np.shape(temp)[0] * np.shape(temp)[1]: break
                x = inputs.numpy()[:, :, ci[0]:ci[0] + 572, ci[1]:ci[1] + 572]
                y = labels.numpy()[:, :, cl[0]: cl[0] + 388, cl[1]:cl[1] + 388]
                print("size of x: ", x.shape)
                print("size of y: ", y.shape)
                import matplotlib.pyplot as plt
                plt.subplot(131); plt.imshow(x[0,0,:,:], cmap='gray')
                plt.subplot(133); plt.imshow(x[0,0,94:478,94:478], cmap='gray')
                plt.subplot(132); plt.imshow(y[0,0,:,:], cmap='gray')
                plt.show()
                x = torch.from_numpy(x)
                y = torch.from_numpy(y)
                x, y = to_var(x), to_var(y)
                opt.zero_grad()
                out = net(x)
                loss = criterion(out, y)
                loss.backward()
                opt.step()
                running_loss += loss.data[0]
                count += 1

        net.eval()
        val_loss_temp = NetEval(net, valloader, criterion)
        if epoch > 0 and val_loss_temp < val_loss_min:        # save the model which has the lowest val_loss, ignore first epoch
            val_loss_min = val_loss_temp
            torch.save(net.state_dict(), "Unet2_model_" + leg + "_min_val_loss")  # save model
            min_model_epoch = epoch + 1

        disp = 'Epoch %d: Train loss: %.6f, Val loss: %.6f' % (epoch + 1, running_loss/count, val_loss_temp)
        write_2_log(disp)
        print(disp)
        val_loss.append(val_loss_temp)
        train_loss.append(running_loss/count); running_loss = 0.0

        if (epoch + 1) in model_saved or epoch == 0:        # save checkpoint
            model_name = "Unet2_model_" + str(epoch+1) + "epoch_" + leg
            torch.save(net.state_dict(), model_name)  # save model
            Analysis_crop.analysis(model_file = model_name, valloader = valloader)

    write_2_log("Best model at epoch: " + str(min_model_epoch))
    write_2_log("Total training time: " + str((time.time() - start_begining) / 3600.0))

    val_loss_file = "data/results" + "/val_loss_" + str(N_epoch) + "epoch_" + leg + ".npy"
    train_loss_file = "data/results" + "/training_loss_" + str(N_epoch) + "epoch_" + leg + ".npy"

    np.save(val_loss_file, val_loss)
    np.save(train_loss_file, train_loss)
    print("total processing time in seconds: ", time.time() - start_begining)
    print("total processing time in mins: ", (time.time() - start_begining) / 60.0)
    print("total processing time in hours: ", (time.time() - start_begining) / 3600.0)

    # Analysis.analysis(model_file="Unet2_model_" + leg + "_min_val_loss", valloader=valloader)

    Analysis_crop.PlotLoss(model_file = model_name, loss_train_path = train_loss_file, loss_val_path = val_loss_file, epoch_No = N_epoch)

    write_2_log(time.strftime("%c"))  # time, date of exp
===============
import numpy as np
import torch.nn as nn
import torch
import cv2
from lcn import LecunLCN

LCN_enable = False

def input_filled_mirroring(x, e = 62):      # fill missing data by mirroring the input image
    '''input size 636 --> output size 512'''
    w, h = x.shape
    #e = 62  # extra width on 1 edge
    y = np.zeros((h + e * 2, w + e * 2))
    y[e:h + e, e:w + e] = x
    y[e:e + h, 0:e] = np.flip(y[e:e + h, e:2 * e], 1)  # flip vertically
    y[e:e + h, e + w:2 * e + w] = np.flip(y[e:e + h, w:e + w], 1)  # flip vertically
    y[0:e, 0:2 * e + w] = np.flip(y[e:2 * e, 0:2 * e + w], 0)  # flip horizontally
    y[e + h:2 * e + h, 0:2 * e + w] = np.flip(y[h:e + h, 0:2 * e + w], 0)  # flip horizontally
    return y

def nearest_cells_distance(pos, img):
    # searching in 8 directions to find 2 nearest distances to neighbor cells
    curr_value = img[pos]
    w = img.shape[0];h = img.shape[1]
    count_detect = 0  # detect 2 nearest neighbors. break the search if count_detect = 2
    x, y = pos

    # print("w,h: ", (w, h))
    d1 = 9999999;d2 = 9999999;d3 = 9999999;d4 = 9999999
    d5 = 9999999;d6 = 9999999;d7 = 9999999;d8 = 9999999
    for i in range(1, max(w, h)):
        # (x+1, y), (x+1, y+1), (x+1, y-1),
        # (x, y+1), (x, y-1)
        # (x-1, y), (x-1,y+1), (x-1,y-1),
        if x + i < w:
            if img[(x + i, y)] != curr_value and d1 == 9999999:
                d1 = i; count_detect += 1
            if y + i < h:
                if img[(x + i, y + i)] != curr_value and d2 == 9999999:
                    d2 = i; count_detect += 1
            elif y - i >= 0:
                if img[(x + i, y - i)] != curr_value and d3 == 9999999:
                    d3 = i; count_detect += 1
        if y + i < h:
            if img[(x, y + i)] != curr_value and d4 == 9999999:
                d4 = i; count_detect += 1
        if y - i >= 0:
            if img[(x, y - i)] != curr_value and d5 == 9999999:
                d5 = i; count_detect += 1
        if x - i >= 0:
            if img[(x - i, y)] != curr_value and d6 == 9999999:
                d6 = i; count_detect += 1
            if y + i < h:
                if img[(x - i, y + i)] != curr_value and d7 == 9999999:
                    d7 = i; count_detect += 1
            elif y - i >= 0:
                if img[(x - i, y - i)] != curr_value and d8 == 9999999:
                    d8 = i; count_detect += 1
        if count_detect >= 2: break

    d = [d1, d2, d3, d4, d5, d6, d7, d8]
    min_index = np.argmin(d)
    dist1 = d[min_index]
    d.remove(dist1)
    min_index = np.argmin(d)
    dist2 = d[min_index]
    return dist1, dist2

def create_weight_map(imgs_mask):
        print('-' * 30)
        print('Creating weights for masks ...')
        print('-' * 30)
        weight_map = np.ndarray(
            (len(imgs_mask), 1, np.shape(imgs_mask)[2], np.shape(imgs_mask)[3]), dtype=np.float32)
        w_0 = 10; sigma = 4
        imgs_w, imgs_h = np.shape(imgs_mask)[2], np.shape(imgs_mask)[3]
        total_pixels = imgs_w*imgs_h
        import time
        start = time.time()
        for i in range(len(imgs_mask)):
            if i%10 == 0: print("Done processing: %d images, time passed: %.2f mins" % (i, (time.time() - start)/60.0))
            temp = imgs_mask[i,0,:,:]
            w_border = 1 - np.sum(temp)/total_pixels        # w_c of pixel on the border (black)
            for m in range(imgs_w):
                for n in range(imgs_h):
                    # loop through all pixel of the mask
                    d1,d2 = nearest_cells_distance((m,n), temp)
                    w_c = w_border
                    if temp[m,n] == 0: w_c = 1 - w_border
                    weight_map[i,0,m,n] = w_c*5 + w_0*np.exp(-(d1 + d2)**2/(2*sigma**2))
                    # print("w_0*np.exp(): ", w_0*np.exp(-(d1 + d2)**2/(2*sigma**2)))
                    # print("w_border: ", w_border)

        np.save('data/dataset/weight_map_train.npy', weight_map)

        return weight_map

def load_train_data(npy_path = "data/dataset", hist_equal = False):

    print('-' * 30)
    print('load train images...')

    imgs_train = np.load(npy_path + "/imgs_train.npy")
    imgs_mask_train = np.load(npy_path + "/imgs_mask_train.npy")

    if hist_equal: imgs_train = hist_equalization(imgs_train)

    # weight_map_train = np.load(npy_path + "/weight_map_train.npy")
    # weight_map_train = weight_map_train.astype('float32')

    imgs_train = imgs_train.astype('float32')
    imgs_mask_train = imgs_mask_train.astype('float32')

    if LCN_enable:
        imgs_train = imgs_train.astype('float64')
        imgs_train = LecunLCN(imgs_train, image_shape=imgs_train.shape).output.eval()
        imgs_train = imgs_train.astype('float32')

    if not LCN_enable: imgs_train /= 255

    imgs_train -= imgs_train.mean(axis=0)
    imgs_mask_train /= 255
    imgs_mask_train[imgs_mask_train > 0.5] = 1
    imgs_mask_train[imgs_mask_train <= 0.5] = 0

    # weight_map_train = create_weight_map(imgs_mask_train)

    print("Done loading traing data")
    print('-' * 30)
    return imgs_train, imgs_mask_train

def load_val_data(npy_path = "data/dataset", hist_equal = True):

    print('-' * 30)
    print('load validation images...')

    imgs_train = np.load(npy_path + "/imgs_val.npy")
    imgs_mask_train = np.load(npy_path + "/imgs_mask_val.npy")

    if hist_equal: imgs_train = hist_equalization(imgs_train)

    imgs_train = imgs_train.astype('float32')
    imgs_mask_train = imgs_mask_train.astype('float32')

    if LCN_enable:
        imgs_train = imgs_train.astype('float64')
        imgs_train = LecunLCN(imgs_train, image_shape=imgs_train.shape).output.eval()
        imgs_train = imgs_train.astype('float32')

    if not LCN_enable: imgs_train /= 255
    imgs_train -= imgs_train.mean(axis=0)
    imgs_mask_train /= 255
    imgs_mask_train[imgs_mask_train > 0.5] = 1
    imgs_mask_train[imgs_mask_train <= 0.5] = 0
    print("Done loading validation data")
    print('-' * 30)
    return imgs_train, imgs_mask_train

def load_test_data(npy_path = "data/dataset", hist_equal = True):

    print('-' * 30)
    print('load test images...')

    imgs_test = np.load(npy_path + "/imgs_test.npy")

    if hist_equal: imgs_test = hist_equalization(imgs_test)

    imgs_test = imgs_test.astype('float32')

    if LCN_enable:
        imgs_test = imgs_test.astype('float64')
        imgs_test = LecunLCN(imgs_test, image_shape=imgs_test.shape).output.eval()
        imgs_test = imgs_test.astype('float32')

    if not LCN_enable: imgs_test /= 255

    imgs_test -= imgs_test.mean(axis=0)

    print("Done loading test data")
    print('-' * 30)
    return imgs_test

def load_val_5imgs(npy_path = "data/dataset"):
    print('-' * 30)
    print('load train images...')

    imgs_train = np.load(npy_path + "/imgs_val_5imgs.npy")
    imgs_mask_train = np.load(npy_path + "/imgs_mask_val_5imgs.npy")

    # imgs_train = hist_equalization(imgs_train)

    imgs_train = imgs_train.astype('float64')
    imgs_mask_train = imgs_mask_train.astype('float64')

    if LCN_enable: imgs_train = LecunLCN(imgs_train, image_shape=imgs_train.shape).output.eval()

    if not LCN_enable: imgs_train /= 255

    mean = imgs_train.mean(axis=0)
    imgs_train -= mean


    imgs_mask_train /= 255
    imgs_mask_train[imgs_mask_train > 0.5] = 1
    imgs_mask_train[imgs_mask_train <= 0.5] = 0

    # weight_map_train = self.create_weight_map(imgs_mask_train)

    print("Done loading traing data")
    print('-' * 30)
    return imgs_train, imgs_mask_train

def hist_equalization(inputs):      # inputs are uint8, 0-255, Nx1x636x636
    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))
    output = inputs.copy()
    for i in range(len(inputs)):
        img = inputs[i, 0, :, :]
        # res = cv2.equalizeHist(img)
        res = clahe.apply(img)
        output[i,0,:,:] = res
    return output

### BinaryCrossEntropyLoss2d().forward(logits, labels)
class BinaryCrossEntropyLoss2d(nn.Module):
    def __init__(self, weight=None, size_average=True):
        """
        Binary cross entropy loss 2D
        Args:
            weight:
            size_average:
        """
        super(BinaryCrossEntropyLoss2d, self).__init__()
        self.bce_loss = nn.BCELoss(weight, size_average)

    def forward(self, logits, targets):
        # probs = F.sigmoid(logits)
        probs = logits
        probs_flat = probs.view(-1)  # Flatten
        targets_flat = targets.view(-1)  # Flatten
        return self.bce_loss(probs_flat, targets_flat)      # (output, labels)

class BCE_with_Weights(nn.Module):
    def __init__(self, weights=None):
        """
        Binary cross entropy loss 2D
        Args:
            weights:
        """
        super(BCE_with_Weights, self).__init__()
        self.weights = weights

    def forward(self, output, target):
        if self.weights is not None:
            loss = self.weights * (target * torch.log(output) + (1 - target) * torch.log(1 - output))
        else:
            loss = target * torch.log(output) + (1 - target) * torch.log(1 - output)

        return torch.neg(torch.mean(loss))

class LRN(nn.Module):       # input x is Torch tensor
    def __init__(self, local_size=1, alpha=1.0, beta=0.75, ACROSS_CHANNELS=False):      #LRN(local_size=5, alpha=0.0001, beta=0.75),
        super(LRN, self).__init__()
        self.ACROSS_CHANNELS = ACROSS_CHANNELS
        if self.ACROSS_CHANNELS:
            self.average = nn.AvgPool3d(kernel_size=(local_size, 1, 1),
                                        stride=1, padding=(int((local_size - 1.0) / 2), 0, 0))
        else:
            self.average = nn.AvgPool2d(kernel_size=local_size,
                                        stride=1, padding=int((local_size - 1.0) / 2))
        self.alpha = alpha
        self.beta = beta

    def forward(self, x):
        if self.ACROSS_CHANNELS:
            div = x.pow(2).unsqueeze(1)
            div = self.average(div).squeeze(1)
            div = div.mul(self.alpha).add(1.0).pow(self.beta)
        else:
            div = x.pow(2)
            div = self.average(div)
            div = div.mul(self.alpha).add(1.0).pow(self.beta)
        x = x.div(div)
        return x
Sat Nov 25 03:12:20 2017
Leg22_CROP_dropout_0_2_rmSigmoid_20aug_10ela_3inten_reflect
optim.SGD(net.parameters(), lr=1e-2, momentum=0.99)
Number of epoch max: 6
==========================================================================================
Sat Nov 25 03:13:31 2017
Leg22_CROP_dropout_0_2_rmSigmoid_20aug_10ela_3inten_reflect
Sat Nov 25 03:13:29 2017
import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.autograd import Variable
import math


class ConvBnRelu(nn.Module):
    def __init__(self, in_channels, out_channels, kernel_size, padding, stride):
        super(ConvBnRelu, self).__init__()
        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=kernel_size, padding=padding, stride=stride)
        self.bn = nn.BatchNorm2d(out_channels)
        self.relu = nn.ReLU()

    def forward(self, x):
        x = self.conv(x)
        # x = self.bn(x)
        x = self.relu(x)
        return x


class StackEncoder(nn.Module):
    def __init__(self, in_channels, out_channels):
        super(StackEncoder, self).__init__()
        self.convr1 = ConvBnRelu(in_channels, out_channels, kernel_size=(3, 3), stride=1, padding=0)
        self.convr2 = ConvBnRelu(out_channels, out_channels, kernel_size=(3, 3), stride=1, padding=0)
        self.maxPool = nn.MaxPool2d(kernel_size=(2, 2), stride=2)

    def forward(self, x):
        x = self.convr1(x)
        x = self.convr2(x)
        x_trace = x             # save x to use in concat in the Decoder path
        out = self.maxPool(x)
        return out, x_trace


class StackDecoder(nn.Module):
    def __init__(self, in_channels, out_channels, padding = 0, drop_out=False):
        super(StackDecoder, self).__init__()

        self.drop_out = drop_out
        self.dropout_layer = nn.Dropout2d(p=0.5)

        ''' this is old version
        self.upSample = nn.Upsample(size=upsample_size, scale_factor=(2, 2), mode="bilinear")
        self.convr1 = ConvBnRelu(in_channels, out_channels, kernel_size=(3, 3), stride=1, padding=padding)
        # Crop + concat step between these 2
        self.convr2 = ConvBnRelu(in_channels, out_channels, kernel_size=(3, 3), stride=1, padding=padding)
        '''
        self.upSample = nn.ConvTranspose2d(in_channels, out_channels, 2, stride=2)
        self.convr1 = ConvBnRelu(in_channels, out_channels, kernel_size=(3, 3), stride=1, padding=padding)
        self.convr2 = ConvBnRelu(out_channels, out_channels, kernel_size=(3, 3), stride=1, padding=padding)

    def _crop_concat(self, upsampled, bypass):
        """
         Crop y to the (h, w) of x and concat them.
         Used for the expansive path.
        Returns:
            The concatenated tensor
        """
        c = (bypass.size()[2] - upsampled.size()[2]) // 2
        bypass = F.pad(bypass, (-c, -c, -c, -c))

        return torch.cat((bypass, upsampled), 1)

    def forward(self, x, down_tensor):
        '''old version
        x = self.upSample(x)
        x = self.convr1(x)
        x = self._crop_concat(x, down_tensor)
        x = self.convr2(x)
        '''

        x = self.upSample(x)
        x = self._crop_concat(x, down_tensor)
        x = self.convr1(x)
        if self.drop_out: x = self.dropout_layer(x)
        x = self.convr2(x)
        if self.drop_out: x = self.dropout_layer(x)
        return x


class UNET_CROP(nn.Module):
    def __init__(self):
        super(UNET_CROP, self).__init__()
        # channels, height, width = in_shape

        # self.dropout = dropout

        self.model_code = ""        # variable to save model and main function when loaded

        self.down1 = StackEncoder(1, 64)
        self.down2 = StackEncoder(64, 128)
        self.down3 = StackEncoder(128, 256)
        self.down4 = StackEncoder(256, 512)

        self.center = nn.Sequential(
            # nn.Dropout2d(p=0.2),
            ConvBnRelu(512, 1024, kernel_size=(3, 3), stride=1, padding=0),
            nn.Dropout2d(p=0.2),
            ConvBnRelu(1024, 1024, kernel_size=(3, 3), stride=1, padding=0),
            nn.Dropout2d(p=0.2)
        )

        self.up1 = StackDecoder(in_channels=1024, out_channels=512)
        self.up2 = StackDecoder(in_channels=512, out_channels=256)
        self.up3 = StackDecoder(in_channels=256, out_channels=128)
        self.up4 = StackDecoder(in_channels=128, out_channels=64)

        # 1x1 convolution at the last layer
        # Different from the paper is the output size here
        self.output_seg_map = nn.Conv2d(64, 1, kernel_size=(1, 1), padding=0, stride=1)

        self._initialize_weights()

    def forward(self, x):
        x, x_trace1 = self.down1(x)
        x, x_trace2 = self.down2(x)
        x, x_trace3 = self.down3(x)
        x, x_trace4 = self.down4(x)
        x = self.center(x)
        x = self.up1(x, x_trace4)
        x = self.up2(x, x_trace3)
        x = self.up3(x, x_trace2)
        x = self.up4(x, x_trace1)

        x = self.output_seg_map(x)
        # x = F.sigmoid(x)
        # out = torch.squeeze(out, dim=1)
        return x


    def _initialize_weights(self):
        for m in self.modules():
            if isinstance(m, nn.Conv2d):
                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels
                m.weight.data.normal_(0, math.sqrt(2. / n))
                if m.bias is not None:
                    m.bias.data.zero_()
            elif isinstance(m, nn.BatchNorm2d):
                m.weight.data.fill_(1)
                m.bias.data.zero_()

# x = Variable(torch.randn(1,1,700, 700))       # simulate input image
# net = UNET_CROP()
# out = net(x)
# print("input: ", x)
# print("output: ", out)
===============from __future__ import print_function, division
import torch
from torch import optim
from torch.autograd import Variable
from torch.utils.data import DataLoader
import numpy as np
import torch.nn as nn
import torch.nn.functional as F
import Unet_crop
import tifffile as tiff
import Utils
import time
from sklearn.metrics import average_precision_score, recall_score, f1_score
import Analysis_crop
import cv2

def to_var(x):
    if torch.cuda.is_available():
        return Variable(x.cuda())
    else:
        return Variable(x)

### BinaryCrossEntropyLoss2d().forward(logits, labels)
class BinaryCrossEntropyLoss2d(nn.Module):
    def __init__(self, weight=None, size_average=True):
        """
        Binary cross entropy loss 2D
        Args:
            weight:
            size_average:
        """
        super(BinaryCrossEntropyLoss2d, self).__init__()
        self.bce_loss = nn.BCELoss(weight, size_average)

    def forward(self, probs, targets):
        probs = F.sigmoid(probs)
        probs_flat = probs.view(-1)  # Flatten
        targets_flat = targets.view(-1)  # Flatten
        return self.bce_loss(probs_flat, targets_flat)      # (output, labels)

def NetEval(net,valdata_loader,crit):
    loss = 0.
    count = 0
    net.eval()
    crop_input, crop_label,_ = crop_info()
    for i,data in enumerate(valdata_loader,0):
        # if i > 10: break
        inputs, labels = data
        # inputs = inputs.numpy()
        # labels = labels.numpy()
        for j in range(len(crop_input)):  # training on the crop images and corresponding labels
            ci = crop_input[j]  # crop index for inputs
            cl = crop_label[j]  # crop index for lables
            # temp = labels[0, 0, :, :]  # labels is numpy array 512x512
            # if np.sum(temp) < 0.01 * np.shape(temp)[0] * np.shape(temp)[1]: break
            x = inputs.numpy()[:, :, ci[0]:ci[0] + 572, ci[1]:ci[1] + 572]
            y = labels.numpy()[:, :, cl[0]: cl[0] + 388, cl[1]:cl[1] + 388]
            x = torch.from_numpy(x)
            y = torch.from_numpy(y)
            x, y = to_var(x), to_var(y)
            out = net(x)
            l = crit(out, y)
            loss += l.data[0]
            count += 1
    return loss/count

#process the test data and save to separate .tif image
def NetTest(net,testdata_loader,path = "data/results/"):
    net.eval()
    crop_input, crop_label, average_mask = crop_info()
    for i, data in enumerate(testdata_loader, 0):
        if i >= 30: return 1        # for debug
        # data = to_var(data)
        img_shape = 512
        img = np.zeros((img_shape, img_shape))
        for j in range(len(crop_input)):  # training on the crop images and corresponding labels
            temp = np.zeros((img_shape, img_shape))
            ci = crop_input[j]  # crop index for inputs
            cl = crop_label[j]
            x = data.numpy()[:, :, ci[0]:ci[0] + 572, ci[1]:ci[1] + 572]
            x = torch.from_numpy(x)
            x = to_var(x)
            out = F.sigmoid(net(x))
            out = out.cpu()
            out = out[0,0,:,:]
            # print("j: ", j)
            # print("size of temp: ", np.shape(temp))
            # print("size of output: ", np.shape(out.data.numpy()))
            temp[cl[0]: cl[0] + 388, cl[1]:cl[1] + 388] = out.data.numpy()
            img += temp

        img = img/average_mask
        img = img.reshape(-1)
        img[img < 0.5] = 0; img[img >= 0.5] = 1
        img = img.reshape(img_shape, img_shape)
        img = np.uint8(img * 255)
        imgname = path + str(i) + ".tif"
        tiff.imsave(imgname, img)

# return input image size like 512x512, numpy array
def NetPredict(net, input_image):
    net.eval()
    _, crop_label, average_mask = crop_info()

    # input_image is grayscale input image of 512x512
    data = Utils.input_filled_mirroring(input_image, e = 94)
    imgdatas = np.ndarray((1, 1, data.shape[0], data.shape[1]), dtype=np.uint8)
    imgdatas[0] = np.expand_dims(data, 0)
    data = Utils.hist_equalization(imgdatas)
    data = data.astype('float32')
    data /= 255
    data -= data.mean(axis=0)

    img_shape = input_image.shape
    img = np.zeros((img_shape, img_shape))
    for j in range(len(crop_input)):  # training on the crop images and corresponding labels
        temp = np.zeros((img_shape, img_shape))
        ci = crop_input[j]  # crop index for inputs
        cl = crop_label[j]
        x = data.numpy()[:, :, ci[0]:ci[0] + 572, ci[1]:ci[1] + 572]
        x = torch.from_numpy(x)
        x = to_var(x)
        out = F.sigmoid(net(x))
        out = out.cpu()
        out = out[0, 0, :, :]
        temp[cl[0]: cl[0] + 388, cl[1]:cl[1] + 388] = out.data.numpy()
        img += temp

    img = img / average_mask
    img = img.reshape(-1)
    img[img < 0.5] = 0
    img[img >= 0.5] = 1
    img = img.reshape(img_shape)
    img = np.uint8(img * 255)
    return img


def write_2_log(content):
    path = "log_file.txt"
    output = open(path, "a")
    output.write("\n")
    output.write(content)
    output.close()

def crop_info():
    crop_input = [[0, 0], [128, 0], [0, 128], [128, 128]]
    crop_label = [[0, 0], [124, 0], [0, 124], [124, 124]]
    average_mask = np.ones((512, 512))
    average_mask[124:388, 0:124] = 2
    average_mask[0:124, 124:388] = 2
    average_mask[124:388, 388:512] = 2
    average_mask[388:512, 124:388] = 2
    average_mask[124:388, 124:388] = 4
    return crop_input, crop_label, average_mask

if __name__ == '__main__':
    '''subjects to change for each exp:
    + path to the dataset
    + opt function
    + leg description
    + N_epoch
    + saved_model
    '''
    start_begining = time.time()

    # path = "data/dataset"
    path = "/home/anhxtuan/HanLe/dataset/20aug_10ela_3inten_reflect"
    path = "/home/anhxtuan/HanLe/dataset/20aug_10ela_3inten_reflect_700"

    import os
    print("Does the folder exist?: ", os.path.isdir(path))
    print("Does the path exist?: ", os.path.exists(path))

    imgs_train, imgs_mask_train = Utils.load_train_data(npy_path=path)
    imgs_val, imgs_mask_val = Utils.load_val_data(npy_path=path)
    batch_size = 1
    trainset = zip(imgs_train, imgs_mask_train)
    trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,
                                              shuffle=True, num_workers=2)
    valset = zip(imgs_val, imgs_mask_val)
    valloader = torch.utils.data.DataLoader(valset, batch_size=batch_size,
                                              shuffle=False, num_workers=2)
    # net = Unet.UNet()                     # Unet 1
    # net = Unet_BatchNorm.UNet_BN()          # Unet 2 with batchNorm
    net = Unet_crop.UNET_CROP()

    f1 = open("Unet_crop.py", 'r')     # embede code into the model to be saved later
    f2 = open("UnetTrain_crop.py", 'r')
    f3 = open("Utils.py", 'r')
    model_notes = time.strftime("%c") + "\n" + f1.read() + "\n" + "==="*5 + f2.read() + "\n" + "==="*5 + f3.read()
    f1.close()
    f2.close()
    f3.close()

    criterion = BinaryCrossEntropyLoss2d()
    # criterion = SoftDiceLoss()
    # criterion = nn.BCELoss()

    if torch.cuda.is_available():
        # torch.set_default_tensor_type('torch.cuda.FloatTensor')
        # net.load_state_dict(torch.load("Unet2_model_12epoch_Leg12_droput_0_2_rmSigmoid_20aug_10ela_3inten_reflect"))
        net.cuda()
        # criterion.cuda()

    opt = optim.SGD(net.parameters(), lr=1e-2, momentum=0.99)       # subject to change
    # opt = optim.RMSprop(net.parameters(), lr=2e-4)
    # RMSprop[22](learning rate 0.001) with weight decay set to 0.001.
    # opt = optim.Adam(net.parameters(), lr=1e-3, weight_decay=1e-4)

    train_loss = []
    val_loss = []

    print("[epoch, #image] Loss")
    leg = "Leg22_CROP_dropout_0_2_rmSigmoid_20aug_10ela_3inten_reflect"
    print("Processing: ", leg)
    model_name = ""

    N_epoch = 6
    model_saved = np.arange(2,N_epoch+1,2)
    val_loss_min = 100

    write_2_log("==="*30)
    write_2_log(time.strftime("%c"))       # time, date of exp
    write_2_log(leg)
    write_2_log(model_notes)
    write_2_log(time.strftime("%c"))  # time, date of exp
    write_2_log(leg)
    write_2_log("optim.SGD(net.parameters(), lr=1e-2, momentum=0.99)")
    write_2_log("Number of epoch max: " + str(N_epoch))

    crop_input, crop_label,_ = crop_info()
    min_model_epoch = 0
    for epoch in range(N_epoch):
        running_loss = 0.0; count = 0
        net.train()
        for i, data in enumerate(trainloader, 0):
            # if i > 10: break

            inputs, labels = data
            temp = labels.numpy()
            for j in range(len(crop_input)):       # training on the crop images and corresponding labels
                ci = crop_input[j]          # crop index for inputs
                cl = crop_label[j]          # crop index for lables
                # temp = temp[0, 0, :, :]  # labels is numpy array 512x512
                # if np.sum(temp) < 0.01 * np.shape(temp)[0] * np.shape(temp)[1]: break
                x = inputs.numpy()[:, :, ci[0]:ci[0] + 572, ci[1]:ci[1] + 572]
                y = labels.numpy()[:, :, cl[0]: cl[0] + 388, cl[1]:cl[1] + 388]
                print("size of x: ", x.shape)
                print("size of y: ", y.shape)
                import matplotlib.pyplot as plt
                plt.subplot(131); plt.imshow(x[0,0,:,:], cmap='gray')
                plt.subplot(132); plt.imshow(x[0,0,94:478,94:478], cmap='gray')
                plt.subplot(133); plt.imshow(y[0,0,:,:], cmap='gray')
                plt.show()
                x = torch.from_numpy(x)
                y = torch.from_numpy(y)
                x, y = to_var(x), to_var(y)
                opt.zero_grad()
                out = net(x)
                loss = criterion(out, y)
                loss.backward()
                opt.step()
                running_loss += loss.data[0]
                count += 1

        net.eval()
        val_loss_temp = NetEval(net, valloader, criterion)
        if epoch > 0 and val_loss_temp < val_loss_min:        # save the model which has the lowest val_loss, ignore first epoch
            val_loss_min = val_loss_temp
            torch.save(net.state_dict(), "Unet2_model_" + leg + "_min_val_loss")  # save model
            min_model_epoch = epoch + 1

        disp = 'Epoch %d: Train loss: %.6f, Val loss: %.6f' % (epoch + 1, running_loss/count, val_loss_temp)
        write_2_log(disp)
        print(disp)
        val_loss.append(val_loss_temp)
        train_loss.append(running_loss/count); running_loss = 0.0

        if (epoch + 1) in model_saved or epoch == 0:        # save checkpoint
            model_name = "Unet2_model_" + str(epoch+1) + "epoch_" + leg
            torch.save(net.state_dict(), model_name)  # save model
            Analysis_crop.analysis(model_file = model_name, valloader = valloader)

    write_2_log("Best model at epoch: " + str(min_model_epoch))
    write_2_log("Total training time: " + str((time.time() - start_begining) / 3600.0))

    val_loss_file = "data/results" + "/val_loss_" + str(N_epoch) + "epoch_" + leg + ".npy"
    train_loss_file = "data/results" + "/training_loss_" + str(N_epoch) + "epoch_" + leg + ".npy"

    np.save(val_loss_file, val_loss)
    np.save(train_loss_file, train_loss)
    print("total processing time in seconds: ", time.time() - start_begining)
    print("total processing time in mins: ", (time.time() - start_begining) / 60.0)
    print("total processing time in hours: ", (time.time() - start_begining) / 3600.0)

    # Analysis.analysis(model_file="Unet2_model_" + leg + "_min_val_loss", valloader=valloader)

    Analysis_crop.PlotLoss(model_file = model_name, loss_train_path = train_loss_file, loss_val_path = val_loss_file, epoch_No = N_epoch)

    write_2_log(time.strftime("%c"))  # time, date of exp
===============
import numpy as np
import torch.nn as nn
import torch
import cv2
from lcn import LecunLCN

LCN_enable = False

def input_filled_mirroring(x, e = 62):      # fill missing data by mirroring the input image
    '''input size 636 --> output size 512'''
    w, h = x.shape
    #e = 62  # extra width on 1 edge
    y = np.zeros((h + e * 2, w + e * 2))
    y[e:h + e, e:w + e] = x
    y[e:e + h, 0:e] = np.flip(y[e:e + h, e:2 * e], 1)  # flip vertically
    y[e:e + h, e + w:2 * e + w] = np.flip(y[e:e + h, w:e + w], 1)  # flip vertically
    y[0:e, 0:2 * e + w] = np.flip(y[e:2 * e, 0:2 * e + w], 0)  # flip horizontally
    y[e + h:2 * e + h, 0:2 * e + w] = np.flip(y[h:e + h, 0:2 * e + w], 0)  # flip horizontally
    return y

def nearest_cells_distance(pos, img):
    # searching in 8 directions to find 2 nearest distances to neighbor cells
    curr_value = img[pos]
    w = img.shape[0];h = img.shape[1]
    count_detect = 0  # detect 2 nearest neighbors. break the search if count_detect = 2
    x, y = pos

    # print("w,h: ", (w, h))
    d1 = 9999999;d2 = 9999999;d3 = 9999999;d4 = 9999999
    d5 = 9999999;d6 = 9999999;d7 = 9999999;d8 = 9999999
    for i in range(1, max(w, h)):
        # (x+1, y), (x+1, y+1), (x+1, y-1),
        # (x, y+1), (x, y-1)
        # (x-1, y), (x-1,y+1), (x-1,y-1),
        if x + i < w:
            if img[(x + i, y)] != curr_value and d1 == 9999999:
                d1 = i; count_detect += 1
            if y + i < h:
                if img[(x + i, y + i)] != curr_value and d2 == 9999999:
                    d2 = i; count_detect += 1
            elif y - i >= 0:
                if img[(x + i, y - i)] != curr_value and d3 == 9999999:
                    d3 = i; count_detect += 1
        if y + i < h:
            if img[(x, y + i)] != curr_value and d4 == 9999999:
                d4 = i; count_detect += 1
        if y - i >= 0:
            if img[(x, y - i)] != curr_value and d5 == 9999999:
                d5 = i; count_detect += 1
        if x - i >= 0:
            if img[(x - i, y)] != curr_value and d6 == 9999999:
                d6 = i; count_detect += 1
            if y + i < h:
                if img[(x - i, y + i)] != curr_value and d7 == 9999999:
                    d7 = i; count_detect += 1
            elif y - i >= 0:
                if img[(x - i, y - i)] != curr_value and d8 == 9999999:
                    d8 = i; count_detect += 1
        if count_detect >= 2: break

    d = [d1, d2, d3, d4, d5, d6, d7, d8]
    min_index = np.argmin(d)
    dist1 = d[min_index]
    d.remove(dist1)
    min_index = np.argmin(d)
    dist2 = d[min_index]
    return dist1, dist2

def create_weight_map(imgs_mask):
        print('-' * 30)
        print('Creating weights for masks ...')
        print('-' * 30)
        weight_map = np.ndarray(
            (len(imgs_mask), 1, np.shape(imgs_mask)[2], np.shape(imgs_mask)[3]), dtype=np.float32)
        w_0 = 10; sigma = 4
        imgs_w, imgs_h = np.shape(imgs_mask)[2], np.shape(imgs_mask)[3]
        total_pixels = imgs_w*imgs_h
        import time
        start = time.time()
        for i in range(len(imgs_mask)):
            if i%10 == 0: print("Done processing: %d images, time passed: %.2f mins" % (i, (time.time() - start)/60.0))
            temp = imgs_mask[i,0,:,:]
            w_border = 1 - np.sum(temp)/total_pixels        # w_c of pixel on the border (black)
            for m in range(imgs_w):
                for n in range(imgs_h):
                    # loop through all pixel of the mask
                    d1,d2 = nearest_cells_distance((m,n), temp)
                    w_c = w_border
                    if temp[m,n] == 0: w_c = 1 - w_border
                    weight_map[i,0,m,n] = w_c*5 + w_0*np.exp(-(d1 + d2)**2/(2*sigma**2))
                    # print("w_0*np.exp(): ", w_0*np.exp(-(d1 + d2)**2/(2*sigma**2)))
                    # print("w_border: ", w_border)

        np.save('data/dataset/weight_map_train.npy', weight_map)

        return weight_map

def load_train_data(npy_path = "data/dataset", hist_equal = False):

    print('-' * 30)
    print('load train images...')

    imgs_train = np.load(npy_path + "/imgs_train.npy")
    imgs_mask_train = np.load(npy_path + "/imgs_mask_train.npy")

    if hist_equal: imgs_train = hist_equalization(imgs_train)

    # weight_map_train = np.load(npy_path + "/weight_map_train.npy")
    # weight_map_train = weight_map_train.astype('float32')

    imgs_train = imgs_train.astype('float32')
    imgs_mask_train = imgs_mask_train.astype('float32')

    if LCN_enable:
        imgs_train = imgs_train.astype('float64')
        imgs_train = LecunLCN(imgs_train, image_shape=imgs_train.shape).output.eval()
        imgs_train = imgs_train.astype('float32')

    if not LCN_enable: imgs_train /= 255

    imgs_train -= imgs_train.mean(axis=0)
    imgs_mask_train /= 255
    imgs_mask_train[imgs_mask_train > 0.5] = 1
    imgs_mask_train[imgs_mask_train <= 0.5] = 0

    # weight_map_train = create_weight_map(imgs_mask_train)

    print("Done loading traing data")
    print('-' * 30)
    return imgs_train, imgs_mask_train

def load_val_data(npy_path = "data/dataset", hist_equal = True):

    print('-' * 30)
    print('load validation images...')

    imgs_train = np.load(npy_path + "/imgs_val.npy")
    imgs_mask_train = np.load(npy_path + "/imgs_mask_val.npy")

    if hist_equal: imgs_train = hist_equalization(imgs_train)

    imgs_train = imgs_train.astype('float32')
    imgs_mask_train = imgs_mask_train.astype('float32')

    if LCN_enable:
        imgs_train = imgs_train.astype('float64')
        imgs_train = LecunLCN(imgs_train, image_shape=imgs_train.shape).output.eval()
        imgs_train = imgs_train.astype('float32')

    if not LCN_enable: imgs_train /= 255
    imgs_train -= imgs_train.mean(axis=0)
    imgs_mask_train /= 255
    imgs_mask_train[imgs_mask_train > 0.5] = 1
    imgs_mask_train[imgs_mask_train <= 0.5] = 0
    print("Done loading validation data")
    print('-' * 30)
    return imgs_train, imgs_mask_train

def load_test_data(npy_path = "data/dataset", hist_equal = True):

    print('-' * 30)
    print('load test images...')

    imgs_test = np.load(npy_path + "/imgs_test.npy")

    if hist_equal: imgs_test = hist_equalization(imgs_test)

    imgs_test = imgs_test.astype('float32')

    if LCN_enable:
        imgs_test = imgs_test.astype('float64')
        imgs_test = LecunLCN(imgs_test, image_shape=imgs_test.shape).output.eval()
        imgs_test = imgs_test.astype('float32')

    if not LCN_enable: imgs_test /= 255

    imgs_test -= imgs_test.mean(axis=0)

    print("Done loading test data")
    print('-' * 30)
    return imgs_test

def load_val_5imgs(npy_path = "data/dataset"):
    print('-' * 30)
    print('load train images...')

    imgs_train = np.load(npy_path + "/imgs_val_5imgs.npy")
    imgs_mask_train = np.load(npy_path + "/imgs_mask_val_5imgs.npy")

    # imgs_train = hist_equalization(imgs_train)

    imgs_train = imgs_train.astype('float64')
    imgs_mask_train = imgs_mask_train.astype('float64')

    if LCN_enable: imgs_train = LecunLCN(imgs_train, image_shape=imgs_train.shape).output.eval()

    if not LCN_enable: imgs_train /= 255

    mean = imgs_train.mean(axis=0)
    imgs_train -= mean


    imgs_mask_train /= 255
    imgs_mask_train[imgs_mask_train > 0.5] = 1
    imgs_mask_train[imgs_mask_train <= 0.5] = 0

    # weight_map_train = self.create_weight_map(imgs_mask_train)

    print("Done loading traing data")
    print('-' * 30)
    return imgs_train, imgs_mask_train

def hist_equalization(inputs):      # inputs are uint8, 0-255, Nx1x636x636
    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))
    output = inputs.copy()
    for i in range(len(inputs)):
        img = inputs[i, 0, :, :]
        # res = cv2.equalizeHist(img)
        res = clahe.apply(img)
        output[i,0,:,:] = res
    return output

### BinaryCrossEntropyLoss2d().forward(logits, labels)
class BinaryCrossEntropyLoss2d(nn.Module):
    def __init__(self, weight=None, size_average=True):
        """
        Binary cross entropy loss 2D
        Args:
            weight:
            size_average:
        """
        super(BinaryCrossEntropyLoss2d, self).__init__()
        self.bce_loss = nn.BCELoss(weight, size_average)

    def forward(self, logits, targets):
        # probs = F.sigmoid(logits)
        probs = logits
        probs_flat = probs.view(-1)  # Flatten
        targets_flat = targets.view(-1)  # Flatten
        return self.bce_loss(probs_flat, targets_flat)      # (output, labels)

class BCE_with_Weights(nn.Module):
    def __init__(self, weights=None):
        """
        Binary cross entropy loss 2D
        Args:
            weights:
        """
        super(BCE_with_Weights, self).__init__()
        self.weights = weights

    def forward(self, output, target):
        if self.weights is not None:
            loss = self.weights * (target * torch.log(output) + (1 - target) * torch.log(1 - output))
        else:
            loss = target * torch.log(output) + (1 - target) * torch.log(1 - output)

        return torch.neg(torch.mean(loss))

class LRN(nn.Module):       # input x is Torch tensor
    def __init__(self, local_size=1, alpha=1.0, beta=0.75, ACROSS_CHANNELS=False):      #LRN(local_size=5, alpha=0.0001, beta=0.75),
        super(LRN, self).__init__()
        self.ACROSS_CHANNELS = ACROSS_CHANNELS
        if self.ACROSS_CHANNELS:
            self.average = nn.AvgPool3d(kernel_size=(local_size, 1, 1),
                                        stride=1, padding=(int((local_size - 1.0) / 2), 0, 0))
        else:
            self.average = nn.AvgPool2d(kernel_size=local_size,
                                        stride=1, padding=int((local_size - 1.0) / 2))
        self.alpha = alpha
        self.beta = beta

    def forward(self, x):
        if self.ACROSS_CHANNELS:
            div = x.pow(2).unsqueeze(1)
            div = self.average(div).squeeze(1)
            div = div.mul(self.alpha).add(1.0).pow(self.beta)
        else:
            div = x.pow(2)
            div = self.average(div)
            div = div.mul(self.alpha).add(1.0).pow(self.beta)
        x = x.div(div)
        return x
Sat Nov 25 03:13:31 2017
Leg22_CROP_dropout_0_2_rmSigmoid_20aug_10ela_3inten_reflect
optim.SGD(net.parameters(), lr=1e-2, momentum=0.99)
Number of epoch max: 6
==========================================================================================
Sat Nov 25 03:18:25 2017
Leg22_CROP_dropout_0_2_rmSigmoid_20aug_10ela_3inten_reflect
Sat Nov 25 03:18:23 2017
import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.autograd import Variable
import math


class ConvBnRelu(nn.Module):
    def __init__(self, in_channels, out_channels, kernel_size, padding, stride):
        super(ConvBnRelu, self).__init__()
        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=kernel_size, padding=padding, stride=stride)
        self.bn = nn.BatchNorm2d(out_channels)
        self.relu = nn.ReLU()

    def forward(self, x):
        x = self.conv(x)
        # x = self.bn(x)
        x = self.relu(x)
        return x


class StackEncoder(nn.Module):
    def __init__(self, in_channels, out_channels):
        super(StackEncoder, self).__init__()
        self.convr1 = ConvBnRelu(in_channels, out_channels, kernel_size=(3, 3), stride=1, padding=0)
        self.convr2 = ConvBnRelu(out_channels, out_channels, kernel_size=(3, 3), stride=1, padding=0)
        self.maxPool = nn.MaxPool2d(kernel_size=(2, 2), stride=2)

    def forward(self, x):
        x = self.convr1(x)
        x = self.convr2(x)
        x_trace = x             # save x to use in concat in the Decoder path
        out = self.maxPool(x)
        return out, x_trace


class StackDecoder(nn.Module):
    def __init__(self, in_channels, out_channels, padding = 0, drop_out=False):
        super(StackDecoder, self).__init__()

        self.drop_out = drop_out
        self.dropout_layer = nn.Dropout2d(p=0.5)

        ''' this is old version
        self.upSample = nn.Upsample(size=upsample_size, scale_factor=(2, 2), mode="bilinear")
        self.convr1 = ConvBnRelu(in_channels, out_channels, kernel_size=(3, 3), stride=1, padding=padding)
        # Crop + concat step between these 2
        self.convr2 = ConvBnRelu(in_channels, out_channels, kernel_size=(3, 3), stride=1, padding=padding)
        '''
        self.upSample = nn.ConvTranspose2d(in_channels, out_channels, 2, stride=2)
        self.convr1 = ConvBnRelu(in_channels, out_channels, kernel_size=(3, 3), stride=1, padding=padding)
        self.convr2 = ConvBnRelu(out_channels, out_channels, kernel_size=(3, 3), stride=1, padding=padding)

    def _crop_concat(self, upsampled, bypass):
        """
         Crop y to the (h, w) of x and concat them.
         Used for the expansive path.
        Returns:
            The concatenated tensor
        """
        c = (bypass.size()[2] - upsampled.size()[2]) // 2
        bypass = F.pad(bypass, (-c, -c, -c, -c))

        return torch.cat((bypass, upsampled), 1)

    def forward(self, x, down_tensor):
        '''old version
        x = self.upSample(x)
        x = self.convr1(x)
        x = self._crop_concat(x, down_tensor)
        x = self.convr2(x)
        '''

        x = self.upSample(x)
        x = self._crop_concat(x, down_tensor)
        x = self.convr1(x)
        if self.drop_out: x = self.dropout_layer(x)
        x = self.convr2(x)
        if self.drop_out: x = self.dropout_layer(x)
        return x


class UNET_CROP(nn.Module):
    def __init__(self):
        super(UNET_CROP, self).__init__()
        # channels, height, width = in_shape

        # self.dropout = dropout

        self.model_code = ""        # variable to save model and main function when loaded

        self.down1 = StackEncoder(1, 64)
        self.down2 = StackEncoder(64, 128)
        self.down3 = StackEncoder(128, 256)
        self.down4 = StackEncoder(256, 512)

        self.center = nn.Sequential(
            # nn.Dropout2d(p=0.2),
            ConvBnRelu(512, 1024, kernel_size=(3, 3), stride=1, padding=0),
            nn.Dropout2d(p=0.2),
            ConvBnRelu(1024, 1024, kernel_size=(3, 3), stride=1, padding=0),
            nn.Dropout2d(p=0.2)
        )

        self.up1 = StackDecoder(in_channels=1024, out_channels=512)
        self.up2 = StackDecoder(in_channels=512, out_channels=256)
        self.up3 = StackDecoder(in_channels=256, out_channels=128)
        self.up4 = StackDecoder(in_channels=128, out_channels=64)

        # 1x1 convolution at the last layer
        # Different from the paper is the output size here
        self.output_seg_map = nn.Conv2d(64, 1, kernel_size=(1, 1), padding=0, stride=1)

        self._initialize_weights()

    def forward(self, x):
        x, x_trace1 = self.down1(x)
        x, x_trace2 = self.down2(x)
        x, x_trace3 = self.down3(x)
        x, x_trace4 = self.down4(x)
        x = self.center(x)
        x = self.up1(x, x_trace4)
        x = self.up2(x, x_trace3)
        x = self.up3(x, x_trace2)
        x = self.up4(x, x_trace1)

        x = self.output_seg_map(x)
        # x = F.sigmoid(x)
        # out = torch.squeeze(out, dim=1)
        return x


    def _initialize_weights(self):
        for m in self.modules():
            if isinstance(m, nn.Conv2d):
                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels
                m.weight.data.normal_(0, math.sqrt(2. / n))
                if m.bias is not None:
                    m.bias.data.zero_()
            elif isinstance(m, nn.BatchNorm2d):
                m.weight.data.fill_(1)
                m.bias.data.zero_()

# x = Variable(torch.randn(1,1,700, 700))       # simulate input image
# net = UNET_CROP()
# out = net(x)
# print("input: ", x)
# print("output: ", out)
===============from __future__ import print_function, division
import torch
from torch import optim
from torch.autograd import Variable
from torch.utils.data import DataLoader
import numpy as np
import torch.nn as nn
import torch.nn.functional as F
import Unet_crop
import tifffile as tiff
import Utils
import time
from sklearn.metrics import average_precision_score, recall_score, f1_score
import Analysis_crop
import cv2

def to_var(x):
    if torch.cuda.is_available():
        return Variable(x.cuda())
    else:
        return Variable(x)

### BinaryCrossEntropyLoss2d().forward(logits, labels)
class BinaryCrossEntropyLoss2d(nn.Module):
    def __init__(self, weight=None, size_average=True):
        """
        Binary cross entropy loss 2D
        Args:
            weight:
            size_average:
        """
        super(BinaryCrossEntropyLoss2d, self).__init__()
        self.bce_loss = nn.BCELoss(weight, size_average)

    def forward(self, probs, targets):
        probs = F.sigmoid(probs)
        probs_flat = probs.view(-1)  # Flatten
        targets_flat = targets.view(-1)  # Flatten
        return self.bce_loss(probs_flat, targets_flat)      # (output, labels)

def NetEval(net,valdata_loader,crit):
    loss = 0.
    count = 0
    net.eval()
    crop_input, crop_label,_ = crop_info()
    for i,data in enumerate(valdata_loader,0):
        # if i > 10: break
        inputs, labels = data
        # inputs = inputs.numpy()
        # labels = labels.numpy()
        for j in range(len(crop_input)):  # training on the crop images and corresponding labels
            ci = crop_input[j]  # crop index for inputs
            cl = crop_label[j]  # crop index for lables
            # temp = labels[0, 0, :, :]  # labels is numpy array 512x512
            # if np.sum(temp) < 0.01 * np.shape(temp)[0] * np.shape(temp)[1]: break
            x = inputs.numpy()[:, :, ci[0]:ci[0] + 572, ci[1]:ci[1] + 572]
            y = labels.numpy()[:, :, cl[0]: cl[0] + 388, cl[1]:cl[1] + 388]
            x = torch.from_numpy(x)
            y = torch.from_numpy(y)
            x, y = to_var(x), to_var(y)
            out = net(x)
            l = crit(out, y)
            loss += l.data[0]
            count += 1
    return loss/count

#process the test data and save to separate .tif image
def NetTest(net,testdata_loader,path = "data/results/"):
    net.eval()
    crop_input, crop_label, average_mask = crop_info()
    for i, data in enumerate(testdata_loader, 0):
        if i >= 30: return 1        # for debug
        # data = to_var(data)
        img_shape = 512
        img = np.zeros((img_shape, img_shape))
        for j in range(len(crop_input)):  # training on the crop images and corresponding labels
            temp = np.zeros((img_shape, img_shape))
            ci = crop_input[j]  # crop index for inputs
            cl = crop_label[j]
            x = data.numpy()[:, :, ci[0]:ci[0] + 572, ci[1]:ci[1] + 572]
            x = torch.from_numpy(x)
            x = to_var(x)
            out = F.sigmoid(net(x))
            out = out.cpu()
            out = out[0,0,:,:]
            # print("j: ", j)
            # print("size of temp: ", np.shape(temp))
            # print("size of output: ", np.shape(out.data.numpy()))
            temp[cl[0]: cl[0] + 388, cl[1]:cl[1] + 388] = out.data.numpy()
            img += temp

        img = img/average_mask
        img = img.reshape(-1)
        img[img < 0.5] = 0; img[img >= 0.5] = 1
        img = img.reshape(img_shape, img_shape)
        img = np.uint8(img * 255)
        imgname = path + str(i) + ".tif"
        tiff.imsave(imgname, img)

# return input image size like 512x512, numpy array
def NetPredict(net, input_image):
    net.eval()
    _, crop_label, average_mask = crop_info()

    # input_image is grayscale input image of 512x512
    data = Utils.input_filled_mirroring(input_image, e = 94)
    imgdatas = np.ndarray((1, 1, data.shape[0], data.shape[1]), dtype=np.uint8)
    imgdatas[0] = np.expand_dims(data, 0)
    data = Utils.hist_equalization(imgdatas)
    data = data.astype('float32')
    data /= 255
    data -= data.mean(axis=0)

    img_shape = input_image.shape
    img = np.zeros((img_shape, img_shape))
    for j in range(len(crop_input)):  # training on the crop images and corresponding labels
        temp = np.zeros((img_shape, img_shape))
        ci = crop_input[j]  # crop index for inputs
        cl = crop_label[j]
        x = data.numpy()[:, :, ci[0]:ci[0] + 572, ci[1]:ci[1] + 572]
        x = torch.from_numpy(x)
        x = to_var(x)
        out = F.sigmoid(net(x))
        out = out.cpu()
        out = out[0, 0, :, :]
        temp[cl[0]: cl[0] + 388, cl[1]:cl[1] + 388] = out.data.numpy()
        img += temp

    img = img / average_mask
    img = img.reshape(-1)
    img[img < 0.5] = 0
    img[img >= 0.5] = 1
    img = img.reshape(img_shape)
    img = np.uint8(img * 255)
    return img


def write_2_log(content):
    path = "log_file.txt"
    output = open(path, "a")
    output.write("\n")
    output.write(content)
    output.close()

def crop_info():
    crop_input = [[0, 0], [128, 0], [0, 128], [128, 128]]
    crop_label = [[0, 0], [124, 0], [0, 124], [124, 124]]
    average_mask = np.ones((512, 512))
    average_mask[124:388, 0:124] = 2
    average_mask[0:124, 124:388] = 2
    average_mask[124:388, 388:512] = 2
    average_mask[388:512, 124:388] = 2
    average_mask[124:388, 124:388] = 4
    return crop_input, crop_label, average_mask

if __name__ == '__main__':
    '''subjects to change for each exp:
    + path to the dataset
    + opt function
    + leg description
    + N_epoch
    + saved_model
    '''
    start_begining = time.time()

    # path = "data/dataset"
    path = "/home/anhxtuan/HanLe/dataset/20aug_10ela_3inten_reflect"
    path = "/home/anhxtuan/HanLe/dataset/20aug_10ela_3inten_reflect_700"

    import os
    print("Does the folder exist?: ", os.path.isdir(path))
    print("Does the path exist?: ", os.path.exists(path))

    imgs_train, imgs_mask_train = Utils.load_train_data(npy_path=path)
    imgs_val, imgs_mask_val = Utils.load_val_data(npy_path=path)
    batch_size = 1
    trainset = zip(imgs_train, imgs_mask_train)
    trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,
                                              shuffle=True, num_workers=2)
    valset = zip(imgs_val, imgs_mask_val)
    valloader = torch.utils.data.DataLoader(valset, batch_size=batch_size,
                                              shuffle=False, num_workers=2)
    # net = Unet.UNet()                     # Unet 1
    # net = Unet_BatchNorm.UNet_BN()          # Unet 2 with batchNorm
    net = Unet_crop.UNET_CROP()

    f1 = open("Unet_crop.py", 'r')     # embede code into the model to be saved later
    f2 = open("UnetTrain_crop.py", 'r')
    f3 = open("Utils.py", 'r')
    model_notes = time.strftime("%c") + "\n" + f1.read() + "\n" + "==="*5 + f2.read() + "\n" + "==="*5 + f3.read()
    f1.close()
    f2.close()
    f3.close()

    criterion = BinaryCrossEntropyLoss2d()
    # criterion = SoftDiceLoss()
    # criterion = nn.BCELoss()

    if torch.cuda.is_available():
        # torch.set_default_tensor_type('torch.cuda.FloatTensor')
        # net.load_state_dict(torch.load("Unet2_model_12epoch_Leg12_droput_0_2_rmSigmoid_20aug_10ela_3inten_reflect"))
        net.cuda()
        # criterion.cuda()

    opt = optim.SGD(net.parameters(), lr=1e-2, momentum=0.99)       # subject to change
    # opt = optim.RMSprop(net.parameters(), lr=2e-4)
    # RMSprop[22](learning rate 0.001) with weight decay set to 0.001.
    # opt = optim.Adam(net.parameters(), lr=1e-3, weight_decay=1e-4)

    train_loss = []
    val_loss = []

    print("[epoch, #image] Loss")
    leg = "Leg22_CROP_dropout_0_2_rmSigmoid_20aug_10ela_3inten_reflect"
    print("Processing: ", leg)
    model_name = ""

    N_epoch = 6
    model_saved = np.arange(2,N_epoch+1,2)
    val_loss_min = 100

    write_2_log("==="*30)
    write_2_log(time.strftime("%c"))       # time, date of exp
    write_2_log(leg)
    write_2_log(model_notes)
    write_2_log(time.strftime("%c"))  # time, date of exp
    write_2_log(leg)
    write_2_log("optim.SGD(net.parameters(), lr=1e-2, momentum=0.99)")
    write_2_log("Number of epoch max: " + str(N_epoch))

    crop_input, crop_label,_ = crop_info()
    min_model_epoch = 0
    for epoch in range(N_epoch):
        running_loss = 0.0; count = 0
        net.train()
        for i, data in enumerate(trainloader, 0):
            # if i > 10: break

            inputs, labels = data
            temp = labels.numpy()
            for j in range(len(crop_input)):       # training on the crop images and corresponding labels
                ci = crop_input[j]          # crop index for inputs
                cl = crop_label[j]          # crop index for lables
                # temp = temp[0, 0, :, :]  # labels is numpy array 512x512
                # if np.sum(temp) < 0.01 * np.shape(temp)[0] * np.shape(temp)[1]: break
                x = inputs.numpy()[:, :, ci[0]:ci[0] + 572, ci[1]:ci[1] + 572]
                y = labels.numpy()[:, :, cl[0]: cl[0] + 388, cl[1]:cl[1] + 388]
                print("size of x: ", x.shape)
                print("size of y: ", y.shape)
                import matplotlib.pyplot as plt
                plt.subplot(141); plt.imshow(inputs.numpy()[0,0,:,:], cmap='gray'); plt.title(str(j))
                plt.subplot(142); plt.imshow(x[0,0,:,:], cmap='gray')
                plt.subplot(143); plt.imshow(x[0,0,94:478,94:478], cmap='gray')
                plt.subplot(144); plt.imshow(y[0,0,:,:], cmap='gray')
                plt.show()
                x = torch.from_numpy(x)
                y = torch.from_numpy(y)
                x, y = to_var(x), to_var(y)
                opt.zero_grad()
                out = net(x)
                loss = criterion(out, y)
                loss.backward()
                opt.step()
                running_loss += loss.data[0]
                count += 1

        net.eval()
        val_loss_temp = NetEval(net, valloader, criterion)
        if epoch > 0 and val_loss_temp < val_loss_min:        # save the model which has the lowest val_loss, ignore first epoch
            val_loss_min = val_loss_temp
            torch.save(net.state_dict(), "Unet2_model_" + leg + "_min_val_loss")  # save model
            min_model_epoch = epoch + 1

        disp = 'Epoch %d: Train loss: %.6f, Val loss: %.6f' % (epoch + 1, running_loss/count, val_loss_temp)
        write_2_log(disp)
        print(disp)
        val_loss.append(val_loss_temp)
        train_loss.append(running_loss/count); running_loss = 0.0

        if (epoch + 1) in model_saved or epoch == 0:        # save checkpoint
            model_name = "Unet2_model_" + str(epoch+1) + "epoch_" + leg
            torch.save(net.state_dict(), model_name)  # save model
            Analysis_crop.analysis(model_file = model_name, valloader = valloader)

    write_2_log("Best model at epoch: " + str(min_model_epoch))
    write_2_log("Total training time: " + str((time.time() - start_begining) / 3600.0))

    val_loss_file = "data/results" + "/val_loss_" + str(N_epoch) + "epoch_" + leg + ".npy"
    train_loss_file = "data/results" + "/training_loss_" + str(N_epoch) + "epoch_" + leg + ".npy"

    np.save(val_loss_file, val_loss)
    np.save(train_loss_file, train_loss)
    print("total processing time in seconds: ", time.time() - start_begining)
    print("total processing time in mins: ", (time.time() - start_begining) / 60.0)
    print("total processing time in hours: ", (time.time() - start_begining) / 3600.0)

    # Analysis.analysis(model_file="Unet2_model_" + leg + "_min_val_loss", valloader=valloader)

    Analysis_crop.PlotLoss(model_file = model_name, loss_train_path = train_loss_file, loss_val_path = val_loss_file, epoch_No = N_epoch)

    write_2_log(time.strftime("%c"))  # time, date of exp
===============
import numpy as np
import torch.nn as nn
import torch
import cv2
from lcn import LecunLCN

LCN_enable = False

def input_filled_mirroring(x, e = 62):      # fill missing data by mirroring the input image
    '''input size 636 --> output size 512'''
    w, h = x.shape
    #e = 62  # extra width on 1 edge
    y = np.zeros((h + e * 2, w + e * 2))
    y[e:h + e, e:w + e] = x
    y[e:e + h, 0:e] = np.flip(y[e:e + h, e:2 * e], 1)  # flip vertically
    y[e:e + h, e + w:2 * e + w] = np.flip(y[e:e + h, w:e + w], 1)  # flip vertically
    y[0:e, 0:2 * e + w] = np.flip(y[e:2 * e, 0:2 * e + w], 0)  # flip horizontally
    y[e + h:2 * e + h, 0:2 * e + w] = np.flip(y[h:e + h, 0:2 * e + w], 0)  # flip horizontally
    return y

def nearest_cells_distance(pos, img):
    # searching in 8 directions to find 2 nearest distances to neighbor cells
    curr_value = img[pos]
    w = img.shape[0];h = img.shape[1]
    count_detect = 0  # detect 2 nearest neighbors. break the search if count_detect = 2
    x, y = pos

    # print("w,h: ", (w, h))
    d1 = 9999999;d2 = 9999999;d3 = 9999999;d4 = 9999999
    d5 = 9999999;d6 = 9999999;d7 = 9999999;d8 = 9999999
    for i in range(1, max(w, h)):
        # (x+1, y), (x+1, y+1), (x+1, y-1),
        # (x, y+1), (x, y-1)
        # (x-1, y), (x-1,y+1), (x-1,y-1),
        if x + i < w:
            if img[(x + i, y)] != curr_value and d1 == 9999999:
                d1 = i; count_detect += 1
            if y + i < h:
                if img[(x + i, y + i)] != curr_value and d2 == 9999999:
                    d2 = i; count_detect += 1
            elif y - i >= 0:
                if img[(x + i, y - i)] != curr_value and d3 == 9999999:
                    d3 = i; count_detect += 1
        if y + i < h:
            if img[(x, y + i)] != curr_value and d4 == 9999999:
                d4 = i; count_detect += 1
        if y - i >= 0:
            if img[(x, y - i)] != curr_value and d5 == 9999999:
                d5 = i; count_detect += 1
        if x - i >= 0:
            if img[(x - i, y)] != curr_value and d6 == 9999999:
                d6 = i; count_detect += 1
            if y + i < h:
                if img[(x - i, y + i)] != curr_value and d7 == 9999999:
                    d7 = i; count_detect += 1
            elif y - i >= 0:
                if img[(x - i, y - i)] != curr_value and d8 == 9999999:
                    d8 = i; count_detect += 1
        if count_detect >= 2: break

    d = [d1, d2, d3, d4, d5, d6, d7, d8]
    min_index = np.argmin(d)
    dist1 = d[min_index]
    d.remove(dist1)
    min_index = np.argmin(d)
    dist2 = d[min_index]
    return dist1, dist2

def create_weight_map(imgs_mask):
        print('-' * 30)
        print('Creating weights for masks ...')
        print('-' * 30)
        weight_map = np.ndarray(
            (len(imgs_mask), 1, np.shape(imgs_mask)[2], np.shape(imgs_mask)[3]), dtype=np.float32)
        w_0 = 10; sigma = 4
        imgs_w, imgs_h = np.shape(imgs_mask)[2], np.shape(imgs_mask)[3]
        total_pixels = imgs_w*imgs_h
        import time
        start = time.time()
        for i in range(len(imgs_mask)):
            if i%10 == 0: print("Done processing: %d images, time passed: %.2f mins" % (i, (time.time() - start)/60.0))
            temp = imgs_mask[i,0,:,:]
            w_border = 1 - np.sum(temp)/total_pixels        # w_c of pixel on the border (black)
            for m in range(imgs_w):
                for n in range(imgs_h):
                    # loop through all pixel of the mask
                    d1,d2 = nearest_cells_distance((m,n), temp)
                    w_c = w_border
                    if temp[m,n] == 0: w_c = 1 - w_border
                    weight_map[i,0,m,n] = w_c*5 + w_0*np.exp(-(d1 + d2)**2/(2*sigma**2))
                    # print("w_0*np.exp(): ", w_0*np.exp(-(d1 + d2)**2/(2*sigma**2)))
                    # print("w_border: ", w_border)

        np.save('data/dataset/weight_map_train.npy', weight_map)

        return weight_map

def load_train_data(npy_path = "data/dataset", hist_equal = False):

    print('-' * 30)
    print('load train images...')

    imgs_train = np.load(npy_path + "/imgs_train.npy")
    imgs_mask_train = np.load(npy_path + "/imgs_mask_train.npy")

    if hist_equal: imgs_train = hist_equalization(imgs_train)

    # weight_map_train = np.load(npy_path + "/weight_map_train.npy")
    # weight_map_train = weight_map_train.astype('float32')

    imgs_train = imgs_train.astype('float32')
    imgs_mask_train = imgs_mask_train.astype('float32')

    if LCN_enable:
        imgs_train = imgs_train.astype('float64')
        imgs_train = LecunLCN(imgs_train, image_shape=imgs_train.shape).output.eval()
        imgs_train = imgs_train.astype('float32')

    if not LCN_enable: imgs_train /= 255

    imgs_train -= imgs_train.mean(axis=0)
    imgs_mask_train /= 255
    imgs_mask_train[imgs_mask_train > 0.5] = 1
    imgs_mask_train[imgs_mask_train <= 0.5] = 0

    # weight_map_train = create_weight_map(imgs_mask_train)

    print("Done loading traing data")
    print('-' * 30)
    return imgs_train, imgs_mask_train

def load_val_data(npy_path = "data/dataset", hist_equal = True):

    print('-' * 30)
    print('load validation images...')

    imgs_train = np.load(npy_path + "/imgs_val.npy")
    imgs_mask_train = np.load(npy_path + "/imgs_mask_val.npy")

    if hist_equal: imgs_train = hist_equalization(imgs_train)

    imgs_train = imgs_train.astype('float32')
    imgs_mask_train = imgs_mask_train.astype('float32')

    if LCN_enable:
        imgs_train = imgs_train.astype('float64')
        imgs_train = LecunLCN(imgs_train, image_shape=imgs_train.shape).output.eval()
        imgs_train = imgs_train.astype('float32')

    if not LCN_enable: imgs_train /= 255
    imgs_train -= imgs_train.mean(axis=0)
    imgs_mask_train /= 255
    imgs_mask_train[imgs_mask_train > 0.5] = 1
    imgs_mask_train[imgs_mask_train <= 0.5] = 0
    print("Done loading validation data")
    print('-' * 30)
    return imgs_train, imgs_mask_train

def load_test_data(npy_path = "data/dataset", hist_equal = True):

    print('-' * 30)
    print('load test images...')

    imgs_test = np.load(npy_path + "/imgs_test.npy")

    if hist_equal: imgs_test = hist_equalization(imgs_test)

    imgs_test = imgs_test.astype('float32')

    if LCN_enable:
        imgs_test = imgs_test.astype('float64')
        imgs_test = LecunLCN(imgs_test, image_shape=imgs_test.shape).output.eval()
        imgs_test = imgs_test.astype('float32')

    if not LCN_enable: imgs_test /= 255

    imgs_test -= imgs_test.mean(axis=0)

    print("Done loading test data")
    print('-' * 30)
    return imgs_test

def load_val_5imgs(npy_path = "data/dataset"):
    print('-' * 30)
    print('load train images...')

    imgs_train = np.load(npy_path + "/imgs_val_5imgs.npy")
    imgs_mask_train = np.load(npy_path + "/imgs_mask_val_5imgs.npy")

    # imgs_train = hist_equalization(imgs_train)

    imgs_train = imgs_train.astype('float64')
    imgs_mask_train = imgs_mask_train.astype('float64')

    if LCN_enable: imgs_train = LecunLCN(imgs_train, image_shape=imgs_train.shape).output.eval()

    if not LCN_enable: imgs_train /= 255

    mean = imgs_train.mean(axis=0)
    imgs_train -= mean


    imgs_mask_train /= 255
    imgs_mask_train[imgs_mask_train > 0.5] = 1
    imgs_mask_train[imgs_mask_train <= 0.5] = 0

    # weight_map_train = self.create_weight_map(imgs_mask_train)

    print("Done loading traing data")
    print('-' * 30)
    return imgs_train, imgs_mask_train

def hist_equalization(inputs):      # inputs are uint8, 0-255, Nx1x636x636
    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))
    output = inputs.copy()
    for i in range(len(inputs)):
        img = inputs[i, 0, :, :]
        # res = cv2.equalizeHist(img)
        res = clahe.apply(img)
        output[i,0,:,:] = res
    return output

### BinaryCrossEntropyLoss2d().forward(logits, labels)
class BinaryCrossEntropyLoss2d(nn.Module):
    def __init__(self, weight=None, size_average=True):
        """
        Binary cross entropy loss 2D
        Args:
            weight:
            size_average:
        """
        super(BinaryCrossEntropyLoss2d, self).__init__()
        self.bce_loss = nn.BCELoss(weight, size_average)

    def forward(self, logits, targets):
        # probs = F.sigmoid(logits)
        probs = logits
        probs_flat = probs.view(-1)  # Flatten
        targets_flat = targets.view(-1)  # Flatten
        return self.bce_loss(probs_flat, targets_flat)      # (output, labels)

class BCE_with_Weights(nn.Module):
    def __init__(self, weights=None):
        """
        Binary cross entropy loss 2D
        Args:
            weights:
        """
        super(BCE_with_Weights, self).__init__()
        self.weights = weights

    def forward(self, output, target):
        if self.weights is not None:
            loss = self.weights * (target * torch.log(output) + (1 - target) * torch.log(1 - output))
        else:
            loss = target * torch.log(output) + (1 - target) * torch.log(1 - output)

        return torch.neg(torch.mean(loss))

class LRN(nn.Module):       # input x is Torch tensor
    def __init__(self, local_size=1, alpha=1.0, beta=0.75, ACROSS_CHANNELS=False):      #LRN(local_size=5, alpha=0.0001, beta=0.75),
        super(LRN, self).__init__()
        self.ACROSS_CHANNELS = ACROSS_CHANNELS
        if self.ACROSS_CHANNELS:
            self.average = nn.AvgPool3d(kernel_size=(local_size, 1, 1),
                                        stride=1, padding=(int((local_size - 1.0) / 2), 0, 0))
        else:
            self.average = nn.AvgPool2d(kernel_size=local_size,
                                        stride=1, padding=int((local_size - 1.0) / 2))
        self.alpha = alpha
        self.beta = beta

    def forward(self, x):
        if self.ACROSS_CHANNELS:
            div = x.pow(2).unsqueeze(1)
            div = self.average(div).squeeze(1)
            div = div.mul(self.alpha).add(1.0).pow(self.beta)
        else:
            div = x.pow(2)
            div = self.average(div)
            div = div.mul(self.alpha).add(1.0).pow(self.beta)
        x = x.div(div)
        return x
Sat Nov 25 03:18:25 2017
Leg22_CROP_dropout_0_2_rmSigmoid_20aug_10ela_3inten_reflect
optim.SGD(net.parameters(), lr=1e-2, momentum=0.99)
Number of epoch max: 6